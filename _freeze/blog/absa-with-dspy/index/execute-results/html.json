{
  "hash": "1bd0d04ebf52e2ec7de5e159aa0dc3e8",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Aspect-based Sentiment Analysis with DSPy\"\nauthor: \"Paul Simmering\"\ndate: \"2024-11-24\"\nbibliography: bibliography.bib  \ncategories: [\"Machine Learning\", \"Python\"]\nimage: \"image.webp\"\ncache: false\ntoc: true\nformat:\n    html:\n        mermaid: \n          theme: neutral\n---\n\n\n\n\nLast year, my colleague Paavo Huoviala and I explored prompting and fine-tuning large language models for aspect-based sentiment analysis (ABSA) [@simmering2023large]. Like many researchers at the time, we spent considerable effort manually crafting prompts and selecting few-shot examples. But what if we could automate this process? Enter DSPy - a Python library that automatically optimizes LLM prompts. In this article, I'll revisit our ABSA experiments using DSPy's automated approach instead of manual prompt engineering.\n\n| Resource | Link |\n|----------|------|\n| 💻 Code | [GitHub](https://github.com/psimm/website/blob/master/blog/absa-with-dspy/index.qmd) |\n| 📊 Experiments | [Weights & Biases project](https://wandb.ai/psimm/absa-dspy) |\n| 📝 Dataset | [Hugging Face Hub](https://huggingface.co/datasets/psimm/absa-semeval2014-alpaca) |\n\n\n::: {.callout-note collapse=\"true\"}\n## DSPy version 2.5.32\n\nDSPy is in rapid development. I've encountered outdated tutorials, dead links in the documentation and deprecation warnings. The code of this article may not work with future versions.\n:::\n\n## DSPy: Programming — not prompting — LLMs\n\n![](dspy_logo.webp){width=50%}\n\n[DSPy](https://dspy.ai) is a Python library developed by Stanford NLP. Rather than manually crafting prompts and seeing them break whenever something changes elsewhere in the pipeline, DSPy automates the process of finding the optimal prompts. The documentation has an [overview](https://dspy.ai/learn/) of the main building blocks of the library. In this article, I'll introduce the elements needed to optimize a structured prediction task, using ABSA as an example.\n\n### Experiment setup\n\n\n\n\n```{mermaid}\n%%{init: {\n  'theme': 'base',\n  'themeVariables': {\n    'primaryColor': '#ffffff',\n    'primaryTextColor': '#2d3748',\n    'primaryBorderColor': '#90cdf4',\n    'lineColor': '#64748b',\n    'secondaryColor': '#ffffff',\n    'tertiaryColor': '#ffffff',\n    'fontSize': '22px',\n    'labelFontSize': '18px',\n    'edgeLabelFontSize': '18px'\n  }\n}}%%\ngraph TB\n    %% Define styles\n    classDef default fill:#ffffff,stroke:#90cdf4,stroke-width:2px\n    classDef highlight fill:#fdf2f8,stroke:#ed64a6,stroke-width:3px\n    classDef api fill:#ffffff,stroke:#4fd1c5,stroke-width:2px\n    \n    subgraph Data [\"1️⃣ Data\"]\n        D1[SemEval Dataset] --> |\"Transform\"| D2[DSPy Examples]\n    end\n    \n    subgraph Definition [\"2️⃣ Model Definition\"]\n        M2[Pydantic Models] --> |\"Define Structure\"| M1[DSPy Signature]\n        M1 --> |\"Initialize\"| M3[Predictor]\n        M4[Language Models] --> |\"Power\"| M3\n        A1[OpenAI API] --> |\"Provide\"| M4\n        A2[Fireworks.ai API] --> |\"Provide\"| M4\n    end\n    \n    subgraph Optimization [\"3️⃣ Optimization\"]\n        O1[Evaluation Function] --> |\"Guide\"| O2[MIPROv2 Optimizer]\n        M3 --> |\"Optimize\"| O2\n        D2 --> |\"Train\"| O2\n        O2 --> |\"Output\"| O3[Optimized Predictor]\n    end\n    \n    subgraph Evaluation [\"4️⃣ Evaluation\"]\n        O3 --> |\"Test\"| E1[Test Set Evaluation]\n        O1 --> |\"Measure\"| E1\n        E1 --> |\"Log\"| E2[Weights & Biases]\n    end\n\n    %% Apply styles\n    class O2 highlight\n    class A1,A2,E2 api\n    \n    %% Links between subgraphs\n    linkStyle default stroke:#64748b,stroke-width:2px\n```\n\n\n\n\nThe steps will be explained in the following sections.\n\n## Dataset for Aspect-based Sentiment Analysis\n\nThe goal of ABSA is to analyze a review and extract the discussed aspects of a product or service and the sentiment towards each aspect. For example, the review \"The pizza was great, but the service was terrible\" contains two aspects: \"pizza\" (positive) and \"service\" (negative). There are more advanced variants of ABSA, but for this article I'll focus on the basic task. I will also let a single model handle the extraction and the classification.\n\n### SemEval 2014 Task 4\n\nI'm using the SemEval 2014 Task 4 dataset by @pontiki_semeval. The [dataset](https://huggingface.co/datasets/psimm/absa-semeval2014-alpaca) is available on Hugging Face. This is a cleaned version of the original XML files consisting of train and test splits. The small number of examples with the \"conflict\" label are excluded, as is common in the literature.\n\n::: {#3f3da0b7 .cell execution_count=1}\n``` {.python .cell-code}\nimport polars as pl\n\nurl = \"hf://datasets/psimm/absa-semeval2014-alpaca\"\n\ntrain = pl.read_parquet(url + \"/data/train-00000-of-00001.parquet\")\ntest = pl.read_parquet(url + \"/data/test-00000-of-00001.parquet\")\n```\n:::\n\n\n::: {#f81cb7c8 .cell execution_count=2}\n``` {.python .cell-code code-fold=\"true\"}\nfrom great_tables import GT\n\noverview = (\n    train.vstack(test)\n    .group_by([\"split\", \"domain\"])\n    .agg(examples=pl.len())\n    .sort(\"split\", \"domain\", descending=True)\n)\nGT(overview).tab_header(\"SemEval 2014 Task 4 Dataset\").cols_label(\n    split=\"Split\",\n    domain=\"Domain\",\n    examples=\"Examples\",\n).cols_align(align=\"right\", columns=[\"examples\"])\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n```{=html}\n<div id=\"fltaujneqw\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>\n#fltaujneqw table {\n          font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;\n          -webkit-font-smoothing: antialiased;\n          -moz-osx-font-smoothing: grayscale;\n        }\n\n#fltaujneqw thead, tbody, tfoot, tr, td, th { border-style: none; }\n tr { background-color: transparent; }\n#fltaujneqw p { margin: 0; padding: 0; }\n #fltaujneqw .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; }\n #fltaujneqw .gt_caption { padding-top: 4px; padding-bottom: 4px; }\n #fltaujneqw .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; }\n #fltaujneqw .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; }\n #fltaujneqw .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; }\n #fltaujneqw .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; }\n #fltaujneqw .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; }\n #fltaujneqw .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; }\n #fltaujneqw .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; }\n #fltaujneqw .gt_column_spanner_outer:first-child { padding-left: 0; }\n #fltaujneqw .gt_column_spanner_outer:last-child { padding-right: 0; }\n #fltaujneqw .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; }\n #fltaujneqw .gt_spanner_row { border-bottom-style: hidden; }\n #fltaujneqw .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; }\n #fltaujneqw .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; }\n #fltaujneqw .gt_from_md> :first-child { margin-top: 0; }\n #fltaujneqw .gt_from_md> :last-child { margin-bottom: 0; }\n #fltaujneqw .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; }\n #fltaujneqw .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; }\n #fltaujneqw .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; }\n #fltaujneqw .gt_row_group_first td { border-top-width: 2px; }\n #fltaujneqw .gt_row_group_first th { border-top-width: 2px; }\n #fltaujneqw .gt_striped { background-color: rgba(128,128,128,0.05); }\n #fltaujneqw .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; }\n #fltaujneqw .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; }\n #fltaujneqw .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; text-align: left; }\n #fltaujneqw .gt_left { text-align: left; }\n #fltaujneqw .gt_center { text-align: center; }\n #fltaujneqw .gt_right { text-align: right; font-variant-numeric: tabular-nums; }\n #fltaujneqw .gt_font_normal { font-weight: normal; }\n #fltaujneqw .gt_font_bold { font-weight: bold; }\n #fltaujneqw .gt_font_italic { font-style: italic; }\n #fltaujneqw .gt_super { font-size: 65%; }\n #fltaujneqw .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; }\n #fltaujneqw .gt_asterisk { font-size: 100%; vertical-align: 0; }\n \n</style>\n<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n<thead>\n\n  <tr class=\"gt_heading\">\n    <td colspan=\"3\" class=\"gt_heading gt_title gt_font_normal\">SemEval 2014 Task 4 Dataset</td>\n  </tr>\n<tr class=\"gt_col_headings\">\n  <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Split\">Split</th>\n  <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Domain\">Domain</th>\n  <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Examples\">Examples</th>\n</tr>\n</thead>\n<tbody class=\"gt_table_body\">\n  <tr>\n    <td class=\"gt_row gt_left\">train</td>\n    <td class=\"gt_row gt_left\">restaurants</td>\n    <td class=\"gt_row gt_right\">2957</td>\n  </tr>\n  <tr>\n    <td class=\"gt_row gt_left\">train</td>\n    <td class=\"gt_row gt_left\">laptops</td>\n    <td class=\"gt_row gt_right\">3002</td>\n  </tr>\n  <tr>\n    <td class=\"gt_row gt_left\">test</td>\n    <td class=\"gt_row gt_left\">restaurants</td>\n    <td class=\"gt_row gt_right\">786</td>\n  </tr>\n  <tr>\n    <td class=\"gt_row gt_left\">test</td>\n    <td class=\"gt_row gt_left\">laptops</td>\n    <td class=\"gt_row gt_right\">786</td>\n  </tr>\n</tbody>\n\n\n</table>\n\n</div>\n        \n```\n:::\n:::\n\n\nThe dataset contains a similar number of restaurant and laptop reviews.\n\nThe goal is to choose the optimal prompt and few-shot examples to maximize the F1 score of the aspect extraction and classification. To achieve this, DSPy needs to be able to evaluate the metrics and a training set to learn from.\n\n## Model Definition\n\n### Pydantic models for ABSA\n\nWe create classes to represent the input and output of the task using the data validation library [Pydantic](https://docs.pydantic.dev/latest/). This helps with validating the data and provides a structured output format for predictor. The `Field` class is used to describe the expected data type. Their descriptions match the ones used in [@simmering2023large]. This is a form of prompting, but DSPy also supports automatically setting the structure's descriptions using the [`optimize_signature`](https://dspy.ai/learn/8-typed_predictors/?h=typed#optimizing-typed-predictors) optimizer. In this experiment I'll stick with the original descriptions and only vary the normal prompt and few-shot examples.\n\n::: {#ad14c1b2 .cell execution_count=3}\n``` {.python .cell-code}\nfrom typing import Literal\nfrom pydantic import BaseModel, Field\n\n\nclass Input(BaseModel):\n    text: str = Field()\n\n\nclass Aspect(BaseModel):\n    term: str = Field(\n        description=\"An aspect term, which is a verbatim text snippet. Single or multiword terms naming particular aspects of the reviewed product or service.\"\n    )\n    polarity: Literal[\"positive\", \"neutral\", \"negative\"] = Field(\n        description=\"The polarity expressed towards the aspect term. Valid polarities are ‘positive’, ‘neutral’, ‘negative'.\"\n    )\n\n    def __hash__(self):\n        \"\"\"\n        Make the aspect hashable to enable set operations in evaluation.\n        Hash is case-insensitive.\n        \"\"\"\n        return hash((self.term.lower(), self.polarity.lower()))\n\n    def __eq__(self, other):\n        \"\"\"\n        Define equality for case-insensitive comparison.\n        \"\"\"\n        if not isinstance(other, Aspect):\n            return False\n        return (\n            self.term.lower() == other.term.lower()\n            and self.polarity.lower() == other.polarity.lower()\n        )\n\n\nclass Aspects(BaseModel):\n    aspects: list[Aspect] = Field(\n        description=\"An array of aspects and their polarities. If no aspects are mentioned in the text, use an empty array.\"\n    )\n```\n:::\n\n\nThe `__hash__` and `__eq__` methods will be helpful for evaluation, because they allow for use of set operations to compare gold and predicted aspects.\n\n### Transform dataset to DSPy examples\n\nEach row in the dataset needs to be turned into an instance of the `dspy.Example` class. The `with_inputs` method is used to tell DSPy which column contains the input. Other columns are used as expected model outputs.\n\n::: {#f44c58eb .cell execution_count=4}\n``` {.python .cell-code}\nimport json\nimport dspy\n\n\ndef to_example(row):\n    return dspy.Example(\n        text=row[\"input\"],\n        aspects=Aspects(aspects=json.loads(row[\"output\"])[\"aspects\"]),\n    ).with_inputs(\"text\")\n\n\ntrainset = [to_example(row) for row in train.to_dicts()]\ntestset = [to_example(row) for row in test.to_dicts()]\n```\n:::\n\n\nLet's look at the first example.\n\n::: {#09dd5344 .cell execution_count=5}\n``` {.python .cell-code}\ntrainset[0]\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```\nExample({'text': 'I charge it at night and skip taking the cord with me because of the good battery life.', 'aspects': Aspects(aspects=[Aspect(term='cord', polarity='neutral'), Aspect(term='battery life', polarity='positive')])}) (input_keys={'text'})\n```\n:::\n:::\n\n\n### Creating a DSPy typed predictor\n\nIn DSPy, a module is a language model and a way of prompting. They can also consist of multiple requests and also include external tools such as a vector database for retrieval augmented generation. In this example, we have a single request using few-shot examples and chain of thought.\n\nIn order to be able to parse the output as a dictionary, the LLM must output valid JSON. Therefore I'll use a [Typed Predictor](https://dspy.ai/learn/8-typed_predictors/?h=typed) in DSPy, which is similar to structured outputs via instructor or a similar library.\n\n::: {#a3cc5301 .cell execution_count=6}\n``` {.python .cell-code}\nclass AbsaSignature(dspy.Signature):\n    text: Input = dspy.InputField()\n    aspects: Aspects = dspy.OutputField()\n\n\npredictor = dspy.ChainOfThought(AbsaSignature)\n```\n:::\n\n\nWe also need to choose a language model. DSPy works with OpenAI, Anthropic, Ollama, vllm and other OpenAI-compatible platforms and libraries. This is powered by [litellm](https://github.com/BerriAI/litellm) under the hood.\n\nFor this article, I'll use OpenAI's gpt-4o-mini as well as the 70B version of Meta's Llama 3.1 hosted on [fireworks.ai](https://fireworks.ai). Fireworks.ai generously supplied me with credits as part of the [Mastering LLMs For Developers & Data Scientists](https://maven.com/parlance-labs/fine-tuning?utm_campaign=d45fef&utm_medium=partner&utm_source=instructor) course.\n\n::: {#27231850 .cell execution_count=7}\n``` {.python .cell-code}\n# FIREWORKS_AI_API_KEY environment variable must be set.\n\nlm = dspy.LM(\n    api_base=\"https://api.fireworks.ai/inference/v1/\",\n    model=\"fireworks_ai/accounts/fireworks/models/llama-v3p1-70b-instruct\",\n    temperature=0.0,  # best for structured outputs\n    cache=True,\n    max_tokens=250,\n)\ndspy.configure(lm=lm)\n```\n:::\n\n\n## Optimization\n\nLet's run a single example to check that everything is working.\n\n::: {#8bcb4a1e .cell execution_count=8}\n``` {.python .cell-code}\npredictor(text=\"The pizza was great, but the service was terrible\")\n```\n\n::: {.cell-output .cell-output-display execution_count=8}\n```\nPrediction(\n    rationale='We produce the aspects by identifying the terms \"pizza\" and \"service\" as aspects and determining their polarities based on the context. The term \"pizza\" is associated with the positive sentiment \"great\", while the term \"service\" is associated with the negative sentiment \"terrible\".',\n    aspects=Aspects(aspects=[Aspect(term='pizza', polarity='positive'), Aspect(term='service', polarity='negative')])\n)\n```\n:::\n:::\n\n\nThat's a good start. I'm a fan of [Hamel Husain's advice](https://hamel.dev/blog/posts/prompt/) to always demand: \"Show me the prompt\", so let's check what DSPy actually sent to OpenAI:\n\n::: {#7884caed .cell execution_count=9}\n``` {.python .cell-code}\nlm.inspect_history(n=1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\n\n\n[2024-11-27T08:47:57.615393]\n\nSystem message:\n\nYour input fields are:\n1. `text` (Input)\n\nYour output fields are:\n1. `rationale` (str): ${produce the aspects}. We ...\n2. `aspects` (Aspects)\n\nAll interactions will be structured in the following way, with the appropriate values filled in.\n\n[[ ## text ## ]]\n{text}\n\n[[ ## rationale ## ]]\n{rationale}\n\n[[ ## aspects ## ]]\n{aspects}        # note: the value you produce must be pareseable according to the following JSON schema: {\"type\": \"object\", \"$defs\": {\"Aspect\": {\"type\": \"object\", \"properties\": {\"polarity\": {\"type\": \"string\", \"description\": \"The polarity expressed towards the aspect term. Valid polarities are ‘positive’, ‘neutral’, ‘negative'.\", \"enum\": [\"positive\", \"neutral\", \"negative\"], \"title\": \"Polarity\"}, \"term\": {\"type\": \"string\", \"description\": \"An aspect term, which is a verbatim text snippet. Single or multiword terms naming particular aspects of the reviewed product or service.\", \"title\": \"Term\"}}, \"required\": [\"term\", \"polarity\"], \"title\": \"Aspect\"}}, \"properties\": {\"aspects\": {\"type\": \"array\", \"description\": \"An array of aspects and their polarities. If no aspects are mentioned in the text, use an empty array.\", \"items\": {\"$ref\": \"#/$defs/Aspect\"}, \"title\": \"Aspects\"}}, \"required\": [\"aspects\"], \"title\": \"Aspects\"}\n\n[[ ## completed ## ]]\n\nIn adhering to this structure, your objective is: \n        Given the fields `text`, produce the fields `aspects`.\n\n\nUser message:\n\n[[ ## text ## ]]\nThe pizza was great, but the service was terrible\n\nRespond with the corresponding output fields, starting with the field `[[ ## rationale ## ]]`, then `[[ ## aspects ## ]]` (must be formatted as a valid Python Aspects), and then ending with the marker for `[[ ## completed ## ]]`.\n\n\nResponse:\n\n[[ ## rationale ## ]]\nWe produce the aspects by identifying the terms \"pizza\" and \"service\" as aspects and determining their polarities based on the context. The term \"pizza\" is associated with the positive sentiment \"great\", while the term \"service\" is associated with the negative sentiment \"terrible\".\n\n[[ ## aspects ## ]]\n{\"aspects\": [{\"term\": \"pizza\", \"polarity\": \"positive\"}, {\"term\": \"service\", \"polarity\": \"negative\"}]}\n\n[[ ## completed ## ]]\n\n\n\n\n\n```\n:::\n:::\n\n\nVerbose but it works. It doesn't use function calling or a different way to get structured outputs, so there is some chance of getting an invalid JSON.\n\n### Specify the evaluation function\n\nAn evaluation function takes an example and a prediction and returns an F1 score. A true positive is a predicted aspect that is also in the gold answer, a false positive is a predicted aspect that is not in the gold answer, and a false negative is a gold answer aspect that is not predicted. Here are the precision, recall, and F1 score functions.\n\n::: {#8ef5a97a .cell execution_count=10}\n``` {.python .cell-code}\ndef precision(tp: int, fp: int) -> float:\n    # Handle division by zero\n    return 0.0 if tp + fp == 0 else tp / (tp + fp)\n\n\ndef recall(tp: int, fn: int) -> float:\n    return 0.0 if tp + fn == 0 else tp / (tp + fn)\n\n\ndef f1_score(tp: int, fp: int, fn: int) -> float:\n    prec = precision(tp, fp)\n    rec = recall(tp, fn)\n    return 0.0 if prec + rec == 0 else 2 * (prec * rec) / (prec + rec)\n```\n:::\n\n\nNext is the evaluation function which compares the gold and predicted aspects. To count as a true positive, both the term and the polarity have to be correct. As it is conventional on this benchmark, the case where both the gold answers and the prediction are empty is treated as a correct prediction of no aspects.\n\n::: {#5e7ebd83 .cell execution_count=11}\n``` {.python .cell-code}\ndef evaluate_absa(example: dspy.Example, prediction: Aspects, trace=None) -> float:\n    gold_aspects = set(example.aspects.aspects)\n    pred_aspects = set(prediction.aspects.aspects)\n\n    tp = len(gold_aspects & pred_aspects)\n    fp = len(pred_aspects - gold_aspects)\n    fn = len(gold_aspects - pred_aspects)\n\n    if len(gold_aspects) == 0 and len(pred_aspects) == 0:\n        tp += 1  # correct prediction of no aspects\n\n    return f1_score(tp, fp, fn)\n```\n:::\n\n\nLet's try the evaluation function with a single example. We expect the F1 score to be 1.0, because the prediction matches the gold answer exactly.\n\n::: {#602c772c .cell execution_count=12}\n``` {.python .cell-code}\nexample = dspy.Example(\n    text=\"The pizza was great, but the service was terrible\",\n    aspects=Aspects(\n        aspects=[\n            Aspect(term=\"pizza\", polarity=\"positive\"),\n            Aspect(term=\"service\", polarity=\"negative\"),\n        ]\n    ),\n).with_inputs(\"text\")\nprediction = predictor(text=example.text)\nevaluate_absa(example, prediction)\n```\n\n::: {.cell-output .cell-output-display execution_count=12}\n```\n1.0\n```\n:::\n:::\n\n\n### Optimizers\n\nDSPy has a variety of [optimizers](https://dspy.ai/learn/optimization/optimizers/?h=optimizers), loops that change the prompt and/or few-shot examples and evaluate the performance. They're analogous to optimizers like SGD and Adam in PyTorch. The choice of optimizer depends on the task, the amount of labeled data and the computational resources available. As we have a large labeled dataset, it's not necessary to have the model bootstrap artificial examples. Our 2023 paper found that fine-tuning yields the best results, but the goal of this article is to showcase DSPy's prompt optimization.\n\nThe most powerful optimizer available for a prompting approach for this task is [MIPROv2]([Multiprompt Instruction PRoposal Optimizer Version 2](https://dspy.ai/deep-dive/optimizers/miprov2/?h=miprov)) (Multiprompt Instruction PRoposal Optimizer Version 2) by @opsahlong2024optimizinginstructionsdemonstrationsmultistage. MIPROv2 uses Bayesian optimization to find an optimal combination of few-shot examples and prompt instructions.\n\n::: {#7801440e .cell execution_count=13}\n``` {.python .cell-code}\noptimizer_settings = dict(\n    metric=evaluate_absa,\n    num_threads=12,  # make parallel requests to Fireworks.ai\n    max_errors=1000,  # keep going even when invalid JSON is returned\n)\noptimizer = dspy.teleprompt.MIPROv2(**optimizer_settings)\n```\n:::\n\n\nThe final step is to call the `compile` method, which starts the optimization process. After about 5 minutes, the best prompt and few-shot examples are saved to a JSON file.\n\n::: {#868b79c0 .cell execution_count=14}\n``` {.python .cell-code}\n# Define settings for the comilation step of the optimizer.\ncompile_settings = dict(\n    minibatch_size=50,  # evaluate changes on a subset of the validation set\n    minibatch_full_eval_steps=10,  # evaluate on the full validation set after every 10 steps\n    max_labeled_demos=4,  # the number of few-shot examples to use\n    max_bootstrapped_demos=1,  # not required because we have labeled examples, but setting it to 0 causes an error during sampling\n    num_trials=3,  # how many combinations of few-shot examples and prompt instructions to try\n    seed=42,  # for reproducibility\n    requires_permission_to_run=False,  # skip confirmation dialog\n)\n```\n:::\n\n\nWe save the optimized predictor to a JSON file. It's a small config file listing the chosen few-shot examples and the optimized prompt.\n\n```python\noptimized_predictor = optimizer.compile(\n    student=predictor, trainset=trainset, **compile_settings\n)\noptimized_predictor.save(\"configs/absa_model.json\")\n```\n\nLet's check if we can load it again:\n\n::: {#a2496a19 .cell execution_count=15}\n``` {.python .cell-code}\noptimized_predictor = dspy.ChainOfThought(signature=AbsaSignature)\noptimized_predictor.load(path=\"configs/absa_model.json\")\n```\n:::\n\n\nAgain: \"Show me the prompt\".\n\n::: {#d485987e .cell execution_count=16}\n``` {.python .cell-code}\nprint(optimized_predictor.extended_signature.instructions)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nYou are a product reviewer tasked with analyzing customer feedback for laptops and netbooks. Given the fields `text`, which contains a customer review, produce the fields `aspects`, which should include the specific features or aspects of the laptop or netbook mentioned in the review, along with their corresponding sentiment or polarity.\n```\n:::\n:::\n\n\nand show me the chosen few-shot examples:\n\n::: {#7354e08f .cell execution_count=17}\n``` {.python .cell-code}\nfor demo in optimized_predictor.demos[:3]:  # first 3 examples\n    print(demo[\"text\"])\n    print(demo[\"aspects\"])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n-Called headquarters again, they report that TFT panel is broken, should be fixed by the end of the week (week 3).\n{\"aspects\":[{\"term\":\"TFT panel\",\"polarity\":\"negative\"}]}\nBut we had paid for bluetooth, and there was none.\n{\"aspects\":[{\"term\":\"bluetooth\",\"polarity\":\"negative\"}]}\nThe powerpoint opened seamlessly in the apple and the mac hooked up to the projector so easily it was almost scary.\n{\"aspects\":[{\"term\":\"powerpoint\",\"polarity\":\"positive\"}]}\n```\n:::\n:::\n\n\n## Evaluation\n\nSo far, we've only evaluated on the validation part of the training set (this was automatically done by DSPy). Let's evaluate the optimized predictor on the test set.\n\n::: {#d7aabd27 .cell execution_count=18}\n``` {.python .cell-code}\nevaluator = dspy.Evaluate(\n    devset=testset,\n    metric=evaluate_absa,\n    display_progress=True,\n    num_threads=12,\n)\n```\n:::\n\n\n::: {#bbcea2bb .cell execution_count=19}\n``` {.python .cell-code}\nscore = evaluator(optimized_predictor)\n```\n:::\n\n\nThe first run yields an F1 score of 47.6. That's rather poor, but the compiler settings only allow for 4 labeled examples and 1 bootstrapped example and only 3 trials.\n\n## Hyperparameter optimization\n\nWhat would happen if we changed the hyperparameters? Let's do a grid search over the number of few-shot examples and the number of trials, as well as try different models.\n\n::: {#3ed87875 .cell execution_count=20}\n``` {.python .cell-code}\nimport itertools\n\nmax_labeled_demos = [5, 10, 20, 40]\nnum_trials = [15, 30, 60]\nchain_of_thought = [True, False]\n\ndefault_lm_settings = dict(\n    temperature=0.0,  # best for structured outputs, no creativity needed\n    cache=True,\n    max_tokens=250,\n)\n\nlm_settings = [\n    {\n        \"model\": \"fireworks_ai/accounts/fireworks/models/llama-v3p1-70b-instruct\",\n        \"api_base\": \"https://api.fireworks.ai/inference/v1/\",\n        **default_lm_settings,\n    },\n    {\n        \"model\": \"gpt-4o-mini-2024-07-18\",\n        **default_lm_settings,\n    },\n]\n\ngrid = list(\n    itertools.product(max_labeled_demos, num_trials, chain_of_thought, lm_settings)\n)\n```\n:::\n\n\nThis results in a grid with 48 combinations. Next, we iterate over the grid, perform the optimization run and save the results to Weights & Biases.\n\n::: {#5a345e61 .cell execution_count=21}\n``` {.python .cell-code}\nimport os\nfrom copy import deepcopy\n\nimport wandb\nfrom tqdm import tqdm\n\nassert os.getenv(\"FIREWORKS_AI_API_KEY\") is not None, \"FIREWORKS_AI_API_KEY is not set.\"\nassert os.getenv(\"OPENAI_API_KEY\") is not None, \"OPENAI_API_KEY is not set.\"\n\nfor max_labeled_demos, num_trials, chain_of_thought, lm_settings in tqdm(grid):\n\n    # Generate a filename for the run\n    modelname = lm_settings[\"model\"].replace(\"/\", \"_\")\n    cot_name = \"cot\" if chain_of_thought else \"predict\"\n    run_name = f\"{modelname}_{max_labeled_demos}_{num_trials}_{cot_name}\"\n    filepath = \"configs/\" + run_name + \".json\"\n\n    if os.path.exists(filepath):\n        print(f\"Skipping {run_name} because it already exists.\")\n        continue\n    else:\n        print(f\"Running {run_name}.\")\n\n    # Create fresh copies of settings for this run\n    run_compile_settings = deepcopy(compile_settings)\n    run_optimizer_settings = deepcopy(optimizer_settings)\n\n    # Update settings\n    run_compile_settings[\"max_labeled_demos\"] = max_labeled_demos\n    run_compile_settings[\"num_trials\"] = num_trials\n\n    if chain_of_thought:\n        predictor = dspy.ChainOfThought(AbsaSignature)\n    else:\n        predictor = dspy.Predict(AbsaSignature)\n\n    # Do an optimization run and evaluate the resulting model\n    try:\n        dspy.configure(lm=dspy.LM(**lm_settings))\n        optimizer = dspy.teleprompt.MIPROv2(**run_optimizer_settings)\n        optimized_predictor = optimizer.compile(\n            student=predictor, trainset=trainset, **run_compile_settings\n        )\n        score = evaluator(optimized_predictor)\n    except Exception as e:\n        print(\n            f\"Failed run with settings: max_labeled_demos={max_labeled_demos}, \"\n            f\"num_trials={num_trials}, model={lm_settings['model']}\"\n        )\n        print(f\"Error: {str(e)}\")\n        continue\n\n    optimized_predictor.save(filepath)\n\n    # Log experiment to W&B\n    config = {\n        \"output_schema\": Aspects.model_json_schema(),\n        \"compile_settings\": run_compile_settings,\n        \"optimizer_settings\": run_optimizer_settings,\n        \"lm_settings\": lm_settings,\n    }\n\n    with wandb.init(project=\"absa-dspy\", config=config, name=run_name) as run:\n        wandb.log({\"f1\": score})\n        # Save config to artifact\n        artifact = wandb.Artifact(\n            name=f\"dspy_config_{run_name}\",\n            type=\"config\", \n            description=f\"Config file for {run_name}\"\n        )\n        artifact.add_file(filepath)\n        run.log_artifact(artifact)\n```\n:::\n\n\n## Comparison with manual prompts\n\nIn the 2023 paper, co-author and I manually crafted prompts and chose few-shot examples that, in our opinion, illustrated the task well. Inference was done using the OpenAI API and using function calling to ensure structured outputs. To make the comparison fair, we'll now use the same prompts within DSPy.\n\nThe manual prompts and few-shot examples are available on [Github](https://github.com/psimm/website/blob/master/blog/absa-with-dspy/configs/manual_prompt.json).\n\nThe models `gpt-4-0613` and `gpt-3.5-turbo-0613` that were used in the 2023 paper are no longer available on the OpenAI API. Therefore, we use the closest substitutes here.\n\n::: {#9befd245 .cell execution_count=22}\n``` {.python .cell-code}\nmodels = [\n    \"gpt-4o-2024-11-20\",  # similar to gpt-4-0613\n    \"gpt-3.5-turbo-0125\",  # similar to gpt-3.5-turbo-0613\n    \"gpt-4o-mini-2024-07-18\",  # reference\n]\n\nmanual_predictor = dspy.Predict(AbsaSignature)\nmanual_predictor.load(path=\"configs/manual_prompt.json\")\n\nfor model in models:\n    lm = dspy.LM(\n        model=model,\n        temperature=0,\n        cache=True,\n        max_tokens=250,\n    )\n    dspy.configure(lm=lm)\n    score = evaluator(manual_predictor)\n    runname = f\"{model}_manual_prompt\"\n\n    config = {\n        \"output_schema\": Aspects.model_json_schema(),\n        \"compile_settings\": {\n            \"max_labeled_demos\": len(manual_predictor.demos),\n            \"max_bootstrapped_demos\": 0,\n        },\n        \"lm_settings\": {\n            \"model\": model,\n        },\n    }\n\n    with wandb.init(project=\"absa-dspy\", name=runname, config=config) as run:\n        wandb.log({\"f1\": score})\n        # Save manual prompt to artifact\n        artifact = wandb.Artifact(\n            name=f\"dspy_config_{runname}\",\n            type=\"model\",\n            description=\"Manual prompt configuration\"\n        )\n        artifact.add_file(\"configs/manual_prompt.json\")\n        run.log_artifact(artifact)\n```\n:::\n\n\n## Results and discussion\n\nWe load the results from the Weights & Biases project and show the most relevant columns for a comparison of the runs.\n\n::: {#f10c6003 .cell execution_count=23}\n``` {.python .cell-code code-fold=\"true\"}\nimport wandb\n\napi = wandb.Api()\n# Get all runs from the project\nruns = api.runs(\"psimm/absa-dspy\")\n\n# Convert to DataFrame\nresults = []\nfor run in runs:\n    results.append(\n        {\n            \"run_name\": run.name,\n            \"model\": run.config[\"lm_settings\"][\"model\"],\n            \"max_demos\": run.config[\"compile_settings\"][\"max_labeled_demos\"],\n            \"max_bootstrapped_demos\": run.config[\"compile_settings\"][\n                \"max_bootstrapped_demos\"\n            ],\n            \"num_trials\": run.config.get(\"compile_settings\", {}).get(\n                \"num_trials\", None\n            ),\n            \"chain_of_thought\": run.config[\"chain_of_thought\"],\n            \"f1\": run.summary[\"f1\"],\n        }\n    )\n\nresults_df = pl.DataFrame(results)\n\ntable_df = (\n    results_df.with_columns(\n        method=pl.when(pl.col(\"run_name\").str.contains(\"manual\"))\n        .then(pl.lit(\"Manual (2023)\"))\n        .otherwise(pl.lit(\"DSPy\")),\n        model=pl.col(\"model\").str.replace(\n            \"fireworks_ai/accounts/fireworks/models/\", \"\"\n        ),\n        demos=pl.when(pl.col(\"max_bootstrapped_demos\") == 0)\n        .then(pl.col(\"max_demos\").cast(pl.Utf8))\n        .otherwise(\n            pl.col(\"max_demos\").cast(pl.Utf8)\n            + \" + \"\n            + pl.col(\"max_bootstrapped_demos\").cast(pl.Utf8)\n        ),\n        chain_of_thought=pl.when(pl.col(\"chain_of_thought\"))\n        .then(pl.lit(\"✅\"))\n        .otherwise(pl.lit(\"❌\")),\n    )\n    .sort(\"f1\", descending=True)\n    .select(\n        \"model\",\n        \"method\",\n        \"num_trials\",\n        \"demos\",\n        \"chain_of_thought\",\n        \"f1\",\n    )\n)\n\nGT(table_df).tab_header(\"SemEval 2014 Task 4 1+2 Few-Shot Predictors\").cols_label(\n    model=\"Model\",\n    method=\"Method\",\n    demos=\"Examples¹\",\n    num_trials=\"Trials\",\n    chain_of_thought=\"CoT\",\n    f1=\"F1\",\n).cols_align(align=\"right\", columns=[\"demos\", \"num_trials\", \"f1\"]).fmt_number(\n    columns=[\"f1\"], decimals=2\n).tab_source_note(\n    \"¹ Bootstrapped + labeled examples. Notes: Limited Llama 3.1 70B non-CoT runs due to API constraints. Manual prompt runs use 10 examples vs. 6 in original paper.\"\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=20}\n```{=html}\n<div id=\"lfuefcygyc\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>\n#lfuefcygyc table {\n          font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;\n          -webkit-font-smoothing: antialiased;\n          -moz-osx-font-smoothing: grayscale;\n        }\n\n#lfuefcygyc thead, tbody, tfoot, tr, td, th { border-style: none; }\n tr { background-color: transparent; }\n#lfuefcygyc p { margin: 0; padding: 0; }\n #lfuefcygyc .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; }\n #lfuefcygyc .gt_caption { padding-top: 4px; padding-bottom: 4px; }\n #lfuefcygyc .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; }\n #lfuefcygyc .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; }\n #lfuefcygyc .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; }\n #lfuefcygyc .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; }\n #lfuefcygyc .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; }\n #lfuefcygyc .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; }\n #lfuefcygyc .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; }\n #lfuefcygyc .gt_column_spanner_outer:first-child { padding-left: 0; }\n #lfuefcygyc .gt_column_spanner_outer:last-child { padding-right: 0; }\n #lfuefcygyc .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; }\n #lfuefcygyc .gt_spanner_row { border-bottom-style: hidden; }\n #lfuefcygyc .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; }\n #lfuefcygyc .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; }\n #lfuefcygyc .gt_from_md> :first-child { margin-top: 0; }\n #lfuefcygyc .gt_from_md> :last-child { margin-bottom: 0; }\n #lfuefcygyc .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; }\n #lfuefcygyc .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; }\n #lfuefcygyc .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; }\n #lfuefcygyc .gt_row_group_first td { border-top-width: 2px; }\n #lfuefcygyc .gt_row_group_first th { border-top-width: 2px; }\n #lfuefcygyc .gt_striped { background-color: rgba(128,128,128,0.05); }\n #lfuefcygyc .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; }\n #lfuefcygyc .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; }\n #lfuefcygyc .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; text-align: left; }\n #lfuefcygyc .gt_left { text-align: left; }\n #lfuefcygyc .gt_center { text-align: center; }\n #lfuefcygyc .gt_right { text-align: right; font-variant-numeric: tabular-nums; }\n #lfuefcygyc .gt_font_normal { font-weight: normal; }\n #lfuefcygyc .gt_font_bold { font-weight: bold; }\n #lfuefcygyc .gt_font_italic { font-style: italic; }\n #lfuefcygyc .gt_super { font-size: 65%; }\n #lfuefcygyc .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; }\n #lfuefcygyc .gt_asterisk { font-size: 100%; vertical-align: 0; }\n \n</style>\n<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n<thead>\n\n  <tr class=\"gt_heading\">\n    <td colspan=\"6\" class=\"gt_heading gt_title gt_font_normal\">SemEval 2014 Task 4 1+2 Few-Shot Predictors</td>\n  </tr>\n<tr class=\"gt_col_headings\">\n  <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Model\">Model</th>\n  <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Method\">Method</th>\n  <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Trials\">Trials</th>\n  <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Examples¹\">Examples¹</th>\n  <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"CoT\">CoT</th>\n  <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"F1\">F1</th>\n</tr>\n</thead>\n<tbody class=\"gt_table_body\">\n  <tr>\n    <td class=\"gt_row gt_left\">gpt-4o-2024-11-20</td>\n    <td class=\"gt_row gt_left\">Manual (2023)</td>\n    <td class=\"gt_row gt_right\">None</td>\n    <td class=\"gt_row gt_right\">10</td>\n    <td class=\"gt_row gt_left\">❌</td>\n    <td class=\"gt_row gt_right\">71.28</td>\n  </tr>\n  <tr>\n    <td class=\"gt_row gt_left\">gpt-4o-mini-2024-07-18</td>\n    <td class=\"gt_row gt_left\">DSPy</td>\n    <td class=\"gt_row gt_right\">15</td>\n    <td class=\"gt_row gt_right\">40 + 1</td>\n    <td class=\"gt_row gt_left\">❌</td>\n    <td class=\"gt_row gt_right\">62.83</td>\n  </tr>\n  <tr>\n    <td class=\"gt_row gt_left\">llama-v3p1-70b-instruct</td>\n    <td class=\"gt_row gt_left\">DSPy</td>\n    <td class=\"gt_row gt_right\">60</td>\n    <td class=\"gt_row gt_right\">5 + 1</td>\n    <td class=\"gt_row gt_left\">❌</td>\n    <td class=\"gt_row gt_right\">61.49</td>\n  </tr>\n  <tr>\n    <td class=\"gt_row gt_left\">gpt-4o-mini-2024-07-18</td>\n    <td class=\"gt_row gt_left\">DSPy</td>\n    <td class=\"gt_row gt_right\">60</td>\n    <td class=\"gt_row gt_right\">10 + 1</td>\n    <td class=\"gt_row gt_left\">❌</td>\n    <td class=\"gt_row gt_right\">61.34</td>\n  </tr>\n  <tr>\n    <td class=\"gt_row gt_left\">gpt-4o-mini-2024-07-18</td>\n    <td class=\"gt_row gt_left\">DSPy</td>\n    <td class=\"gt_row gt_right\">15</td>\n    <td class=\"gt_row gt_right\">20 + 1</td>\n    <td class=\"gt_row gt_left\">❌</td>\n    <td class=\"gt_row gt_right\">60.87</td>\n  </tr>\n  <tr>\n    <td class=\"gt_row gt_left\">gpt-4o-mini-2024-07-18</td>\n    <td class=\"gt_row gt_left\">DSPy</td>\n    <td class=\"gt_row gt_right\">30</td>\n    <td class=\"gt_row gt_right\">20 + 1</td>\n    <td class=\"gt_row gt_left\">❌</td>\n    <td class=\"gt_row gt_right\">60.87</td>\n  </tr>\n  <tr>\n    <td class=\"gt_row gt_left\">gpt-4o-mini-2024-07-18</td>\n    <td class=\"gt_row gt_left\">DSPy</td>\n    <td class=\"gt_row gt_right\">60</td>\n    <td class=\"gt_row gt_right\">20 + 1</td>\n    <td class=\"gt_row gt_left\">❌</td>\n    <td class=\"gt_row gt_right\">60.87</td>\n  </tr>\n  <tr>\n    <td class=\"gt_row gt_left\">llama-v3p1-70b-instruct</td>\n    <td class=\"gt_row gt_left\">DSPy</td>\n    <td class=\"gt_row gt_right\">15</td>\n    <td class=\"gt_row gt_right\">40 + 1</td>\n    <td class=\"gt_row gt_left\">❌</td>\n    <td class=\"gt_row gt_right\">60.32</td>\n  </tr>\n  <tr>\n    <td class=\"gt_row gt_left\">llama-v3p1-70b-instruct</td>\n    <td class=\"gt_row gt_left\">DSPy</td>\n    <td class=\"gt_row gt_right\">60</td>\n    <td class=\"gt_row gt_right\">5 + 1</td>\n    <td class=\"gt_row gt_left\">✅</td>\n    <td class=\"gt_row gt_right\">60.27</td>\n  </tr>\n  <tr>\n    <td class=\"gt_row gt_left\">gpt-4o-mini-2024-07-18</td>\n    <td class=\"gt_row gt_left\">DSPy</td>\n    <td class=\"gt_row gt_right\">60</td>\n    <td class=\"gt_row gt_right\">40 + 1</td>\n    <td class=\"gt_row gt_left\">✅</td>\n    <td class=\"gt_row gt_right\">59.80</td>\n  </tr>\n  <tr>\n    <td class=\"gt_row gt_left\">gpt-4o-mini-2024-07-18</td>\n    <td class=\"gt_row gt_left\">DSPy</td>\n    <td class=\"gt_row gt_right\">15</td>\n    <td class=\"gt_row gt_right\">20 + 1</td>\n    <td class=\"gt_row gt_left\">✅</td>\n    <td class=\"gt_row gt_right\">59.68</td>\n  </tr>\n  <tr>\n    <td class=\"gt_row gt_left\">gpt-4o-mini-2024-07-18</td>\n    <td class=\"gt_row gt_left\">DSPy</td>\n    <td class=\"gt_row gt_right\">30</td>\n    <td class=\"gt_row gt_right\">20 + 1</td>\n    <td class=\"gt_row gt_left\">✅</td>\n    <td class=\"gt_row gt_right\">59.68</td>\n  </tr>\n  <tr>\n    <td class=\"gt_row gt_left\">gpt-4o-mini-2024-07-18</td>\n    <td class=\"gt_row gt_left\">DSPy</td>\n    <td class=\"gt_row gt_right\">60</td>\n    <td class=\"gt_row gt_right\">20 + 1</td>\n    <td class=\"gt_row gt_left\">✅</td>\n    <td class=\"gt_row gt_right\">59.68</td>\n  </tr>\n  <tr>\n    <td class=\"gt_row gt_left\">gpt-4o-mini-2024-07-18</td>\n    <td class=\"gt_row gt_left\">DSPy</td>\n    <td class=\"gt_row gt_right\">30</td>\n    <td class=\"gt_row gt_right\">40 + 1</td>\n    <td class=\"gt_row gt_left\">✅</td>\n    <td class=\"gt_row gt_right\">59.60</td>\n  </tr>\n  <tr>\n    <td class=\"gt_row gt_left\">gpt-4o-mini-2024-07-18</td>\n    <td class=\"gt_row gt_left\">DSPy</td>\n    <td class=\"gt_row gt_right\">15</td>\n    <td class=\"gt_row gt_right\">40 + 1</td>\n    <td class=\"gt_row gt_left\">✅</td>\n    <td class=\"gt_row gt_right\">59.32</td>\n  </tr>\n  <tr>\n    <td class=\"gt_row gt_left\">gpt-4o-mini-2024-07-18</td>\n    <td class=\"gt_row gt_left\">DSPy</td>\n    <td class=\"gt_row gt_right\">60</td>\n    <td class=\"gt_row gt_right\">5 + 1</td>\n    <td class=\"gt_row gt_left\">❌</td>\n    <td class=\"gt_row gt_right\">58.83</td>\n  </tr>\n  <tr>\n    <td class=\"gt_row gt_left\">llama-v3p1-70b-instruct</td>\n    <td class=\"gt_row gt_left\">DSPy</td>\n    <td class=\"gt_row gt_right\">30</td>\n    <td class=\"gt_row gt_right\">10 + 1</td>\n    <td class=\"gt_row gt_left\">❌</td>\n    <td class=\"gt_row gt_right\">58.79</td>\n  </tr>\n  <tr>\n    <td class=\"gt_row gt_left\">llama-v3p1-70b-instruct</td>\n    <td class=\"gt_row gt_left\">DSPy</td>\n    <td class=\"gt_row gt_right\">60</td>\n    <td class=\"gt_row gt_right\">10 + 1</td>\n    <td class=\"gt_row gt_left\">❌</td>\n    <td class=\"gt_row gt_right\">58.79</td>\n  </tr>\n  <tr>\n    <td class=\"gt_row gt_left\">llama-v3p1-70b-instruct</td>\n    <td class=\"gt_row gt_left\">DSPy</td>\n    <td class=\"gt_row gt_right\">30</td>\n    <td class=\"gt_row gt_right\">5 + 1</td>\n    <td class=\"gt_row gt_left\">❌</td>\n    <td class=\"gt_row gt_right\">58.36</td>\n  </tr>\n  <tr>\n    <td class=\"gt_row gt_left\">llama-v3p1-70b-instruct</td>\n    <td class=\"gt_row gt_left\">DSPy</td>\n    <td class=\"gt_row gt_right\">60</td>\n    <td class=\"gt_row gt_right\">20 + 1</td>\n    <td class=\"gt_row gt_left\">❌</td>\n    <td class=\"gt_row gt_right\">57.98</td>\n  </tr>\n  <tr>\n    <td class=\"gt_row gt_left\">llama-v3p1-70b-instruct</td>\n    <td class=\"gt_row gt_left\">DSPy</td>\n    <td class=\"gt_row gt_right\">30</td>\n    <td class=\"gt_row gt_right\">20 + 1</td>\n    <td class=\"gt_row gt_left\">❌</td>\n    <td class=\"gt_row gt_right\">57.84</td>\n  </tr>\n  <tr>\n    <td class=\"gt_row gt_left\">gpt-3.5-turbo-0125</td>\n    <td class=\"gt_row gt_left\">Manual (2023)</td>\n    <td class=\"gt_row gt_right\">None</td>\n    <td class=\"gt_row gt_right\">10</td>\n    <td class=\"gt_row gt_left\">❌</td>\n    <td class=\"gt_row gt_right\">57.45</td>\n  </tr>\n  <tr>\n    <td class=\"gt_row gt_left\">llama-v3p1-70b-instruct</td>\n    <td class=\"gt_row gt_left\">DSPy</td>\n    <td class=\"gt_row gt_right\">60</td>\n    <td class=\"gt_row gt_right\">40 + 1</td>\n    <td class=\"gt_row gt_left\">✅</td>\n    <td class=\"gt_row gt_right\">56.46</td>\n  </tr>\n  <tr>\n    <td class=\"gt_row gt_left\">gpt-4o-mini-2024-07-18</td>\n    <td class=\"gt_row gt_left\">Manual (2023)</td>\n    <td class=\"gt_row gt_right\">None</td>\n    <td class=\"gt_row gt_right\">10</td>\n    <td class=\"gt_row gt_left\">❌</td>\n    <td class=\"gt_row gt_right\">55.67</td>\n  </tr>\n  <tr>\n    <td class=\"gt_row gt_left\">llama-v3p1-70b-instruct</td>\n    <td class=\"gt_row gt_left\">DSPy</td>\n    <td class=\"gt_row gt_right\">15</td>\n    <td class=\"gt_row gt_right\">20 + 1</td>\n    <td class=\"gt_row gt_left\">❌</td>\n    <td class=\"gt_row gt_right\">54.90</td>\n  </tr>\n  <tr>\n    <td class=\"gt_row gt_left\">llama-v3p1-70b-instruct</td>\n    <td class=\"gt_row gt_left\">DSPy</td>\n    <td class=\"gt_row gt_right\">60</td>\n    <td class=\"gt_row gt_right\">10 + 1</td>\n    <td class=\"gt_row gt_left\">✅</td>\n    <td class=\"gt_row gt_right\">54.33</td>\n  </tr>\n  <tr>\n    <td class=\"gt_row gt_left\">llama-v3p1-70b-instruct</td>\n    <td class=\"gt_row gt_left\">DSPy</td>\n    <td class=\"gt_row gt_right\">15</td>\n    <td class=\"gt_row gt_right\">40 + 1</td>\n    <td class=\"gt_row gt_left\">✅</td>\n    <td class=\"gt_row gt_right\">54.09</td>\n  </tr>\n  <tr>\n    <td class=\"gt_row gt_left\">llama-v3p1-70b-instruct</td>\n    <td class=\"gt_row gt_left\">DSPy</td>\n    <td class=\"gt_row gt_right\">30</td>\n    <td class=\"gt_row gt_right\">40 + 1</td>\n    <td class=\"gt_row gt_left\">✅</td>\n    <td class=\"gt_row gt_right\">54.09</td>\n  </tr>\n  <tr>\n    <td class=\"gt_row gt_left\">gpt-4o-mini-2024-07-18</td>\n    <td class=\"gt_row gt_left\">DSPy</td>\n    <td class=\"gt_row gt_right\">15</td>\n    <td class=\"gt_row gt_right\">5 + 1</td>\n    <td class=\"gt_row gt_left\">❌</td>\n    <td class=\"gt_row gt_right\">53.70</td>\n  </tr>\n  <tr>\n    <td class=\"gt_row gt_left\">gpt-4o-mini-2024-07-18</td>\n    <td class=\"gt_row gt_left\">DSPy</td>\n    <td class=\"gt_row gt_right\">30</td>\n    <td class=\"gt_row gt_right\">5 + 1</td>\n    <td class=\"gt_row gt_left\">❌</td>\n    <td class=\"gt_row gt_right\">53.70</td>\n  </tr>\n  <tr>\n    <td class=\"gt_row gt_left\">llama-v3p1-70b-instruct</td>\n    <td class=\"gt_row gt_left\">DSPy</td>\n    <td class=\"gt_row gt_right\">30</td>\n    <td class=\"gt_row gt_right\">5 + 1</td>\n    <td class=\"gt_row gt_left\">✅</td>\n    <td class=\"gt_row gt_right\">53.05</td>\n  </tr>\n  <tr>\n    <td class=\"gt_row gt_left\">gpt-4o-mini-2024-07-18</td>\n    <td class=\"gt_row gt_left\">DSPy</td>\n    <td class=\"gt_row gt_right\">60</td>\n    <td class=\"gt_row gt_right\">10 + 1</td>\n    <td class=\"gt_row gt_left\">✅</td>\n    <td class=\"gt_row gt_right\">52.64</td>\n  </tr>\n  <tr>\n    <td class=\"gt_row gt_left\">gpt-4o-mini-2024-07-18</td>\n    <td class=\"gt_row gt_left\">DSPy</td>\n    <td class=\"gt_row gt_right\">15</td>\n    <td class=\"gt_row gt_right\">10 + 1</td>\n    <td class=\"gt_row gt_left\">❌</td>\n    <td class=\"gt_row gt_right\">51.19</td>\n  </tr>\n  <tr>\n    <td class=\"gt_row gt_left\">gpt-4o-mini-2024-07-18</td>\n    <td class=\"gt_row gt_left\">DSPy</td>\n    <td class=\"gt_row gt_right\">30</td>\n    <td class=\"gt_row gt_right\">10 + 1</td>\n    <td class=\"gt_row gt_left\">❌</td>\n    <td class=\"gt_row gt_right\">51.19</td>\n  </tr>\n  <tr>\n    <td class=\"gt_row gt_left\">gpt-4o-mini-2024-07-18</td>\n    <td class=\"gt_row gt_left\">DSPy</td>\n    <td class=\"gt_row gt_right\">15</td>\n    <td class=\"gt_row gt_right\">5 + 1</td>\n    <td class=\"gt_row gt_left\">✅</td>\n    <td class=\"gt_row gt_right\">51.16</td>\n  </tr>\n  <tr>\n    <td class=\"gt_row gt_left\">gpt-4o-mini-2024-07-18</td>\n    <td class=\"gt_row gt_left\">DSPy</td>\n    <td class=\"gt_row gt_right\">30</td>\n    <td class=\"gt_row gt_right\">5 + 1</td>\n    <td class=\"gt_row gt_left\">✅</td>\n    <td class=\"gt_row gt_right\">51.16</td>\n  </tr>\n  <tr>\n    <td class=\"gt_row gt_left\">gpt-4o-mini-2024-07-18</td>\n    <td class=\"gt_row gt_left\">DSPy</td>\n    <td class=\"gt_row gt_right\">60</td>\n    <td class=\"gt_row gt_right\">5 + 1</td>\n    <td class=\"gt_row gt_left\">✅</td>\n    <td class=\"gt_row gt_right\">51.16</td>\n  </tr>\n  <tr>\n    <td class=\"gt_row gt_left\">llama-v3p1-70b-instruct</td>\n    <td class=\"gt_row gt_left\">DSPy</td>\n    <td class=\"gt_row gt_right\">30</td>\n    <td class=\"gt_row gt_right\">20 + 1</td>\n    <td class=\"gt_row gt_left\">✅</td>\n    <td class=\"gt_row gt_right\">50.90</td>\n  </tr>\n  <tr>\n    <td class=\"gt_row gt_left\">llama-v3p1-70b-instruct</td>\n    <td class=\"gt_row gt_left\">DSPy</td>\n    <td class=\"gt_row gt_right\">60</td>\n    <td class=\"gt_row gt_right\">20 + 1</td>\n    <td class=\"gt_row gt_left\">✅</td>\n    <td class=\"gt_row gt_right\">50.90</td>\n  </tr>\n  <tr>\n    <td class=\"gt_row gt_left\">gpt-4o-mini-2024-07-18</td>\n    <td class=\"gt_row gt_left\">DSPy</td>\n    <td class=\"gt_row gt_right\">30</td>\n    <td class=\"gt_row gt_right\">10 + 1</td>\n    <td class=\"gt_row gt_left\">✅</td>\n    <td class=\"gt_row gt_right\">49.97</td>\n  </tr>\n  <tr>\n    <td class=\"gt_row gt_left\">gpt-4o-mini-2024-07-18</td>\n    <td class=\"gt_row gt_left\">DSPy</td>\n    <td class=\"gt_row gt_right\">15</td>\n    <td class=\"gt_row gt_right\">10 + 1</td>\n    <td class=\"gt_row gt_left\">✅</td>\n    <td class=\"gt_row gt_right\">49.74</td>\n  </tr>\n  <tr>\n    <td class=\"gt_row gt_left\">llama-v3p1-70b-instruct</td>\n    <td class=\"gt_row gt_left\">DSPy</td>\n    <td class=\"gt_row gt_right\">15</td>\n    <td class=\"gt_row gt_right\">20 + 1</td>\n    <td class=\"gt_row gt_left\">✅</td>\n    <td class=\"gt_row gt_right\">49.47</td>\n  </tr>\n  <tr>\n    <td class=\"gt_row gt_left\">llama-v3p1-70b-instruct</td>\n    <td class=\"gt_row gt_left\">DSPy</td>\n    <td class=\"gt_row gt_right\">15</td>\n    <td class=\"gt_row gt_right\">10 + 1</td>\n    <td class=\"gt_row gt_left\">❌</td>\n    <td class=\"gt_row gt_right\">48.63</td>\n  </tr>\n  <tr>\n    <td class=\"gt_row gt_left\">llama-v3p1-70b-instruct</td>\n    <td class=\"gt_row gt_left\">DSPy</td>\n    <td class=\"gt_row gt_right\">15</td>\n    <td class=\"gt_row gt_right\">5 + 1</td>\n    <td class=\"gt_row gt_left\">✅</td>\n    <td class=\"gt_row gt_right\">47.73</td>\n  </tr>\n  <tr>\n    <td class=\"gt_row gt_left\">llama-v3p1-70b-instruct</td>\n    <td class=\"gt_row gt_left\">DSPy</td>\n    <td class=\"gt_row gt_right\">30</td>\n    <td class=\"gt_row gt_right\">10 + 1</td>\n    <td class=\"gt_row gt_left\">✅</td>\n    <td class=\"gt_row gt_right\">47.30</td>\n  </tr>\n  <tr>\n    <td class=\"gt_row gt_left\">llama-v3p1-70b-instruct</td>\n    <td class=\"gt_row gt_left\">DSPy</td>\n    <td class=\"gt_row gt_right\">15</td>\n    <td class=\"gt_row gt_right\">5 + 1</td>\n    <td class=\"gt_row gt_left\">❌</td>\n    <td class=\"gt_row gt_right\">46.46</td>\n  </tr>\n  <tr>\n    <td class=\"gt_row gt_left\">llama-v3p1-70b-instruct</td>\n    <td class=\"gt_row gt_left\">DSPy</td>\n    <td class=\"gt_row gt_right\">15</td>\n    <td class=\"gt_row gt_right\">10 + 1</td>\n    <td class=\"gt_row gt_left\">✅</td>\n    <td class=\"gt_row gt_right\">46.31</td>\n  </tr>\n</tbody>\n  <tfoot class=\"gt_sourcenotes\">\n  \n  <tr>\n    <td class=\"gt_sourcenote\" colspan=\"6\">¹ Bootstrapped + labeled examples. Notes: Limited Llama 3.1 70B non-CoT runs due to API constraints. Manual prompt runs use 10 examples vs. 6 in original paper.</td>\n  </tr>\n\n</tfoot>\n\n</table>\n\n</div>\n        \n```\n:::\n:::\n\n\n### Comparison to the 2023 manual prompts\n\nThe DSPy runs are competitive with the manually crafted prompts from the 2023 paper. In contrast to the manual prompt, DSPy instructions are relatively short and emphasize the use of few-shot examples to illustrate the task.\n\n### Impact of hyperparameters\n\nTo understand which factors significantly influence the F1 score, we'll run a simple linear regression analysis. The manual runs are excluded. To analyze the impact of the model choice, we'll create a boolean variable for `gpt-4o-mini` and treat `llama-v3p1-70b-instruct` as the baseline.\n\n::: {#99800e78 .cell execution_count=24}\n``` {.python .cell-code code-fold=\"true\"}\nimport statsmodels.api as sm\nimport pandas as pd\n\n# Prepare data for regression\nreg_df = results_df.filter(\n    ~pl.col(\"run_name\").str.contains(\"manual\"),\n    pl.col(\"model\").str.contains(\"gpt-4o-mini\") | pl.col(\"model\").str.contains(\"llama\"),\n).with_columns(  # exclude manual prompts\n    pl.col(\"model\").str.contains(\"gpt-4o-mini\").alias(\"is_gpt4_mini\"),\n)\n\n\n# Convert to pandas and ensure numeric types\nX = reg_df.select(\n    [\"max_demos\", \"chain_of_thought\", \"num_trials\", \"is_gpt4_mini\"]\n).to_pandas()\n\n# Convert boolean columns to int\nbool_columns = [\"chain_of_thought\", \"is_gpt4_mini\"]\nfor col in bool_columns:\n    X[col] = X[col].astype(int)\n\ny = reg_df.select(\"f1\").to_pandas()\n\n# Add constant for intercept\nX = sm.add_constant(X)\n\n# Fit regression\nmodel = sm.OLS(y, X).fit()\nn = len(reg_df)\nr2 = model.rsquared\n\n# Print results using GT\ndf = pd.DataFrame(\n    model.summary().tables[1],\n    columns=[\n        \"Parameter\",\n        \"Coefficient\",\n        \"Std Error\",\n        \"t\",\n        \"p>|t|\",\n        \"[0.025\",\n        \"0.975]\",\n    ],\n)\n\ndf = df.iloc[1:]  # remove row with repeated column names\n\nGT(df).tab_header(\n    title=\"Hyperparameter Analysis\", subtitle=\"Dependent variable: F1 score\"\n).cols_align(align=\"right\").tab_source_note(f\"n={n} runs, R²={r2:.2f}\")\n```\n\n::: {.cell-output .cell-output-display execution_count=21}\n```{=html}\n<div id=\"wuknesukxi\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>\n#wuknesukxi table {\n          font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;\n          -webkit-font-smoothing: antialiased;\n          -moz-osx-font-smoothing: grayscale;\n        }\n\n#wuknesukxi thead, tbody, tfoot, tr, td, th { border-style: none; }\n tr { background-color: transparent; }\n#wuknesukxi p { margin: 0; padding: 0; }\n #wuknesukxi .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; }\n #wuknesukxi .gt_caption { padding-top: 4px; padding-bottom: 4px; }\n #wuknesukxi .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; }\n #wuknesukxi .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; }\n #wuknesukxi .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; }\n #wuknesukxi .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; }\n #wuknesukxi .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; }\n #wuknesukxi .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; }\n #wuknesukxi .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; }\n #wuknesukxi .gt_column_spanner_outer:first-child { padding-left: 0; }\n #wuknesukxi .gt_column_spanner_outer:last-child { padding-right: 0; }\n #wuknesukxi .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; }\n #wuknesukxi .gt_spanner_row { border-bottom-style: hidden; }\n #wuknesukxi .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; }\n #wuknesukxi .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; }\n #wuknesukxi .gt_from_md> :first-child { margin-top: 0; }\n #wuknesukxi .gt_from_md> :last-child { margin-bottom: 0; }\n #wuknesukxi .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; }\n #wuknesukxi .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; }\n #wuknesukxi .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; }\n #wuknesukxi .gt_row_group_first td { border-top-width: 2px; }\n #wuknesukxi .gt_row_group_first th { border-top-width: 2px; }\n #wuknesukxi .gt_striped { background-color: rgba(128,128,128,0.05); }\n #wuknesukxi .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; }\n #wuknesukxi .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; }\n #wuknesukxi .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; text-align: left; }\n #wuknesukxi .gt_left { text-align: left; }\n #wuknesukxi .gt_center { text-align: center; }\n #wuknesukxi .gt_right { text-align: right; font-variant-numeric: tabular-nums; }\n #wuknesukxi .gt_font_normal { font-weight: normal; }\n #wuknesukxi .gt_font_bold { font-weight: bold; }\n #wuknesukxi .gt_font_italic { font-style: italic; }\n #wuknesukxi .gt_super { font-size: 65%; }\n #wuknesukxi .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; }\n #wuknesukxi .gt_asterisk { font-size: 100%; vertical-align: 0; }\n \n</style>\n<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n<thead>\n\n  <tr class=\"gt_heading\">\n    <td colspan=\"7\" class=\"gt_heading gt_title gt_font_normal\">Hyperparameter Analysis</td>\n  </tr>\n  <tr class=\"gt_heading\">\n    <td colspan=\"7\" class=\"gt_heading gt_subtitle gt_font_normal gt_bottom_border\">Dependent variable: F1 score</td>\n  </tr>\n<tr class=\"gt_col_headings\">\n  <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Parameter\">Parameter</th>\n  <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Coefficient\">Coefficient</th>\n  <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Std Error\">Std Error</th>\n  <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"t\">t</th>\n  <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"p&amp;gt;|t|\">p&gt;|t|</th>\n  <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"[0.025\">[0.025</th>\n  <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"0.975]\">0.975]</th>\n</tr>\n</thead>\n<tbody class=\"gt_table_body\">\n  <tr>\n    <td class=\"gt_row gt_right\">const</td>\n    <td class=\"gt_row gt_right\">   49.3654</td>\n    <td class=\"gt_row gt_right\">    1.457</td>\n    <td class=\"gt_row gt_right\">   33.885</td>\n    <td class=\"gt_row gt_right\"> 0.000</td>\n    <td class=\"gt_row gt_right\">   46.419</td>\n    <td class=\"gt_row gt_right\">   52.312</td>\n  </tr>\n  <tr>\n    <td class=\"gt_row gt_right\">max_demos</td>\n    <td class=\"gt_row gt_right\">    0.2021</td>\n    <td class=\"gt_row gt_right\">    0.042</td>\n    <td class=\"gt_row gt_right\">    4.794</td>\n    <td class=\"gt_row gt_right\"> 0.000</td>\n    <td class=\"gt_row gt_right\">    0.117</td>\n    <td class=\"gt_row gt_right\">    0.287</td>\n  </tr>\n  <tr>\n    <td class=\"gt_row gt_right\">chain_of_thought</td>\n    <td class=\"gt_row gt_right\">   -4.3317</td>\n    <td class=\"gt_row gt_right\">    1.038</td>\n    <td class=\"gt_row gt_right\">   -4.172</td>\n    <td class=\"gt_row gt_right\"> 0.000</td>\n    <td class=\"gt_row gt_right\">   -6.432</td>\n    <td class=\"gt_row gt_right\">   -2.232</td>\n  </tr>\n  <tr>\n    <td class=\"gt_row gt_right\">num_trials</td>\n    <td class=\"gt_row gt_right\">    0.1062</td>\n    <td class=\"gt_row gt_right\">    0.027</td>\n    <td class=\"gt_row gt_right\">    3.892</td>\n    <td class=\"gt_row gt_right\"> 0.000</td>\n    <td class=\"gt_row gt_right\">    0.051</td>\n    <td class=\"gt_row gt_right\">    0.161</td>\n  </tr>\n  <tr>\n    <td class=\"gt_row gt_right\">is_gpt4_mini</td>\n    <td class=\"gt_row gt_right\">    2.2964</td>\n    <td class=\"gt_row gt_right\">    1.016</td>\n    <td class=\"gt_row gt_right\">    2.260</td>\n    <td class=\"gt_row gt_right\"> 0.029</td>\n    <td class=\"gt_row gt_right\">    0.241</td>\n    <td class=\"gt_row gt_right\">    4.351</td>\n  </tr>\n</tbody>\n  <tfoot class=\"gt_sourcenotes\">\n  \n  <tr>\n    <td class=\"gt_sourcenote\" colspan=\"7\">n=44 runs, R²=0.56</td>\n  </tr>\n\n</tfoot>\n\n</table>\n\n</div>\n        \n```\n:::\n:::\n\n\n### Few-shot examples\n\nMore examples are generally better, as indicated by the positive coefficient in the regression. However, the top runs didn't use more than 20 examples, indicating that there are diminishing returns.\n\n### Chain of thought (CoT)\n\nRuns where the model was instructed to perform an intermediate reasoning step yielded worse results than those without. This is an unusual result - typically CoT helps LLMs achieve better results, for example the main advantage of OpenAI's `o1-preview` over `gpt-4o` is the advanced CoT that is built into it. However, on this structured task, CoT reasoning seems to be detrimental and a waste of output tokens.\n\n### Model choice\n\n- `gpt-4o-mini-2024-07-18` seems to have an edge over `llama-v3p1-70b-instruct`, but the confidence interval is wide.\n- `gpt-4o-2024-11-20` performs better than the other models that were tested. I expect that performance of similar sized models such as `Llama 3.1 405B` will be similar. Due to cost considerations, I've skipped the optimization of a large model with DSPy.\n- `gpt-3.5-turbo-0125` performed better than `gpt-4o-mini-2024-07-18`, but worse than the deprecated `gpt-3.5-turbo-0613` performed during the experiments for the 2023 paper (57.45 vs. 65.65 F1 Score).\n\n### Number of trials\n\nUsing more trials is associated with higher F1 scores. However, the table also shows setups with identical results at 15, 30 and 60 trials. Going beyond 60 trials isn't likely to be helpful.\n\n## Review of DSPy\n\nHere are my conclusions based on this experiment.\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n**Pros ✅**\n\n- Creates prompts that are as good as or better than manually crafted prompts.\n- No need to manually craft prompts, leading to faster iteration speed.\n- Able to deal with multi-step workflows.\n- Naturally encourages a structured approach focused on evaluation.\n- Supports many LLMs, via APIs and locally.\n- Lightweight JSON export of the optimized prompts.\n- Supports custom evaluation metrics.\n- Built-in threading and caching, which saved me time and money.\n- Actively developed and has a large community.\n- Lots of [tutorial notebooks](https://github.com/stanfordnlp/dspy/tree/main/examples).\n:::\n\n::: {.column width=\"50%\"}\n**Cons ❌**\n\n- Generated prompts seem too short to explain the nuances of the task, placing a lot of burden on the few-shot examples. They need to implicitly explain the annotation rules and cover all relevant cases.\n- Loss of control over the exact prompt. But arguably, if you want to control the prompt DSPy is not the approach to go for anyway.\n- Adds a layer of abstraction to a stack that's already complex.\n- Structured output is not guaranteed, because it's based on prompting only. Integration with function calling, JSON mode or constrained generation APIs and libraries would improve the reliability of the format.\n- Steep learning curve with many concepts to understand.\n- I encountered some bugs and deprecated functions and tutorials.\n:::\n\n::::\n\nDSPy is a great alternative to manual prompting, especially for tasks that have a clear evaluation metric and are demonstrable using few-shot examples. The high variability in the results of my grid search experiment indicates that it's necessary to run DSPy multiple times with different settings to find the best performing configuration.\n\nA feature that I haven't explored here is the fine-tuning [optimizer](https://dspy.ai/learn/optimization/optimizers/?h=fine#automatic-finetuning) of DSPy that actually modifies the model weights. It's promising for this task, as a fine-tuned `gpt-3.5-turbo-0613` is still the [record holder](https://paperswithcode.com/sota/aspect-based-sentiment-analysis-on-semeval-6) at an F1 score of 83.76.\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}