<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Paul Simmering&#39;s Blog</title>
<link>https://simmering.dev/</link>
<atom:link href="https://simmering.dev/index.xml" rel="self" type="application/rss+xml"/>
<description>Data science, machine learning and developer productivity.</description>
<language>en</language>
<generator>quarto-1.6.33</generator>
<lastBuildDate>Sat, 14 Dec 2024 23:00:00 GMT</lastBuildDate>
<item>
  <title>Type-safe LLM agents with PydanticAI</title>
  <dc:creator>Paul Simmering</dc:creator>
  <link>https://simmering.dev/blog/pydantic-ai/</link>
  <description><![CDATA[ 





<p>Pydantic AI is a new agent framework by the company behind Pydantic, the popular data validation library. Pydantic has transformed how I write Python, so I’m excited for their take on agents. In this article I’ll walk through an example app and comment on my experience developing with PydanticAI.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
PydanticAI version 0.0.12
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>PydanticAI is currently in beta. The assessment of the library in this article is based on version 0.0.12. Code examples may not work with future versions.</p>
</div>
</div>
</div>
<ul>
<li>currently supports OpenAI, Anthropic, Gemini, Ollama, Groq, Mistral and also has an interface to add more providers</li>
<li>type safe with structured responses including streamed responses</li>
<li>optional integration with <a href="https://pydantic.dev/logfire">Logfire</a>, a commercial service by the Pydantic team for logging LLM calls</li>
</ul>
<p>Type-safety is a big deal in agent development - the more tools an agent has at its disposal and the more complex their arguments are, the higher the risk of type errors.</p>
<section id="example-app-market-research-knowledge-manager" class="level2">
<h2 class="anchored" data-anchor-id="example-app-market-research-knowledge-manager">Example app: Market research knowledge manager</h2>
<p>Large companies conduct market research to understand their customers, competition and market trends. Over time, they amass a library of thousands of reports, tables and transcripts. Knowledge management becomes a challenge, because teams are not aware of existing research.</p>
<p>Let’s build an example agent that answers questions based on information in a database with multiple tables.</p>
<section id="database" class="level3">
<h3 class="anchored" data-anchor-id="database">Database</h3>
<p>I’m using <a href="https://duckdb.org">DuckDB</a> to create a local database which will be made available to the agent.</p>
<div id="bc29b192" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="annotated-cell-1" style="background: #f1f3f5;"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> duckdb</span>
<span id="annotated-cell-1-2"></span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-1" data-target-annotation="1">1</button><span id="annotated-cell-1-3" class="code-annotation-target">con <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> duckdb.<span class="ex" style="color: null;
background-color: null;
font-style: inherit;">connect</span>()</span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-1" data-target-annotation="2">2</button><span id="annotated-cell-1-4" class="code-annotation-target">con.execute(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"INSTALL vss"</span>)</span>
<span id="annotated-cell-1-5">con.execute(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"LOAD vss"</span>)</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-hidden code-annotation-container-grid">
<dt data-target-cell="annotated-cell-1" data-target-annotation="1">1</dt>
<dd>
<span data-code-cell="annotated-cell-1" data-code-lines="3" data-code-annotation="1">Create an ephemeral in-memory database. In production you’d want to use a persistent database.</span>
</dd>
<dt data-target-cell="annotated-cell-1" data-target-annotation="2">2</dt>
<dd>
<span data-code-cell="annotated-cell-1" data-code-lines="4" data-code-annotation="2">Install the vector similarity search extension, which will be needed for fuzzy title matching.</span>
</dd>
</dl>
</div>
<div class="cell-output cell-output-display" data-execution_count="29">
<pre><code>&lt;duckdb.duckdb.DuckDBPyConnection at 0x16838f870&gt;</code></pre>
</div>
</div>
<p>I’ll insert a set of reports into the database. The data included is fictional and was generated by an LLM. The data consists of 40 reports like this:</p>
<div id="4408ee14" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> polars <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pl</span>
<span id="cb2-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> great_tables <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> GT</span>
<span id="cb2-3"></span>
<span id="cb2-4">reports <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pl.read_csv(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"data/reports.csv"</span>)</span>
<span id="cb2-5">GT(reports.head(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>))</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="30">
<div id="ggtxmjgqhw" style="padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>
#ggtxmjgqhw table {
          font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;
          -webkit-font-smoothing: antialiased;
          -moz-osx-font-smoothing: grayscale;
        }

#ggtxmjgqhw thead, tbody, tfoot, tr, td, th { border-style: none; }
 tr { background-color: transparent; }
#ggtxmjgqhw p { margin: 0; padding: 0; }
 #ggtxmjgqhw .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; }
 #ggtxmjgqhw .gt_caption { padding-top: 4px; padding-bottom: 4px; }
 #ggtxmjgqhw .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; }
 #ggtxmjgqhw .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; }
 #ggtxmjgqhw .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; }
 #ggtxmjgqhw .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; }
 #ggtxmjgqhw .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; }
 #ggtxmjgqhw .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; }
 #ggtxmjgqhw .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; }
 #ggtxmjgqhw .gt_column_spanner_outer:first-child { padding-left: 0; }
 #ggtxmjgqhw .gt_column_spanner_outer:last-child { padding-right: 0; }
 #ggtxmjgqhw .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; }
 #ggtxmjgqhw .gt_spanner_row { border-bottom-style: hidden; }
 #ggtxmjgqhw .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; }
 #ggtxmjgqhw .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; }
 #ggtxmjgqhw .gt_from_md> :first-child { margin-top: 0; }
 #ggtxmjgqhw .gt_from_md> :last-child { margin-bottom: 0; }
 #ggtxmjgqhw .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; }
 #ggtxmjgqhw .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; }
 #ggtxmjgqhw .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; }
 #ggtxmjgqhw .gt_row_group_first td { border-top-width: 2px; }
 #ggtxmjgqhw .gt_row_group_first th { border-top-width: 2px; }
 #ggtxmjgqhw .gt_striped { background-color: rgba(128,128,128,0.05); }
 #ggtxmjgqhw .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; }
 #ggtxmjgqhw .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; }
 #ggtxmjgqhw .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; text-align: left; }
 #ggtxmjgqhw .gt_left { text-align: left; }
 #ggtxmjgqhw .gt_center { text-align: center; }
 #ggtxmjgqhw .gt_right { text-align: right; font-variant-numeric: tabular-nums; }
 #ggtxmjgqhw .gt_font_normal { font-weight: normal; }
 #ggtxmjgqhw .gt_font_bold { font-weight: bold; }
 #ggtxmjgqhw .gt_font_italic { font-style: italic; }
 #ggtxmjgqhw .gt_super { font-size: 65%; }
 #ggtxmjgqhw .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; }
 #ggtxmjgqhw .gt_asterisk { font-size: 100%; vertical-align: 0; }
 
</style>

<table class="gt_table caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-quarto-disable-processing="false" data-quarto-bootstrap="false">
<thead>
<tr class="gt_col_headings header">
<th id="id" class="gt_col_heading gt_columns_bottom_border gt_right" data-quarto-table-cell-role="th" scope="col">id</th>
<th id="date" class="gt_col_heading gt_columns_bottom_border gt_left" data-quarto-table-cell-role="th" scope="col">date</th>
<th id="institute" class="gt_col_heading gt_columns_bottom_border gt_left" data-quarto-table-cell-role="th" scope="col">institute</th>
<th id="country" class="gt_col_heading gt_columns_bottom_border gt_left" data-quarto-table-cell-role="th" scope="col">country</th>
<th id="topic" class="gt_col_heading gt_columns_bottom_border gt_left" data-quarto-table-cell-role="th" scope="col">topic</th>
<th id="title" class="gt_col_heading gt_columns_bottom_border gt_left" data-quarto-table-cell-role="th" scope="col">title</th>
</tr>
</thead>
<tbody class="gt_table_body">
<tr class="odd">
<td class="gt_row gt_right">1</td>
<td class="gt_row gt_left">2018-07-20</td>
<td class="gt_row gt_left">Research DNA GmbH</td>
<td class="gt_row gt_left">Germany</td>
<td class="gt_row gt_left">Automotive</td>
<td class="gt_row gt_left">Global Electric Vehicle Market Outlook 2018-2023</td>
</tr>
<tr class="even">
<td class="gt_row gt_right">2</td>
<td class="gt_row gt_left">2018-08-15</td>
<td class="gt_row gt_left">Market Insights Inc.</td>
<td class="gt_row gt_left">USA</td>
<td class="gt_row gt_left">Healthcare</td>
<td class="gt_row gt_left">Digital Health Market Size and Growth Analysis</td>
</tr>
<tr class="odd">
<td class="gt_row gt_right">3</td>
<td class="gt_row gt_left">2018-09-10</td>
<td class="gt_row gt_left">Global Trends Research</td>
<td class="gt_row gt_left">UK</td>
<td class="gt_row gt_left">FMCG</td>
<td class="gt_row gt_left">Premium Beauty and Personal Care Market Trends</td>
</tr>
<tr class="even">
<td class="gt_row gt_right">4</td>
<td class="gt_row gt_left">2018-10-05</td>
<td class="gt_row gt_left">Data Analytics Group</td>
<td class="gt_row gt_left">Canada</td>
<td class="gt_row gt_left">Electronics</td>
<td class="gt_row gt_left">Smartphone Industry Competitive Analysis</td>
</tr>
<tr class="odd">
<td class="gt_row gt_right">5</td>
<td class="gt_row gt_left">2018-11-12</td>
<td class="gt_row gt_left">Innovative Solutions Ltd.</td>
<td class="gt_row gt_left">Australia</td>
<td class="gt_row gt_left">Insurance</td>
<td class="gt_row gt_left">Insurtech Market Landscape and Opportunities</td>
</tr>
</tbody>
</table>


</div>
        
</div>
</div>
<p>To make the title searchable, I’ll embed it using an <a href="https://platform.openai.com/docs/guides/embeddings">OpenAI embedding endpoint</a>. The result will be stored in a new column with 1536 dimensions.</p>
<div id="9eb89b1f" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> openai <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> OpenAI</span>
<span id="cb3-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> tqdm <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> tqdm</span>
<span id="cb3-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pickle</span>
<span id="cb3-4"></span>
<span id="cb3-5"></span>
<span id="cb3-6"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> embed_text(text: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span>]:</span>
<span id="cb3-7">    client <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> OpenAI()</span>
<span id="cb3-8">    model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"text-embedding-3-small"</span></span>
<span id="cb3-9">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> client.embeddings.create(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">input</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>text, model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>model).data[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].embedding</span>
<span id="cb3-10"></span>
<span id="cb3-11"></span>
<span id="cb3-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Load cache</span></span>
<span id="cb3-13"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">try</span>:</span>
<span id="cb3-14">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">open</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"title_embeddings_cache.pkl"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"rb"</span>) <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> f:</span>
<span id="cb3-15">        cache <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pickle.load(f)</span>
<span id="cb3-16"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">except</span> <span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">FileNotFoundError</span>:</span>
<span id="cb3-17">    cache <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {}</span>
<span id="cb3-18"></span>
<span id="cb3-19"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Embed titles with caching</span></span>
<span id="cb3-20">title_embeddings <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb3-21"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> title <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> tqdm(reports[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"title"</span>]):</span>
<span id="cb3-22">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> title <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> cache:</span>
<span id="cb3-23">        cache[title] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> embed_text(title)</span>
<span id="cb3-24">    title_embeddings.append(cache[title])</span>
<span id="cb3-25"></span>
<span id="cb3-26"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Save cache</span></span>
<span id="cb3-27"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">open</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"title_embeddings_cache.pkl"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"wb"</span>) <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> f:</span>
<span id="cb3-28">    pickle.dump(cache, f)</span>
<span id="cb3-29"></span>
<span id="cb3-30">reports <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> reports.with_columns(</span>
<span id="cb3-31">    pl.Series(</span>
<span id="cb3-32">        name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"title_embedding"</span>,</span>
<span id="cb3-33">        values<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>title_embeddings,</span>
<span id="cb3-34">        dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>pl.Array(inner<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>pl.Float64, shape<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1536</span>),</span>
<span id="cb3-35">    )</span>
<span id="cb3-36">)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>  0%|          | 0/40 [00:00&lt;?, ?it/s]100%|██████████| 40/40 [00:00&lt;00:00, 476625.45it/s]</code></pre>
</div>
</div>
<p>Now, I’ll insert the data including the embeddings into the database. The embeddings are stored in a fixed-size <code>ARRAY</code> column. The co-location of the structured data and the embeddings in the same table is convenient for our use case.</p>
<div id="cb224c72" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="annotated-cell-4" style="background: #f1f3f5;"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-4-1">con.execute(</span>
<span id="annotated-cell-4-2">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="annotated-cell-4-3"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    CREATE OR REPLACE TABLE reports AS</span></span>
<span id="annotated-cell-4-4"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    SELECT</span></span>
<span id="annotated-cell-4-5"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        id::varchar AS id,</span></span>
<span id="annotated-cell-4-6"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        date::date AS date,</span></span>
<span id="annotated-cell-4-7"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        institute::varchar AS institute,</span></span>
<span id="annotated-cell-4-8"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        country::varchar AS country,</span></span>
<span id="annotated-cell-4-9"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        topic::varchar AS topic,</span></span>
<span id="annotated-cell-4-10"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        title::varchar AS title,</span></span>
<span id="annotated-cell-4-11"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        title_embedding::float[1536] AS title_embedding</span></span>
<span id="annotated-cell-4-12"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    FROM reports;</span></span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-4" data-target-annotation="1">1</button><span id="annotated-cell-4-13" class="code-annotation-target"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="annotated-cell-4-14">)</span>
<span id="annotated-cell-4-15"></span>
<span id="annotated-cell-4-16">con.execute(</span>
<span id="annotated-cell-4-17">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"CREATE INDEX titles_hnsw_index ON reports USING HNSW(title_embedding) WITH (metric='cosine');"</span></span>
<span id="annotated-cell-4-18">)</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-hidden code-annotation-container-grid">
<dt data-target-cell="annotated-cell-4" data-target-annotation="1">1</dt>
<dd>
<span data-code-cell="annotated-cell-4" data-code-lines="13" data-code-annotation="1">This works because DuckDB can read from a Polars DataFrame.</span>
</dd>
</dl>
</div>
<div class="cell-output cell-output-display" data-execution_count="32">
<pre><code>&lt;duckdb.duckdb.DuckDBPyConnection at 0x16838f870&gt;</code></pre>
</div>
</div>
<p>I also create a hierarchical navigable small world (HNSW) index on the title embeddings. This enables approximate nearest neighbor search with logarithmic complexity. It’s enabled by the <a href="https://duckdb.org/docs/extensions/vss">vss</a> extension.</p>
</section>
<section id="agent" class="level3">
<h3 class="anchored" data-anchor-id="agent">Agent</h3>
<p>Let’s set up an agent powered by the <a href="https://groq.com">Groq</a> inference API. It serves a range of open source models. Specifically, I’ll use the <code>llama-3.3-70b-versatile</code> model released by Meta on December 6th. Artificial Analysis has a detailed <a href="https://artificialanalysis.ai/models/llama-3-3-instruct-70b/providers">report</a> showing that it advanced the speed-accuracy trade-off. The model has tool calling capabilities, which are critical for our use case.</p>
<div id="4f7c8cf7" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="annotated-cell-5" style="background: #f1f3f5;"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-5-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pydantic_ai <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Agent</span>
<span id="annotated-cell-5-2"></span>
<span id="annotated-cell-5-3">agent <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Agent(</span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-5" data-target-annotation="1">1</button><span id="annotated-cell-5-4" class="code-annotation-target">    model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"groq:llama-3.3-70b-versatile"</span>,</span>
<span id="annotated-cell-5-5">    system_prompt<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"You are a market research expert and answer questions using a database of reports."</span>,</span>
<span id="annotated-cell-5-6">)</span>
<span id="annotated-cell-5-7"></span>
<span id="annotated-cell-5-8">result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> agent.run_sync(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Who are you?"</span>)</span>
<span id="annotated-cell-5-9"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(result.data)</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-hidden code-annotation-container-grid">
<dt data-target-cell="annotated-cell-5" data-target-annotation="1">1</dt>
<dd>
<span data-code-cell="annotated-cell-5" data-code-lines="4" data-code-annotation="1">See the <a href="https://ai.pydantic.dev/api/models/base/#pydantic_ai.models.KnownModelName">KnownModelName</a> documentation for a list of supported models.</span>
</dd>
</dl>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>I am a market research expert, providing insights and answers based on a vast database of reports and studies. My expertise spans various industries, markets, and trends, allowing me to offer data-driven responses to your questions. Whether you're looking for information on consumer behavior, market size, competitive analysis, or emerging trends, I'm here to help. What would you like to know?</code></pre>
</div>
</div>
<p>Let’s add tools to the agent. First, it needs a way to access the database.</p>
<div id="85e7b4b2" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="annotated-cell-6" style="background: #f1f3f5;"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-6-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> dataclasses <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> dataclass</span>
<span id="annotated-cell-6-2"></span>
<span id="annotated-cell-6-3"></span>
<span id="annotated-cell-6-4"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@dataclass</span></span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-6" data-target-annotation="1">1</button><span id="annotated-cell-6-5" class="code-annotation-target"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> SupportDependencies:</span>
<span id="annotated-cell-6-6">    db: duckdb.DuckDBPyConnection</span>
<span id="annotated-cell-6-7"></span>
<span id="annotated-cell-6-8"></span>
<span id="annotated-cell-6-9">deps <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> SupportDependencies(db<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>con)</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-hidden code-annotation-container-grid">
<dt data-target-cell="annotated-cell-6" data-target-annotation="1">1</dt>
<dd>
<span data-code-cell="annotated-cell-6" data-code-lines="5" data-code-annotation="1">A dataclass that contains dependencies needed by the agent.</span>
</dd>
</dl>
</div>
</div>
<p>Next, let’s give the agent a tool to search the database of reports. Based on the user’s question, it can choose which field to search. The result is always a markdown-formatted table with one row per report.</p>
<div id="3400e2ba" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="annotated-cell-7" style="background: #f1f3f5;"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-7-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> typing <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Literal</span>
<span id="annotated-cell-7-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pydantic_ai <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> RunContext</span>
<span id="annotated-cell-7-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pydantic <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> validate_call, Field</span>
<span id="annotated-cell-7-4"></span>
<span id="annotated-cell-7-5"></span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-7" data-target-annotation="1">1</button><span id="annotated-cell-7-6" class="code-annotation-target"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@agent.tool</span></span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-7" data-target-annotation="2">2</button><span id="annotated-cell-7-7" class="code-annotation-target"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@validate_call</span>(config<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>{<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"arbitrary_types_allowed"</span>: <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>})</span>
<span id="annotated-cell-7-8"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> search_reports_by_field(</span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-7" data-target-annotation="3">3</button><span id="annotated-cell-7-9" class="code-annotation-target">    ctx: RunContext[SupportDependencies],</span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-7" data-target-annotation="4">4</button><span id="annotated-cell-7-10" class="code-annotation-target">    field: Literal[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"id"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"date"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"institute"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"country"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"topic"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"title"</span>],</span>
<span id="annotated-cell-7-11">    value: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Field(</span>
<span id="annotated-cell-7-12">        description<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"The value to search for in the field. Case insensitive."</span></span>
<span id="annotated-cell-7-13">    ),</span>
<span id="annotated-cell-7-14">) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>:</span>
<span id="annotated-cell-7-15">    query <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"SELECT date, institute, country, topic, title FROM reports WHERE lower(</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>field<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">) = lower(?)"</span></span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-7" data-target-annotation="5">5</button><span id="annotated-cell-7-16" class="code-annotation-target">    df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ctx.deps.db.execute(query, [value]).df()</span>
<span id="annotated-cell-7-17">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> df.shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>:</span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-7" data-target-annotation="6">6</button><span id="annotated-cell-7-18" class="code-annotation-target">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"No reports found."</span></span>
<span id="annotated-cell-7-19">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> df.to_markdown()</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-hidden code-annotation-container-grid">
<dt data-target-cell="annotated-cell-7" data-target-annotation="1">1</dt>
<dd>
<span data-code-cell="annotated-cell-7" data-code-lines="6" data-code-annotation="1">Use the <code>@agent.tool</code> decorator to register the function as a tool.</span>
</dd>
<dt data-target-cell="annotated-cell-7" data-target-annotation="2">2</dt>
<dd>
<span data-code-cell="annotated-cell-7" data-code-lines="7" data-code-annotation="2">Use the <code>@validate_call</code> decorator to enable type checking of the function arguments. <code>arbitrary_types_allowed</code> is required because the <code>RunContext</code> type is not a standard type.</span>
</dd>
<dt data-target-cell="annotated-cell-7" data-target-annotation="3">3</dt>
<dd>
<span data-code-cell="annotated-cell-7" data-code-lines="9" data-code-annotation="3">The <code>RunContext</code> type hint is required for the tool to access the dependencies.</span>
</dd>
<dt data-target-cell="annotated-cell-7" data-target-annotation="4">4</dt>
<dd>
<span data-code-cell="annotated-cell-7" data-code-lines="10" data-code-annotation="4">Tell the model about the available fields in the database and validate that only those are selected.</span>
</dd>
<dt data-target-cell="annotated-cell-7" data-target-annotation="5">5</dt>
<dd>
<span data-code-cell="annotated-cell-7" data-code-lines="16" data-code-annotation="5">The database query returns a pandas DataFrame, which is converted to a markdown-formatted string.</span>
</dd>
<dt data-target-cell="annotated-cell-7" data-target-annotation="6">6</dt>
<dd>
<span data-code-cell="annotated-cell-7" data-code-lines="18" data-code-annotation="6">Provide a clear message if no reports are found. Otherwise, the function would return a markdown table with no rows, which could be confusing.</span>
</dd>
</dl>
</div>
</div>
<div id="003a7678" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1">deps <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> SupportDependencies(db<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>con)</span>
<span id="cb7-2">result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> agent.run_sync(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Which reports do we have from Germany?"</span>, deps<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>deps)</span>
<span id="cb7-3"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(result.data)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>We have four reports from Germany:
1. "Global Electric Vehicle Market Outlook 2018-2023" by Research DNA GmbH, published on July 20, 2018, focusing on the automotive topic.
2. "Digital Advertising Spend Analysis" by Tech Innovations Ltd., published on March 10, 2020, focusing on the media topic.
3. "Beverage Market Competitive Analysis" by Research DNA GmbH, published on January 5, 2022, focusing on the FMCG topic.
4. "Medical Imaging Equipment Market Size" by Tech Innovations Ltd., published on February 1, 2024, focusing on the healthcare topic.</code></pre>
</div>
</div>
<p>This lets the agent execute searches based on the exact match of a field. However, users are unlikely to remember the exact title or id of a report, so let’s also add the ability to search for similar titles.</p>
<div id="2824f1a4" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@agent.tool</span></span>
<span id="cb9-2"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@validate_call</span>(config<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>{<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"arbitrary_types_allowed"</span>: <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>})</span>
<span id="cb9-3"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> search_reports_by_title_similarity(</span>
<span id="cb9-4">    ctx: RunContext[SupportDependencies],</span>
<span id="cb9-5">    title: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>,</span>
<span id="cb9-6">) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>:</span>
<span id="cb9-7">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Embed the title given by the user</span></span>
<span id="cb9-8">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">try</span>:</span>
<span id="cb9-9">        title_embedding <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> embed_text(title)</span>
<span id="cb9-10">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">except</span> <span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">Exception</span> <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> e:</span>
<span id="cb9-11">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Error embedding title: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>e<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span></span>
<span id="cb9-12"></span>
<span id="cb9-13">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Search for similar titles</span></span>
<span id="cb9-14">    title_embedding_str <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"["</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">","</span>.join(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">map</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>, title_embedding)) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"]"</span></span>
<span id="cb9-15">    query <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb9-16"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        SELECT date, institute, country, topic, title</span></span>
<span id="cb9-17"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        FROM reports</span></span>
<span id="cb9-18"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        ORDER BY array_distance(title_embedding, ?::FLOAT[1536])</span></span>
<span id="cb9-19"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        LIMIT 5</span></span>
<span id="cb9-20"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb9-21">    df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ctx.deps.db.execute(query, [title_embedding_str]).df()</span>
<span id="cb9-22">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> df.shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>:</span>
<span id="cb9-23">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"No reports found."</span></span>
<span id="cb9-24">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> df.to_markdown()</span></code></pre></div>
</div>
<p>Let’s ask the agent about a topic that is not in the database.</p>
<div id="92f045e5" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1">result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> agent.run_sync(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Search for reports mentioning quantum computing"</span>, deps<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>deps)</span>
<span id="cb10-2"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(result.data)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Unfortunately, there are no reports in the database that mention quantum computing. The search results show reports from various institutes and countries, but none of them are related to quantum computing. If you're looking for information on this topic, I suggest trying a different search term or checking other databases.</code></pre>
</div>
</div>
<p>To see which tool the agent chose, we can inspect the message history.</p>
<div id="12a15efe" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> message <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> result.all_messages():</span>
<span id="cb12-2">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(message)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>SystemPrompt(content='You are a market research expert and answer questions using a database of reports.', role='system')
UserPrompt(content='Search for reports mentioning quantum computing', timestamp=datetime.datetime(2024, 12, 15, 10, 55, 33, 37839, tzinfo=datetime.timezone.utc), role='user')
ModelStructuredResponse(calls=[ToolCall(tool_name='search_reports_by_title_similarity', args=ArgsJson(args_json='{"title": "quantum computing"}'), tool_id='call_dmmx')], timestamp=datetime.datetime(2024, 12, 15, 10, 55, 33, tzinfo=datetime.timezone.utc), role='model-structured-response')
ToolReturn(tool_name='search_reports_by_title_similarity', content='|    | date                | institute            | country   | topic       | title                                |\n|---:|:--------------------|:---------------------|:----------|:------------|:-------------------------------------|\n|  0 | 2024-04-06 00:00:00 | Education Analytics  | Canada    | Electronics | Semiconductor Industry Analysis      |\n|  1 | 2022-03-10 00:00:00 | Market Insights Inc. | USA       | Electronics | Gaming Hardware Market Assessment    |\n|  2 | 2020-07-30 00:00:00 | Education Analytics  | Canada    | Healthcare  | Healthcare IT Market Growth Analysis |\n|  3 | 2023-07-25 00:00:00 | Market Dynamics      | Italy     | Insurance   | Cyber Insurance Market Assessment    |\n|  4 | 2021-07-18 00:00:00 | Telecom Research Hub | Spain     | Automotive  | Connected Car Market Opportunities   |', tool_id='call_dmmx', timestamp=datetime.datetime(2024, 12, 15, 10, 55, 34, 255689, tzinfo=datetime.timezone.utc), role='tool-return')
ModelStructuredResponse(calls=[ToolCall(tool_name='search_reports_by_field', args=ArgsJson(args_json='{"field": "topic", "value": "Electronics"}'), tool_id='call_s389'), ToolCall(tool_name='search_reports_by_field', args=ArgsJson(args_json='{"field": "topic", "value": "Technology"}'), tool_id='call_n0ze'), ToolCall(tool_name='search_reports_by_title_similarity', args=ArgsJson(args_json='{"title": "Quantum Computing"}'), tool_id='call_qhpp'), ToolCall(tool_name='search_reports_by_field', args=ArgsJson(args_json='{"field": "institute", "value": "Market Insights Inc."}'), tool_id='call_jx99')], timestamp=datetime.datetime(2024, 12, 15, 10, 55, 34, tzinfo=datetime.timezone.utc), role='model-structured-response')
ToolReturn(tool_name='search_reports_by_field', content='No reports found.', tool_id='call_s389', timestamp=datetime.datetime(2024, 12, 15, 10, 55, 34, 869134, tzinfo=datetime.timezone.utc), role='tool-return')
ToolReturn(tool_name='search_reports_by_field', content='No reports found.', tool_id='call_n0ze', timestamp=datetime.datetime(2024, 12, 15, 10, 55, 34, 869189, tzinfo=datetime.timezone.utc), role='tool-return')
ToolReturn(tool_name='search_reports_by_title_similarity', content='|    | date                | institute            | country   | topic       | title                                |\n|---:|:--------------------|:---------------------|:----------|:------------|:-------------------------------------|\n|  0 | 2024-04-06 00:00:00 | Education Analytics  | Canada    | Electronics | Semiconductor Industry Analysis      |\n|  1 | 2022-03-10 00:00:00 | Market Insights Inc. | USA       | Electronics | Gaming Hardware Market Assessment    |\n|  2 | 2023-07-25 00:00:00 | Market Dynamics      | Italy     | Insurance   | Cyber Insurance Market Assessment    |\n|  3 | 2020-07-30 00:00:00 | Education Analytics  | Canada    | Healthcare  | Healthcare IT Market Growth Analysis |\n|  4 | 2021-07-18 00:00:00 | Telecom Research Hub | Spain     | Automotive  | Connected Car Market Opportunities   |', tool_id='call_qhpp', timestamp=datetime.datetime(2024, 12, 15, 10, 55, 35, 282999, tzinfo=datetime.timezone.utc), role='tool-return')
ToolReturn(tool_name='search_reports_by_field', content='|    | date                | institute            | country   | topic       | title                                          |\n|---:|:--------------------|:---------------------|:----------|:------------|:-----------------------------------------------|\n|  0 | 2018-08-15 00:00:00 | Market Insights Inc. | USA       | Healthcare  | Digital Health Market Size and Growth Analysis |\n|  1 | 2022-03-10 00:00:00 | Market Insights Inc. | USA       | Electronics | Gaming Hardware Market Assessment              |', tool_id='call_jx99', timestamp=datetime.datetime(2024, 12, 15, 10, 55, 34, 870446, tzinfo=datetime.timezone.utc), role='tool-return')
ModelTextResponse(content="Unfortunately, there are no reports in the database that mention quantum computing. The search results show reports from various institutes and countries, but none of them are related to quantum computing. If you're looking for information on this topic, I suggest trying a different search term or checking other databases.", timestamp=datetime.datetime(2024, 12, 15, 10, 55, 35, tzinfo=datetime.timezone.utc), role='model-text-response')</code></pre>
</div>
</div>
<p>The model ended up making three tool calls:</p>
<ol type="1">
<li><code>search_reports_by_title_similarity</code> to find titles similar to “quantum computing”. It got a result but was smart enough to understand that they were not relevant.</li>
<li><code>search_reports_by_field</code> to find reports with the topic “Electronics”. It got results and again understood that they were not relevant.</li>
<li><code>search_reports_by_field</code> to find reports with the topic “Quantum Computing” with no results.</li>
</ol>
<p>TODO: Talk about what other tools could be added. TODO: Read other examples from PydanticAI documentation.</p>
</section>
</section>
<section id="discussion" class="level2">
<h2 class="anchored" data-anchor-id="discussion">Discussion</h2>
<section id="comparison-to-other-libraries" class="level3">
<h3 class="anchored" data-anchor-id="comparison-to-other-libraries">Comparison to other libraries</h3>
<p>PydanticAI is a late entrant to the agent framework space. It joins several established libraries including:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Library</th>
<th>Description</th>
<th style="text-align: right;">Github Stars ⭐</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><a href="https://github.com/Significant-Gravitas/AutoGPT">AutoGPT</a></td>
<td>AI automation platform with frontend, server and monitoring</td>
<td style="text-align: right;">169k</td>
</tr>
<tr class="even">
<td><a href="https://github.com/langchain-ai/langchain">LangChain</a></td>
<td>Package ecosystem for LLM applications</td>
<td style="text-align: right;">96k</td>
</tr>
<tr class="odd">
<td><a href="https://github.com/microsoft/autogen">autogen</a></td>
<td>Multi-agent AI chat framework by Microsoft</td>
<td style="text-align: right;">36k</td>
</tr>
<tr class="even">
<td><a href="https://github.com/crewAIInc/crewai">crewAI</a></td>
<td>Framework for orchestrating role-based AI agents</td>
<td style="text-align: right;">22k</td>
</tr>
<tr class="odd">
<td><a href="https://github.com/openai/swarm">swarm</a></td>
<td>Educational framework for multi-agent apps by OpenAI</td>
<td style="text-align: right;">17k</td>
</tr>
<tr class="even">
<td><a href="https://github.com/phidatahq/phidata">phidata</a></td>
<td>Multi-agent backend and chat frontent</td>
<td style="text-align: right;">16k</td>
</tr>
</tbody>
</table>
<p>There are dozens of other libraries with fewer stars. In addition, there are libraries specialized for RAG like <a href="https://github.com/run-llama/llama_index">LlamaIndex</a> and <a href="https://github.com/deepset-ai/haystack">Haystack</a>. The competition landscape doesn’t show signs of consolidation or slowing down.</p>
</section>
<section id="development-team" class="level3">
<h3 class="anchored" data-anchor-id="development-team">Development team</h3>
<p>Pydantic Services, the company behind Pydantic, has raised a $12.5m <a href="https://www.crunchbase.com/funding_round/pydantic-services-series-a--ddd115fb">Series A</a> in October 2024. This is great news for the project: funding pays for full time developers. Of course, it raises the question of how Pydantic will make money, and the answer to that is Logfire. This is a good model that gives long-term stability to the project and follows the lead of LangChain with its commercial product, <a href="https://www.langchain.com/langsmith">LangSmith</a>.</p>
<p>I just hope that the integration remains optional. While Logfire looks great, my team already uses <a href="https://wandb.ai/site/weave/">Weave</a> by Weights &amp; Biases, and having to switch would be a barrier to adopting PydanticAI.</p>
</section>
<section id="review" class="level3">
<h3 class="anchored" data-anchor-id="review">Review</h3>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Pros ✅</strong></p>
<ul>
<li>Sensible abstractions that don’t get in the way.</li>
<li>Type safety and integration with Pydantic.</li>
<li>Strong reputation of the Pydantic team.</li>
<li>Pydantic is familiar to many Python developers who will have an easier time learning PydanticAI.</li>
<li>Great support for streaming responses and async tool calling. This is critical for live chat applications.</li>
<li>High quality documentation and examples.</li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>Cons ❌</strong></p>
<ul>
<li>Launches into a competitive market with many established libraries.</li>
<li>Early stage of development, so expect breaking changes.</li>
<li>Economic incentives to lock users into Logfire. This hasn’t happened but is a risk.</li>
</ul>
</div>
</div>
<p>I’m looking forward to an opportunity to build a full-scale application with PydanticAI.</p>
<p>Photo by <a href="https://unsplash.com/@magicpattern?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">MagicPattern</a> on <a href="https://unsplash.com/photos/purple-and-black-polka-dot-textile-eHH_5rn3xnU?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Unsplash</a></p>


</section>
</section>

 ]]></description>
  <category>Machine Learning</category>
  <category>Python</category>
  <guid>https://simmering.dev/blog/pydantic-ai/</guid>
  <pubDate>Sat, 14 Dec 2024 23:00:00 GMT</pubDate>
  <media:content url="https://simmering.dev/blog/pydantic-ai/image.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Constrained by Context, Not Reasoning</title>
  <dc:creator>Paul Simmering</dc:creator>
  <link>https://simmering.dev/blog/context-constrained/</link>
  <description><![CDATA[ 





<p>Frontier LLMs rarely give completely wrong answers. Even when their responses aren’t exactly what we need, they’re usually logical given the information provided.</p>
<p>Recent advances in chain-of-thought reasoning, such as in models like <a href="https://openai.com/index/learning-to-reason-with-llms/">OpenAI’s o1</a> and <a href="https://www.alibabacloud.com/blog/alibaba-cloud-unveils-open-source-ai-reasoning-model-qwq-and-new-image-editing-tool_601813">Alibaba’s QwQ</a>, have led to remarkable achievements. These models now outperform most humans on complex tasks like competition mathematics (AIME 2024) and PhD-level science questions (GPQA Diamond).</p>
<p>Yet here’s the paradox: despite this impressive reasoning capability, LLMs often struggle to provide immediately useful outputs for everyday professional tasks. Usually, their output has to be edited or the prompt rewritten multiple times to produce a copy-pasteable result. This leads to my thesis: <strong>The real-world effectiveness of LLMs is now limited more by their awareness of context than by their reasoning capabilities</strong>.</p>
<p>Think of an LLM as a brilliant but newly hired colleague who hasn’t been properly onboarded. While they can tackle complex problems, they miss crucial contextual details required to fit their work into the existing workflows. The challenge isn’t their intelligence—it’s their need for situational awareness.</p>
<section id="context-makes-outputs-more-useful" class="level2">
<h2 class="anchored" data-anchor-id="context-makes-outputs-more-useful">Context makes outputs more useful</h2>
<p>Here are some examples of how adding context lets LLMs produce outputs that are more readily applicable:</p>
<ul>
<li>When summarizing a technical document, telling the model “This is for marketing executives who need to understand the business implications” yields very different (and more useful) results than just asking for a summary</li>
<li>For educational content, specifying “Explain this for a high school student” versus “Explain this for a graduate student” completely changes the depth and terminology used</li>
<li>In correspondence, sharing details like “This is for a long-time client who prefers informal communication” helps create more appropriately-toned messages For social media, providing examples of past successful posts or a company style guide helps the model match the preferred tone</li>
<li>In software development, showing the model your existing codebase helps it suggest solutions that integrate seamlessly with your architecture</li>
<li>During translation work, specifying “This is medical documentation” versus “This is marketing material” ensures appropriate terminology and tone</li>
</ul>
</section>
<section id="infusing-context-actively-and-passively" class="level2">
<h2 class="anchored" data-anchor-id="infusing-context-actively-and-passively">Infusing context actively and passively</h2>
<p>It’s tedious to write a detailed briefing each time, just like you wouldn’t want to repeat onboarding of a colleague. Here are ways to reuse prompts or passively infuse context:</p>
<ul>
<li>Write a persistent system prompt that’s automatically applied to all conversations. In ChatGPT, you can do this by creating a custom GPT.</li>
<li>Enable chat history to be able to copy-paste successful prompts into new conversations.</li>
<li>Turn on features that let the model learn from past interactions (if not dealing with sensitive data).</li>
<li>When writing in an editor enhanced by AI, prefer one long document over spreading content across many shorter documents.</li>
<li>Work with developer tools like GitHub Copilot or Cursor that read your code base rather than copy-pasting snippets into a separate chat window. This also works for non-coding tasks, such as writing articles.</li>
<li>Use dictation to speak your prompt effortlessly. Speak about the situation and the task in a stream of consciousness.</li>
<li>Share your screen with an assistant. This <a href="https://beebom.com/how-you-can-try-google-project-astra-stream-realtime/">feature</a> was added to Google Gemini in December 2024. While my experience testing it was mixed, I think this could become an effective way to continuously share context. It makes most sense with apps that don’t have their own built-in assistant.</li>
</ul>
<hr>
<p>Photo by <a href="https://unsplash.com/@magicpattern?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">MagicPattern</a> on <a href="https://unsplash.com/photos/purple-and-pink-letter-blocks-jbywvpa9vH8?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Unsplash</a></p>


</section>

 ]]></description>
  <category>Productivity</category>
  <guid>https://simmering.dev/blog/context-constrained/</guid>
  <pubDate>Fri, 13 Dec 2024 23:00:00 GMT</pubDate>
  <media:content url="https://simmering.dev/blog/context-constrained/image.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Aspect-based Sentiment Analysis with DSPy</title>
  <dc:creator>Paul Simmering</dc:creator>
  <link>https://simmering.dev/blog/absa-with-dspy/</link>
  <description><![CDATA[ 





<p>Last year, my colleague Paavo Huoviala and I explored prompting and fine-tuning large language models for aspect-based sentiment analysis (ABSA) <span class="citation" data-cites="simmering2023large">(Simmering and Huoviala 2023)</span>. Like many researchers at the time, we spent considerable effort manually crafting prompts and selecting few-shot examples. But what if we could automate this process? Enter DSPy - a Python library that automatically optimizes LLM prompts. In this article, I’ll revisit our ABSA experiments using DSPy’s automated approach instead of manual prompt engineering.</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Resource</th>
<th>Link</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>💻 Code</td>
<td><a href="https://github.com/psimm/website/blob/master/blog/absa-with-dspy/index.qmd">GitHub</a></td>
</tr>
<tr class="even">
<td>📊 Experiments</td>
<td><a href="https://wandb.ai/psimm/absa-dspy">Weights &amp; Biases project</a></td>
</tr>
<tr class="odd">
<td>📝 Dataset</td>
<td><a href="https://huggingface.co/datasets/psimm/absa-semeval2014-alpaca">Hugging Face Hub</a></td>
</tr>
</tbody>
</table>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
DSPy version 2.5.32
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>DSPy is in rapid development. I’ve encountered outdated tutorials, dead links in the documentation and deprecation warnings. The code of this article may not work with future versions.</p>
</div>
</div>
</div>
<section id="dspy-programming-not-prompting-llms" class="level2">
<h2 class="anchored" data-anchor-id="dspy-programming-not-prompting-llms">DSPy: Programming — not prompting — LLMs</h2>
<p><img src="https://simmering.dev/blog/absa-with-dspy/dspy_logo.webp" class="img-fluid" style="width:50.0%"></p>
<p><a href="https://dspy.ai">DSPy</a> is a Python library developed by Stanford NLP. Rather than manually crafting prompts and seeing them break whenever something changes elsewhere in the pipeline, DSPy automates the process of finding the optimal prompts. The documentation has an <a href="https://dspy.ai/learn/">overview</a> of the main building blocks of the library. In this article, I’ll introduce the elements needed to optimize a structured prediction task, using ABSA as an example.</p>
<section id="experiment-setup" class="level3">
<h3 class="anchored" data-anchor-id="experiment-setup">Experiment setup</h3>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">%%{init: {
  'theme': 'base',
  'themeVariables': {
    'primaryColor': '#ffffff',
    'primaryTextColor': '#2d3748',
    'primaryBorderColor': '#90cdf4',
    'lineColor': '#64748b',
    'secondaryColor': '#ffffff',
    'tertiaryColor': '#ffffff',
    'fontSize': '22px',
    'labelFontSize': '18px',
    'edgeLabelFontSize': '18px'
  }
}}%%
graph TB
    %% Define styles
    classDef default fill:#ffffff,stroke:#90cdf4,stroke-width:2px
    classDef highlight fill:#fdf2f8,stroke:#ed64a6,stroke-width:3px
    classDef api fill:#ffffff,stroke:#4fd1c5,stroke-width:2px
    
    subgraph Data ["1️⃣ Data"]
        D1[SemEval Dataset] --&gt; |"Transform"| D2[DSPy Examples]
    end
    
    subgraph Definition ["2️⃣ Model Definition"]
        M2[Pydantic Models] --&gt; |"Define Structure"| M1[DSPy Signature]
        M1 --&gt; |"Initialize"| M3[Predictor]
        M4[Language Models] --&gt; |"Power"| M3
        A1[OpenAI API] --&gt; |"Provide"| M4
        A2[Fireworks.ai API] --&gt; |"Provide"| M4
    end
    
    subgraph Optimization ["3️⃣ Optimization"]
        O1[Evaluation Function] --&gt; |"Guide"| O2[MIPROv2 Optimizer]
        M3 --&gt; |"Optimize"| O2
        D2 --&gt; |"Train"| O2
        O2 --&gt; |"Output"| O3[Optimized Predictor]
    end
    
    subgraph Evaluation ["4️⃣ Evaluation"]
        O3 --&gt; |"Test"| E1[Test Set Evaluation]
        O1 --&gt; |"Measure"| E1
        E1 --&gt; |"Log"| E2[Weights &amp; Biases]
    end

    %% Apply styles
    class O2 highlight
    class A1,A2,E2 api
    
    %% Links between subgraphs
    linkStyle default stroke:#64748b,stroke-width:2px
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<p>The steps will be explained in the following sections.</p>
</section>
</section>
<section id="dataset-for-aspect-based-sentiment-analysis" class="level2">
<h2 class="anchored" data-anchor-id="dataset-for-aspect-based-sentiment-analysis">Dataset for Aspect-based Sentiment Analysis</h2>
<p>The goal of ABSA is to analyze a review and extract the discussed aspects of a product or service and the sentiment towards each aspect. For example, the review “The pizza was great, but the service was terrible” contains two aspects: “pizza” (positive) and “service” (negative). There are more advanced variants of ABSA, but for this article I’ll focus on the basic task. I will also let a single model handle the extraction and the classification.</p>
<section id="semeval-2014-task-4" class="level3">
<h3 class="anchored" data-anchor-id="semeval-2014-task-4">SemEval 2014 Task 4</h3>
<p>I’m using the SemEval 2014 Task 4 dataset by <span class="citation" data-cites="pontiki_semeval">Pontiki et al. (2014)</span>. The <a href="https://huggingface.co/datasets/psimm/absa-semeval2014-alpaca">dataset</a> is available on Hugging Face. This is a cleaned version of the original XML files consisting of train and test splits. The small number of examples with the “conflict” label are excluded, as is common in the literature.</p>
<div id="c9a578ab" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> polars <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pl</span>
<span id="cb1-2"></span>
<span id="cb1-3">url <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"hf://datasets/psimm/absa-semeval2014-alpaca"</span></span>
<span id="cb1-4"></span>
<span id="cb1-5">train <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pl.read_parquet(url <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"/data/train-00000-of-00001.parquet"</span>)</span>
<span id="cb1-6">test <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pl.read_parquet(url <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"/data/test-00000-of-00001.parquet"</span>)</span></code></pre></div>
</div>
<div id="b21443cd" class="cell" data-execution_count="2">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> great_tables <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> GT</span>
<span id="cb2-2"></span>
<span id="cb2-3">overview <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (</span>
<span id="cb2-4">    train.vstack(test)</span>
<span id="cb2-5">    .group_by([<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"split"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"domain"</span>])</span>
<span id="cb2-6">    .agg(examples<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>pl.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>())</span>
<span id="cb2-7">    .sort(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"split"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"domain"</span>, descending<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb2-8">)</span>
<span id="cb2-9">GT(overview).tab_header(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"SemEval 2014 Task 4 Dataset"</span>).cols_label(</span>
<span id="cb2-10">    split<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Split"</span>,</span>
<span id="cb2-11">    domain<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Domain"</span>,</span>
<span id="cb2-12">    examples<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Examples"</span>,</span>
<span id="cb2-13">).cols_align(align<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"right"</span>, columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"examples"</span>])</span></code></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="2">
<div id="oykrqaoiln" style="padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>
#oykrqaoiln table {
          font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;
          -webkit-font-smoothing: antialiased;
          -moz-osx-font-smoothing: grayscale;
        }

#oykrqaoiln thead, tbody, tfoot, tr, td, th { border-style: none; }
 tr { background-color: transparent; }
#oykrqaoiln p { margin: 0; padding: 0; }
 #oykrqaoiln .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; }
 #oykrqaoiln .gt_caption { padding-top: 4px; padding-bottom: 4px; }
 #oykrqaoiln .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; }
 #oykrqaoiln .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; }
 #oykrqaoiln .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; }
 #oykrqaoiln .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; }
 #oykrqaoiln .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; }
 #oykrqaoiln .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; }
 #oykrqaoiln .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; }
 #oykrqaoiln .gt_column_spanner_outer:first-child { padding-left: 0; }
 #oykrqaoiln .gt_column_spanner_outer:last-child { padding-right: 0; }
 #oykrqaoiln .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; }
 #oykrqaoiln .gt_spanner_row { border-bottom-style: hidden; }
 #oykrqaoiln .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; }
 #oykrqaoiln .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; }
 #oykrqaoiln .gt_from_md> :first-child { margin-top: 0; }
 #oykrqaoiln .gt_from_md> :last-child { margin-bottom: 0; }
 #oykrqaoiln .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; }
 #oykrqaoiln .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; }
 #oykrqaoiln .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; }
 #oykrqaoiln .gt_row_group_first td { border-top-width: 2px; }
 #oykrqaoiln .gt_row_group_first th { border-top-width: 2px; }
 #oykrqaoiln .gt_striped { background-color: rgba(128,128,128,0.05); }
 #oykrqaoiln .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; }
 #oykrqaoiln .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; }
 #oykrqaoiln .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; text-align: left; }
 #oykrqaoiln .gt_left { text-align: left; }
 #oykrqaoiln .gt_center { text-align: center; }
 #oykrqaoiln .gt_right { text-align: right; font-variant-numeric: tabular-nums; }
 #oykrqaoiln .gt_font_normal { font-weight: normal; }
 #oykrqaoiln .gt_font_bold { font-weight: bold; }
 #oykrqaoiln .gt_font_italic { font-style: italic; }
 #oykrqaoiln .gt_super { font-size: 65%; }
 #oykrqaoiln .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; }
 #oykrqaoiln .gt_asterisk { font-size: 100%; vertical-align: 0; }
 
</style>

<table class="gt_table caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-quarto-disable-processing="false" data-quarto-bootstrap="false">
<thead>
<tr class="gt_heading header">
<th colspan="3" class="gt_heading gt_title gt_font_normal">SemEval 2014 Task 4 Dataset</th>
</tr>
<tr class="gt_col_headings even">
<th id="Split" class="gt_col_heading gt_columns_bottom_border gt_left" data-quarto-table-cell-role="th" scope="col">Split</th>
<th id="Domain" class="gt_col_heading gt_columns_bottom_border gt_left" data-quarto-table-cell-role="th" scope="col">Domain</th>
<th id="Examples" class="gt_col_heading gt_columns_bottom_border gt_right" data-quarto-table-cell-role="th" scope="col">Examples</th>
</tr>
</thead>
<tbody class="gt_table_body">
<tr class="odd">
<td class="gt_row gt_left">train</td>
<td class="gt_row gt_left">restaurants</td>
<td class="gt_row gt_right">2957</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">train</td>
<td class="gt_row gt_left">laptops</td>
<td class="gt_row gt_right">3002</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">test</td>
<td class="gt_row gt_left">restaurants</td>
<td class="gt_row gt_right">786</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">test</td>
<td class="gt_row gt_left">laptops</td>
<td class="gt_row gt_right">786</td>
</tr>
</tbody>
</table>


</div>
        
</div>
</div>
<p>The dataset contains a similar number of restaurant and laptop reviews.</p>
<p>The goal is to choose the optimal prompt and few-shot examples to maximize the F1 score of the aspect extraction and classification. To achieve this, DSPy needs to be able to evaluate the metrics and a training set to learn from.</p>
</section>
</section>
<section id="model-definition" class="level2">
<h2 class="anchored" data-anchor-id="model-definition">Model Definition</h2>
<section id="pydantic-models-for-absa" class="level3">
<h3 class="anchored" data-anchor-id="pydantic-models-for-absa">Pydantic models for ABSA</h3>
<p>We create classes to represent the input and output of the task using the data validation library <a href="https://docs.pydantic.dev/latest/">Pydantic</a>. This helps with validating the data and provides a structured output format for predictor. The <code>Field</code> class is used to describe the expected data type. Their descriptions match the ones used in <span class="citation" data-cites="simmering2023large">(Simmering and Huoviala 2023)</span>. This is a form of prompting, but DSPy also supports automatically setting the structure’s descriptions using the <a href="https://dspy.ai/learn/8-typed_predictors/?h=typed#optimizing-typed-predictors"><code>optimize_signature</code></a> optimizer. In this experiment I’ll stick with the original descriptions and only vary the normal prompt and few-shot examples.</p>
<div id="fa24fc6d" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> typing <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Literal</span>
<span id="cb3-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pydantic <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> BaseModel, Field</span>
<span id="cb3-3"></span>
<span id="cb3-4"></span>
<span id="cb3-5"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> Input(BaseModel):</span>
<span id="cb3-6">    text: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Field()</span>
<span id="cb3-7"></span>
<span id="cb3-8"></span>
<span id="cb3-9"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> Aspect(BaseModel):</span>
<span id="cb3-10">    term: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Field(</span>
<span id="cb3-11">        description<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"An aspect term, which is a verbatim text snippet. Single or multiword terms naming particular aspects of the reviewed product or service."</span></span>
<span id="cb3-12">    )</span>
<span id="cb3-13">    polarity: Literal[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"positive"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"neutral"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"negative"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Field(</span>
<span id="cb3-14">        description<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"The polarity expressed towards the aspect term. Valid polarities are ‘positive’, ‘neutral’, ‘negative'."</span></span>
<span id="cb3-15">    )</span>
<span id="cb3-16"></span>
<span id="cb3-17">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__hash__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>):</span>
<span id="cb3-18">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb3-19"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Make the aspect hashable to enable set operations in evaluation.</span></span>
<span id="cb3-20"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Hash is case-insensitive.</span></span>
<span id="cb3-21"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb3-22">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">hash</span>((<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.term.lower(), <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.polarity.lower()))</span>
<span id="cb3-23"></span>
<span id="cb3-24">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__eq__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, other):</span>
<span id="cb3-25">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb3-26"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Define equality for case-insensitive comparison.</span></span>
<span id="cb3-27"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb3-28">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">isinstance</span>(other, Aspect):</span>
<span id="cb3-29">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span></span>
<span id="cb3-30">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> (</span>
<span id="cb3-31">            <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.term.lower() <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> other.term.lower()</span>
<span id="cb3-32">            <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">and</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.polarity.lower() <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> other.polarity.lower()</span>
<span id="cb3-33">        )</span>
<span id="cb3-34"></span>
<span id="cb3-35"></span>
<span id="cb3-36"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> Aspects(BaseModel):</span>
<span id="cb3-37">    aspects: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>[Aspect] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Field(</span>
<span id="cb3-38">        description<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"An array of aspects and their polarities. If no aspects are mentioned in the text, use an empty array."</span></span>
<span id="cb3-39">    )</span></code></pre></div>
</div>
<p>The <code>__hash__</code> and <code>__eq__</code> methods will be helpful for evaluation, because they allow for use of set operations to compare gold and predicted aspects.</p>
</section>
<section id="transform-dataset-to-dspy-examples" class="level3">
<h3 class="anchored" data-anchor-id="transform-dataset-to-dspy-examples">Transform dataset to DSPy examples</h3>
<p>Each row in the dataset needs to be turned into an instance of the <code>dspy.Example</code> class. The <code>with_inputs</code> method is used to tell DSPy which column contains the input. Other columns are used as expected model outputs.</p>
<div id="ba082b2b" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> json</span>
<span id="cb4-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> dspy</span>
<span id="cb4-3"></span>
<span id="cb4-4"></span>
<span id="cb4-5"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> to_example(row):</span>
<span id="cb4-6">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> dspy.Example(</span>
<span id="cb4-7">        text<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>row[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"input"</span>],</span>
<span id="cb4-8">        aspects<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>Aspects(aspects<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>json.loads(row[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"output"</span>])[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"aspects"</span>]),</span>
<span id="cb4-9">    ).with_inputs(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"text"</span>)</span>
<span id="cb4-10"></span>
<span id="cb4-11"></span>
<span id="cb4-12">trainset <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [to_example(row) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> row <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> train.to_dicts()]</span>
<span id="cb4-13">testset <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [to_example(row) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> row <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> test.to_dicts()]</span></code></pre></div>
</div>
<p>Let’s look at the first example.</p>
<div id="ee11a3cc" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">trainset[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>Example({'text': 'I charge it at night and skip taking the cord with me because of the good battery life.', 'aspects': Aspects(aspects=[Aspect(term='cord', polarity='neutral'), Aspect(term='battery life', polarity='positive')])}) (input_keys={'text'})</code></pre>
</div>
</div>
</section>
<section id="creating-a-dspy-typed-predictor" class="level3">
<h3 class="anchored" data-anchor-id="creating-a-dspy-typed-predictor">Creating a DSPy typed predictor</h3>
<p>In DSPy, a module is a language model and a way of prompting. They can also consist of multiple requests and also include external tools such as a vector database for retrieval augmented generation. In this example, we have a single request using few-shot examples and chain of thought.</p>
<p>In order to be able to parse the output as a dictionary, the LLM must output valid JSON. Therefore I’ll use a <a href="https://dspy.ai/learn/8-typed_predictors/?h=typed">Typed Predictor</a> in DSPy, which is similar to structured outputs via instructor or a similar library.</p>
<div id="01bdde17" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> AbsaSignature(dspy.Signature):</span>
<span id="cb7-2">    text: Input <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dspy.InputField()</span>
<span id="cb7-3">    aspects: Aspects <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dspy.OutputField()</span>
<span id="cb7-4"></span>
<span id="cb7-5"></span>
<span id="cb7-6">predictor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dspy.ChainOfThought(AbsaSignature)</span></code></pre></div>
</div>
<p>We also need to choose a language model. DSPy works with OpenAI, Anthropic, Ollama, vllm and other OpenAI-compatible platforms and libraries. This is powered by <a href="https://github.com/BerriAI/litellm">litellm</a> under the hood.</p>
<p>For this article, I’ll use OpenAI’s gpt-4o-mini as well as the 70B version of Meta’s Llama 3.1 hosted on <a href="https://fireworks.ai">fireworks.ai</a>. Fireworks.ai generously supplied me with credits as part of the <a href="https://maven.com/parlance-labs/fine-tuning?utm_campaign=d45fef&amp;utm_medium=partner&amp;utm_source=instructor">Mastering LLMs For Developers &amp; Data Scientists</a> course.</p>
<div id="9ba79829" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># FIREWORKS_AI_API_KEY environment variable must be set.</span></span>
<span id="cb8-2"></span>
<span id="cb8-3">lm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dspy.LM(</span>
<span id="cb8-4">    api_base<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"https://api.fireworks.ai/inference/v1/"</span>,</span>
<span id="cb8-5">    model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"fireworks_ai/accounts/fireworks/models/llama-v3p1-70b-instruct"</span>,</span>
<span id="cb8-6">    temperature<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span>,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># best for structured outputs</span></span>
<span id="cb8-7">    cache<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb8-8">    max_tokens<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">250</span>,</span>
<span id="cb8-9">)</span>
<span id="cb8-10">dspy.configure(lm<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>lm)</span></code></pre></div>
</div>
</section>
</section>
<section id="optimization" class="level2">
<h2 class="anchored" data-anchor-id="optimization">Optimization</h2>
<p>Let’s run a single example to check that everything is working.</p>
<div id="dcddfe3d" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1">predictor(text<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"The pizza was great, but the service was terrible"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>Prediction(
    rationale='We produce the aspects by identifying the terms "pizza" and "service" as aspects and determining their polarities based on the context. The term "pizza" is associated with the positive sentiment "great", while the term "service" is associated with the negative sentiment "terrible".',
    aspects=Aspects(aspects=[Aspect(term='pizza', polarity='positive'), Aspect(term='service', polarity='negative')])
)</code></pre>
</div>
</div>
<p>That’s a good start. I’m a fan of <a href="https://hamel.dev/blog/posts/prompt/">Hamel Husain’s advice</a> to always demand: “Show me the prompt”, so let’s check what DSPy actually sent to OpenAI:</p>
<div id="35504bec" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1">lm.inspect_history(n<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>



[2024-11-27T08:58:15.497789]

System message:

Your input fields are:
1. `text` (Input)

Your output fields are:
1. `rationale` (str): ${produce the aspects}. We ...
2. `aspects` (Aspects)

All interactions will be structured in the following way, with the appropriate values filled in.

[[ ## text ## ]]
{text}

[[ ## rationale ## ]]
{rationale}

[[ ## aspects ## ]]
{aspects}        # note: the value you produce must be pareseable according to the following JSON schema: {"type": "object", "$defs": {"Aspect": {"type": "object", "properties": {"polarity": {"type": "string", "description": "The polarity expressed towards the aspect term. Valid polarities are ‘positive’, ‘neutral’, ‘negative'.", "enum": ["positive", "neutral", "negative"], "title": "Polarity"}, "term": {"type": "string", "description": "An aspect term, which is a verbatim text snippet. Single or multiword terms naming particular aspects of the reviewed product or service.", "title": "Term"}}, "required": ["term", "polarity"], "title": "Aspect"}}, "properties": {"aspects": {"type": "array", "description": "An array of aspects and their polarities. If no aspects are mentioned in the text, use an empty array.", "items": {"$ref": "#/$defs/Aspect"}, "title": "Aspects"}}, "required": ["aspects"], "title": "Aspects"}

[[ ## completed ## ]]

In adhering to this structure, your objective is: 
        Given the fields `text`, produce the fields `aspects`.


User message:

[[ ## text ## ]]
The pizza was great, but the service was terrible

Respond with the corresponding output fields, starting with the field `[[ ## rationale ## ]]`, then `[[ ## aspects ## ]]` (must be formatted as a valid Python Aspects), and then ending with the marker for `[[ ## completed ## ]]`.


Response:

[[ ## rationale ## ]]
We produce the aspects by identifying the terms "pizza" and "service" as aspects and determining their polarities based on the context. The term "pizza" is associated with the positive sentiment "great", while the term "service" is associated with the negative sentiment "terrible".

[[ ## aspects ## ]]
{"aspects": [{"term": "pizza", "polarity": "positive"}, {"term": "service", "polarity": "negative"}]}

[[ ## completed ## ]]




</code></pre>
</div>
</div>
<p>Verbose but it works. It doesn’t use function calling or a different way to get structured outputs, so there is some chance of getting an invalid JSON.</p>
<section id="specify-the-evaluation-function" class="level3">
<h3 class="anchored" data-anchor-id="specify-the-evaluation-function">Specify the evaluation function</h3>
<p>An evaluation function takes an example and a prediction and returns an F1 score. A true positive is a predicted aspect that is also in the gold answer, a false positive is a predicted aspect that is not in the gold answer, and a false negative is a gold answer aspect that is not predicted. Here are the precision, recall, and F1 score functions.</p>
<div id="2a060d62" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> precision(tp: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>, fp: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span>:</span>
<span id="cb13-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Handle division by zero</span></span>
<span id="cb13-3">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> tp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> fp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span> tp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> (tp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> fp)</span>
<span id="cb13-4"></span>
<span id="cb13-5"></span>
<span id="cb13-6"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> recall(tp: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>, fn: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span>:</span>
<span id="cb13-7">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> tp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> fn <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span> tp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> (tp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> fn)</span>
<span id="cb13-8"></span>
<span id="cb13-9"></span>
<span id="cb13-10"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> f1_score(tp: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>, fp: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>, fn: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span>:</span>
<span id="cb13-11">    prec <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> precision(tp, fp)</span>
<span id="cb13-12">    rec <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> recall(tp, fn)</span>
<span id="cb13-13">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> prec <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> rec <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> (prec <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> rec) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> (prec <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> rec)</span></code></pre></div>
</div>
<p>Next is the evaluation function which compares the gold and predicted aspects. To count as a true positive, both the term and the polarity have to be correct. As it is conventional on this benchmark, the case where both the gold answers and the prediction are empty is treated as a correct prediction of no aspects.</p>
<div id="a5bf9cf4" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> evaluate_absa(example: dspy.Example, prediction: Aspects, trace<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span>:</span>
<span id="cb14-2">    gold_aspects <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">set</span>(example.aspects.aspects)</span>
<span id="cb14-3">    pred_aspects <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">set</span>(prediction.aspects.aspects)</span>
<span id="cb14-4"></span>
<span id="cb14-5">    tp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(gold_aspects <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&amp;</span> pred_aspects)</span>
<span id="cb14-6">    fp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(pred_aspects <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> gold_aspects)</span>
<span id="cb14-7">    fn <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(gold_aspects <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> pred_aspects)</span>
<span id="cb14-8"></span>
<span id="cb14-9">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(gold_aspects) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">and</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(pred_aspects) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>:</span>
<span id="cb14-10">        tp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># correct prediction of no aspects</span></span>
<span id="cb14-11"></span>
<span id="cb14-12">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> f1_score(tp, fp, fn)</span></code></pre></div>
</div>
<p>Let’s try the evaluation function with a single example. We expect the F1 score to be 1.0, because the prediction matches the gold answer exactly.</p>
<div id="0bc42ba9" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1">example <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dspy.Example(</span>
<span id="cb15-2">    text<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"The pizza was great, but the service was terrible"</span>,</span>
<span id="cb15-3">    aspects<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>Aspects(</span>
<span id="cb15-4">        aspects<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[</span>
<span id="cb15-5">            Aspect(term<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"pizza"</span>, polarity<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"positive"</span>),</span>
<span id="cb15-6">            Aspect(term<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"service"</span>, polarity<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"negative"</span>),</span>
<span id="cb15-7">        ]</span>
<span id="cb15-8">    ),</span>
<span id="cb15-9">).with_inputs(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"text"</span>)</span>
<span id="cb15-10">prediction <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> predictor(text<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>example.text)</span>
<span id="cb15-11">evaluate_absa(example, prediction)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="12">
<pre><code>1.0</code></pre>
</div>
</div>
</section>
<section id="optimizers" class="level3">
<h3 class="anchored" data-anchor-id="optimizers">Optimizers</h3>
<p>DSPy has a variety of <a href="https://dspy.ai/learn/optimization/optimizers/?h=optimizers">optimizers</a>, loops that change the prompt and/or few-shot examples and evaluate the performance. They’re analogous to optimizers like SGD and Adam in PyTorch. The choice of optimizer depends on the task, the amount of labeled data and the computational resources available. As we have a large labeled dataset, it’s not necessary to have the model bootstrap artificial examples. Our 2023 paper found that fine-tuning yields the best results, but the goal of this article is to showcase DSPy’s prompt optimization.</p>
<p>The most powerful optimizer available for a prompting approach for this task is <a href="[Multiprompt Instruction PRoposal Optimizer Version 2](https://dspy.ai/deep-dive/optimizers/miprov2/?h=miprov)">MIPROv2</a> (Multiprompt Instruction PRoposal Optimizer Version 2) by <span class="citation" data-cites="opsahlong2024optimizinginstructionsdemonstrationsmultistage">Opsahl-Ong et al. (2024)</span>. MIPROv2 uses Bayesian optimization to find an optimal combination of few-shot examples and prompt instructions.</p>
<div id="556aaa52" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1">optimizer_settings <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">dict</span>(</span>
<span id="cb17-2">    metric<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>evaluate_absa,</span>
<span id="cb17-3">    num_threads<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># make parallel requests to Fireworks.ai</span></span>
<span id="cb17-4">    max_errors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># keep going even when invalid JSON is returned</span></span>
<span id="cb17-5">)</span>
<span id="cb17-6">optimizer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dspy.teleprompt.MIPROv2(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>optimizer_settings)</span></code></pre></div>
</div>
<p>The final step is to call the <code>compile</code> method, which starts the optimization process. After about 5 minutes, the best prompt and few-shot examples are saved to a JSON file.</p>
<div id="c003b7c7" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define settings for the comilation step of the optimizer.</span></span>
<span id="cb18-2">compile_settings <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">dict</span>(</span>
<span id="cb18-3">    minibatch_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># evaluate changes on a subset of the validation set</span></span>
<span id="cb18-4">    minibatch_full_eval_steps<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># evaluate on the full validation set after every 10 steps</span></span>
<span id="cb18-5">    max_labeled_demos<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># the number of few-shot examples to use</span></span>
<span id="cb18-6">    max_bootstrapped_demos<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># not required because we have labeled examples, but setting it to 0 causes an error during sampling</span></span>
<span id="cb18-7">    num_trials<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># how many combinations of few-shot examples and prompt instructions to try</span></span>
<span id="cb18-8">    seed<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># for reproducibility</span></span>
<span id="cb18-9">    requires_permission_to_run<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># skip confirmation dialog</span></span>
<span id="cb18-10">)</span></code></pre></div>
</div>
<p>We save the optimized predictor to a JSON file. It’s a small config file listing the chosen few-shot examples and the optimized prompt.</p>
<div class="sourceCode" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1">optimized_predictor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> optimizer.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">compile</span>(</span>
<span id="cb19-2">    student<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>predictor, trainset<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>trainset, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>compile_settings</span>
<span id="cb19-3">)</span>
<span id="cb19-4">optimized_predictor.save(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"configs/absa_model.json"</span>)</span></code></pre></div>
<p>Let’s check if we can load it again:</p>
<div id="08ac763f" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1">optimized_predictor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dspy.ChainOfThought(signature<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>AbsaSignature)</span>
<span id="cb20-2">optimized_predictor.load(path<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"configs/absa_model.json"</span>)</span></code></pre></div>
</div>
<p>Again: “Show me the prompt”.</p>
<div id="eaed34bf" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(optimized_predictor.extended_signature.instructions)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>You are a product reviewer tasked with analyzing customer feedback for laptops and netbooks. Given the fields `text`, which contains a customer review, produce the fields `aspects`, which should include the specific features or aspects of the laptop or netbook mentioned in the review, along with their corresponding sentiment or polarity.</code></pre>
</div>
</div>
<p>and show me the chosen few-shot examples:</p>
<div id="e49e8c57" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> demo <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> optimized_predictor.demos[:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>]:  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># first 3 examples</span></span>
<span id="cb23-2">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(demo[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"text"</span>])</span>
<span id="cb23-3">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(demo[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"aspects"</span>])</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>-Called headquarters again, they report that TFT panel is broken, should be fixed by the end of the week (week 3).
{"aspects":[{"term":"TFT panel","polarity":"negative"}]}
But we had paid for bluetooth, and there was none.
{"aspects":[{"term":"bluetooth","polarity":"negative"}]}
The powerpoint opened seamlessly in the apple and the mac hooked up to the projector so easily it was almost scary.
{"aspects":[{"term":"powerpoint","polarity":"positive"}]}</code></pre>
</div>
</div>
</section>
</section>
<section id="evaluation" class="level2">
<h2 class="anchored" data-anchor-id="evaluation">Evaluation</h2>
<p>So far, we’ve only evaluated on the validation part of the training set (this was automatically done by DSPy). Let’s evaluate the optimized predictor on the test set.</p>
<div id="9ebae982" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1">evaluator <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dspy.Evaluate(</span>
<span id="cb25-2">    devset<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>testset,</span>
<span id="cb25-3">    metric<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>evaluate_absa,</span>
<span id="cb25-4">    display_progress<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb25-5">    num_threads<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>,</span>
<span id="cb25-6">)</span></code></pre></div>
</div>
<div id="aab61074" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1">score <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> evaluator(optimized_predictor)</span></code></pre></div>
</div>
<p>The first run yields an F1 score of 47.6. That’s rather poor, but the compiler settings only allow for 4 labeled examples and 1 bootstrapped example and only 3 trials.</p>
</section>
<section id="hyperparameter-optimization" class="level2">
<h2 class="anchored" data-anchor-id="hyperparameter-optimization">Hyperparameter optimization</h2>
<p>What would happen if we changed the hyperparameters? Let’s do a grid search over the number of few-shot examples and the number of trials, as well as try different models.</p>
<div id="d029a7bb" class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> itertools</span>
<span id="cb27-2"></span>
<span id="cb27-3">max_labeled_demos <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">40</span>]</span>
<span id="cb27-4">num_trials <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">15</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">30</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">60</span>]</span>
<span id="cb27-5">chain_of_thought <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>]</span>
<span id="cb27-6"></span>
<span id="cb27-7">default_lm_settings <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">dict</span>(</span>
<span id="cb27-8">    temperature<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span>,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># best for structured outputs, no creativity needed</span></span>
<span id="cb27-9">    cache<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb27-10">    max_tokens<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">250</span>,</span>
<span id="cb27-11">)</span>
<span id="cb27-12"></span>
<span id="cb27-13">lm_settings <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [</span>
<span id="cb27-14">    {</span>
<span id="cb27-15">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"model"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"fireworks_ai/accounts/fireworks/models/llama-v3p1-70b-instruct"</span>,</span>
<span id="cb27-16">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"api_base"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"https://api.fireworks.ai/inference/v1/"</span>,</span>
<span id="cb27-17">        <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>default_lm_settings,</span>
<span id="cb27-18">    },</span>
<span id="cb27-19">    {</span>
<span id="cb27-20">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"model"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"gpt-4o-mini-2024-07-18"</span>,</span>
<span id="cb27-21">        <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>default_lm_settings,</span>
<span id="cb27-22">    },</span>
<span id="cb27-23">]</span>
<span id="cb27-24"></span>
<span id="cb27-25">grid <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>(</span>
<span id="cb27-26">    itertools.product(max_labeled_demos, num_trials, chain_of_thought, lm_settings)</span>
<span id="cb27-27">)</span></code></pre></div>
</div>
<p>This results in a grid with 48 combinations. Next, we iterate over the grid, perform the optimization run and save the results to Weights &amp; Biases.</p>
<div id="d4cf55fc" class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb28" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> os</span>
<span id="cb28-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> copy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> deepcopy</span>
<span id="cb28-3"></span>
<span id="cb28-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> wandb</span>
<span id="cb28-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> tqdm <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> tqdm</span>
<span id="cb28-6"></span>
<span id="cb28-7"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">assert</span> os.getenv(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"FIREWORKS_AI_API_KEY"</span>) <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"FIREWORKS_AI_API_KEY is not set."</span></span>
<span id="cb28-8"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">assert</span> os.getenv(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"OPENAI_API_KEY"</span>) <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"OPENAI_API_KEY is not set."</span></span>
<span id="cb28-9"></span>
<span id="cb28-10"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> max_labeled_demos, num_trials, chain_of_thought, lm_settings <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> tqdm(grid):</span>
<span id="cb28-11"></span>
<span id="cb28-12">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate a filename for the run</span></span>
<span id="cb28-13">    modelname <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> lm_settings[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"model"</span>].replace(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"/"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"_"</span>)</span>
<span id="cb28-14">    cot_name <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cot"</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> chain_of_thought <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"predict"</span></span>
<span id="cb28-15">    run_name <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>modelname<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">_</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>max_labeled_demos<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">_</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>num_trials<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">_</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>cot_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span></span>
<span id="cb28-16">    filepath <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"configs/"</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> run_name <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">".json"</span></span>
<span id="cb28-17"></span>
<span id="cb28-18">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> os.path.exists(filepath):</span>
<span id="cb28-19">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Skipping </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>run_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> because it already exists."</span>)</span>
<span id="cb28-20">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">continue</span></span>
<span id="cb28-21">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb28-22">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Running </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>run_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">."</span>)</span>
<span id="cb28-23"></span>
<span id="cb28-24">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create fresh copies of settings for this run</span></span>
<span id="cb28-25">    run_compile_settings <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> deepcopy(compile_settings)</span>
<span id="cb28-26">    run_optimizer_settings <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> deepcopy(optimizer_settings)</span>
<span id="cb28-27"></span>
<span id="cb28-28">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Update settings</span></span>
<span id="cb28-29">    run_compile_settings[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"max_labeled_demos"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> max_labeled_demos</span>
<span id="cb28-30">    run_compile_settings[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"num_trials"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> num_trials</span>
<span id="cb28-31"></span>
<span id="cb28-32">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> chain_of_thought:</span>
<span id="cb28-33">        predictor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dspy.ChainOfThought(AbsaSignature)</span>
<span id="cb28-34">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb28-35">        predictor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dspy.Predict(AbsaSignature)</span>
<span id="cb28-36"></span>
<span id="cb28-37">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Do an optimization run and evaluate the resulting model</span></span>
<span id="cb28-38">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">try</span>:</span>
<span id="cb28-39">        dspy.configure(lm<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>dspy.LM(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>lm_settings))</span>
<span id="cb28-40">        optimizer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dspy.teleprompt.MIPROv2(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>run_optimizer_settings)</span>
<span id="cb28-41">        optimized_predictor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> optimizer.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">compile</span>(</span>
<span id="cb28-42">            student<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>predictor, trainset<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>trainset, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>run_compile_settings</span>
<span id="cb28-43">        )</span>
<span id="cb28-44">        score <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> evaluator(optimized_predictor)</span>
<span id="cb28-45">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">except</span> <span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">Exception</span> <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> e:</span>
<span id="cb28-46">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(</span>
<span id="cb28-47">            <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Failed run with settings: max_labeled_demos=</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>max_labeled_demos<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">, "</span></span>
<span id="cb28-48">            <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"num_trials=</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>num_trials<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">, model=</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>lm_settings[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'model'</span>]<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span></span>
<span id="cb28-49">        )</span>
<span id="cb28-50">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Error: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>(e)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb28-51">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">continue</span></span>
<span id="cb28-52"></span>
<span id="cb28-53">    optimized_predictor.save(filepath)</span>
<span id="cb28-54"></span>
<span id="cb28-55">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Log experiment to W&amp;B</span></span>
<span id="cb28-56">    config <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb28-57">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"output_schema"</span>: Aspects.model_json_schema(),</span>
<span id="cb28-58">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"compile_settings"</span>: run_compile_settings,</span>
<span id="cb28-59">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"optimizer_settings"</span>: run_optimizer_settings,</span>
<span id="cb28-60">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"lm_settings"</span>: lm_settings,</span>
<span id="cb28-61">    }</span>
<span id="cb28-62"></span>
<span id="cb28-63">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> wandb.init(project<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"absa-dspy"</span>, config<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>config, name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>run_name) <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> run:</span>
<span id="cb28-64">        wandb.log({<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"f1"</span>: score})</span>
<span id="cb28-65">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Save config to artifact</span></span>
<span id="cb28-66">        artifact <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> wandb.Artifact(</span>
<span id="cb28-67">            name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"dspy_config_</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>run_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>,</span>
<span id="cb28-68">            <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">type</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"config"</span>, </span>
<span id="cb28-69">            description<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Config file for </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>run_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span></span>
<span id="cb28-70">        )</span>
<span id="cb28-71">        artifact.add_file(filepath)</span>
<span id="cb28-72">        run.log_artifact(artifact)</span></code></pre></div>
</div>
</section>
<section id="comparison-with-manual-prompts" class="level2">
<h2 class="anchored" data-anchor-id="comparison-with-manual-prompts">Comparison with manual prompts</h2>
<p>In the 2023 paper, co-author and I manually crafted prompts and chose few-shot examples that, in our opinion, illustrated the task well. Inference was done using the OpenAI API and using function calling to ensure structured outputs. To make the comparison fair, we’ll now use the same prompts within DSPy.</p>
<p>The manual prompts and few-shot examples are available on <a href="https://github.com/psimm/website/blob/master/blog/absa-with-dspy/configs/manual_prompt.json">Github</a>.</p>
<p>The models <code>gpt-4-0613</code> and <code>gpt-3.5-turbo-0613</code> that were used in the 2023 paper are no longer available on the OpenAI API. Therefore, we use the closest substitutes here.</p>
<div id="88dcd13e" class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb29" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1">models <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [</span>
<span id="cb29-2">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"gpt-4o-2024-11-20"</span>,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># similar to gpt-4-0613</span></span>
<span id="cb29-3">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"gpt-3.5-turbo-0125"</span>,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># similar to gpt-3.5-turbo-0613</span></span>
<span id="cb29-4">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"gpt-4o-mini-2024-07-18"</span>,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># reference</span></span>
<span id="cb29-5">]</span>
<span id="cb29-6"></span>
<span id="cb29-7">manual_predictor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dspy.Predict(AbsaSignature)</span>
<span id="cb29-8">manual_predictor.load(path<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"configs/manual_prompt.json"</span>)</span>
<span id="cb29-9"></span>
<span id="cb29-10"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> model <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> models:</span>
<span id="cb29-11">    lm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dspy.LM(</span>
<span id="cb29-12">        model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>model,</span>
<span id="cb29-13">        temperature<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,</span>
<span id="cb29-14">        cache<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb29-15">        max_tokens<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">250</span>,</span>
<span id="cb29-16">    )</span>
<span id="cb29-17">    dspy.configure(lm<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>lm)</span>
<span id="cb29-18">    score <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> evaluator(manual_predictor)</span>
<span id="cb29-19">    runname <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>model<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">_manual_prompt"</span></span>
<span id="cb29-20"></span>
<span id="cb29-21">    config <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb29-22">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"output_schema"</span>: Aspects.model_json_schema(),</span>
<span id="cb29-23">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"compile_settings"</span>: {</span>
<span id="cb29-24">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"max_labeled_demos"</span>: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(manual_predictor.demos),</span>
<span id="cb29-25">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"max_bootstrapped_demos"</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,</span>
<span id="cb29-26">        },</span>
<span id="cb29-27">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"lm_settings"</span>: {</span>
<span id="cb29-28">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"model"</span>: model,</span>
<span id="cb29-29">        },</span>
<span id="cb29-30">    }</span>
<span id="cb29-31"></span>
<span id="cb29-32">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> wandb.init(project<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"absa-dspy"</span>, name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>runname, config<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>config) <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> run:</span>
<span id="cb29-33">        wandb.log({<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"f1"</span>: score})</span>
<span id="cb29-34">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Save manual prompt to artifact</span></span>
<span id="cb29-35">        artifact <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> wandb.Artifact(</span>
<span id="cb29-36">            name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"dspy_config_</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>runname<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>,</span>
<span id="cb29-37">            <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">type</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"model"</span>,</span>
<span id="cb29-38">            description<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Manual prompt configuration"</span></span>
<span id="cb29-39">        )</span>
<span id="cb29-40">        artifact.add_file(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"configs/manual_prompt.json"</span>)</span>
<span id="cb29-41">        run.log_artifact(artifact)</span></code></pre></div>
</div>
</section>
<section id="results-and-discussion" class="level2">
<h2 class="anchored" data-anchor-id="results-and-discussion">Results and discussion</h2>
<p>We load the results from the Weights &amp; Biases project and show the most relevant columns for a comparison of the runs.</p>
<div id="a36f5554" class="cell" data-execution_count="23">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb30" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> wandb</span>
<span id="cb30-2"></span>
<span id="cb30-3">api <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> wandb.Api()</span>
<span id="cb30-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get all runs from the project</span></span>
<span id="cb30-5">runs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> api.runs(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"psimm/absa-dspy"</span>)</span>
<span id="cb30-6"></span>
<span id="cb30-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Convert to DataFrame</span></span>
<span id="cb30-8">results <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb30-9"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> run <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> runs:</span>
<span id="cb30-10">    results.append(</span>
<span id="cb30-11">        {</span>
<span id="cb30-12">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"run_name"</span>: run.name,</span>
<span id="cb30-13">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"model"</span>: run.config[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"lm_settings"</span>][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"model"</span>],</span>
<span id="cb30-14">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"max_demos"</span>: run.config[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"compile_settings"</span>][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"max_labeled_demos"</span>],</span>
<span id="cb30-15">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"max_bootstrapped_demos"</span>: run.config[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"compile_settings"</span>][</span>
<span id="cb30-16">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"max_bootstrapped_demos"</span></span>
<span id="cb30-17">            ],</span>
<span id="cb30-18">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"num_trials"</span>: run.config.get(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"compile_settings"</span>, {}).get(</span>
<span id="cb30-19">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"num_trials"</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span></span>
<span id="cb30-20">            ),</span>
<span id="cb30-21">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"chain_of_thought"</span>: run.config[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"chain_of_thought"</span>],</span>
<span id="cb30-22">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"f1"</span>: run.summary[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"f1"</span>],</span>
<span id="cb30-23">        }</span>
<span id="cb30-24">    )</span>
<span id="cb30-25"></span>
<span id="cb30-26">results_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pl.DataFrame(results)</span>
<span id="cb30-27"></span>
<span id="cb30-28">table_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (</span>
<span id="cb30-29">    results_df.with_columns(</span>
<span id="cb30-30">        method<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>pl.when(pl.col(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"run_name"</span>).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>.contains(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"manual"</span>))</span>
<span id="cb30-31">        .then(pl.lit(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Manual (2023)"</span>))</span>
<span id="cb30-32">        .otherwise(pl.lit(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"DSPy"</span>)),</span>
<span id="cb30-33">        model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>pl.col(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"model"</span>).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>.replace(</span>
<span id="cb30-34">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"fireworks_ai/accounts/fireworks/models/"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span></span>
<span id="cb30-35">        ),</span>
<span id="cb30-36">        demos<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>pl.when(pl.col(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"max_bootstrapped_demos"</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb30-37">        .then(pl.col(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"max_demos"</span>).cast(pl.Utf8))</span>
<span id="cb30-38">        .otherwise(</span>
<span id="cb30-39">            pl.col(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"max_demos"</span>).cast(pl.Utf8)</span>
<span id="cb30-40">            <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">" + "</span></span>
<span id="cb30-41">            <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> pl.col(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"max_bootstrapped_demos"</span>).cast(pl.Utf8)</span>
<span id="cb30-42">        ),</span>
<span id="cb30-43">        chain_of_thought<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>pl.when(pl.col(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"chain_of_thought"</span>))</span>
<span id="cb30-44">        .then(pl.lit(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"✅"</span>))</span>
<span id="cb30-45">        .otherwise(pl.lit(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"❌"</span>)),</span>
<span id="cb30-46">    )</span>
<span id="cb30-47">    .sort(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"f1"</span>, descending<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb30-48">    .select(</span>
<span id="cb30-49">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"model"</span>,</span>
<span id="cb30-50">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"method"</span>,</span>
<span id="cb30-51">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"num_trials"</span>,</span>
<span id="cb30-52">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"demos"</span>,</span>
<span id="cb30-53">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"chain_of_thought"</span>,</span>
<span id="cb30-54">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"f1"</span>,</span>
<span id="cb30-55">    )</span>
<span id="cb30-56">)</span>
<span id="cb30-57"></span>
<span id="cb30-58">GT(table_df).tab_header(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"SemEval 2014 Task 4 1+2 Few-Shot Predictors"</span>).cols_label(</span>
<span id="cb30-59">    model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Model"</span>,</span>
<span id="cb30-60">    method<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Method"</span>,</span>
<span id="cb30-61">    demos<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Examples¹"</span>,</span>
<span id="cb30-62">    num_trials<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Trials"</span>,</span>
<span id="cb30-63">    chain_of_thought<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"CoT"</span>,</span>
<span id="cb30-64">    f1<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"F1"</span>,</span>
<span id="cb30-65">).cols_align(align<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"right"</span>, columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"demos"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"num_trials"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"f1"</span>]).fmt_number(</span>
<span id="cb30-66">    columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"f1"</span>], decimals<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span></span>
<span id="cb30-67">).tab_source_note(</span>
<span id="cb30-68">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"¹ Bootstrapped + labeled examples. Notes: Limited Llama 3.1 70B non-CoT runs due to API constraints. Manual prompt runs use 10 examples vs. 6 in original paper."</span></span>
<span id="cb30-69">)</span></code></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="20">
<div id="fhjsfutory" style="padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>
#fhjsfutory table {
          font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;
          -webkit-font-smoothing: antialiased;
          -moz-osx-font-smoothing: grayscale;
        }

#fhjsfutory thead, tbody, tfoot, tr, td, th { border-style: none; }
 tr { background-color: transparent; }
#fhjsfutory p { margin: 0; padding: 0; }
 #fhjsfutory .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; }
 #fhjsfutory .gt_caption { padding-top: 4px; padding-bottom: 4px; }
 #fhjsfutory .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; }
 #fhjsfutory .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; }
 #fhjsfutory .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; }
 #fhjsfutory .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; }
 #fhjsfutory .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; }
 #fhjsfutory .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; }
 #fhjsfutory .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; }
 #fhjsfutory .gt_column_spanner_outer:first-child { padding-left: 0; }
 #fhjsfutory .gt_column_spanner_outer:last-child { padding-right: 0; }
 #fhjsfutory .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; }
 #fhjsfutory .gt_spanner_row { border-bottom-style: hidden; }
 #fhjsfutory .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; }
 #fhjsfutory .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; }
 #fhjsfutory .gt_from_md> :first-child { margin-top: 0; }
 #fhjsfutory .gt_from_md> :last-child { margin-bottom: 0; }
 #fhjsfutory .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; }
 #fhjsfutory .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; }
 #fhjsfutory .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; }
 #fhjsfutory .gt_row_group_first td { border-top-width: 2px; }
 #fhjsfutory .gt_row_group_first th { border-top-width: 2px; }
 #fhjsfutory .gt_striped { background-color: rgba(128,128,128,0.05); }
 #fhjsfutory .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; }
 #fhjsfutory .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; }
 #fhjsfutory .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; text-align: left; }
 #fhjsfutory .gt_left { text-align: left; }
 #fhjsfutory .gt_center { text-align: center; }
 #fhjsfutory .gt_right { text-align: right; font-variant-numeric: tabular-nums; }
 #fhjsfutory .gt_font_normal { font-weight: normal; }
 #fhjsfutory .gt_font_bold { font-weight: bold; }
 #fhjsfutory .gt_font_italic { font-style: italic; }
 #fhjsfutory .gt_super { font-size: 65%; }
 #fhjsfutory .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; }
 #fhjsfutory .gt_asterisk { font-size: 100%; vertical-align: 0; }
 
</style>

<table class="gt_table caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-quarto-disable-processing="false" data-quarto-bootstrap="false">
<thead>
<tr class="gt_heading header">
<th colspan="6" class="gt_heading gt_title gt_font_normal">SemEval 2014 Task 4 1+2 Few-Shot Predictors</th>
</tr>
<tr class="gt_col_headings even">
<th id="Model" class="gt_col_heading gt_columns_bottom_border gt_left" data-quarto-table-cell-role="th" scope="col">Model</th>
<th id="Method" class="gt_col_heading gt_columns_bottom_border gt_left" data-quarto-table-cell-role="th" scope="col">Method</th>
<th id="Trials" class="gt_col_heading gt_columns_bottom_border gt_right" data-quarto-table-cell-role="th" scope="col">Trials</th>
<th id="Examples¹" class="gt_col_heading gt_columns_bottom_border gt_right" data-quarto-table-cell-role="th" scope="col">Examples¹</th>
<th id="CoT" class="gt_col_heading gt_columns_bottom_border gt_left" data-quarto-table-cell-role="th" scope="col">CoT</th>
<th id="F1" class="gt_col_heading gt_columns_bottom_border gt_right" data-quarto-table-cell-role="th" scope="col">F1</th>
</tr>
</thead>
<tbody class="gt_table_body">
<tr class="odd">
<td class="gt_row gt_left">gpt-4o-2024-11-20</td>
<td class="gt_row gt_left">Manual (2023)</td>
<td class="gt_row gt_right">None</td>
<td class="gt_row gt_right">10</td>
<td class="gt_row gt_left">❌</td>
<td class="gt_row gt_right">71.28</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">15</td>
<td class="gt_row gt_right">40 + 1</td>
<td class="gt_row gt_left">❌</td>
<td class="gt_row gt_right">62.83</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">llama-v3p1-70b-instruct</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">60</td>
<td class="gt_row gt_right">5 + 1</td>
<td class="gt_row gt_left">❌</td>
<td class="gt_row gt_right">61.49</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">60</td>
<td class="gt_row gt_right">10 + 1</td>
<td class="gt_row gt_left">❌</td>
<td class="gt_row gt_right">61.34</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">15</td>
<td class="gt_row gt_right">20 + 1</td>
<td class="gt_row gt_left">❌</td>
<td class="gt_row gt_right">60.87</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">30</td>
<td class="gt_row gt_right">20 + 1</td>
<td class="gt_row gt_left">❌</td>
<td class="gt_row gt_right">60.87</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">60</td>
<td class="gt_row gt_right">20 + 1</td>
<td class="gt_row gt_left">❌</td>
<td class="gt_row gt_right">60.87</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">llama-v3p1-70b-instruct</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">15</td>
<td class="gt_row gt_right">40 + 1</td>
<td class="gt_row gt_left">❌</td>
<td class="gt_row gt_right">60.32</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">llama-v3p1-70b-instruct</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">60</td>
<td class="gt_row gt_right">5 + 1</td>
<td class="gt_row gt_left">✅</td>
<td class="gt_row gt_right">60.27</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">60</td>
<td class="gt_row gt_right">40 + 1</td>
<td class="gt_row gt_left">✅</td>
<td class="gt_row gt_right">59.80</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">15</td>
<td class="gt_row gt_right">20 + 1</td>
<td class="gt_row gt_left">✅</td>
<td class="gt_row gt_right">59.68</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">30</td>
<td class="gt_row gt_right">20 + 1</td>
<td class="gt_row gt_left">✅</td>
<td class="gt_row gt_right">59.68</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">60</td>
<td class="gt_row gt_right">20 + 1</td>
<td class="gt_row gt_left">✅</td>
<td class="gt_row gt_right">59.68</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">30</td>
<td class="gt_row gt_right">40 + 1</td>
<td class="gt_row gt_left">✅</td>
<td class="gt_row gt_right">59.60</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">15</td>
<td class="gt_row gt_right">40 + 1</td>
<td class="gt_row gt_left">✅</td>
<td class="gt_row gt_right">59.32</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">60</td>
<td class="gt_row gt_right">5 + 1</td>
<td class="gt_row gt_left">❌</td>
<td class="gt_row gt_right">58.83</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">llama-v3p1-70b-instruct</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">30</td>
<td class="gt_row gt_right">10 + 1</td>
<td class="gt_row gt_left">❌</td>
<td class="gt_row gt_right">58.79</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">llama-v3p1-70b-instruct</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">60</td>
<td class="gt_row gt_right">10 + 1</td>
<td class="gt_row gt_left">❌</td>
<td class="gt_row gt_right">58.79</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">llama-v3p1-70b-instruct</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">30</td>
<td class="gt_row gt_right">5 + 1</td>
<td class="gt_row gt_left">❌</td>
<td class="gt_row gt_right">58.36</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">llama-v3p1-70b-instruct</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">60</td>
<td class="gt_row gt_right">20 + 1</td>
<td class="gt_row gt_left">❌</td>
<td class="gt_row gt_right">57.98</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">llama-v3p1-70b-instruct</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">30</td>
<td class="gt_row gt_right">20 + 1</td>
<td class="gt_row gt_left">❌</td>
<td class="gt_row gt_right">57.84</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">gpt-3.5-turbo-0125</td>
<td class="gt_row gt_left">Manual (2023)</td>
<td class="gt_row gt_right">None</td>
<td class="gt_row gt_right">10</td>
<td class="gt_row gt_left">❌</td>
<td class="gt_row gt_right">57.45</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">llama-v3p1-70b-instruct</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">60</td>
<td class="gt_row gt_right">40 + 1</td>
<td class="gt_row gt_left">✅</td>
<td class="gt_row gt_right">56.46</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">Manual (2023)</td>
<td class="gt_row gt_right">None</td>
<td class="gt_row gt_right">10</td>
<td class="gt_row gt_left">❌</td>
<td class="gt_row gt_right">55.67</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">llama-v3p1-70b-instruct</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">15</td>
<td class="gt_row gt_right">20 + 1</td>
<td class="gt_row gt_left">❌</td>
<td class="gt_row gt_right">54.90</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">llama-v3p1-70b-instruct</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">60</td>
<td class="gt_row gt_right">10 + 1</td>
<td class="gt_row gt_left">✅</td>
<td class="gt_row gt_right">54.33</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">llama-v3p1-70b-instruct</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">15</td>
<td class="gt_row gt_right">40 + 1</td>
<td class="gt_row gt_left">✅</td>
<td class="gt_row gt_right">54.09</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">llama-v3p1-70b-instruct</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">30</td>
<td class="gt_row gt_right">40 + 1</td>
<td class="gt_row gt_left">✅</td>
<td class="gt_row gt_right">54.09</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">15</td>
<td class="gt_row gt_right">5 + 1</td>
<td class="gt_row gt_left">❌</td>
<td class="gt_row gt_right">53.70</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">30</td>
<td class="gt_row gt_right">5 + 1</td>
<td class="gt_row gt_left">❌</td>
<td class="gt_row gt_right">53.70</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">llama-v3p1-70b-instruct</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">30</td>
<td class="gt_row gt_right">5 + 1</td>
<td class="gt_row gt_left">✅</td>
<td class="gt_row gt_right">53.05</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">60</td>
<td class="gt_row gt_right">10 + 1</td>
<td class="gt_row gt_left">✅</td>
<td class="gt_row gt_right">52.64</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">15</td>
<td class="gt_row gt_right">10 + 1</td>
<td class="gt_row gt_left">❌</td>
<td class="gt_row gt_right">51.19</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">30</td>
<td class="gt_row gt_right">10 + 1</td>
<td class="gt_row gt_left">❌</td>
<td class="gt_row gt_right">51.19</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">15</td>
<td class="gt_row gt_right">5 + 1</td>
<td class="gt_row gt_left">✅</td>
<td class="gt_row gt_right">51.16</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">30</td>
<td class="gt_row gt_right">5 + 1</td>
<td class="gt_row gt_left">✅</td>
<td class="gt_row gt_right">51.16</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">60</td>
<td class="gt_row gt_right">5 + 1</td>
<td class="gt_row gt_left">✅</td>
<td class="gt_row gt_right">51.16</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">llama-v3p1-70b-instruct</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">30</td>
<td class="gt_row gt_right">20 + 1</td>
<td class="gt_row gt_left">✅</td>
<td class="gt_row gt_right">50.90</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">llama-v3p1-70b-instruct</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">60</td>
<td class="gt_row gt_right">20 + 1</td>
<td class="gt_row gt_left">✅</td>
<td class="gt_row gt_right">50.90</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">30</td>
<td class="gt_row gt_right">10 + 1</td>
<td class="gt_row gt_left">✅</td>
<td class="gt_row gt_right">49.97</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">15</td>
<td class="gt_row gt_right">10 + 1</td>
<td class="gt_row gt_left">✅</td>
<td class="gt_row gt_right">49.74</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">llama-v3p1-70b-instruct</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">15</td>
<td class="gt_row gt_right">20 + 1</td>
<td class="gt_row gt_left">✅</td>
<td class="gt_row gt_right">49.47</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">llama-v3p1-70b-instruct</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">15</td>
<td class="gt_row gt_right">10 + 1</td>
<td class="gt_row gt_left">❌</td>
<td class="gt_row gt_right">48.63</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">llama-v3p1-70b-instruct</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">15</td>
<td class="gt_row gt_right">5 + 1</td>
<td class="gt_row gt_left">✅</td>
<td class="gt_row gt_right">47.73</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">llama-v3p1-70b-instruct</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">30</td>
<td class="gt_row gt_right">10 + 1</td>
<td class="gt_row gt_left">✅</td>
<td class="gt_row gt_right">47.30</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">llama-v3p1-70b-instruct</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">15</td>
<td class="gt_row gt_right">5 + 1</td>
<td class="gt_row gt_left">❌</td>
<td class="gt_row gt_right">46.46</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">llama-v3p1-70b-instruct</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">15</td>
<td class="gt_row gt_right">10 + 1</td>
<td class="gt_row gt_left">✅</td>
<td class="gt_row gt_right">46.31</td>
</tr>
</tbody><tfoot class="gt_sourcenotes">
<tr class="odd">
<td colspan="6" class="gt_sourcenote">¹ Bootstrapped + labeled examples. Notes: Limited Llama 3.1 70B non-CoT runs due to API constraints. Manual prompt runs use 10 examples vs. 6 in original paper.</td>
</tr>
</tfoot>

</table>


</div>
        
</div>
</div>
<section id="comparison-to-the-2023-manual-prompts" class="level3">
<h3 class="anchored" data-anchor-id="comparison-to-the-2023-manual-prompts">Comparison to the 2023 manual prompts</h3>
<p>The DSPy runs are competitive with the manually crafted prompts from the 2023 paper. In contrast to the manual prompt, DSPy instructions are relatively short and emphasize the use of few-shot examples to illustrate the task.</p>
</section>
<section id="impact-of-hyperparameters" class="level3">
<h3 class="anchored" data-anchor-id="impact-of-hyperparameters">Impact of hyperparameters</h3>
<p>To understand which factors significantly influence the F1 score, we’ll run a simple linear regression analysis. The manual runs are excluded. To analyze the impact of the model choice, we’ll create a boolean variable for <code>gpt-4o-mini</code> and treat <code>llama-v3p1-70b-instruct</code> as the baseline.</p>
<div id="6973a37c" class="cell" data-execution_count="24">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb31" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> statsmodels.api <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> sm</span>
<span id="cb31-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb31-3"></span>
<span id="cb31-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Prepare data for regression</span></span>
<span id="cb31-5">reg_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> results_df.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">filter</span>(</span>
<span id="cb31-6">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">~</span>pl.col(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"run_name"</span>).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>.contains(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"manual"</span>),</span>
<span id="cb31-7">    pl.col(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"model"</span>).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>.contains(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"gpt-4o-mini"</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">|</span> pl.col(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"model"</span>).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>.contains(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"llama"</span>),</span>
<span id="cb31-8">).with_columns(  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># exclude manual prompts</span></span>
<span id="cb31-9">    pl.col(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"model"</span>).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>.contains(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"gpt-4o-mini"</span>).alias(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"is_gpt4_mini"</span>),</span>
<span id="cb31-10">)</span>
<span id="cb31-11"></span>
<span id="cb31-12"></span>
<span id="cb31-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Convert to pandas and ensure numeric types</span></span>
<span id="cb31-14">X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> reg_df.select(</span>
<span id="cb31-15">    [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"max_demos"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"chain_of_thought"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"num_trials"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"is_gpt4_mini"</span>]</span>
<span id="cb31-16">).to_pandas()</span>
<span id="cb31-17"></span>
<span id="cb31-18"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Convert boolean columns to int</span></span>
<span id="cb31-19">bool_columns <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"chain_of_thought"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"is_gpt4_mini"</span>]</span>
<span id="cb31-20"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> col <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> bool_columns:</span>
<span id="cb31-21">    X[col] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> X[col].astype(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>)</span>
<span id="cb31-22"></span>
<span id="cb31-23">y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> reg_df.select(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"f1"</span>).to_pandas()</span>
<span id="cb31-24"></span>
<span id="cb31-25"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Add constant for intercept</span></span>
<span id="cb31-26">X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> sm.add_constant(X)</span>
<span id="cb31-27"></span>
<span id="cb31-28"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Fit regression</span></span>
<span id="cb31-29">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> sm.OLS(y, X).fit()</span>
<span id="cb31-30">n <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(reg_df)</span>
<span id="cb31-31">r2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.rsquared</span>
<span id="cb31-32"></span>
<span id="cb31-33"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Print results using GT</span></span>
<span id="cb31-34">df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame(</span>
<span id="cb31-35">    model.summary().tables[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>],</span>
<span id="cb31-36">    columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[</span>
<span id="cb31-37">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Parameter"</span>,</span>
<span id="cb31-38">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Coefficient"</span>,</span>
<span id="cb31-39">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Std Error"</span>,</span>
<span id="cb31-40">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"t"</span>,</span>
<span id="cb31-41">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"p&gt;|t|"</span>,</span>
<span id="cb31-42">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"[0.025"</span>,</span>
<span id="cb31-43">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"0.975]"</span>,</span>
<span id="cb31-44">    ],</span>
<span id="cb31-45">)</span>
<span id="cb31-46"></span>
<span id="cb31-47">df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df.iloc[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>:]  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># remove row with repeated column names</span></span>
<span id="cb31-48"></span>
<span id="cb31-49">GT(df).tab_header(</span>
<span id="cb31-50">    title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Hyperparameter Analysis"</span>, subtitle<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Dependent variable: F1 score"</span></span>
<span id="cb31-51">).cols_align(align<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"right"</span>).tab_source_note(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"n=</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>n<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> runs, R²=</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>r2<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.2f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span></code></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="21">
<div id="weybrcaczr" style="padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>
#weybrcaczr table {
          font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;
          -webkit-font-smoothing: antialiased;
          -moz-osx-font-smoothing: grayscale;
        }

#weybrcaczr thead, tbody, tfoot, tr, td, th { border-style: none; }
 tr { background-color: transparent; }
#weybrcaczr p { margin: 0; padding: 0; }
 #weybrcaczr .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; }
 #weybrcaczr .gt_caption { padding-top: 4px; padding-bottom: 4px; }
 #weybrcaczr .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; }
 #weybrcaczr .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; }
 #weybrcaczr .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; }
 #weybrcaczr .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; }
 #weybrcaczr .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; }
 #weybrcaczr .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; }
 #weybrcaczr .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; }
 #weybrcaczr .gt_column_spanner_outer:first-child { padding-left: 0; }
 #weybrcaczr .gt_column_spanner_outer:last-child { padding-right: 0; }
 #weybrcaczr .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; }
 #weybrcaczr .gt_spanner_row { border-bottom-style: hidden; }
 #weybrcaczr .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; }
 #weybrcaczr .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; }
 #weybrcaczr .gt_from_md> :first-child { margin-top: 0; }
 #weybrcaczr .gt_from_md> :last-child { margin-bottom: 0; }
 #weybrcaczr .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; }
 #weybrcaczr .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; }
 #weybrcaczr .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; }
 #weybrcaczr .gt_row_group_first td { border-top-width: 2px; }
 #weybrcaczr .gt_row_group_first th { border-top-width: 2px; }
 #weybrcaczr .gt_striped { background-color: rgba(128,128,128,0.05); }
 #weybrcaczr .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; }
 #weybrcaczr .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; }
 #weybrcaczr .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; text-align: left; }
 #weybrcaczr .gt_left { text-align: left; }
 #weybrcaczr .gt_center { text-align: center; }
 #weybrcaczr .gt_right { text-align: right; font-variant-numeric: tabular-nums; }
 #weybrcaczr .gt_font_normal { font-weight: normal; }
 #weybrcaczr .gt_font_bold { font-weight: bold; }
 #weybrcaczr .gt_font_italic { font-style: italic; }
 #weybrcaczr .gt_super { font-size: 65%; }
 #weybrcaczr .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; }
 #weybrcaczr .gt_asterisk { font-size: 100%; vertical-align: 0; }
 
</style>

<table class="gt_table caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-quarto-disable-processing="false" data-quarto-bootstrap="false">
<thead>
<tr class="gt_heading header">
<th colspan="7" class="gt_heading gt_title gt_font_normal">Hyperparameter Analysis</th>
</tr>
<tr class="gt_heading even">
<th colspan="7" class="gt_heading gt_subtitle gt_font_normal gt_bottom_border">Dependent variable: F1 score</th>
</tr>
<tr class="gt_col_headings header">
<th id="Parameter" class="gt_col_heading gt_columns_bottom_border gt_right" data-quarto-table-cell-role="th" scope="col">Parameter</th>
<th id="Coefficient" class="gt_col_heading gt_columns_bottom_border gt_right" data-quarto-table-cell-role="th" scope="col">Coefficient</th>
<th id="Std Error" class="gt_col_heading gt_columns_bottom_border gt_right" data-quarto-table-cell-role="th" scope="col">Std Error</th>
<th id="t" class="gt_col_heading gt_columns_bottom_border gt_right" data-quarto-table-cell-role="th" scope="col">t</th>
<th id="p&amp;gt;|t|" class="gt_col_heading gt_columns_bottom_border gt_right" data-quarto-table-cell-role="th" scope="col">p&gt;|t|</th>
<th id="[0.025" class="gt_col_heading gt_columns_bottom_border gt_right" data-quarto-table-cell-role="th" scope="col">[0.025</th>
<th id="0.975]" class="gt_col_heading gt_columns_bottom_border gt_right" data-quarto-table-cell-role="th" scope="col">0.975]</th>
</tr>
</thead>
<tbody class="gt_table_body">
<tr class="odd">
<td class="gt_row gt_right">const</td>
<td class="gt_row gt_right">49.3654</td>
<td class="gt_row gt_right">1.457</td>
<td class="gt_row gt_right">33.885</td>
<td class="gt_row gt_right">0.000</td>
<td class="gt_row gt_right">46.419</td>
<td class="gt_row gt_right">52.312</td>
</tr>
<tr class="even">
<td class="gt_row gt_right">max_demos</td>
<td class="gt_row gt_right">0.2021</td>
<td class="gt_row gt_right">0.042</td>
<td class="gt_row gt_right">4.794</td>
<td class="gt_row gt_right">0.000</td>
<td class="gt_row gt_right">0.117</td>
<td class="gt_row gt_right">0.287</td>
</tr>
<tr class="odd">
<td class="gt_row gt_right">chain_of_thought</td>
<td class="gt_row gt_right">-4.3317</td>
<td class="gt_row gt_right">1.038</td>
<td class="gt_row gt_right">-4.172</td>
<td class="gt_row gt_right">0.000</td>
<td class="gt_row gt_right">-6.432</td>
<td class="gt_row gt_right">-2.232</td>
</tr>
<tr class="even">
<td class="gt_row gt_right">num_trials</td>
<td class="gt_row gt_right">0.1062</td>
<td class="gt_row gt_right">0.027</td>
<td class="gt_row gt_right">3.892</td>
<td class="gt_row gt_right">0.000</td>
<td class="gt_row gt_right">0.051</td>
<td class="gt_row gt_right">0.161</td>
</tr>
<tr class="odd">
<td class="gt_row gt_right">is_gpt4_mini</td>
<td class="gt_row gt_right">2.2964</td>
<td class="gt_row gt_right">1.016</td>
<td class="gt_row gt_right">2.260</td>
<td class="gt_row gt_right">0.029</td>
<td class="gt_row gt_right">0.241</td>
<td class="gt_row gt_right">4.351</td>
</tr>
</tbody><tfoot class="gt_sourcenotes">
<tr class="odd">
<td colspan="7" class="gt_sourcenote">n=44 runs, R²=0.56</td>
</tr>
</tfoot>

</table>


</div>
        
</div>
</div>
</section>
<section id="few-shot-examples" class="level3">
<h3 class="anchored" data-anchor-id="few-shot-examples">Few-shot examples</h3>
<p>More examples are generally better, as indicated by the positive coefficient in the regression. However, the top runs didn’t use more than 20 examples, indicating that there are diminishing returns.</p>
</section>
<section id="chain-of-thought-cot" class="level3">
<h3 class="anchored" data-anchor-id="chain-of-thought-cot">Chain of thought (CoT)</h3>
<p>Runs where the model was instructed to perform an intermediate reasoning step yielded worse results than those without. This is an unusual result - typically CoT helps LLMs achieve better results, for example the main advantage of OpenAI’s <code>o1-preview</code> over <code>gpt-4o</code> is the advanced CoT that is built into it. However, on this structured task and using DSPy’s <code>Predictor</code> and <code>ChainOfThought</code> classes, CoT seems to be detrimental.</p>
</section>
<section id="model-choice" class="level3">
<h3 class="anchored" data-anchor-id="model-choice">Model choice</h3>
<ul>
<li><code>gpt-4o-mini-2024-07-18</code> seems to have an edge over <code>llama-v3p1-70b-instruct</code>, but the confidence interval is wide.</li>
<li><code>gpt-4o-2024-11-20</code> performs better than the other models that were tested. I expect that performance of similar sized models such as <code>Llama 3.1 405B</code> will be similar. Due to cost considerations, I’ve skipped the optimization of a large model with DSPy.</li>
<li><code>gpt-3.5-turbo-0125</code> performed better than <code>gpt-4o-mini-2024-07-18</code>, but worse than the deprecated <code>gpt-3.5-turbo-0613</code> performed during the experiments for the 2023 paper (57.45 vs.&nbsp;65.65 F1 Score).</li>
</ul>
</section>
<section id="number-of-trials" class="level3">
<h3 class="anchored" data-anchor-id="number-of-trials">Number of trials</h3>
<p>Using more trials is associated with higher F1 scores. However, the table also shows setups with identical results at 15, 30 and 60 trials. Going beyond 60 trials isn’t likely to be helpful.</p>
</section>
</section>
<section id="review-of-dspy" class="level2">
<h2 class="anchored" data-anchor-id="review-of-dspy">Review of DSPy</h2>
<p>Here are my conclusions based on this experiment.</p>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Pros ✅</strong></p>
<ul>
<li>Creates prompts that are as good as or better than manually crafted prompts.</li>
<li>No need to manually craft prompts, leading to faster iteration speed.</li>
<li>Able to deal with multi-step workflows.</li>
<li>Naturally encourages a structured approach focused on evaluation.</li>
<li>Supports many LLMs, via APIs and locally.</li>
<li>Lightweight JSON export of the optimized prompts.</li>
<li>Supports custom evaluation metrics.</li>
<li>Built-in threading and caching, which saved me time and money.</li>
<li>Actively developed and has a large community.</li>
<li>Lots of <a href="https://github.com/stanfordnlp/dspy/tree/main/examples">tutorial notebooks</a>.</li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>Cons ❌</strong></p>
<ul>
<li>Generated prompts seem too short to explain the nuances of the task, placing a lot of burden on the few-shot examples. They need to implicitly explain the annotation rules and cover all relevant cases.</li>
<li>Loss of control over the exact prompt. But arguably, if you want to control the prompt DSPy is not the approach to go for anyway.</li>
<li>Adds a layer of abstraction to a stack that’s already complex.</li>
<li>Structured output is not guaranteed, because it’s based on prompting only. Integration with function calling, JSON mode or constrained generation APIs and libraries would improve the reliability of the format.</li>
<li>Steep learning curve with many concepts to understand.</li>
<li>I encountered some bugs and deprecated functions and tutorials.</li>
</ul>
</div>
</div>
<p>DSPy is a great alternative to manual prompting, especially for tasks that have a clear evaluation metric and are demonstrable using few-shot examples. The high variability in the results of my grid search experiment indicates that it’s necessary to run DSPy multiple times with different settings to find the best performing configuration.</p>
<p>A feature that I haven’t explored here is the fine-tuning <a href="https://dspy.ai/learn/optimization/optimizers/?h=fine#automatic-finetuning">optimizer</a> of DSPy that actually modifies the model weights. It’s promising for this task, as a fine-tuned <code>gpt-3.5-turbo-0613</code> is still the <a href="https://paperswithcode.com/sota/aspect-based-sentiment-analysis-on-semeval-6">record holder</a> at an F1 score of 83.76.</p>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0">
<div id="ref-opsahlong2024optimizinginstructionsdemonstrationsmultistage" class="csl-entry">
Opsahl-Ong, Krista, Michael J Ryan, Josh Purtell, David Broman, Christopher Potts, Matei Zaharia, and Omar Khattab. 2024. <span>“Optimizing Instructions and Demonstrations for Multi-Stage Language Model Programs.”</span> <a href="https://arxiv.org/abs/2406.11695">https://arxiv.org/abs/2406.11695</a>.
</div>
<div id="ref-pontiki_semeval" class="csl-entry">
Pontiki, Maria, Dimitris Galanis, John Pavlopoulos, Harris Papageorgiou, Ion Androutsopoulos, and Suresh Manandhar. 2014. <span>“<span>SemEval</span>-2014 <span>Task</span> 4: <span>Aspect</span> <span>Based</span> <span>Sentiment</span> <span>Analysis</span>.”</span> In <em>Proceedings of the 8th <span>International</span> <span>Workshop</span> on <span>Semantic</span> <span>Evaluation</span> (<span>SemEval</span> 2014)</em>, 27–35. Dublin, Ireland: Association for Computational Linguistics. <a href="https://doi.org/10.3115/v1/S14-2004">https://doi.org/10.3115/v1/S14-2004</a>.
</div>
<div id="ref-simmering2023large" class="csl-entry">
Simmering, Paul F., and Paavo Huoviala. 2023. <span>“Large Language Models for Aspect-Based Sentiment Analysis.”</span> <a href="https://arxiv.org/abs/2310.18025">https://arxiv.org/abs/2310.18025</a>.
</div>
</div></section></div> ]]></description>
  <category>Machine Learning</category>
  <category>Python</category>
  <guid>https://simmering.dev/blog/absa-with-dspy/</guid>
  <pubDate>Sat, 23 Nov 2024 23:00:00 GMT</pubDate>
  <media:content url="https://simmering.dev/blog/absa-with-dspy/image.webp" medium="image" type="image/webp"/>
</item>
<item>
  <title>From 5-7-5 to Thousand Lines: The Case for Longer Prompts</title>
  <dc:creator>Paul Simmering</dc:creator>
  <link>https://simmering.dev/blog/long-prompts/</link>
  <description><![CDATA[ 





<p>Prompts are the key to guide LLMs for any task, from a chatbot to a text classifier. Longer prompts are usually better than shorter ones, as I’ll argue below. There is a tradeoff, though: each interaction with a long prompt has a longer input sequence, which increases inference cost and latency. Further, a long prompt takes up more of the model’s context window, leaving less for user interaction. But both of these concerns are becoming less relevant with recent developments.</p>
<section id="long-prompts-are-getting-cheaper" class="level2">
<h2 class="anchored" data-anchor-id="long-prompts-are-getting-cheaper">Long prompts are getting cheaper</h2>
<p>There are two developments that keep bringing down the cost of long prompts:</p>
<ol type="1">
<li><p><strong>Decrease in input token cost</strong> on API platforms like OpenAI, Anthropic and others. At launch of gpt-3.5-turbo in March 2023, OpenAI charged $2 for 1 million input tokens. By August 2024, it’s $0.15 for gpt-4o-mini, a more capable model. This is a 92.5% reduction in cost. It reflects the fierce competition and the increasing efficiency of inference software, a fall in GPU prices and advances in quantization. Similar trends can be observed in inference cost for open source models, though it’s harder to reach the same economies of scale as the big platforms.</p></li>
<li><p><strong>Context caching</strong>, meaning that the model doesn’t have to recompute the prefix of the prompt for each interaction. This is also called prompt caching. It uses a KV cache (see a good explanation by <span class="citation" data-cites="log2023kvcache">Log (2023)</span>) to skip the calculation of the attention keys and values for cached tokens. Originally, this was only used within a single generation task to avoid having to re-read all tokens for each additional token generated. However, it can also be used across different generations. It’s integrated in <a href="https://docs.vllm.ai/en/stable/automatic_prefix_caching/apc.html">vLLM</a> <span class="citation" data-cites="kwon2023efficientmemorymanagementlarge">(Kwon et al. 2023)</span>, an inference library that can serve many popular open source models. Since June 2024, three API platforms have also added this feature: <a href="https://platform.deepseek.com/api-docs/news/news0802/">DeepSeek</a>, <a href="https://ai.google.dev/gemini-api/docs/caching?lang=python">Google Gemini</a> and <a href="https://www.anthropic.com/news/prompt-caching">Anthropic</a>.</p></li>
</ol>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/long-prompts/kv_cache_example.JPEG" class="img-fluid figure-img"></p>
<figcaption>Context caching lets subsequent requests with the same prefix use a cache. Image from <a href="platform">DeepSeek</a>.</figcaption>
</figure>
</div>
<table class="caption-top table">
<colgroup>
<col style="width: 11%">
<col style="width: 20%">
<col style="width: 16%">
<col style="width: 33%">
<col style="width: 16%">
</colgroup>
<thead>
<tr class="header">
<th>Platform</th>
<th>Model</th>
<th>Regular price</th>
<th>Caching price</th>
<th>Savings</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>DeepSeek</td>
<td>deepseek-chat</td>
<td>$0.14 / Mtok</td>
<td>$0.014 / Mtok for cache read</td>
<td>90%</td>
</tr>
<tr class="even">
<td>Anthropic</td>
<td>Claude 3.5 Sonnet</td>
<td>$3.00 / Mtok</td>
<td>$3.75 / MTok for cache write, $0.30 /Mtok for cache hits</td>
<td>90%</td>
</tr>
<tr class="odd">
<td>Gemini</td>
<td>Gemini 1.5 Pro</td>
<td>$3.50 / Mtok</td>
<td>Free cache read, $4.50 / Mtok per hour for storage</td>
<td>Variable</td>
</tr>
</tbody>
</table>
<p>The table above compares the cost savings from prompt caching on different platforms. Mtok stands for million tokens.</p>
<p>The pricing models are quite different. DeepSeek offers the best savings at 90% reduction on cache hit and no storage fees. Keep in mind that this is not a frontier model. The documentation says the cache is cleared after a few hours. Further, the feature is active by default and doesn’t require a change in code. This is different at Anthropic where the cache has to be explicitly enabled and writing to it carries a higher cost than a normal input token. As of August 31, the cache only has a 5 minute time to live (TTL), making it only useful apps with high frequency of the same prompt. Gemini charges for storage and gives control over the TTL with a default of one hour and requires explicit enabling.</p>
<p>Why is it so expensive to store 1 million tokens for one hour? The reason is that the KV cache takes a surprising amount of memory. The formula for the memory per token is:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7Bmemory%7D%20=%20n_%7Btokens%7D%20*%202%20*%20n_%7Bheads%7D%20*%20d_%7Bhead%7D%20*%20n_%7Blayers%7D%20*%20%5Ctext%7Bprecision%20(bytes)%7D%0A"></p>
<p>The 2 represents the key and value vectors, <img src="https://latex.codecogs.com/png.latex?n_%7Bheads%7D"> is the number of attention heads, <img src="https://latex.codecogs.com/png.latex?d_%7Bhead%7D"> is the dimension of the attention head, <img src="https://latex.codecogs.com/png.latex?n_%7Blayers%7D"> is the number of layers and precision is the number of bytes used to store a single weight. Note that this doesn’t include optimizations like sparsity, quantizastion or grouped query attention <span class="citation" data-cites="ainslie2023gqatraininggeneralizedmultiquery">(Ainslie et al. 2023)</span>.</p>
<p>For a 1024 token sequence on a 175B GPT-3 model with 96 heads with 128 dimensions and 96 layers at FP16 precision, this results in</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A1024%20*%202%20*%2096%20*%20128%20*%2096%20*%2016%20%5Ctext%7B%20bytes%7D%20=%2038.65%20%5Ctext%7B%20GB%7D%0A"></p>
<p>This has to be stored in GPU memory to be accessible for the model.</p>
<p>But while $4.5 / Mtok might seem expensive for just one hour, if that input token is used at least twice in that hour, it’s already cheaper than the regular input token price. The savings are multiplied with each additional use. For use of open models on your own GPUs, this means that allocating a portion of your GPU memory to cache can be an excellent investment. It also means that for same-y inference requests, GPU memory matters more than its speed.</p>
</section>
<section id="context-sizes-are-getting-larger" class="level2">
<h2 class="anchored" data-anchor-id="context-sizes-are-getting-larger">Context sizes are getting larger</h2>
<p>Current frontier models have a context length of at least 128,000 tokens - equivalent to roughly 100,000 words or a 400 page novel.</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Provider</th>
<th>Model</th>
<th>Context size</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Google</td>
<td>Gemini 1.5 Pro</td>
<td>2m</td>
</tr>
<tr class="even">
<td>Anthropic</td>
<td>Claude 3.5 Sonnet</td>
<td>200k</td>
</tr>
<tr class="odd">
<td>Alibaba</td>
<td>Qwen2 72B</td>
<td>128k</td>
</tr>
<tr class="even">
<td>Meta</td>
<td>Llama 3.1 Instruct 405B</td>
<td>128k</td>
</tr>
<tr class="odd">
<td>Mistral</td>
<td>Mistral Large 2</td>
<td>128k</td>
</tr>
<tr class="even">
<td>OpenAI</td>
<td>GPT-4o</td>
<td>128k</td>
</tr>
</tbody>
</table>
<p>Source: <a href="https://artificialanalysis.ai">Artificialanalysis.ai</a></p>
<p>In contrast, early models like gpt-3.5-turbo in March 2023 only had a context size of 4096 tokens. In a RAG context, this means that more text chunks can be included in the prompt and in a chat context, more questions and answers can be included before the oldest ones are evicted. The problem that a prompt doesn’t fit into the context window is effectively solved for almost all applications.</p>
</section>
<section id="longer-prompts-are-often-better" class="level2">
<h2 class="anchored" data-anchor-id="longer-prompts-are-often-better">Longer prompts are often better</h2>
<p>Ok, so long prompts are getting cheaper. But how does a longer prompt help?</p>
<section id="more-detailed-guidelines" class="level3">
<h3 class="anchored" data-anchor-id="more-detailed-guidelines">1. More detailed guidelines</h3>
<p>A longer prompt can provide more context to the model, letting it perform a task more accurately or represent a brand or character more faithfully. Consider including information like this:</p>
<ul>
<li>Background information about the website, app or task that the model is embedded in.</li>
<li>Behavioral constraints, like not using certain words or phrases. For example telling the prompt to avoid starting answers with “Certainly!”, to make it sound less AI-like.</li>
<li>Style guidelines, like using a certain tone or level of formality, whether to address the user by first or last name, or to use emojis.</li>
<li>Characterization, giving the model a personality or role to play. For example, a chatbot for a bank could be characterized as a friendly and professional customer service agent.</li>
<li>A more detailed task description, like a list of steps to follow or a description of the desired output.</li>
<li>Information about the user, like their name, location, or preferences.</li>
<li>A translation glossary, if the model is used in a multilingual setting.</li>
</ul>
<p>If you’re looking for inspiration for a chatbot prompt, check the recently revealed prompts for Anthropic’s <a href="https://docs.anthropic.com/en/release-notes/system-prompts#july-12th-2024">Claude</a>.</p>
</section>
<section id="many-shot-in-context-learning" class="level3">
<h3 class="anchored" data-anchor-id="many-shot-in-context-learning">2. Many-shot in-context learning</h3>
<p>Few-shot examples can be included in the prompt for in-context learning (ICL). These examples can teach the model about the rules for the task, the desired output format, intermediate reasoning steps and handling of edge cases. Commonly this is done with 1 to 5 examples, but with prefix caching it’s possible to include 50, 100 or even more examples.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/long-prompts/many_shot_learning.png" class="img-fluid figure-img"></p>
<figcaption>Many-shot in-context learning. Image from Agarwal et al.&nbsp;(2024)</figcaption>
</figure>
</div>
<p><span class="citation" data-cites="agarwal2024manyshotincontextlearning">Agarwal et al. (2024)</span> ran this experiment with Gemini 1.5 Pro across several tasks. Many-shot ICL outperformed few-shot learning in all cases. For sentiment analysis they went as far as 2048 examples in the prompt, achieving an increase in 18.2 percentage points over a 32-shot prompt. In many of their experiments the limiting factor wasn’t the context size, but the number of available examples.</p>
<p>This allows a prompting approach become closer to fine-tuning, but without the need for training or a model store. <span class="citation" data-cites="bertsch2024incontextlearninglongcontextmodels">Bertsch et al. (2024)</span> made the comparison between many-shot ICL and LoRA <span class="citation" data-cites="hu2021loralowrankadaptationlarge">(Hu et al. 2021)</span> on 5 classification tasks and conclude that “finetuning is more data-hungry than ICL”. In their experiments with Llama2-7b, many-shot prompting outperformed fine-tuning up to about 1000 examples (see figure 2 of their paper).</p>
</section>
<section id="more-rag-context" class="level3">
<h3 class="anchored" data-anchor-id="more-rag-context">3. More RAG context</h3>
<p>A key design parameter in retrieval augmented generation (RAG) is the number of text chunks to retrieve from a source. With a larger context size, more and longer text chunks can be included in the prompt. This increases the likelihood that the information required to answer the query is present in the prompt.</p>
<p><span class="citation" data-cites="leng2024longcontextrag">Leng et al. (2024)</span> tested RAG answer correctness on 13 open source and proprietary LLMs.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/long-prompts/long_context_performance.png" class="img-fluid figure-img"></p>
<figcaption>Long context performance of GPT, Claude, Llama, Mistral and DBRX models on 4 curated RAG datasets (Databricks DocsQA, FinanceBench, HotPotQA and Natural Questions), from Leng et al.&nbsp;(2024).</figcaption>
</figure>
</div>
<p>As the graph above shows, answer correctness increased with longer context all models up to 4k tokens and up to 32k tokens for most models. This is driven by the boost in retrieval (see experiment 1 in the article).</p>
<p>However, the “lost in the middle” problem can occur, a phenomemon first found by <span class="citation" data-cites="liu2023lostmiddlelanguagemodels">(Liu et al. 2023)</span>, where information presented in the middle is not used as well as information presented at the beginning or end. It can be measured by the “needle in a haystack” method, meaning that a piece of information is hidden in a long text and the model has to find it. The longer the text, the harder it is to find the information. The RULER benchmark by <span class="citation" data-cites="hsieh2024rulerwhatsrealcontext">(Hsieh et al. 2024)</span> extended this to more complex tasks and introduced the concept of an effective context length, which is shorter than the technical context length of a model.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/long-prompts/lost_in_the_middle.png" class="img-fluid figure-img" style="width:50.0%"></p>
<figcaption>Lost in the middle problem. Image from Liu et al.&nbsp;(2023)</figcaption>
</figure>
</div>
<p>Retrieving more information also increases the risk of including irrelevant information. If chunk ranking works correctly, lower ranking chunks are less likely to be relevant and adding them reduces the density of relevant information. <span class="citation" data-cites="levy2024tasktokensimpactinput">Levy, Jacoby, and Goldberg (2024)</span> found that irrelevant information isn’t neutral, it’s detrimental to model performance on a question-answering task.</p>
</section>
<section id="more-functions-for-agentic-models" class="level3">
<h3 class="anchored" data-anchor-id="more-functions-for-agentic-models">4. More functions for agentic models</h3>
<p>Models used as agents are given function signatures in a JSON schema. Each of these has to be sent to the model as part of the prompt. The more functions and the more arguments they have, the longer the prompt. With lower prompt costs, it’s becoming more economical to have agents with many different and more detailed functions in their repertoire.</p>
<p>Common functions include:</p>
<ul>
<li>Send a task to a sub-agent</li>
<li>Web search</li>
<li>Query a database by using text-to-SQL</li>
<li>Redirect to a human agent</li>
<li>Call a REST API, e.g.&nbsp;to send an email or schedule a meeting</li>
<li>Execute code in Python, JavaScript or another language</li>
</ul>
<p>The Berkeley function calling leaderboard <span class="citation" data-cites="berkeley-function-calling-leaderboard">(Yan et al. 2024)</span> offers detailed benchmarks for a variety of function calling tasks.</p>
</section>
</section>
<section id="conclusion-revisit-your-prompts" class="level2">
<h2 class="anchored" data-anchor-id="conclusion-revisit-your-prompts">Conclusion: revisit your prompts</h2>
<p>In 2023, the cost of long prompts was a major concern. Each input token was precious. This has changed with the introduction of prompt caching and a massive reduction in input token cost. It’s worth reevaluating prompts and consider whether adding more information would benefit the application.</p>
<p>About the title: 5-7-5 refers to the syllable count in a haiku, a form of short poetry from Japan.</p>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0">
<div id="ref-agarwal2024manyshotincontextlearning" class="csl-entry">
Agarwal, Rishabh, Avi Singh, Lei M. Zhang, Bernd Bohnet, Luis Rosias, Stephanie Chan, Biao Zhang, et al. 2024. <span>“Many-Shot in-Context Learning.”</span> <a href="https://arxiv.org/abs/2404.11018">https://arxiv.org/abs/2404.11018</a>.
</div>
<div id="ref-ainslie2023gqatraininggeneralizedmultiquery" class="csl-entry">
Ainslie, Joshua, James Lee-Thorp, Michiel de Jong, Yury Zemlyanskiy, Federico Lebrón, and Sumit Sanghai. 2023. <span>“GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints.”</span> <a href="https://arxiv.org/abs/2305.13245">https://arxiv.org/abs/2305.13245</a>.
</div>
<div id="ref-bertsch2024incontextlearninglongcontextmodels" class="csl-entry">
Bertsch, Amanda, Maor Ivgi, Uri Alon, Jonathan Berant, Matthew R. Gormley, and Graham Neubig. 2024. <span>“In-Context Learning with Long-Context Models: An in-Depth Exploration.”</span> <a href="https://arxiv.org/abs/2405.00200">https://arxiv.org/abs/2405.00200</a>.
</div>
<div id="ref-hsieh2024rulerwhatsrealcontext" class="csl-entry">
Hsieh, Cheng-Ping, Simeng Sun, Samuel Kriman, Shantanu Acharya, Dima Rekesh, Fei Jia, Yang Zhang, and Boris Ginsburg. 2024. <span>“RULER: What’s the Real Context Size of Your Long-Context Language Models?”</span> <a href="https://arxiv.org/abs/2404.06654">https://arxiv.org/abs/2404.06654</a>.
</div>
<div id="ref-hu2021loralowrankadaptationlarge" class="csl-entry">
Hu, Edward J., Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. 2021. <span>“LoRA: Low-Rank Adaptation of Large Language Models.”</span> <a href="https://arxiv.org/abs/2106.09685">https://arxiv.org/abs/2106.09685</a>.
</div>
<div id="ref-kwon2023efficientmemorymanagementlarge" class="csl-entry">
Kwon, Woosuk, Zhuohan Li, Siyuan Zhuang, Ying Sheng, Lianmin Zheng, Cody Hao Yu, Joseph E. Gonzalez, Hao Zhang, and Ion Stoica. 2023. <span>“Efficient Memory Management for Large Language Model Serving with PagedAttention.”</span> <a href="https://arxiv.org/abs/2309.06180">https://arxiv.org/abs/2309.06180</a>.
</div>
<div id="ref-leng2024longcontextrag" class="csl-entry">
Leng, Quinn, Jacob Portes, Sam Havens, Matei Zaharia, and Michael Carbin. 2024. <span>“Long Context RAG Performance of LLMs.”</span> <a href="https://www.databricks.com/blog/long-context-rag-performance-llms" class="uri">https://www.databricks.com/blog/long-context-rag-performance-llms</a>.
</div>
<div id="ref-levy2024tasktokensimpactinput" class="csl-entry">
Levy, Mosh, Alon Jacoby, and Yoav Goldberg. 2024. <span>“Same Task, More Tokens: The Impact of Input Length on the Reasoning Performance of Large Language Models.”</span> <a href="https://arxiv.org/abs/2402.14848">https://arxiv.org/abs/2402.14848</a>.
</div>
<div id="ref-liu2023lostmiddlelanguagemodels" class="csl-entry">
Liu, Nelson F., Kevin Lin, John Hewitt, Ashwin Paranjape, Michele Bevilacqua, Fabio Petroni, and Percy Liang. 2023. <span>“Lost in the Middle: How Language Models Use Long Contexts.”</span> <a href="https://arxiv.org/abs/2307.03172">https://arxiv.org/abs/2307.03172</a>.
</div>
<div id="ref-log2023kvcache" class="csl-entry">
Log, Matt. 2023. <span>“What Is the KV Cache?”</span> https://mett29.github.io/posts/kv-cache/.
</div>
<div id="ref-berkeley-function-calling-leaderboard" class="csl-entry">
Yan, Fanjia, Huanzhi Mao, Charlie Cheng-Jie Ji, Tianjun Zhang, Shishir G. Patil, Ion Stoica, and Joseph E. Gonzalez. 2024. <span>“Berkeley Function Calling Leaderboard.”</span> In. <a href="https://gorilla.cs.berkeley.edu/blogs/8_berkeley_function_calling_leaderboard.html" class="uri">https://gorilla.cs.berkeley.edu/blogs/8_berkeley_function_calling_leaderboard.html</a>.
</div>
</div></section></div> ]]></description>
  <category>Machine Learning</category>
  <guid>https://simmering.dev/blog/long-prompts/</guid>
  <pubDate>Sat, 31 Aug 2024 22:00:00 GMT</pubDate>
  <media:content url="https://simmering.dev/blog/long-prompts/image.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>OpenAI’s structured output vs. instructor and outlines</title>
  <dc:creator>Paul Simmering</dc:creator>
  <link>https://simmering.dev/blog/openai_structured_output/</link>
  <description><![CDATA[ 





<p>On August 6 OpenAI released <a href="https://openai.com/index/introducing-structured-outputs-in-the-api/">structured outputs</a> in their API. Is structured outputs a replacement for instructor, outlines and other libraries that provide structured outputs for language models? Let’s compare them.</p>
<p>OpenAI’s structured outputs makes the following code possible:</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> json</span>
<span id="cb1-2"></span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pydantic <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> BaseModel</span>
<span id="cb1-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> openai <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> OpenAI</span>
<span id="cb1-5"></span>
<span id="cb1-6"></span>
<span id="cb1-7"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> Ingredient(BaseModel):</span>
<span id="cb1-8">    name: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span></span>
<span id="cb1-9">    amount: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span></span>
<span id="cb1-10">    kcal: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span></span>
<span id="cb1-11"></span>
<span id="cb1-12"></span>
<span id="cb1-13"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> Recipe(BaseModel):</span>
<span id="cb1-14">    ingredients: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>[Ingredient]</span>
<span id="cb1-15">    instructions: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span></span>
<span id="cb1-16"></span>
<span id="cb1-17"></span>
<span id="cb1-18">client <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> OpenAI()</span>
<span id="cb1-19"></span>
<span id="cb1-20">completion <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> client.beta.chat.completions.parse(</span>
<span id="cb1-21">    model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"gpt-4o-2024-08-06"</span>,</span>
<span id="cb1-22">    messages<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[{<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"role"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"user"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"content"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Write an apple pie recipe"</span>}],</span>
<span id="cb1-23">    response_format<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>Recipe,</span>
<span id="cb1-24">)</span>
<span id="cb1-25"></span>
<span id="cb1-26">apple_pie_recipe <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Recipe(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>json.loads(completion.choices[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].message.content))</span></code></pre></div>
<p>It’s guaranteed that the output will be JSON that can be parsed into a <code>Recipe</code> object. The code looks very similar to the code you’d write with any of the <a href="../../blog/structured_output/">10 libraries</a> I compared in May.</p>
<p>Besides removing the need for a library, structured output works quite differently from function calling under the hood. With function calling the model is trained to follow an instruction given as a JSON schema and is likely but not guaranteed to follow it. At any token position it’s still free to output a token that doesn’t fit the schema. With structured output, the output of the model is constrained to fit the schema. This is the same approach as the <a href="https://github.com/outlines-dev/outlines">outlines</a> library uses for open source models.</p>
<section id="pros-and-cons" class="level2">
<h2 class="anchored" data-anchor-id="pros-and-cons">Pros and cons</h2>
<p>The structured output feature has several advantages over function calling:</p>
<ol type="1">
<li>✅ The definition of the output format doesn’t count as input tokens, making it significantly cheaper, especially for short input messages and complex output formats.</li>
<li>✅ The output is 100% guaranteed to follow the structure, in contrast to JSON mode and function calling which are just very likely to follow the structure.</li>
<li>✅ It doesn’t slow down the generation process, rather it speeds it up because tokens with no alternatives can be automatically placed rather than generated by the model.</li>
</ol>
<p>But also some downsides:</p>
<ol type="1">
<li>❌ OpenAI’s implementation only works with its own models.</li>
<li>❌ It only supports a subset of JSON schema. In particular, they don’t support <code>minLength</code> and <code>maxLength</code> constraints. See their <a href="https://platform.openai.com/docs/guides/structured-outputs">docs</a>. These are supported by outlines and instructor.</li>
<li>❌ The first API call with a schema has a higher latency than subsequent calls because the schema has to be compiled.</li>
</ol>
<p>I expect that the first two downsides will be addressed in the future. Thanks to the outlines library, the implementation of structured outputs is already available for open source models. Perhaps providers like Fireworks AI and Groq will adopt it with the same API specification as OpenAI. They’ve done this with function calling. In turn, platform-agnostic libraries like mirascope, marvin and instructor may adopt it as well.</p>
</section>
<section id="are-instructor-and-other-structured-output-libraries-obsolete" class="level2">
<h2 class="anchored" data-anchor-id="are-instructor-and-other-structured-output-libraries-obsolete">Are instructor and other structured output libraries obsolete?</h2>
<p>Right after the announcement, Jason Liu, author of instructor posted:</p>
<blockquote class="blockquote">
<p>They solved instructor.</p>
</blockquote>
<p>on <a href="https://x.com/jxnlco/status/1820880349288595629">X</a>. Later he added a longer <a href="https://x.com/jxnlco/status/1820976130096074940">post</a> with his thoughts.</p>
<p>Yes, the core value proposition of: “give me a Pydantic model and I’ll use function calling to guarantee the output fits the schema” is now covered for OpenAI models, but only for OpenAI models. If you’re using other models or want to stay flexible, structured output libraries are still useful. Each library also comes with additional features, as I’ve covered in my <a href="../../blog/structured_output/">comparison</a>. Examples are multiple provider support, error handling, caching, chaining and more.</p>
<p>So in short: no, they’re not obsolete, but their space is getting squeezed.</p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>If you’re exclusively using OpenAI models and only need basic structured responses, I recommend using OpenAI’s structured outputs. It’s the most convenient, secure and cheapest method. If you prefer other LLM providers or want your code to be provider-agnostic, I recommend sticking with outlines (if self-hosting) or instructor (if using API providers).</p>


</section>

 ]]></description>
  <category>Machine Learning</category>
  <category>Python</category>
  <guid>https://simmering.dev/blog/openai_structured_output/</guid>
  <pubDate>Fri, 09 Aug 2024 22:00:00 GMT</pubDate>
  <media:content url="https://simmering.dev/blog/openai_structured_output/image.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Levels of Abstraction in the LLM Stack</title>
  <dc:creator>Paul Simmering</dc:creator>
  <link>https://simmering.dev/blog/abstractions/</link>
  <description><![CDATA[ 





<p>Training and serving LLMs requires a tall software stack. You can engage with this stack at different levels of abstraction, from low-level frameworks like CUDA to ready-to-go inference APIs like the OpenAI API. The aim of this article is to provide an overview of the abstraction levels and help you choose the right one for your project. Typical questions are:</p>
<ul>
<li>“<em>Should I use OpenAI’s GPT models or an open source model?</em>”</li>
<li>“<em>Should I use HuggingFace transformers or load the model into PyTorch directly?</em>”</li>
<li>“<em>Should I use AWS SageMaker or rent plain EC2 instances and manage everything myself?</em>”</li>
</ul>
<p>The choice depends on you and your project, but this overview and the decision criteria at the end may help you decide. I’ll discuss 3 levels of abstraction:</p>
<ol type="1">
<li>Open source tools and frameworks</li>
<li>Managed LLM services, e.g.&nbsp;AWS SageMaker</li>
<li>Cloud APIs, e.g.&nbsp;OpenAI</li>
</ol>
<section id="open-source-llm-stack" class="level2">
<h2 class="anchored" data-anchor-id="open-source-llm-stack">1. Open source LLM stack</h2>
<p>The open source LLM stack is the most flexible and customizable option and what is underlying the other two options. It consists of several layers. The list below has examples of tools at each level. I’ve not included optional MLOps tools like experiment tracking, monitoring, model store etc. which are not on the critical path for training and serving LLMs.</p>
<p>The term open source is not accurate for the lowest levels: hardware is proprietary and Nvidia holds a near-monopoly on GPUs for machine learning. Cloud providers are also proprietary, but there are many to choose from and they allow running open source software.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 17%">
<col style="width: 33%">
<col style="width: 48%">
</colgroup>
<thead>
<tr class="header">
<th>Level</th>
<th>Description</th>
<th>Examples</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1. Hardware</td>
<td>Physical graphics processors with high VRAM</td>
<td>Nvidia H100, AMD MI350, Intel Gaudi 3</td>
</tr>
<tr class="even">
<td>2. Cloud Providers</td>
<td>Platforms offering rentable GPU resources for LLM training and inference</td>
<td>AWS, Google Cloud, Azure, Modal, Lambda Labs</td>
</tr>
<tr class="odd">
<td>3. Acceleration Framework</td>
<td>Software interfaces for efficient use of GPUs for machine learning</td>
<td>CUDA, ROCm</td>
</tr>
<tr class="even">
<td>4. Distributed Computing</td>
<td>Libraries for distributing training workloads across multiple GPUs and machines</td>
<td>DeepSpeed, horovod, Ray, accelerate</td>
</tr>
<tr class="odd">
<td>5. Low-level Frameworks</td>
<td>Core libraries for building and training large language models</td>
<td>PyTorch, TensorFlow, JAX</td>
</tr>
<tr class="even">
<td>6. High-level Frameworks</td>
<td>Libraries that build on top of low-level frameworks to simplify common uses</td>
<td>Hugging Face Transformers, PyTorch Lightning, Axolotl</td>
</tr>
<tr class="odd">
<td>7. Inference Engine</td>
<td>Software for efficient LLM execution and serving</td>
<td>vLLM, llama.cpp, TorchServe, ONNX</td>
</tr>
<tr class="even">
<td>8. LLM Orchestration</td>
<td>Tools for prompting and chaining LLM calls, constraining and censoring output. These are also compatible with managed ML services and inference APIs</td>
<td>LangChain, llamaindex, litellm, instructor, outlines, guardrails</td>
</tr>
</tbody>
</table>
<p>To illustrate, let’s compare the type of code you’d write at the low and high levels of abstraction.</p>
<p>Creating a simple neural network in PyTorch:</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch.nn <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> nn</span>
<span id="cb1-3"></span>
<span id="cb1-4"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> MyModel(nn.Module):</span>
<span id="cb1-5">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>):</span>
<span id="cb1-6">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">super</span>().<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>()</span>
<span id="cb1-7">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.l1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.Linear(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">768</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">512</span>)</span>
<span id="cb1-8">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.l2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.Linear(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">512</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">256</span>)</span>
<span id="cb1-9">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.l3 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.Linear(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">256</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb1-10"></span>
<span id="cb1-11">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> forward(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, x):</span>
<span id="cb1-12">        x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.relu(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.l1(x))</span>
<span id="cb1-13">        x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.relu(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.l2(x))</span>
<span id="cb1-14">        x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.l3(x)</span>
<span id="cb1-15">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> x</span></code></pre></div>
<p>Loading a pre-trained transformer model from Hugging Face:</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> transformers <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> BertTokenizer, BertForSequenceClassification</span>
<span id="cb2-2"></span>
<span id="cb2-3">tokenizer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> BertTokenizer.from_pretrained(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'bert-base-uncased'</span>)</span>
<span id="cb2-4">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> BertForSequenceClassification.from_pretrained(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'bert-base-uncased'</span>)</span></code></pre></div>
<p>PyTorch confronts you with the details of layers, their sizes, activation functions and more. Hugging Face abstracts them away.</p>
<section id="more-alternatives-at-higher-levels" class="level3">
<h3 class="anchored" data-anchor-id="more-alternatives-at-higher-levels">More alternatives at higher levels</h3>
<p>There tend to be more alternatives the higher you go in the stack. Recently, I’ve <a href="../../blog/structured_output/">compared</a> 10 different libraries for structured LLM outputs, all at the highest level of abstraction. In contrast, there is no widely used alternative to Nvidia GPUs and CUDA for the hardware and acceleration levels.</p>
</section>
<section id="too-much-abstraction" class="level3">
<h3 class="anchored" data-anchor-id="too-much-abstraction">Too much abstraction?</h3>
<p>There is such a thing as too many layers of abstractions. Hamel Husain put it well in his article: <a href="https://hamel.dev/blog/posts/prompt/">“Fuck You, Show Me The Prompt”</a>. Make sure you know which tokens are actually being sent to the LLM, and whether there’s more than one round-trip involved in getting a response. For education, too many layers can also hinder understanding. Andrej Karpathy is known for re-implementing the GPT architecture for education, for example <a href="https://github.com/karpathy/nanoGPT">nanoGPT</a>, which is GPT2 in ~600 lines of Python.</p>
</section>
<section id="fine-tune-dont-train-from-scratch" class="level3">
<h3 class="anchored" data-anchor-id="fine-tune-dont-train-from-scratch">Fine-tune, don’t train from scratch</h3>
<p>Training LLMs from scratch is almost never worth it for organizations whose main business isn’t providing foundation models for others. It requires far too much training data and GPU hours. As an example, even the smallest of Meta’s Llama 3.1 models was trained for 1.46M GPU hours (<a href="https://huggingface.co/blog/llama31#:~:text=The%20Llama%203.1%20models%20were%20trained%20on%20over,for%208B%2C%207.0M%20for%2070B%2C%2030.84M%20for%20405B%29.">source</a>). In contrast, fine-tuning a LoRA adapter for that model can be done in less than 1 GPU hour on an H100.</p>
<p>When working with lower-level libraries like PyTorch, it’s therefore necessary to start by copying the architecture of an existing LLM and loading its weights. Tweaks like a new output layer must be done carefully in order to preserve the usefulness of the learned weights. This is in contrast to less compute-intensive machine learning models, where training one’s own model from scratch is common. For these reasons, starting from a high-level framework like Hugging Face Transformers is more common for working with LLMs.</p>
</section>
</section>
<section id="managed-ml-services" class="level2">
<h2 class="anchored" data-anchor-id="managed-ml-services">2. Managed ML services</h2>
<p>AWS SageMaker, Google Cloud AI Platform, and Azure Machine Learning are examples of managed LLM services. They wrap the DIY stack in their cloud infrastructure, providing a unified interface for training, serving and monitoring models. Essentially, these services bundle the DIY stack into a single product, freeing you from having to manage the details. You still have a selection of open source models to fine-tuned with your own data.</p>
<p>This approach caters to enterprises with large-scale ML needs and tight security requirements. They’re typically already using the cloud provider for other services and want to keep everything in one place.</p>
</section>
<section id="inference-apis" class="level2">
<h2 class="anchored" data-anchor-id="inference-apis">3. Inference APIs</h2>
<p>Pre-trained LLMs are offered via API by OpenAI, Anthropic and many others including cloud providers with services like AWS Bedrock. These APIs are the highest level of abstraction, letting you directly connect your app to a powerful LLM without any setup or training. The downside is that you have the least control over the model and your data.</p>
<p>Some inference API providers, like Fireworks.ai also offer fine-tuning, getting close to the level of control you’d have with a managed service.</p>
</section>
<section id="choosing-the-right-level-of-abstraction" class="level2">
<h2 class="anchored" data-anchor-id="choosing-the-right-level-of-abstraction">Choosing the right level of abstraction</h2>
<p>Which level of abstraction do you want to work at?</p>
<section id="high-level-of-abstraction" class="level3">
<h3 class="anchored" data-anchor-id="high-level-of-abstraction">High level of abstraction</h3>
<p>Choose a higher level of abstraction if you:</p>
<ul>
<li>Are a beginner seeking quick first successes</li>
<li>Work at a startup focused on product-market fit</li>
<li>Are a researcher in a different field wishing to use LLMs</li>
<li>Want to integrate LLMs without deep ML expertise</li>
<li>Are already committed to a specific cloud ecosystem</li>
<li>Have no need for deep customization of models (you’d know if you did)</li>
</ul>
<p>The danger of choosing a too high level of abstraction is that you may hit a wall when you need to do something the tool doesn’t support. For example, OpenAI’s API doesn’t support reinforcement learning from human feedback (RLHF), only supervised fine-tuning. If you need RLHF, you’d have to switch to a lower level of abstraction.</p>
</section>
<section id="low-level-of-abstraction" class="level3">
<h3 class="anchored" data-anchor-id="low-level-of-abstraction">Low level of abstraction</h3>
<p>Opt for a lower level of abstraction if you:</p>
<ul>
<li>Are a researcher or engineer pushing LLM boundaries</li>
<li>Require fine-grained control over the model</li>
<li>Need on-premises or on-device deployment</li>
<li>Desire a deep understanding of the underlying technology</li>
<li>Prioritize code and model portability</li>
<li>Have engineers familiar with distributed systems and GPU programming</li>
</ul>
<p>The danger of choosing a too low level of abstraction is that you may spend too much time on infrastructure and not enough on the actual problem you’re trying to solve. For example, if you’re building a prototype for a meeting summarization chatbot, your time is better spent talking to project managers than optimizing your distributed training setup.</p>
</section>
<section id="cost-can-go-both-ways" class="level3">
<h3 class="anchored" data-anchor-id="cost-can-go-both-ways">Cost can go both ways</h3>
<p>High level tools can add a tax, but prices have been decreasing quickly. Managed services and API providers can leverage economies of scale and have highly optimized infrastructure. This can be difficult to achieve with a DIY stack. For example, a privately owned GPU deployed for inference may be underutilized outside of business hours, while a GPU at a cloud provider services other customers.</p>
</section>
<section id="keep-your-training-data-portable" class="level3">
<h3 class="anchored" data-anchor-id="keep-your-training-data-portable">Keep your training data portable</h3>
<p>The linear progression from low to high abstraction is a simplification. As the ecosystem matures, interoperability increases. For example, Hugging Face Transformers abstracts away the model architecture, but you can still access the PyTorch model and adjust it. Then that model can be deployed to AWS SageMaker. Not all combinations are possible though - for example a GPT model fine-tuned on OpenAI’s API can only run on that account. When it’s cheap to do so, use solutions that have as little lock-in as possible. Especially your training data should remain portable. In a time where research labs one-up each other weekly with better base models, being able to switch to a new model quickly is an advantage.</p>


</section>
</section>

 ]]></description>
  <category>Machine Learning</category>
  <guid>https://simmering.dev/blog/abstractions/</guid>
  <pubDate>Wed, 07 Aug 2024 22:00:00 GMT</pubDate>
  <media:content url="https://simmering.dev/blog/abstractions/image.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Less stress, more focus: How to handle waiting times in development</title>
  <dc:creator>Paul Simmering</dc:creator>
  <link>https://simmering.dev/blog/waiting/</link>
  <description><![CDATA[ 





<p>It’s unfortunate, but there are many waiting times in data science. Dealing with them well can make work more productive and enjoyable. Common waiting times include:</p>
<ul>
<li>model is training</li>
<li>data pipeline is running</li>
<li>report is rendering</li>
<li>Docker image is building</li>
<li>tests are running</li>
<li>someone else is reviewing your code</li>
<li>huge upload/download</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/waiting/compiling.png" class="img-fluid figure-img"></p>
<figcaption>Waiting isn’t new in software development. <a href="https://xkcd.com/303/">XKCD 303</a></figcaption>
</figure>
</div>
<p>These waits range from seconds to days.</p>
<p>Ideally, there would not be any waiting times. Many can be eliminated or reduced Here are the top strategies, ranked by effectiveness in my experience:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 29%">
<col style="width: 44%">
<col style="width: 26%">
</colgroup>
<thead>
<tr class="header">
<th>Strategy</th>
<th>Effectiveness</th>
<th>Downsides</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Caching results</td>
<td>Very high, cuts wait times to zero</td>
<td>Stale data</td>
</tr>
<tr class="even">
<td>Indexing databases</td>
<td>High, can massively speed up queries</td>
<td>Not always possible, slows down writes</td>
</tr>
<tr class="odd">
<td>Mocking dependencies</td>
<td>High, can speed up tests</td>
<td>Adds complexity</td>
</tr>
<tr class="even">
<td>Running with smaller inputs</td>
<td>High, can speed up debugging</td>
<td>Not the real result</td>
</tr>
<tr class="odd">
<td>Writing more efficient code</td>
<td>Medium, can speed up code</td>
<td>It’s hard</td>
</tr>
<tr class="even">
<td>Parallelizing code</td>
<td>Medium, can speed up code</td>
<td>Hard and adds complexity</td>
</tr>
<tr class="odd">
<td>Using faster hardware</td>
<td>Medium, can speed up code</td>
<td>Expensive, not always effective</td>
</tr>
</tbody>
</table>
<p>It’s very easy to lose 50% or more of one’s productivity to waiting times. The most common form is an inefficient debug cycle: change code, wait for build, run code, wait for results, repeat. Bonus points if the code is a CI/CD pipeline.</p>
<p>Eliminating a waiting time in a workflow is a huge win, especially when multiple people are using the same workflow.</p>
<p>However, many waiting times are unavoidable, especially when working with large language models. Given that these wait times occur regularly, it makes sense to put together a little plan for what to do with them.</p>
<p>I suggest spending the time in a way that guards focus and short-term memory of the work at hand. Else, you’re effectively doing this:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/waiting/focus.jpeg" class="img-fluid figure-img"></p>
<figcaption>Programmer focus (from Monkeyuser.com)</figcaption>
</figure>
</div>
<p>Except the interruptions are self-inflicted.</p>
<p>The longer the wait is, the more it’s worth to switch context. Here’s a rough, opinionated guide based on my experience and research by <a href="http://www.chrisparnin.me/pdf/parnin-sqj11.pdf">Parnin and Rugaber (2010)</a>. The authors measure <em>edit lag</em>, the time between a developer returning to a task and making the first edit. In a study of 10,000 Java developers, they measured these edit lags:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/waiting/edit_lag.png" class="img-fluid figure-img"></p>
<figcaption>Edit lag, Parning and Rugaber (2010)</figcaption>
</figure>
</div>
<p>For difficult tasks, the edit lag after an interruption can easily exceed the length of the interruption itself. Let’s get to the tactics to handle waiting times.</p>
<section id="seconds-to-minutes" class="level2">
<h2 class="anchored" data-anchor-id="seconds-to-minutes">Seconds to minutes</h2>
<p>These wait times can turn into interruptions, but they don’t have to. It’s tempting to fill smaller breaks with social media or news. However, this floods the short-term memory with new information, replacing the context of the work you were doing. Plus, scrolling is addictive and tends to exceed the actual wait time.</p>
<p>If possible, resist the urge to switch context. It’s ok to just wait for a moment. Look out the window, stretch, take a sip of water, breathe. If you must do something, I suggest doing a physical task like tidying up your desk or making a cup of tea, rather than a computer task.</p>
</section>
<section id="minutes-to-an-hour" class="level2">
<h2 class="anchored" data-anchor-id="minutes-to-an-hour">Minutes to an hour</h2>
<p>This is too long to just do nothing. Before switching context, try to leave an intentional cue for yourself to pick up where you left off, such as a TODO comment that lets you pick up the thread. Keep the IDE open with the file you were working on.</p>
<p>Ideally, pick a little task that is still relevant to your main task. Read through the code, write a comment, plan your next steps, write another test or refactor a small piece of code. Alternatively take a little break or knock out some easy tasks, such as answering emails.</p>
<p>Starting a new big task is not worth it, as it would take a ramp-up time to get back into the context of that task first. This is one of the main points behind Paul Graham’s <a href="http://www.paulgraham.com/makersschedule.html">Maker’s Schedule, Manager’s Schedule</a>.</p>
</section>
<section id="hours-to-days" class="level2">
<h2 class="anchored" data-anchor-id="hours-to-days">Hours to days</h2>
<p>Outside of training large models or running simulations, waiting times this long shouldn’t occur for technical reasons. If they do, it’s a sign that a process is not well-optimized. Fix the process, don’t suffer this wait time too often.</p>
<p>For processes involving humans this sort of wait time is normal though. There the best strategy is to have a plan for what to do during the wait time. When allocating tasks in a team I suggest that every developer has one or more backup tasks that can be worked on when waiting on something on the main task.</p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>Waiting times are a fact of life in data science. They can be reduced, but not eliminated. It’s worth having a plan for how to spend the time to avoid losing focus and short-term memory. This can make work not just more productive but also more enjoyable, as the stress of re-finding context is reduced.</p>


</section>

 ]]></description>
  <category>Productivity</category>
  <guid>https://simmering.dev/blog/waiting/</guid>
  <pubDate>Sat, 27 Jul 2024 22:00:00 GMT</pubDate>
  <media:content url="https://simmering.dev/blog/waiting/clocks.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Text Tournament: Rank Marketing Copy with LLMs</title>
  <dc:creator>Paul Simmering</dc:creator>
  <link>https://simmering.dev/blog/text-tournament/</link>
  <description><![CDATA[ 





<p>The launch of the <a href="../../projects/aspectwise/index.html">review analysis project</a> has me working on various marketing tasks. Naturally, I built a tool to let LLMs help with the creative process. It’s called Text Tournament and the purpose is to compare ideas for company names, taglines, product descriptions and ad copy in a tournament-style competition. The project is available on <a href="https://github.com/psimm/text-tournament">GitHub</a> under the MIT license.</p>
<p>This is the companion blog post to the project which explains my thought process and technical details.</p>
<section id="the-tournament" class="level2">
<h2 class="anchored" data-anchor-id="the-tournament">The Tournament</h2>
<p>The user gives a set of competitors and a set of attributes. Each competitor is paired with every other competitor on each aspect. For example, if there are three name choices for a Spotify competitor, say ‘Streamio’, ‘MelodiX’ and ‘SoundWave’ and two attributes ‘memorability’ and ‘pronounceability’, the tournament would look like this:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Competitor 1</th>
<th>Competitor 2</th>
<th>Attribute</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Streamio</td>
<td>MelodiX</td>
<td>memorability</td>
</tr>
<tr class="even">
<td>Streamio</td>
<td>SoundWave</td>
<td>memorability</td>
</tr>
<tr class="odd">
<td>MelodiX</td>
<td>SoundWave</td>
<td>memorability</td>
</tr>
<tr class="even">
<td>Streamio</td>
<td>MelodiX</td>
<td>pronounceability</td>
</tr>
<tr class="odd">
<td>Streamio</td>
<td>SoundWave</td>
<td>pronounceability</td>
</tr>
<tr class="even">
<td>MelodiX</td>
<td>SoundWave</td>
<td>pronounceability</td>
</tr>
</tbody>
</table>
<p>Each of these pairings is turned into a prompt for the LLM, like “Compare the company names Streamio and MelodiX. Which one is more memorable?”</p>
<p>Each pairing is run twice, once as A vs.&nbsp;B and once as B vs.&nbsp;A. The reason is that LLMs tend to have a bias towards picking the first option <span class="citation" data-cites="dominguezolmedo2024questioningsurveyresponseslarge">(Dominguez-Olmedo, Hardt, and Mendler-Dünner 2024)</span>.</p>
</section>
<section id="structured-output-reasoning" class="level2">
<h2 class="anchored" data-anchor-id="structured-output-reasoning">Structured output &amp; reasoning</h2>
<p>To make sure that the LLM’s answer is interpretable, I used <a href="https://github.com/jxnl/instructor">instructor</a>. Further, I asked the model to not just pick the winner but also to provide a reason. This is done with a simple Pydantic model:</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> Rating(BaseModel):</span>
<span id="cb1-2">    reason: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span></span>
<span id="cb1-3">    preferred: Literal[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>]</span></code></pre></div>
<p>By asking for the reason first, the tokens generated as the reason are influencing the token chosen for the “preferred” field. This makes use of the auto-regressive nature of the model.</p>
<p>The benefit of the reason is that it typically improves the model’s thinking and it also provides an inspectable record. For example, here are two outputs from the tournament above:</p>
<p>Streamio vs MelodiX on pronounceability:</p>
<blockquote class="blockquote">
<p>Streamio is straightforward to pronounce with a clear phonetic structure, while MelodiX may cause hesitation due to the unusual capital ‘X’ at the end.</p>
</blockquote>
<p>MelodiX vs SoundWave on memorability:</p>
<blockquote class="blockquote">
<p>The name ‘MelodiX’ is unique and contains a playful twist with the ‘X’ at the end, making it more distinctive and easier to remember. The name ‘SoundWave’ is more generic and can be easily confused with other similar terms in the tech and music industry.</p>
</blockquote>
</section>
<section id="ranking-competitors-with-the-bradley-terry-model" class="level2">
<h2 class="anchored" data-anchor-id="ranking-competitors-with-the-bradley-terry-model">Ranking competitors with the Bradley-Terry model</h2>
<p>The simplest approach is to count the number of wins for each competitor. However, this doesn’t take into account the strength of the competitors. A competitor that has only faced weak competitors might have a high win count but not be the best choice. I considered two ranking methods that account for this: the Elo <span class="citation" data-cites="elo1978rating">(Elo and Sloan 1978)</span> model and the Bradley-Terry <span class="citation" data-cites="bradley1952rank">(Bradley and Terry 1952)</span> model.</p>
<p>Elo is better known due to the popularity of ranking method in Chess. Many people are familiar with the concept of a player’s Elo rating and how it changes after a match.</p>
<p>The downside of Elo in this context is that ordering of the matches matters. Thce results of the LLM calls are coming in all at once. I’d have to artificially order the matches to use Elo. This is not ideal.</p>
<p>The Bradley-Terry model is a better fit for this situation. It’s a probabilistic model that estimates the strength of competitors based on the outcomes of matches.</p>
<p>The probability of competitor <img src="https://latex.codecogs.com/png.latex?i"> beating competitor <img src="https://latex.codecogs.com/png.latex?j"> is given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(i%20%5Ctext%7B%20beats%20%7D%20j)%20=%20%5Cfrac%7Br_i%7D%7Br_i%20+%20r_j%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?r_i"> is the strength of competitor <img src="https://latex.codecogs.com/png.latex?i">. The model is fit by modifying the strengths <code>r</code> to maximize the likelihood of the observed outcomes.</p>
<p>The Bradley-Terry model is also the basis for Direct Preference Optimization <span class="citation" data-cites="rafailov2024direct">(Rafailov et al. 2024)</span>. So I’m asking an LLM that was likely trained with DPO to do be a ranking model itself. So meta. This also means that the outputs of the ranking could be used as inputs to the DPO model. For example, a larger model could be used to teach a smaller model how to rank the competitors.</p>
</section>
<section id="results" class="level2">
<h2 class="anchored" data-anchor-id="results">Results</h2>
<p>I ran a tournament with more name options and additional attributes to compare them on. Here is the overall result:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/text-tournament/ranking.png" class="img-fluid figure-img"></p>
<figcaption>Tournament results</figcaption>
</figure>
</div>
<p>Does it match your preferences?</p>
<p>The full results with rankings on each attribute are available on this <a href="">Github page</a>.</p>
</section>
<section id="validity" class="level2">
<h2 class="anchored" data-anchor-id="validity">Validity</h2>
<p>The rankings produced by the tournament are not a replacement for tests with real users and human judgment. LLMs are known to be politically biased, may give random answers, and are heavily influenced by how a question is posed. The rankings are a tool to help with the creative process, not a definitive answer. If you decide to use it, I suggest starting with a low-stakes use case like the title of a blog post.</p>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0">
<div id="ref-bradley1952rank" class="csl-entry">
Bradley, Ralph Allan, and Milton E Terry. 1952. <span>“Rank Analysis of Incomplete Block Designs: I. The Method of Paired Comparisons.”</span> <em>Biometrika</em> 39 (3/4): 324–45.
</div>
<div id="ref-dominguezolmedo2024questioningsurveyresponseslarge" class="csl-entry">
Dominguez-Olmedo, Ricardo, Moritz Hardt, and Celestine Mendler-Dünner. 2024. <span>“Questioning the Survey Responses of Large Language Models.”</span> <a href="https://arxiv.org/abs/2306.07951">https://arxiv.org/abs/2306.07951</a>.
</div>
<div id="ref-elo1978rating" class="csl-entry">
Elo, Arpad E, and Sam Sloan. 1978. <span>“The Rating of Chessplayers: Past and Present.”</span>
</div>
<div id="ref-rafailov2024direct" class="csl-entry">
Rafailov, Rafael, Archit Sharma, Eric Mitchell, Christopher D Manning, Stefano Ermon, and Chelsea Finn. 2024. <span>“Direct Preference Optimization: Your Language Model Is Secretly a Reward Model.”</span> <em>Advances in Neural Information Processing Systems</em> 36.
</div>
</div></section></div> ]]></description>
  <category>Machine Learning</category>
  <category>Python</category>
  <category>Marketing</category>
  <guid>https://simmering.dev/blog/text-tournament/</guid>
  <pubDate>Mon, 22 Jul 2024 22:00:00 GMT</pubDate>
  <media:content url="https://simmering.dev/blog/text-tournament/tournament.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Let Research Settle Before Consuming It</title>
  <dc:creator>Paul Simmering</dc:creator>
  <link>https://simmering.dev/blog/settled-knowledge/</link>
  <description><![CDATA[ 





<p>The pace of publishing in machine learning is extremely high. There were 242,290 AI publications in 2022. That’s 663 per day, or one every two minutes. Based on comments on X, Reddit and Discord, I can see that many people feel FOMO, overwhelmed or inadequate because they can’t keep up, even in subfields they’re supposed to be experts in.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/settled-knowledge/publications.png" class="img-fluid figure-img"></p>
<figcaption>Number of AI publications by year, Source: <a href="https://aiindex.stanford.edu/report/">Stanford University AI Index 2024</a></figcaption>
</figure>
</div>
<p>For those who can afford it, the antidote is to deliberately let research settle before consuming it. This means holding off on reading papers and waiting for the ideas to be integrated into textbooks, video courses and libraries, or at least wait to see which papers are getting cited more than others. This has advantages:</p>
<ul>
<li><strong>Higher quality learning materials</strong>: The initial paper is rarely the best explanation or fullest version of an idea. It necessarily doesn’t have as many real world examples as later explanations. It comes from the single perspective of an author with the intent to communicate to peers that are equally deep in the field. Later explanations are written by people with a teaching background and have been refined by feedback and real world experiences. They also have more accessible formats. Most people find it easier to learn from a video course or a textbook than from a collection of papers.</li>
<li><strong>Higher quality software implementations</strong>: Software behind research papers is often brittle and not suitable for production. Waiting for a library to implement the idea means you get a more robust and better documented implementation. It’s also more likely to be compatible with other tools you’re using and easier to install.</li>
<li><strong>Less likely to be wrong or irrelevant</strong>: The initial paper may have a mistake or a result that’s not replicable with other datasets. It may be a theoretical dead end or be quickly surpassed by other research. Waiting a while lets the community sort out what actually works.</li>
</ul>
<p>Time for learning is precious. Spending it on debugging software or deciphering a paper that is later proven wrong is a waste. By delaying consumption of research your learning is more efficient so you can learn more and more long-term valuable skills in the same time.</p>
<p>Of course, waiting is a luxury that those in research can’t afford because they’d be scooped and forever behind the curve. Let’s rank roles in the ecosystem by how close they have to be to the cutting edge:</p>
<ol type="1">
<li>Research scientist in university or industry lab</li>
<li>Research engineer developing platforms for researchers</li>
<li>Novel software developer creating cutting-edge products</li>
<li>Consultant advising on business integration</li>
<li>General developer at a company that uses ML but not at the cutting edge</li>
<li>Developer in slow-moving industry exploring ML adoption</li>
</ol>
<p>The lower you are on the list, the longer you can afford to wait before consuming research. The dropoff is steep. A researcher needs to be up to date with the latest papers within weeks, while a developer in a slow-moving industry can wait multiple years before an idea could become relevant in their work.</p>
<p>Staying at the bleeding edge carries a cost in learning efficiency and stress. If your role permits it, consider letting research settle more before consuming it.</p>



 ]]></description>
  <category>Advice</category>
  <category>Machine Learning</category>
  <guid>https://simmering.dev/blog/settled-knowledge/</guid>
  <pubDate>Fri, 19 Jul 2024 22:00:00 GMT</pubDate>
  <media:content url="https://simmering.dev/blog/settled-knowledge/spiral.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>The World is Large and Very Detailed</title>
  <dc:creator>Paul Simmering</dc:creator>
  <link>https://simmering.dev/blog/detailed-world/</link>
  <description><![CDATA[ 





<p><img src="https://simmering.dev/blog/detailed-world/world.jpg" class="img-fluid"></p>
<p>It’s easy to underestimate how vast and heterogeneous the world is. For entrepreneurs and developers this has two implications:</p>
<ol type="1">
<li>There are many niches to exploit.</li>
<li>It’s hard to scale.</li>
</ol>
<section id="detail-creates-opportunities" class="level2">
<h2 class="anchored" data-anchor-id="detail-creates-opportunities">Detail creates opportunities</h2>
<p>Some examples of detail: geography, languages, currencies, time zones, cultural norms, consumer preferences, age groups, currencies, laws, corporate structures, payment systems and so on. The detail is layered, like geographical features: countries contain states, which contain cities, which contain neighborhoods. Each combination of details creates a different environment for businesses to carve out their niche.</p>
<p>This puts a natural dampener on monopolies. The existence of an incumbent doesn’t mean that there is no room for a new player. This is most obvious in local businesses: just because there is a hairdresser in town doesn’t mean that there isn’t room for another in a different neighborhood. In digital businesses, this is less obvious but still true. Some examples:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>General incumbent</th>
<th>Competitor</th>
<th>Niche</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Zoom</td>
<td>Tuple</td>
<td>Remote pair programming</td>
</tr>
<tr class="even">
<td>Google</td>
<td>DuckDuckGo</td>
<td>Privacy-first search</td>
</tr>
<tr class="odd">
<td>AWS</td>
<td>Modal</td>
<td>Dev-friendly serverless platform</td>
</tr>
<tr class="even">
<td>Word</td>
<td>iA Writer</td>
<td>Distraction-free writing</td>
</tr>
<tr class="odd">
<td>Excel</td>
<td>AirTable</td>
<td>Linked records</td>
</tr>
<tr class="even">
<td>PowerPoint</td>
<td>Pitch</td>
<td>Pitch decks</td>
</tr>
<tr class="odd">
<td>VSCode</td>
<td>Cursor</td>
<td>AI-powered code completion</td>
</tr>
<tr class="even">
<td>Indeed</td>
<td>RemoteOK</td>
<td>Remote job board</td>
</tr>
<tr class="odd">
<td>Yelp</td>
<td>HappyCow</td>
<td>Vegan restaurant search</td>
</tr>
<tr class="even">
<td>Audible</td>
<td>Blinkist</td>
<td>Audio book summaries</td>
</tr>
</tbody>
</table>
<p>In each of these cases the job can be done using the general incumbent, but the competitors offer better experiences within their niches.</p>
<p>Even seemingly standardized technologies like SQL (officially <a href="https://blog.ansi.org/sql-standard-iso-iec-9075-2023-ansi-x3-135/">standardized</a> in 1986) have a huge number of <a href="https://db-engines.com/en/ranking">implementations</a>. Why? Because no single database covers every use case.</p>
<p>The level of detail of the world also provides a natural moat for employees against automation and offshoring.</p>
<ul>
<li>Self-driving cars have been in works for decades, but there are still millions of truck drivers. Why? Trucking is a detailed task that involves driving in all sorts of conditions, loading and unloading cargo and dealing with customers.</li>
<li>Remote work has been a thing for more than 10 years, but software companies still have expensive offices in the Bay Area populated by highly paid developers. Why? Because they have inertia, culture, social networks and talent density that only exist in that particular place.</li>
<li>Figma released its new <a href="https://www.figma.com/ai/">AI</a>. Does this mean that designers will be out of a job? No, because the AI doesn’t have the context and communication skills that a designer has.</li>
</ul>
</section>
<section id="detail-is-the-enemy-of-scaling" class="level2">
<h2 class="anchored" data-anchor-id="detail-is-the-enemy-of-scaling">Detail is the enemy of scaling</h2>
<p>In the same way that detail creates niches, it also inhibits scaling because each new detail requires a new solution. If the world is infinitely detailed, a given solution only applies to an infinitesimally small part of the world.</p>
<p>But the practical level of detail is not infinite: the further you zoom out the more systems and standards become visible. The laws of physics are the same everywhere. A microprocessor works the same way in Paris as in Tokyo. More than 5.4 billion people have a <a href="https://www.weforum.org/agenda/2023/04/charted-there-are-more-phones-than-people-in-the-world/">mobile phone</a>.</p>
<p>This unlocks huge economies of scale: technology that is applicable in many conditions can be invented once, mass-manufactured or copy-pasted millions of times, and used by millions of people. That is why technology companies are the <a href="https://companiesmarketcap.com">most valuable companies</a> in the world.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/detailed-world/marketcap.png" class="img-fluid figure-img"></p>
<figcaption>Largest companies by market cap. From companiesmarketcap.com, July 13 2024</figcaption>
</figure>
</div>
<p>Standardization can turn to natural monopolies when network effects come into play. The more people use a communication platform or a marketplace, the more valuable it becomes. This is why Facebook, Google and Amazon are so dominant. Standardization can also create monopolies to due scale, hence the dominance of TSMC in the semiconductor space.</p>
<p>But it’s also easy to overestimate how much can be standardized. Recently, a friend of mine who works in finance cautioned me about specializing in machine learning. He argued that the field is essentially solved because an LLM can answer any question. The economy needs one research company to develop the model and everyone else just uses their API. Applied LLM developers <a href="https://applied-llms.org/#enough-0-to-1-demos-its-time-for-1-to-n-products">disagree</a>. Building an LLM demo is easy, but real products must meet a much higher bar.</p>
<div class="grid">
<div class="g-col-6">
<p>It’s at this stage that the details of the world painfully intrude. Real world data is often incomplete, noisy, biased, inaccessible or in the wrong format. Predictions may be inaccurate or lack context of the business. The standard chat interface is not suitable for most actual use cases. This is why there is an army of data scientists and <a href="https://www.nytimes.com/2024/06/26/technology/ai-consultants.html">consultants</a> working as “technology sherpas” on the last-mile problems of LLMs. Realizing the economic benefits of LLMs may well require more consultants and software developers than actual ML researchers.</p>
</div>
<div class="g-col-6">
<p><img src="https://simmering.dev/blog/detailed-world/llm_needs.png" class="img-fluid"></p>
</div>
</div>
<p>But my friend isn’t all wrong. Hundreds of startups are building on top of OpenAI’s models. Smartly, OpenAI is leaving the last-mile problems to others and focusing on the core, scalable, and in a way less detailed, technology.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/detailed-world/openai.png" class="img-fluid figure-img" style="width:75.0%"></p>
<figcaption>OpenAI as a platform for companies serving niches</figcaption>
</figure>
</div>
<p>This positioning as the default source of intelligence is lucrative, but requires enormous upfront investment and must be defended against competition. By now, 01 AI, Anthropic, Google, Nvidia and others have released models that have <a href="https://chat.lmsys.org/?leaderboard">surpassed</a> the original GPT-4 model. It models are only measured by their arena benchmark, it’s hard to differentiate. More detail-oriented niches offer more ways to differentiate and are generally less competitive.</p>
</section>
<section id="strategy" class="level2">
<h2 class="anchored" data-anchor-id="strategy">Strategy</h2>
<p>Scalability and detail can be seen in a matrix:</p>
<p><img src="https://simmering.dev/blog/detailed-world/matrix.png" class="img-fluid" style="width:75.0%"></p>
<ul>
<li><strong>New Platforms</strong>: A new technology or business model emerged and has catapulted a company to the top. Their offering is basic but scalable. Examples: OpenAI in 2023, Zoom in 2020, Google in 2000. Naming the year is required because this position is not stable, unless it’s a natural monopoly.</li>
<li><strong>Mature Platforms</strong>: Over time, the platform has added more features and detail to cater to more niches. Examples: AWS, Facebook, MS Office, Stripe. In software, this carries the risk of becoming bloated.</li>
<li><strong>Consulting &amp; bespoke software</strong>: Dealing with each client’s needs separately. Scale is achieved by hiring more people or working more hours. Examples: Accenture, Capgemini, Infosys, freelancers, local businesses.</li>
<li><strong>Failure</strong>: The company has an undifferentiated offering and hasn’t achieved scale. It’s unlikely to survive in the long term.</li>
</ul>
<p>There are plenty of niches to exploit and the existence of an incumbent can be taken as a signal that there is a market, rather than that the market is saturated. The hard part isn’t to find just any niche, but a niche large enough and amenable to scaling.</p>
<p>Questions for entrepreneurs and investors:</p>
<ul>
<li>Where do general incumbents fail to meet the needs of a niche?</li>
<li>What types of scale does the niche support?</li>
<li>Which details can I safely ignore or fix later?</li>
</ul>


</section>

 ]]></description>
  <category>Economics</category>
  <category>Entrepreneurship</category>
  <guid>https://simmering.dev/blog/detailed-world/</guid>
  <pubDate>Fri, 12 Jul 2024 22:00:00 GMT</pubDate>
  <media:content url="https://simmering.dev/blog/detailed-world/world.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Rich Personal Wiki in Quarto</title>
  <dc:creator>Paul Simmering</dc:creator>
  <link>https://simmering.dev/blog/quarto-wiki/</link>
  <description><![CDATA[ 





<p>Machine learning is a deep and constantly evolving field. In an applied project, the details of models are typically compressed into a few lines of a configuration file. Take this excerpt from a configuration file for an LLM training run using <a href="https://github.com/OpenAccess-AI-Collective/axolotl">Axolotl</a>:</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode yaml code-with-copy"><code class="sourceCode yaml"><span id="cb1-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">adapter</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> lora</span></span>
<span id="cb1-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">lora_r</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">32</span></span>
<span id="cb1-3"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">lora_alpha</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">16</span></span>
<span id="cb1-4"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">lora_dropout</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.05</span></span>
<span id="cb1-5"></span>
<span id="cb1-6"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">gradient_accumulation_steps</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span></span>
<span id="cb1-7"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">micro_batch_size</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span></span>
<span id="cb1-8"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">num_epochs</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span></span>
<span id="cb1-9"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">optimizer</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> adamw_bnb_8bit</span></span>
<span id="cb1-10"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">lr_scheduler</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> cosine</span></span>
<span id="cb1-11"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">learning_rate</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0002</span></span></code></pre></div>
<p>There are so many concepts packed into just 10 lines: low-rank adapters, backpropagation, batching, quantization, optimizers. Each of these decomposes into sub-concepts and sub-sub-concepts. The further you go down, the closer you get to pure mathematics. In this case, matrix factorization, calculus, binary arithmetic and trigonometry.</p>
<p>I’ve understood each of these at some point in the last 10 years, but I’m not “exam-ready” on all of them at all times. A year ago I started writing a set of notes that form a personal wiki for machine learning topics. In this article I’ll share the software and workflow I use.</p>
<p>This project helped calm some of my anxiety about forgetting. I can’t remember everything, but I can remember where to find it. Re-learning from a note I’ve written myself is much faster than learning from other sources.</p>
<section id="beware-of-pseudowork" class="level2">
<h2 class="anchored" data-anchor-id="beware-of-pseudowork">Beware of pseudowork</h2>
<p>Before I get into the details, I feel obliged to warn about <em>pseudowork</em>. Setting up note taking systems, reading books about learning, reading advice from successful academics, all of these feel productive but don’t accomplish the main goal: understanding and retaining the material. Endless tweaking of the system can be a form of procrastination.</p>
<p>In other words, don’t go too midwit:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/quarto-wiki/notes_midwit.png" class="img-fluid figure-img" style="width:75.0%"></p>
<figcaption>Notes Midwit Meme</figcaption>
</figure>
</div>
<p>With that warning out of the way, I’ll try to convince you that using Quarto for studying <em>is</em> worthwhile, even though it’s a little more complex than Apple Notes.</p>
</section>
<section id="quarto-website-as-a-personal-wiki" class="level2">
<h2 class="anchored" data-anchor-id="quarto-website-as-a-personal-wiki">Quarto website as a personal wiki</h2>
<p>A personal wiki is a repository of documents that are linked to each other.</p>
<section id="section" class="level3">
<h3 class="anchored" data-anchor-id="section"></h3>
<p align="center">
<img src="https://simmering.dev/blog/quarto-wiki/quarto.png" class="img-fluid">
</p>
<p><a href="https://quarto.org">Quarto</a> is a scientific publishing system that is based on Markdown and supports code execution in Python, R and other languages. It can be used to create reports, books, slides and <a href="https://quarto.org/docs/websites/">websites</a> (including this one 😄). I use it to create a personal wiki for machine learning. It’s a collection of <code>.qmd</code> files that contain text, code snippets, formulas and interactive visualizations. The files are rendered to HTML and can be viewed in a browser. Notes (web pages) can be <a href="https://quarto.org/docs/websites/#linking">linked</a> to each other.</p>
</section>
<section id="file-structure" class="level3">
<h3 class="anchored" data-anchor-id="file-structure">File structure</h3>
<p>Each concept gets its own file. For example, to learn about quantization I’ve created three files in the <code>notes</code> folder:</p>
<ol type="1">
<li><code>notes/binary_numbers.qmd</code></li>
<li><code>notes/quantization.qmd</code></li>
<li><code>notes/qlora.qmd</code></li>
</ol>
<p>In <code>binary_numbers.qmd</code>, I’ve written about the binary number system starting with integers and then moving on to floating-point numbers. Hugging Face has an excellent guide on the <a href="https://huggingface.co/blog/hf-bitsandbytes-integration">topic</a> from which I’ve copied visualizations.</p>
<p>In <code>quantization.qmd</code> I’ve written about how reducing the number of bits used to represent weights reduces the memory footprint and computational cost of neural networks. It has a link to <code>binary_numbers.qmd</code> because binary numbers are used in quantization. The <code>qlora.qmd</code> connects it to LoRA adapters.</p>
<div class="grid">
<div class="g-col-6">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/quarto-wiki/files.png" class="img-fluid figure-img" style="width:60.0%"></p>
<figcaption>Note files</figcaption>
</figure>
</div>
</div>
<div class="g-col-6">
<p>When I come across a new concept or find myself unsure of an old one, I create a new file. Starting with a basic definition, I summarize the topic. The last time I had to manually calculate something using the chain rule was in 2017, so recently I refreshed the topic by writing a detailed <code>chain_rule.md</code> note.</p>
</div>
</div>
</section>
<section id="notes" class="level3">
<h3 class="anchored" data-anchor-id="notes">Notes</h3>
<p>Notes are a weave of Markdown, code snippets and images. If you’re familiar with Jupyter notebooks or R Markdown, you’ll feel right at home. Quarto’s <a href="https://quarto.org/docs/get-started/hello/jupyter.html">tutorial</a> is a great place to start.</p>
<p>Here’s an example of a note about derivatives:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/quarto-wiki/derivatives.png" class="img-fluid figure-img"></p>
<figcaption>Example file derivatives.qmd</figcaption>
</figure>
</div>
<p>I end every note with a sources section, e.g.&nbsp;</p>
<pre><code>## Sources

- [Stackoverflow AI in your pocket](https://stackoverflow.blog/2023/08/23/fitting-ai-models-in-your-pocket-with-quantization/)
- [Transformers Quantization Documentation](https://huggingface.co/docs/transformers/quantization)
- [Quantization](https://huggingface.co/blog/merve/quantization)
- [4bit transformers](https://huggingface.co/blog/4bit-transformers-bitsandbytes)
- [A Gentle Introduction to 8-bit Matrix Multiplication for transformers at scale using Hugging Face Transformers, Accelerate and bitsandbytes](https://huggingface.co/blog/hf-bitsandbytes-integration)
- [LLM-Model-VRAM-Calculator](https://huggingface.co/spaces/NyxKrage/LLM-Model-VRAM-Calculator)</code></pre>
<p>in <code>quantization.qmd</code>. These can be links to blog posts, books, papers, documentation, YouTube videos or anything else that helped me understand the topic, like the <a href="https://huggingface.co/spaces/NyxKrage/LLM-Model-VRAM-Calculator">VRAM-calculator</a> in the last link.</p>
</section>
<section id="website" class="level3">
<h3 class="anchored" data-anchor-id="website">Website</h3>
<p>To turn this collection of files into a website, two additional files are needed:</p>
<p>index.qmd:</p>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode yaml code-with-copy"><code class="sourceCode yaml"><span id="cb3-1"><span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">---</span></span>
<span id="cb3-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">title</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Study Wiki"</span></span>
<span id="cb3-3"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">listing</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span></span>
<span id="cb3-4"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">  </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">contents</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> notes</span></span>
<span id="cb3-5"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">  </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sort</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"date desc"</span></span>
<span id="cb3-6"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">  </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">type</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> default</span></span>
<span id="cb3-7"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">  </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sort-ui</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">true</span></span>
<span id="cb3-8"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">  </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">filter-ui</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">true</span></span>
<span id="cb3-9"><span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">---</span></span></code></pre></div>
<p>and <code>_quarto.yml</code>:</p>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode yaml code-with-copy"><code class="sourceCode yaml"><span id="cb4-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">project</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span></span>
<span id="cb4-2"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">  </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">type</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> website</span></span>
<span id="cb4-3"></span>
<span id="cb4-4"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">website</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span></span>
<span id="cb4-5"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">  </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">title</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Study wiki"</span></span>
<span id="cb4-6"></span>
<span id="cb4-7"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">format</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span></span>
<span id="cb4-8"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">  </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">html</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span></span>
<span id="cb4-9"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">    </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">theme</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> darkly</span></span>
<span id="cb4-10"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">    </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">toc</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">true</span></span></code></pre></div>
<p>The overall structure looks like this:</p>
<pre><code>_quarto.yml
index.qmd
notes/
  binary_numbers.qmd
  quantization.qmd
  qlora.qmd</code></pre>
<p>To render the website, run <code>quarto render</code> in the terminal. The website is then available in <code>_site/index.html</code> and can be opened in a browser. Typically, I render individual notes using the <code>render</code> button rather than the whole website.</p>
<p>And this is what the website looks like:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/quarto-wiki/wiki.png" class="img-fluid figure-img"></p>
<figcaption>Personal wiki website, please excuse the mix of German and English</figcaption>
</figure>
</div>
<p>It has sorting and search functionality.</p>
<p>And this is what a note looks like:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/quarto-wiki/batching.png" class="img-fluid figure-img"></p>
<figcaption>Rendered note about batching</figcaption>
</figure>
</div>
<p>It has a table of contents and references to sources. Quarto can be <a href="https://quarto.org/docs/output-formats/html-themes.html">themed</a>, here with the darkly theme.</p>
</section>
<section id="ide-and-extensions" class="level3">
<h3 class="anchored" data-anchor-id="ide-and-extensions">IDE and extensions</h3>
<p>I use Quarto with <a href="https://code.visualstudio.com">VSCode</a> and the <a href="https://marketplace.visualstudio.com/items?itemName=quarto.quarto">Quarto extension</a>. I find <a href="https://plotly.com/python/">Plotly</a> to be the best for these notes because it’s interactive (tooltips, zoom, filter) without a need for customization.</p>
</section>
</section>
<section id="copilots-are-great-at-formulas-and-visualizations" class="level2">
<h2 class="anchored" data-anchor-id="copilots-are-great-at-formulas-and-visualizations">Copilots are great at formulas and visualizations</h2>
<p><a href="https://github.com/features/copilot">Github Copilot</a> and other code completers like <a href="https://www.tabnine.com">TabNine</a> and <a href="https://supermaven.com">Supermaven</a> can generate LaTeX formulas and interactive Plotly visualizations.</p>
<p>Using a copilot, you can fly through creating notes and illustrate them beautifully.</p>
<p>For example, if you’re writing a note about linear regression, you might ask Copilot for the formula:</p>
<blockquote class="blockquote">
<p>Formula for linear regression:</p>
</blockquote>
<p>and Copilot will generate:</p>
<pre><code>$$ y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \ldots + \beta_n x_n $$</code></pre>
<p>which renders as:</p>
<p><img src="https://latex.codecogs.com/png.latex?%20y%20=%20%5Cbeta_0%20+%20%5Cbeta_1%20x_1%20+%20%5Cbeta_2%20x_2%20+%20%5Cldots%20+%20%5Cbeta_n%20x_n%20"></p>
<p>or ask for a visualization:</p>
<blockquote class="blockquote">
<p>Visualization of linear regression using a sample dataset:</p>
</blockquote>
<p>and Copilot might generate:</p>
<div id="1d90c91c" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> plotly.express <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> px</span>
<span id="cb7-2"></span>
<span id="cb7-3">df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> px.data.tips()</span>
<span id="cb7-4">fig <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> px.scatter(df, x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"total_bill"</span>, y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"tip"</span>, trendline<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ols"</span>, height<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">250</span>, width<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">600</span>)</span>
<span id="cb7-5">fig.data[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].line.color <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"red"</span></span>
<span id="cb7-6"></span>
<span id="cb7-7">fig.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>                            <div id="2743f3fa-a0e7-4b9a-9006-5ce693514382" class="plotly-graph-div" style="height:250px; width:600px;"></div>            <script type="text/javascript">                require(["plotly"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById("2743f3fa-a0e7-4b9a-9006-5ce693514382")) {                    Plotly.newPlot(                        "2743f3fa-a0e7-4b9a-9006-5ce693514382",                        [{"hovertemplate":"total_bill=%{x}\u003cbr\u003etip=%{y}\u003cextra\u003e\u003c\u002fextra\u003e","legendgroup":"","marker":{"color":"#636efa","symbol":"circle"},"mode":"markers","name":"","orientation":"v","showlegend":false,"x":[16.99,10.34,21.01,23.68,24.59,25.29,8.77,26.88,15.04,14.78,10.27,35.26,15.42,18.43,14.83,21.58,10.33,16.29,16.97,20.65,17.92,20.29,15.77,39.42,19.82,17.81,13.37,12.69,21.7,19.65,9.55,18.35,15.06,20.69,17.78,24.06,16.31,16.93,18.69,31.27,16.04,17.46,13.94,9.68,30.4,18.29,22.23,32.4,28.55,18.04,12.54,10.29,34.81,9.94,25.56,19.49,38.01,26.41,11.24,48.27,20.29,13.81,11.02,18.29,17.59,20.08,16.45,3.07,20.23,15.01,12.02,17.07,26.86,25.28,14.73,10.51,17.92,27.2,22.76,17.29,19.44,16.66,10.07,32.68,15.98,34.83,13.03,18.28,24.71,21.16,28.97,22.49,5.75,16.32,22.75,40.17,27.28,12.03,21.01,12.46,11.35,15.38,44.3,22.42,20.92,15.36,20.49,25.21,18.24,14.31,14.0,7.25,38.07,23.95,25.71,17.31,29.93,10.65,12.43,24.08,11.69,13.42,14.26,15.95,12.48,29.8,8.52,14.52,11.38,22.82,19.08,20.27,11.17,12.26,18.26,8.51,10.33,14.15,16.0,13.16,17.47,34.3,41.19,27.05,16.43,8.35,18.64,11.87,9.78,7.51,14.07,13.13,17.26,24.55,19.77,29.85,48.17,25.0,13.39,16.49,21.5,12.66,16.21,13.81,17.51,24.52,20.76,31.71,10.59,10.63,50.81,15.81,7.25,31.85,16.82,32.9,17.89,14.48,9.6,34.63,34.65,23.33,45.35,23.17,40.55,20.69,20.9,30.46,18.15,23.1,15.69,19.81,28.44,15.48,16.58,7.56,10.34,43.11,13.0,13.51,18.71,12.74,13.0,16.4,20.53,16.47,26.59,38.73,24.27,12.76,30.06,25.89,48.33,13.27,28.17,12.9,28.15,11.59,7.74,30.14,12.16,13.42,8.58,15.98,13.42,16.27,10.09,20.45,13.28,22.12,24.01,15.69,11.61,10.77,15.53,10.07,12.6,32.83,35.83,29.03,27.18,22.67,17.82,18.78],"xaxis":"x","y":[1.01,1.66,3.5,3.31,3.61,4.71,2.0,3.12,1.96,3.23,1.71,5.0,1.57,3.0,3.02,3.92,1.67,3.71,3.5,3.35,4.08,2.75,2.23,7.58,3.18,2.34,2.0,2.0,4.3,3.0,1.45,2.5,3.0,2.45,3.27,3.6,2.0,3.07,2.31,5.0,2.24,2.54,3.06,1.32,5.6,3.0,5.0,6.0,2.05,3.0,2.5,2.6,5.2,1.56,4.34,3.51,3.0,1.5,1.76,6.73,3.21,2.0,1.98,3.76,2.64,3.15,2.47,1.0,2.01,2.09,1.97,3.0,3.14,5.0,2.2,1.25,3.08,4.0,3.0,2.71,3.0,3.4,1.83,5.0,2.03,5.17,2.0,4.0,5.85,3.0,3.0,3.5,1.0,4.3,3.25,4.73,4.0,1.5,3.0,1.5,2.5,3.0,2.5,3.48,4.08,1.64,4.06,4.29,3.76,4.0,3.0,1.0,4.0,2.55,4.0,3.5,5.07,1.5,1.8,2.92,2.31,1.68,2.5,2.0,2.52,4.2,1.48,2.0,2.0,2.18,1.5,2.83,1.5,2.0,3.25,1.25,2.0,2.0,2.0,2.75,3.5,6.7,5.0,5.0,2.3,1.5,1.36,1.63,1.73,2.0,2.5,2.0,2.74,2.0,2.0,5.14,5.0,3.75,2.61,2.0,3.5,2.5,2.0,2.0,3.0,3.48,2.24,4.5,1.61,2.0,10.0,3.16,5.15,3.18,4.0,3.11,2.0,2.0,4.0,3.55,3.68,5.65,3.5,6.5,3.0,5.0,3.5,2.0,3.5,4.0,1.5,4.19,2.56,2.02,4.0,1.44,2.0,5.0,2.0,2.0,4.0,2.01,2.0,2.5,4.0,3.23,3.41,3.0,2.03,2.23,2.0,5.16,9.0,2.5,6.5,1.1,3.0,1.5,1.44,3.09,2.2,3.48,1.92,3.0,1.58,2.5,2.0,3.0,2.72,2.88,2.0,3.0,3.39,1.47,3.0,1.25,1.0,1.17,4.67,5.92,2.0,2.0,1.75,3.0],"yaxis":"y","type":"scatter"},{"hovertemplate":"\u003cb\u003eOLS trendline\u003c\u002fb\u003e\u003cbr\u003etip = 0.105025 * total_bill + 0.92027\u003cbr\u003eR\u003csup\u003e2\u003c\u002fsup\u003e=0.456617\u003cbr\u003e\u003cbr\u003etotal_bill=%{x}\u003cbr\u003etip=%{y} \u003cb\u003e(trend)\u003c\u002fb\u003e\u003cextra\u003e\u003c\u002fextra\u003e","legendgroup":"","marker":{"color":"#636efa","symbol":"circle"},"mode":"lines","name":"","showlegend":false,"x":[3.07,5.75,7.25,7.25,7.51,7.56,7.74,8.35,8.51,8.52,8.58,8.77,9.55,9.6,9.68,9.78,9.94,10.07,10.07,10.09,10.27,10.29,10.33,10.33,10.34,10.34,10.51,10.59,10.63,10.65,10.77,11.02,11.17,11.24,11.35,11.38,11.59,11.61,11.69,11.87,12.02,12.03,12.16,12.26,12.43,12.46,12.48,12.54,12.6,12.66,12.69,12.74,12.76,12.9,13.0,13.0,13.03,13.13,13.16,13.27,13.28,13.37,13.39,13.42,13.42,13.42,13.51,13.81,13.81,13.94,14.0,14.07,14.15,14.26,14.31,14.48,14.52,14.73,14.78,14.83,15.01,15.04,15.06,15.36,15.38,15.42,15.48,15.53,15.69,15.69,15.77,15.81,15.95,15.98,15.98,16.0,16.04,16.21,16.27,16.29,16.31,16.32,16.4,16.43,16.45,16.47,16.49,16.58,16.66,16.82,16.93,16.97,16.99,17.07,17.26,17.29,17.31,17.46,17.47,17.51,17.59,17.78,17.81,17.82,17.89,17.92,17.92,18.04,18.15,18.24,18.26,18.28,18.29,18.29,18.35,18.43,18.64,18.69,18.71,18.78,19.08,19.44,19.49,19.65,19.77,19.81,19.82,20.08,20.23,20.27,20.29,20.29,20.45,20.49,20.53,20.65,20.69,20.69,20.76,20.9,20.92,21.01,21.01,21.16,21.5,21.58,21.7,22.12,22.23,22.42,22.49,22.67,22.75,22.76,22.82,23.1,23.17,23.33,23.68,23.95,24.01,24.06,24.08,24.27,24.52,24.55,24.59,24.71,25.0,25.21,25.28,25.29,25.56,25.71,25.89,26.41,26.59,26.86,26.88,27.05,27.18,27.2,27.28,28.15,28.17,28.44,28.55,28.97,29.03,29.8,29.85,29.93,30.06,30.14,30.4,30.46,31.27,31.71,31.85,32.4,32.68,32.83,32.9,34.3,34.63,34.65,34.81,34.83,35.26,35.83,38.01,38.07,38.73,39.42,40.17,40.55,41.19,43.11,44.3,45.35,48.17,48.27,48.33,50.81],"xaxis":"x","y":[1.2426948819246395,1.5241605885147065,1.6816973645912365,1.6816973645912365,1.7090037391111685,1.7142549649803862,1.7331593781095698,1.7972243337140252,1.814028256495522,1.8150785016693654,1.8213799727124267,1.8413346310154537,1.9232537545752495,1.9285049804444672,1.9369069418352154,1.9474093935736507,1.9642133163551472,1.9778665036151133,1.9778665036151133,1.9799669939628002,1.9988714070919837,2.000971897439671,2.005172878135045,2.005172878135045,2.0062231233088887,2.0062231233088887,2.024077291264229,2.032479252654977,2.036680233350351,2.038780723698038,2.0513836657841606,2.0776397951302488,2.093393472737902,2.1007451889548068,2.1122978858670853,2.1154486213886163,2.1375037700393302,2.1396042603870176,2.1480062217777656,2.1669106349069494,2.182664312514602,2.183714557688446,2.1973677449484117,2.207870196686847,2.225724364642187,2.2288751001637177,2.230975590511405,2.237277061554466,2.2435785325975273,2.2498800036405884,2.253030739162119,2.258281965031337,2.2603824553790237,2.2750858878128333,2.2855883395512686,2.2855883395512686,2.288739075072799,2.2992415268112345,2.302392262332765,2.313944959245044,2.3149952044188877,2.3244474109834794,2.3265479013311667,2.329698636852697,2.329698636852697,2.329698636852697,2.339150843417289,2.370658198632595,2.370658198632595,2.384311385892561,2.390612856935622,2.3979645731525268,2.406366534543275,2.4179192314555538,2.4231704573247717,2.4410246252801118,2.4452256059754855,2.4672807546262,2.472531980495418,2.4777832063646352,2.496687619493819,2.4998383550153496,2.501938845363037,2.5334462005783425,2.53554669092603,2.539747671621404,2.546049142664465,2.5513003685336826,2.568104291315179,2.568104291315179,2.5765062527059275,2.5807072334013017,2.5954106658351113,2.598561401356642,2.598561401356642,2.6006618917043287,2.604862872399703,2.622717040355043,2.629018511398104,2.631119001745791,2.6332194920934784,2.634269737267322,2.64267169865807,2.6458224341796006,2.647922924527288,2.650023414874975,2.6521239052226617,2.6615761117872534,2.6699780731780023,2.6867819959594987,2.6983346928717773,2.7025356735671515,2.7046361639148384,2.713038125305587,2.7329927836086143,2.7361435191301444,2.7382440094778318,2.753997687085485,2.755047932259328,2.7592489129547024,2.767650874345451,2.787605532648478,2.7907562681700084,2.791806513343852,2.799158229560757,2.8023089650822874,2.8023089650822874,2.8149119071684097,2.8264646040806887,2.8359168106452803,2.8380173009929677,2.8401177913406546,2.841168036514498,2.841168036514498,2.8474695075575593,2.8558714689483073,2.8779266175990217,2.8831778434682396,2.8852783338159265,2.8926300500328312,2.9241374052481373,2.961946231506505,2.967197457375722,2.9840013801572187,2.996604322243341,3.000805302938715,3.001855548112559,3.0291619226324906,3.044915600240144,3.0491165809355176,3.051217071283205,3.051217071283205,3.0680209940647014,3.072221974760075,3.07642295545545,3.089025897541572,3.0932268782369463,3.0932268782369463,3.100578594453851,3.11528202688766,3.1173825172353475,3.1268347237999397,3.1268347237999397,3.1425884014075924,3.1782967373182727,3.1866986987090207,3.199301640795143,3.2434119380965716,3.2549646350088506,3.2749192933118776,3.2822710095287824,3.301175422657966,3.309577384048714,3.310627629222558,3.316929100265619,3.346335965133238,3.353687681350143,3.370491604131639,3.4072501852161627,3.435606804909938,3.4419082759529998,3.447159501822217,3.449259992169904,3.4692146504729315,3.4954707798190197,3.49862151534055,3.5028224960359244,3.515425438122047,3.5458825481635095,3.567937696814224,3.5752894130311286,3.576339658204972,3.6046962778987472,3.6204499555064005,3.639354368635584,3.693967117675448,3.712871530804631,3.7412281504984066,3.7433286408460935,3.761182808801434,3.7748359960613995,3.776936486409087,3.7853384477998353,3.8767097779242223,3.8788102682719097,3.907166887965685,3.918719584877964,3.9628298821793924,3.9691313532224535,4.050000231608406,4.055251457477623,4.0636534188683715,4.077306606128338,4.085708567519086,4.113014942039017,4.119316413082079,4.204386272163405,4.250597059812521,4.265300492246331,4.323063976807724,4.352470841675343,4.368224519282996,4.375576235499901,4.522610559837996,4.557268650574833,4.559369140922519,4.576173063704016,4.578273554051703,4.623434096526975,4.683298071436057,4.912251519333947,4.918552990377008,4.987869171850681,5.060336088845886,5.1391044768841505,5.1790137934902045,5.24622948461619,5.4478765579941495,5.572855733681529,5.683131476935101,5.979300615958977,5.989803067697413,5.9961045387404734,6.256565341853671],"yaxis":"y","type":"scatter","line":{"color":"red"}}],                        {"template":{"data":{"histogram2dcontour":[{"type":"histogram2dcontour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"choropleth":[{"type":"choropleth","colorbar":{"outlinewidth":0,"ticks":""}}],"histogram2d":[{"type":"histogram2d","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmap":[{"type":"heatmap","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmapgl":[{"type":"heatmapgl","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"contourcarpet":[{"type":"contourcarpet","colorbar":{"outlinewidth":0,"ticks":""}}],"contour":[{"type":"contour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"surface":[{"type":"surface","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"mesh3d":[{"type":"mesh3d","colorbar":{"outlinewidth":0,"ticks":""}}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"parcoords":[{"type":"parcoords","line":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolargl":[{"type":"scatterpolargl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"scattergeo":[{"type":"scattergeo","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolar":[{"type":"scatterpolar","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"scattergl":[{"type":"scattergl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatter3d":[{"type":"scatter3d","line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermapbox":[{"type":"scattermapbox","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterternary":[{"type":"scatterternary","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattercarpet":[{"type":"scattercarpet","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"pie":[{"automargin":true,"type":"pie"}]},"layout":{"autotypenumbers":"strict","colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"hovermode":"closest","hoverlabel":{"align":"left"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"bgcolor":"#E5ECF6","angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"ternary":{"bgcolor":"#E5ECF6","aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]]},"xaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"yaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"geo":{"bgcolor":"white","landcolor":"#E5ECF6","subunitcolor":"white","showland":true,"showlakes":true,"lakecolor":"white"},"title":{"x":0.05},"mapbox":{"style":"light"},"margin":{"b":0,"l":0,"r":0,"t":30}}},"xaxis":{"anchor":"y","domain":[0.0,1.0],"title":{"text":"total_bill"}},"yaxis":{"anchor":"x","domain":[0.0,1.0],"title":{"text":"tip"}},"legend":{"tracegroupgap":0},"height":250,"width":600},                        {"responsive": true}                    ).then(function(){
                            
var gd = document.getElementById('2743f3fa-a0e7-4b9a-9006-5ce693514382');
var x = new MutationObserver(function (mutations, observer) {{
        var display = window.getComputedStyle(gd).display;
        if (!display || display === 'none') {{
            console.log([gd, 'removed!']);
            Plotly.purge(gd);
            observer.disconnect();
        }}
}});

// Listen for the removal of the full notebook cells
var notebookContainer = gd.closest('#notebook-container');
if (notebookContainer) {{
    x.observe(notebookContainer, {childList: true});
}}

// Listen for the clearing of the current output cell
var outputEl = gd.closest('.output');
if (outputEl) {{
    x.observe(outputEl, {childList: true});
}}

                        })                };                });            </script>        </div>
</div>
</div>
<p>Using a separate chat like ChatGPT also works, but requires more copy-pasting, which breaks the flow.</p>
</section>
<section id="discussion" class="level2">
<h2 class="anchored" data-anchor-id="discussion">Discussion</h2>
<div class="grid">
<section id="pros" class="level3 g-col-6">
<h3 class="anchored" data-anchor-id="pros">Pros</h3>
<ul>
<li>Enhance understanding with code snippets, formulas and interactive visualizations</li>
<li>Collect the best learning resources in one place</li>
<li>Free, open-source software running locally without needing an internet connection</li>
<li>Text files are future-proof and can be read by any text editor</li>
<li>Possible to version control with Git</li>
<li>Easy to back up</li>
<li>Gets better over time as more notes are added and interlinked</li>
<li>Visualizes learning progress in a satisfying way</li>
</ul>
</section>
<section id="cons" class="level3 g-col-6">
<h3 class="anchored" data-anchor-id="cons">Cons</h3>
<ul>
<li>It doesn’t work well on mobile. You could find a way to read the notes, but editing is not practical</li>
<li>Over-engineering notes with interactivity can turn into pseudowork</li>
<li>Creating many shallow notes using an LLM can also be pseudowork</li>
<li>Learning curve if you’re not familiar with Markdown and a programming language supported by Quarto</li>
</ul>
</section>
</div>
<p>If you’re in machine learning, data engineering, or a similar technical field I highly recommend <a href="https://quarto.org">Quarto</a> for creating a personal wiki. If you don’t need code, formulas or interactive visualizations, <a href="https://obsidian.md">Obsidian</a> is an easier alternative that is based on Markdown and local-first. Finally, Apple Notes and Microsoft OneNote are OK too, if you don’t mind being locked into their ecosystems.</p>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further reading</h2>
<ul>
<li><a href="https://x.com/karpathy/status/1756380066580455557">The shortification of learning</a> by Andrej Karpathy</li>
<li><a href="https://www.scotthyoung.com/blog/2019/02/15/memory/">The Complete Guide to Memory</a> by Scott Young and Jakub Jílek</li>
</ul>


</section>

 ]]></description>
  <category>Productivity</category>
  <category>Machine Learning</category>
  <guid>https://simmering.dev/blog/quarto-wiki/</guid>
  <pubDate>Sat, 06 Jul 2024 22:00:00 GMT</pubDate>
  <media:content url="https://simmering.dev/blog/quarto-wiki/library.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Fast and good</title>
  <dc:creator>Paul Simmering</dc:creator>
  <link>https://simmering.dev/blog/fast-and-good/</link>
  <description><![CDATA[ 





<p>The adage goes: fast, good, cheap. Pick two. As a developer, you probably don’t want to be cheap labor, so I suggest that you strive for fast and good. Not just good, and not just fast—both.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/fast-and-good/good_fast_cheap.png" class="img-fluid figure-img" style="width:65.0%"></p>
<figcaption>Good, fast, cheap</figcaption>
</figure>
</div>
<p>A developer writing bad code quickly creates troublesome “spaghetti code” that may function for a demo but becomes a nightmare to maintain as the project scales. LLMs have made this even easier.</p>
<p>Conversely, a developer who writes good code at a glacial pace may see the project run out of money, be overtaken by competitors or get stuck in a cycle of endless refactoring.</p>
<p>Both outcomes are to be avoided.</p>
<p>But can’t you just write the first version quickly, get feedback, and then rewrite it properly?</p>
<p>You may not get the luxury of a full rewrite. Rewrites are <a href="https://swizec.com/blog/you-can-t-stop-the-business-or-why-rewrites-fail/">risky</a> and often <a href="https://www.joelonsoftware.com/2000/04/06/things-you-should-never-do-part-i/">ill-advised</a>. It’s hard to find the time for a rewrite on a project that is accelerating. It’s not impossible to do a successful rewrite, but rare. Projects like <a href="https://tailwindcss.com/blog/tailwindcss-v4-alpha">Tailwind CSS</a> and <a href="https://docs.pydantic.dev/2.0/blog/pydantic-v2-alpha/">Pydantic</a> have done successful rewrites in Rust. This happened after they achieved amazing adoption and had plenty of resources. For most projects, a rewrite is not a viable option. That means you need to get it right the first time.</p>
<p>The dual optimum of fast and good is achievable with a balanced approach.</p>
<p>Before diving into strategies, I’d like to clarify that fast doesn’t just mean typing quickly. <a href="https://en.wiktionary.org/wiki/slow_is_smooth,_smooth_is_fast">“Slow is smooth, smooth is fast”</a>. The fastest way to write a feature can involve spending 2 hours sketching out the design first.</p>
<p>Now, here are some strategies that helped me, and might help you, get closer to the dual optimum:</p>
<section id="strategies-for-the-dual-optimum" class="level2">
<h2 class="anchored" data-anchor-id="strategies-for-the-dual-optimum">Strategies for the dual optimum</h2>
<section id="prioritize-and-plan" class="level3">
<h3 class="anchored" data-anchor-id="prioritize-and-plan">Prioritize and plan</h3>
<ul>
<li><strong>Don’t build unnecessary features</strong>: much easier said than done, but this belongs at the top of every list of productivity tips.</li>
<li><strong>Involve users early</strong>: work in sprints, get feedback and iterate.</li>
<li><strong>Sketch it first</strong>: write the names of functions and classes before writing the code, then fill in the details.</li>
<li><strong>Don’t over-engineer for scale you don’t have</strong>: Most companies have gigabytes to terrabytes of data, <a href="https://motherduck.com/blog/big-data-is-dead/">not petabytes</a>, and an outage once in a few months is acceptable. Don’t build for the scale of Google if you’re not Google.</li>
<li><strong>Don’t reinvent the wheel</strong>: For everything but your core differentiating features, use libraries and services. It can be worth adjusting your design to fit existing software.</li>
</ul>
</section>
<section id="minimize-waiting" class="level3">
<h3 class="anchored" data-anchor-id="minimize-waiting">Minimize waiting</h3>
<ul>
<li><strong>Minimize waiting for code</strong>: use a fast computer, fast internet connection, and run your code and tests locally if possible</li>
<li><strong>Minimize waiting for people</strong>: establish time limits for code reviews, schedule tasks in a way that minimizes dependencies on others.</li>
</ul>
</section>
<section id="create-an-environment-that-supports-flow" class="level3">
<h3 class="anchored" data-anchor-id="create-an-environment-that-supports-flow">Create an environment that supports flow</h3>
<ul>
<li><strong>Minimize interruptions</strong>: both external and <a href="https://ics.uci.edu/~gmark/Home_page/Publications_files/CHI%202011%20Self-interruption.pdf">self-interruptions</a>.</li>
<li><strong>Embrace bursts of productivity</strong>: use your best hours for coding, take breaks when you’re not productive, get on a <a href="https://www.paulgraham.com/makersschedule.html">maker’s schedule</a>, if possible.</li>
<li><strong>Learn to type fast</strong>: Not because typing speed itself is important, but because it reduces the friction between your thoughts and the code editor and the mental cost of rewriting a section of code.</li>
<li><strong>Learn your tools</strong>: keyboard shortcuts, IDE extensions, terminal commands.</li>
<li><strong>Use a <a href="https://github.com/features/copilot">Copilot</a></strong>: not because it writes better code than you, but because it lets you get it onto the page faster. This is especially useful for boilerplate code and for writing tests and documentation.</li>
</ul>
</section>
<section id="keep-a-clean-codebase" class="level3">
<h3 class="anchored" data-anchor-id="keep-a-clean-codebase">Keep a clean codebase</h3>
<ul>
<li><strong>Be willing to throw away code</strong>: if you realize you’ve gone down the wrong path during a coding session, don’t be afraid to delete parts of the code and start over.</li>
<li><strong>Hop from good state to good state</strong>: When working on a big feature, break it down into smaller tasks that leave the code in a runnable state at the end of each task. This also makes for clean commits and easier code reviews.</li>
<li><strong>Putter, within reason</strong>: Reading and re-reading code, refactoring and tweaking it is necessary to make it good. But don’t overdo it.</li>
</ul>
</section>
<section id="test-and-automate" class="level3">
<h3 class="anchored" data-anchor-id="test-and-automate">Test and automate</h3>
<ul>
<li><strong>Reduce worry about breaking things</strong>: use version control, write tests, use a test environment rather than working on production data.</li>
<li><strong>Automate everything</strong>: use a linter, formatter, test runner, CI/CD, deployment scripts and infrastructure as code.</li>
<li><strong>Write tests as you go</strong>: tests will give you the confidence to refactor and add features quickly. It’s easiest to write tests when you’re writing the code.</li>
</ul>
<p>May you code swiftly and wisely.</p>
<p>The term dual optimum and finding strategies to achieve it came from the book <a href="https://www.goodreads.com/book/show/17730608-winning-without-losing">Winning without Losing</a> by Martin Bjergegaard and Jordan Milne.</p>


</section>
</section>

 ]]></description>
  <category>Productivity</category>
  <guid>https://simmering.dev/blog/fast-and-good/</guid>
  <pubDate>Fri, 21 Jun 2024 22:00:00 GMT</pubDate>
  <media:content url="https://simmering.dev/blog/fast-and-good/good_fast_cheap.png" medium="image" type="image/png" height="132" width="144"/>
</item>
<item>
  <title>The best library for structured LLM output</title>
  <dc:creator>Paul Simmering</dc:creator>
  <link>https://simmering.dev/blog/structured_output/</link>
  <description><![CDATA[ 





<p>By default, Large Language Models (LLMs) output free-form text. But many use cases such as text classification, named entity recognition, relation extraction and information extraction require structured output. There are several Python libraries that help with this. In this article, I compare ten libraries in terms of efficiency, flexibility and ease of use.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/structured_output/image_wide.png" class="img-fluid figure-img"></p>
<figcaption>Image created with Playground v2.5</figcaption>
</figure>
</div>
<section id="python-libraries-for-structured-llm-output" class="level2">
<h2 class="anchored" data-anchor-id="python-libraries-for-structured-llm-output">10 Python libraries for structured LLM output</h2>
<p>Here are the most prominent solutions, sorted by the number of Github stars ⭐:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Library</th>
<th style="text-align: right;">Stars</th>
<th>Method¹</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><a href="https://python.langchain.com/docs/modules/model_io/output_parsers/types/pydantic/">langchain</a></td>
<td style="text-align: right;">84,100</td>
<td>Prompting &amp; function calling</td>
<td>Pydantic output parser as part of langchain</td>
</tr>
<tr class="even">
<td><a href="https://docs.llamaindex.ai/en/stable/module_guides/querying/structured_outputs/pydantic_program/">llama_index</a></td>
<td style="text-align: right;">31,500</td>
<td>Prompting &amp; function calling</td>
<td>Pydantic program as part of llama_index</td>
</tr>
<tr class="odd">
<td><a href="https://github.com/guidance-ai/guidance">guidance</a></td>
<td style="text-align: right;">17,500</td>
<td>Constrained token sampling</td>
<td>Programming paradigm for constrained generation</td>
</tr>
<tr class="even">
<td><a href="https://github.com/outlines-dev/outlines">outlines</a></td>
<td style="text-align: right;">5,800</td>
<td>Constrained token sampling</td>
<td>Constrained token sampling using CFGs²</td>
</tr>
<tr class="odd">
<td><a href="https://github.com/jxnl/instructor">instructor</a></td>
<td style="text-align: right;">5,200</td>
<td>Function calling</td>
<td>Specify Pydantic models to define structure of LLM outputs</td>
</tr>
<tr class="even">
<td><a href="https://github.com/prefecthq/marvin">marvin</a></td>
<td style="text-align: right;">4,800</td>
<td>Function calling</td>
<td>Toolbox of task-specific OpenAI API wrappers</td>
</tr>
<tr class="odd">
<td><a href="https://github.com/explosion/spacy-llm">spacy-llm</a></td>
<td style="text-align: right;">948</td>
<td>Prompting</td>
<td>spaCy plugin to add LLM responses to a pipeline</td>
</tr>
<tr class="even">
<td><a href="https://github.com/bananaml/fructose">fructose</a></td>
<td style="text-align: right;">687</td>
<td>Function calling</td>
<td>LLM calls as strongly-typed functions</td>
</tr>
<tr class="odd">
<td><a href="https://github.com/Mirascope/mirascope">mirascope</a></td>
<td style="text-align: right;">204</td>
<td>Function calling</td>
<td>Prompting, chaining and structured information extraction</td>
</tr>
<tr class="even">
<td><a href="https://github.com/qagentur/texttunnel">texttunnel</a></td>
<td style="text-align: right;">11</td>
<td>Function calling</td>
<td>Efficient async OpenAI API function calling</td>
</tr>
</tbody>
</table>
<p>¹The method describes how the library generates structured output. See the following sections for more details.</p>
<p>²Context-free grammars: a recursive way to define the structure of a natural language, programming language or other sequence of tokens. See <a href="https://en.wikipedia.org/wiki/Context-free_grammar">Wikipedia</a>.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
May 2024
</div>
</div>
<div class="callout-body-container callout-body">
<p>This article was written in May 2024 with the latest versions of the libraries and the number of Github stars at that time. The libraries are under active development and the features may have changed since then.</p>
</div>
</div>
<p>All libraries are released under the MIT or Apache 2.0 license, which are both permissive open-source licenses. Their code is available on Github and they can be installed via pip.</p>
<p>I’ll compare the libraries based on three criteria: efficiency, ease of use and flexibility. Efficiency is about how tokens are generated, ease of use is about how easy it is to get started with the library and flexibility is about how much you can customize the output format.</p>
<p>I’ll use a named entity recognition task as an example because it’s a common task that requires structured output. The task is to extract named entities from the following text:</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1">text <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"""BioNTech SE is set to acquire InstaDeep, </span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb1-2"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">a Tunis-born and U.K.-based artificial intelligence </span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb1-3"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">(AI) startup, for up to £562 million</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb1-4"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"""</span></span></code></pre></div>
<p>In the following sections, I’ll write a code snippet for each library. If possible, I’ll use Pydantic classes to define the schema for the structured output. Depending on the library’s support I’ll use OpenAI’s GPT-4-turbo or Meta’s Llama-3-8B-Instruct (<a href="https://huggingface.co/QuantFactory/Meta-Llama-3-8B-Instruct-GGUF">8-bit quantized and in GGUF format</a>) running on Ollama. I’ll set the temperature to 0.0 to reduce randomness in the output. This is also a little test of how easy it is to customize the parameters.</p>
<p>The libraries will be ordered by their method of generating structured output: prompting (llama_index, spacy-llm), function calling (instructor, marvin, mirascope, langchain, texttunnel), and constrained token sampling (outlines and guidance). llama_index also supports function calling and langchain also supports prompting.</p>
<p>At the start of each section I’ll give an overview of the generation method.</p>
</section>
<section id="prompting-for-structured-output" class="level2">
<h2 class="anchored" data-anchor-id="prompting-for-structured-output">Prompting for structured output</h2>
<p>This is the simplest approach. A prompt describes a desired output format and hopefully the LLM follows it.</p>
<p>Example prompt:</p>
<blockquote class="blockquote">
<p>Your task is to extract named entities from a text. Add no commentary, only extract the entities and their labels. Entities must have one of the following labels: PERSON, ORGANIZATION, LOCATION. Example text: “Apple is a company started by Steve Jobs, Steve Wozniak and Ronald Wayne in Los Altos.” Entities: Apple (ORGANIZATION), Steve Jobs (PERSON), Steve Wozniak (PERSON), Ronald Wayne (PERSON), Los Altos (LOCATION)</p>
</blockquote>
<blockquote class="blockquote">
<p>Text: “BioNTech SE is set to acquire InstaDeep, a Tunis-born and U.K.-based artificial intelligence (AI) startup, for up to £562 million”</p>
</blockquote>
<p>And answer from an LLM:</p>
<blockquote class="blockquote">
<p>BioNTech SE (ORGANIZATION), InstaDeep (ORGANIZATION), Tunis (LOCATION), U.K. (LOCATION)”</p>
</blockquote>
<p>✅ Pros:</p>
<ul>
<li>Works with any LLM</li>
<li>Easy to get started with</li>
</ul>
<p>❌ Cons:</p>
<ul>
<li>LLM may deviate from the format, especially if not fine-tuned on the task</li>
<li>Parsing can be tricky if the LLM outputs additional commentary</li>
<li>Explanation of the format adds an overhead to the prompt, increasing cost and latency</li>
</ul>
<section id="llama_index" class="level3">
<h3 class="anchored" data-anchor-id="llama_index">llama_index</h3>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> typing <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> List, Literal</span>
<span id="cb2-2"></span>
<span id="cb2-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pydantic <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> BaseModel</span>
<span id="cb2-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> llama_index.core.program <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> LLMTextCompletionProgram</span>
<span id="cb2-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> llama_index.llms.openai <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> OpenAI</span>
<span id="cb2-6"></span>
<span id="cb2-7"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> Entity(BaseModel):</span>
<span id="cb2-8">    name: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span></span>
<span id="cb2-9">    label: Literal[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"PERSON"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ORGANIZATION"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"LOCATION"</span>]</span>
<span id="cb2-10"></span>
<span id="cb2-11"></span>
<span id="cb2-12"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> ExtractEntities(BaseModel):</span>
<span id="cb2-13">    entities: List[Entity]</span>
<span id="cb2-14"></span>
<span id="cb2-15"></span>
<span id="cb2-16">prompt_template_str <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"""</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb2-17"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Extract named entities from the following text: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{text}</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb2-18"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb2-19"></span>
<span id="cb2-20">llm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> OpenAI(model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"gpt-4-turbo"</span>, temperature<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span>)</span>
<span id="cb2-21"></span>
<span id="cb2-22">program <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> LLMTextCompletionProgram.from_defaults(</span>
<span id="cb2-23">    output_cls<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>ExtractEntities,</span>
<span id="cb2-24">    prompt_template_str<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>prompt_template_str,</span>
<span id="cb2-25">    llm<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>llm,</span>
<span id="cb2-26">)</span>
<span id="cb2-27"></span>
<span id="cb2-28">output <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> program(text<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>text)</span>
<span id="cb2-29"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(output)</span></code></pre></div>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">entities<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[Entity(name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'BioNTech SE'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ORGANIZATION'</span>), Entity(name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'InstaDeep'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ORGANIZATION'</span>), Entity(name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Tunis'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'LOCATION'</span>), Entity(name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'U.K.'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'LOCATION'</span>)]</span></code></pre></div>
<p>Note that llama_index also has a function calling mode. I’m showing the prompting mode here.</p>
<p>✅ Pros:</p>
<ul>
<li>Works with prompting and function calling</li>
<li>Supports many <a href="https://docs.llamaindex.ai/en/stable/module_guides/models/llms/">LLMs</a> for Pydantic programs</li>
</ul>
<p>❌ Cons:</p>
<ul>
<li>Large library with many features, which can be overwhelming</li>
</ul>
<p>llama_index also has a guidance-based constrained generation mode, but it isn’t compatible with the latest version of guidance.</p>
<p>A common complaint about comprehensive libraries is that they have too many dependencies. This doesn’t apply to llama_index because it can be installed modularly. For example, you can install only the OpenAI module with <code>pip install llama-index-llms-openai</code>.</p>
</section>
<section id="spacy-llm" class="level3">
<h3 class="anchored" data-anchor-id="spacy-llm">spacy-llm</h3>
<p>spacy-llm uses the prompting approach in a sophisticated way. Prompts are built using a jinja-template based system to describe the task, give examples and implement chain-of-thought reasoning. See their <a href="https://github.com/explosion/spacy-llm/tree/main/spacy_llm/tasks/templates">templates</a> directory for examples.</p>
<p>To solve our named entity recognition task, we create a <code>config.cfg</code> file:</p>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode cfg code-with-copy"><code class="sourceCode ini"><span id="cb4-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">[nlp]</span></span>
<span id="cb4-2"><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">lang </span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;"> "en"</span></span>
<span id="cb4-3"><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">pipeline </span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;"> ["llm"]</span></span>
<span id="cb4-4"></span>
<span id="cb4-5"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">[components]</span></span>
<span id="cb4-6"></span>
<span id="cb4-7"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">[components.llm]</span></span>
<span id="cb4-8"><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">factory </span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;"> "llm"</span></span>
<span id="cb4-9"></span>
<span id="cb4-10"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">[components.llm.task]</span></span>
<span id="cb4-11"><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">@llm_tasks </span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;"> "spacy.NER.v3"</span></span>
<span id="cb4-12"><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">labels </span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;"> ["ORGANIZATION", "PERSON", "LOCATION"]</span></span>
<span id="cb4-13"></span>
<span id="cb4-14"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">[components.llm.model]</span></span>
<span id="cb4-15"><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">@llm_models </span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;"> "spacy.GPT-4.v3"</span></span>
<span id="cb4-16"><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">name </span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;"> "gpt-4"</span></span>
<span id="cb4-17"><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">config </span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;"> {"temperature": 0.0}</span></span></code></pre></div>
<p>Then run:</p>
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> spacy_llm.util <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> assemble</span>
<span id="cb5-2">nlp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> assemble(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"config.cfg"</span>)</span>
<span id="cb5-3">doc <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nlp(text)</span>
<span id="cb5-4"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>([(ent.text, ent.label_) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> ent <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> doc.ents])</span></code></pre></div>
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1">[(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'BioNTech SE'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ORGANIZATION'</span>), (<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'InstaDeep'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ORGANIZATION'</span>), (<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Tunis'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'LOCATION'</span>)]</span></code></pre></div>
<p>✅ Pros:</p>
<ul>
<li>Seamless integration with spaCy and Prodigy (for labeling)</li>
<li>Compatible with many APIs and open source LLMs from Hugging Face</li>
<li>Recipes for many tasks available out of the box</li>
</ul>
<p>❌ Cons:</p>
<ul>
<li>Config system and jinja-based prompt templating has a learning curve, especially for those unfamiliar with spaCy</li>
<li>Prompt-based approach is inefficient with respect to token usage</li>
<li>Doesn’t support async/multi-threaded processing (see this <a href="https://github.com/explosion/spacy-llm/discussions/258">discussion</a>)</li>
</ul>
</section>
<section id="function-calling-for-structured-output" class="level3">
<h3 class="anchored" data-anchor-id="function-calling-for-structured-output">Function calling for structured output</h3>
<p>Some LLMs have a function calling mode, which allows passing a function signature to the model along with the prompt. The LLM generates the arguments for the function. The <a href="https://platform.openai.com/docs/guides/function-calling">OpenAI</a> docs explain this in detail.</p>
<p>Example <a href="https://json-schema.org">JSON schema</a> for the named entity recognition task:</p>
<div class="sourceCode" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode json code-with-copy"><code class="sourceCode json"><span id="cb7-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb7-2">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"name"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"extract_entities"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb7-3">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"parameters"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb7-4">        <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"type"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"object"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb7-5">        <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"properties"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb7-6">            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"entities"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb7-7">                <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"type"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"array"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb7-8">                <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"items"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb7-9">                    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"type"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"object"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb7-10">                    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"properties"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb7-11">                        <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"name"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"type"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"string"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">},</span></span>
<span id="cb7-12">                        <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"description"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Named entity extracted from the text"</span></span>
<span id="cb7-13">                        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"label"</span><span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">:</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb7-14">                            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"type"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"string"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb7-15">                            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"enum"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"PERSON"</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ORGANIZATION"</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"LOCATION"</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">]</span></span>
<span id="cb7-16">                        <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">},</span></span>
<span id="cb7-17">                    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">},</span></span>
<span id="cb7-18">                    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"required"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"name"</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"label"</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">]</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb7-19">                    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"additionalProperties"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">false</span></span>
<span id="cb7-20">                <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb7-21">            <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">},</span></span>
<span id="cb7-22">        <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">},</span></span>
<span id="cb7-23">        <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"required"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"answers"</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">]</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb7-24">        <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"additionalProperties"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">false</span></span>
<span id="cb7-25">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">},</span></span>
<span id="cb7-26"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span></code></pre></div>
<p>In OpenAI’s format, the API would respond with:</p>
<div class="sourceCode" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode json code-with-copy"><code class="sourceCode json"><span id="cb8-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb8-2">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"choices"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb8-3">        <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb8-4">            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"message"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb8-5">                <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"function_call"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb8-6">                    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"arguments"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb8-7">                        <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"entities"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb8-8">                            <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"name"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"BioNTech SE"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"label"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ORGANIZATION"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb8-9">                            <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"name"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"InstaDeep"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"label"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ORGANIZATION"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb8-10">                            <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"name"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Tunis"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"label"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"LOCATION"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb8-11">                            <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"name"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"U.K."</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"label"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"LOCATION"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb8-12">                        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">]</span></span>
<span id="cb8-13">                    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb8-14">                <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb8-15">            <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb8-16">        <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb8-17">    <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">]</span></span>
<span id="cb8-18"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span></code></pre></div>
<p>(Simplified for brevity)</p>
<p>✅ Pros:</p>
<ul>
<li>Almost guaranteed valid output (LLMs are trained to generate valid function arguments)</li>
<li>Uses JSON as a standard interchange format</li>
<li>Easy to define constraints in JSON schema</li>
</ul>
<p>❌ Cons:</p>
<ul>
<li>Only a few LLMs support function calling</li>
<li>Adds overhead to the prompt</li>
</ul>
<p>instructor, mirascope, marvin, fructose, llama_index, langchain and texttunnel use this approach. As we’ll see later, Pydantic is a popular wrapper for the JSON schema. It’s less verbose and also provides type checking.</p>
</section>
<section id="instructor" class="level3">
<h3 class="anchored" data-anchor-id="instructor">instructor</h3>
<p>instructor patches LLM clients to accept Pydantic models as input and output. Here’s an example with OpenAI:</p>
<div class="sourceCode" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> typing <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> List, Literal</span>
<span id="cb9-2"></span>
<span id="cb9-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> instructor</span>
<span id="cb9-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pydantic <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> BaseModel</span>
<span id="cb9-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> openai <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> OpenAI</span>
<span id="cb9-6"></span>
<span id="cb9-7"></span>
<span id="cb9-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define the schema for the function calling API</span></span>
<span id="cb9-9"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> Entity(BaseModel):</span>
<span id="cb9-10">    name: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span></span>
<span id="cb9-11">    label: Literal[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"PERSON"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ORGANIZATION"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"LOCATION"</span>]</span>
<span id="cb9-12"></span>
<span id="cb9-13"></span>
<span id="cb9-14"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> ExtractEntities(BaseModel):</span>
<span id="cb9-15">    entities: List[Entity]</span>
<span id="cb9-16"></span>
<span id="cb9-17"></span>
<span id="cb9-18"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Patch the OpenAI client</span></span>
<span id="cb9-19">client <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> instructor.from_openai(OpenAI())</span>
<span id="cb9-20"></span>
<span id="cb9-21"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Call the LLM</span></span>
<span id="cb9-22">entities <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> client.chat.completions.create(</span>
<span id="cb9-23">    model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"gpt-4-turbo"</span>,</span>
<span id="cb9-24">    temperature<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span>,</span>
<span id="cb9-25">    response_model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>ExtractEntities,</span>
<span id="cb9-26">    messages<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[{<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"role"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"user"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"content"</span>: text}],</span>
<span id="cb9-27">)</span>
<span id="cb9-28"></span>
<span id="cb9-29"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(entities)</span></code></pre></div>
<div class="sourceCode" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1">entities<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[Entity(name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'BioNTech SE'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ORGANIZATION'</span>), Entity(name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'InstaDeep'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ORGANIZATION'</span>), Entity(name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Tunis'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'LOCATION'</span>), Entity(name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'U.K.'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'LOCATION'</span>)]</span></code></pre></div>
<p>✅ Pros:</p>
<ul>
<li>Easy to use due to its focused nature and plenty of examples</li>
<li>Patches OpenAI’s client instead of adding own abstractions, so it’s familiar to OpenAI users</li>
<li>Compatible with many APIs through direct support of OpenAI, Anthropic, Cohere, as well as LiteLLM which itself is compatible with <a href="https://docs.litellm.ai/docs/providers">more than 100 LLMs</a>, also support Ollama for local LLMs</li>
<li>Supports detailed Pydantic models with nested structures and validators, including re-tries with an adjusted prompt to show the LLM the formatting error of the previous response</li>
<li>Detailed docs with a cookbook</li>
</ul>
<p>❌ Cons:</p>
<ul>
<li>Does one job well, but doesn’t have many additional features</li>
<li>No complete solution for efficient batch processing, see <a href="docs">https://python.useinstructor.com/blog/2023/11/13/learn-async/?h=batch#practical-implications-of-batch-processing</a> (rate limiting not solved yet, though this is not found in many other libraries either)</li>
</ul>
</section>
<section id="mirascope" class="level3">
<h3 class="anchored" data-anchor-id="mirascope">mirascope</h3>
<div class="sourceCode" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> typing <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Literal, Type, List</span>
<span id="cb11-2"></span>
<span id="cb11-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> mirascope.openai <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> OpenAIExtractor</span>
<span id="cb11-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pydantic <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> BaseModel</span>
<span id="cb11-5"></span>
<span id="cb11-6"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> Entity(BaseModel):</span>
<span id="cb11-7">    name: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span></span>
<span id="cb11-8">    label: Literal[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"PERSON"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ORGANIZATION"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"LOCATION"</span>]</span>
<span id="cb11-9"></span>
<span id="cb11-10"></span>
<span id="cb11-11"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> Entities(BaseModel):</span>
<span id="cb11-12">    entities: List[Entity]</span>
<span id="cb11-13"></span>
<span id="cb11-14"></span>
<span id="cb11-15"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> EntityExtractor(OpenAIExtractor[Entities]):</span>
<span id="cb11-16">    extract_schema: Type[Entity] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Entities</span>
<span id="cb11-17">    prompt_template <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb11-18"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    Extract named entities from the following text:</span></span>
<span id="cb11-19"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{text}</span></span>
<span id="cb11-20"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb11-21"></span>
<span id="cb11-22">    text: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span></span>
<span id="cb11-23"></span>
<span id="cb11-24">entities <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> EntityExtractor(text<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>text).extract()</span>
<span id="cb11-25"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(entities)</span></code></pre></div>
<div class="sourceCode" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1">entities<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[Entity(name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'BioNTech SE'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ORGANIZATION'</span>), Entity(name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'InstaDeep'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ORGANIZATION'</span>), Entity(name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Tunis'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'LOCATION'</span>), Entity(name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'U.K.'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'LOCATION'</span>)]</span></code></pre></div>
<p>✅ Pros:</p>
<ul>
<li>Uses function calling with Pydantic models</li>
<li>Compatible with many LLM <a href="https://github.com/Mirascope/mirascope/blob/dev/docs/concepts/supported_llm_providers.md">providers</a> including OpenAI, Anthropic, Cohere and Groq.</li>
<li>Built in code organization through their colocation principle: everything relevant to an LLM call is in one class</li>
</ul>
<p>❌ Cons:</p>
<ul>
<li>No support for ollama, litellm and Hugging Face yet</li>
<li>Not mature (cookbook missing, many features planned but not yet implemented, few contributors)</li>
</ul>
<p>mirascope is a new library with a lot of potential. For structured output, it has similar functionality to instructor, with a different approach: rather than patching the OpenAI client, it offers classes for each LLM provider. The roadmap has features for agents, RAG, metrics and a CLI. The question is whether there is room for another fully-featured library next to langchain and llama_index.</p>
</section>
<section id="marvin" class="level3">
<h3 class="anchored" data-anchor-id="marvin">marvin</h3>
<div class="sourceCode" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> typing <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Literal</span>
<span id="cb13-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pydantic <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> BaseModel</span>
<span id="cb13-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> marvin</span>
<span id="cb13-4"></span>
<span id="cb13-5">marvin.settings.openai.chat.completions.model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"gpt-4-turbo"</span></span>
<span id="cb13-6"></span>
<span id="cb13-7"></span>
<span id="cb13-8"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> Entity(BaseModel):</span>
<span id="cb13-9">    name: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span></span>
<span id="cb13-10">    label: Literal[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"PERSON"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ORGANIZATION"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"LOCATION"</span>]</span>
<span id="cb13-11"></span>
<span id="cb13-12"></span>
<span id="cb13-13">entities <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> marvin.extract(</span>
<span id="cb13-14">    text,</span>
<span id="cb13-15">    target<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>Entity,</span>
<span id="cb13-16">    model_kwargs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>{<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"temperature"</span>: <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span>},</span>
<span id="cb13-17">)</span>
<span id="cb13-18"></span>
<span id="cb13-19"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(entities)</span></code></pre></div>
<div class="sourceCode" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1">[Entity(name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'BioNTech SE'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ORGANIZATION'</span>), Entity(name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'InstaDeep'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ORGANIZATION'</span>), Entity(name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Tunis'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'LOCATION'</span>), Entity(name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'U.K.'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'LOCATION'</span>)]</span></code></pre></div>
<p>✅ Pros:</p>
<ul>
<li>Easy to use due to its simple API and clear documentation</li>
<li>Many built-in tasks, including multi-modal ones like image classification and speech recognition</li>
</ul>
<p>❌ Cons:</p>
<ul>
<li>Only supports OpenAI models</li>
<li>Limited customization options and no access to underlying API response</li>
</ul>
<p>Marvin was the easiest to use in my test with instructor a close second. The developers describe marvin as a tool for developers who want to use rather than build AI. It’s a way to easily add many AI capabilities to your app. It’s not a tool for AI researchers.</p>
</section>
<section id="fructose" class="level3">
<h3 class="anchored" data-anchor-id="fructose">fructose</h3>
<div class="sourceCode" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> dataclasses <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> dataclass</span>
<span id="cb15-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> enum <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Enum</span>
<span id="cb15-3"></span>
<span id="cb15-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> fructose <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Fructose</span>
<span id="cb15-5"></span>
<span id="cb15-6">ai <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Fructose(model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"gpt-4-turbo"</span>)</span>
<span id="cb15-7"></span>
<span id="cb15-8"></span>
<span id="cb15-9"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> Label(Enum):</span>
<span id="cb15-10">    PERSON <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"PERSON"</span></span>
<span id="cb15-11">    ORGANIZATION <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ORGANIZATION"</span></span>
<span id="cb15-12">    LOCATION <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"LOCATION"</span></span>
<span id="cb15-13"></span>
<span id="cb15-14"></span>
<span id="cb15-15"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@dataclass</span></span>
<span id="cb15-16"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> Entity:</span>
<span id="cb15-17">    name: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span></span>
<span id="cb15-18">    label: Label</span>
<span id="cb15-19"></span>
<span id="cb15-20"></span>
<span id="cb15-21"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@ai</span></span>
<span id="cb15-22"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> extract_entities(text: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>[Entity]:</span>
<span id="cb15-23">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb15-24"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Given a text, extract the named entities with their labels.</span></span>
<span id="cb15-25"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb15-26">    ...</span>
<span id="cb15-27"></span>
<span id="cb15-28"></span>
<span id="cb15-29">entities <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> extract_entities(text)</span>
<span id="cb15-30"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(entities)</span></code></pre></div>
<div class="sourceCode" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1">[Entity(name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'BioNTech SE'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=&lt;</span>Label.ORGANIZATION: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ORGANIZATION'</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span>), Entity(name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'InstaDeep'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=&lt;</span>Label.ORGANIZATION: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ORGANIZATION'</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span>), Entity(name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Tunis'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=&lt;</span>Label.LOCATION: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'LOCATION'</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span>), Entity(name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'U.K.'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=&lt;</span>Label.LOCATION: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'LOCATION'</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span>)]</span></code></pre></div>
<p>✅ Pros:</p>
<ul>
<li>Chainable functions with an elegant syntax</li>
<li>Built-in support for chain of thought prompting</li>
</ul>
<p>❌ Cons:</p>
<ul>
<li>Uses dataclasses instead of Pydantic models</li>
<li>Only OpenAI models are officially supported, though other models implementing OpenAI’s API format <a href="https://github.com/bananaml/fructose/issues/13">can work too</a></li>
<li>I didn’t find a way to set the temperature</li>
<li>No documentation website</li>
<li>Not actively developed</li>
</ul>
</section>
<section id="langchain" class="level3">
<h3 class="anchored" data-anchor-id="langchain">langchain</h3>
<div class="sourceCode" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> typing <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> List, Literal</span>
<span id="cb17-2"></span>
<span id="cb17-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langchain.output_parsers.openai_tools <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> PydanticToolsParser</span>
<span id="cb17-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langchain_core.prompts <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> PromptTemplate</span>
<span id="cb17-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langchain_core.pydantic_v1 <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> BaseModel, Field, validator</span>
<span id="cb17-6"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langchain_openai <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> ChatOpenAI</span>
<span id="cb17-7"></span>
<span id="cb17-8"></span>
<span id="cb17-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set up a Pydantic model for the structured output</span></span>
<span id="cb17-10"></span>
<span id="cb17-11"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> Entity(BaseModel):</span>
<span id="cb17-12">    name: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Field(description<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"name of the entity"</span>)</span>
<span id="cb17-13">    label: Literal[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"PERSON"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ORGANIZATION"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"LOCATION"</span>]</span>
<span id="cb17-14"></span>
<span id="cb17-15"></span>
<span id="cb17-16"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> ExtractEntities(BaseModel):</span>
<span id="cb17-17">    entities: List[Entity]</span>
<span id="cb17-18"></span>
<span id="cb17-19"></span>
<span id="cb17-20"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Choose a model</span></span>
<span id="cb17-21">llm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ChatOpenAI(model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"gpt-4-turbo"</span>, temperature<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span>)</span>
<span id="cb17-22"></span>
<span id="cb17-23"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Force the model to always use the ExtractEntities schema</span></span>
<span id="cb17-24">llm_with_tools <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> llm.bind_tools([ExtractEntities], tool_choice<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ExtractEntities"</span>)</span>
<span id="cb17-25"></span>
<span id="cb17-26"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Add a parser to convert the LLM output to a Pydantic object</span></span>
<span id="cb17-27">chain <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> llm_with_tools <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">|</span> PydanticToolsParser(tools<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[ExtractEntities])</span>
<span id="cb17-28"></span>
<span id="cb17-29">chain.invoke(text)[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span></code></pre></div>
<div class="sourceCode" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1">ExtractEntities(entities<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[Entity(name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'BioNTech SE'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ORGANIZATION'</span>), Entity(name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'InstaDeep'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ORGANIZATION'</span>), Entity(name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Tunis'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'LOCATION'</span>), Entity(name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'U.K.'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'LOCATION'</span>)])</span></code></pre></div>
<p>This is the function calling solution for langchain. It also supports <a href="https://python.langchain.com/v0.1/docs/modules/model_io/output_parsers/types/json/">prompting</a>.</p>
<p>✅ Pros:</p>
<ul>
<li>Has both prompt-based and function calling solutions for structured output generation</li>
<li>Compatibly with many <a href="https://python.langchain.com/v0.1/docs/integrations/platforms/">APIs and LLMs</a></li>
</ul>
<p>❌ Cons:</p>
<p>Langchain is a huge library with many features, which can be overwhelming. There are multiple solutions to the same problem, which can be confusing for beginners. I’ve often read the <a href="https://minimaxir.com/2023/07/langchain-problem/">argument</a> that langchain’s abstractions are adding complexity and figuring out the langchain way of doing things can be harder than working with the underlying libraries directly.</p>
<p>To be fair, in the test case above the solution was easy to find in the <a href="https://python.langchain.com/v0.1/docs/modules/model_io/chat/function_calling/">docs</a> and worked right away.</p>
<p>Like llama_index, langchain can be installed modularly.</p>
</section>
<section id="texttunnel" class="level3">
<h3 class="anchored" data-anchor-id="texttunnel">texttunnel</h3>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>I’m the developer of texttunnel, but I’ll evaluate it as objectively as I can.</p>
</div>
</div>
<div class="sourceCode" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> texttunnel <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> chat, models, processor</span>
<span id="cb19-2"></span>
<span id="cb19-3">function <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb19-4">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"name"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"extract_entities"</span>,</span>
<span id="cb19-5">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"parameters"</span>: {</span>
<span id="cb19-6">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"type"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"object"</span>,</span>
<span id="cb19-7">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"properties"</span>: {</span>
<span id="cb19-8">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"entities"</span>: {</span>
<span id="cb19-9">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"type"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"array"</span>,</span>
<span id="cb19-10">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"items"</span>: {</span>
<span id="cb19-11">                    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"type"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"object"</span>,</span>
<span id="cb19-12">                    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"properties"</span>: {</span>
<span id="cb19-13">                        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"name"</span>: {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"type"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"string"</span>},</span>
<span id="cb19-14">                        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"label"</span>: {</span>
<span id="cb19-15">                            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"type"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"string"</span>,</span>
<span id="cb19-16">                            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"enum"</span>: [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"PERSON"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ORGANIZATION"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"LOCATION"</span>],</span>
<span id="cb19-17">                        },</span>
<span id="cb19-18">                    },</span>
<span id="cb19-19">                    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"required"</span>: [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"name"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"label"</span>],</span>
<span id="cb19-20">                    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"additionalProperties"</span>: <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>,</span>
<span id="cb19-21">                },</span>
<span id="cb19-22">            },</span>
<span id="cb19-23">        },</span>
<span id="cb19-24">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"required"</span>: [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"answers"</span>],</span>
<span id="cb19-25">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"additionalProperties"</span>: <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>,</span>
<span id="cb19-26">    },</span>
<span id="cb19-27">}</span>
<span id="cb19-28"></span>
<span id="cb19-29"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Build requests and process them</span></span>
<span id="cb19-30">requests <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> chat.build_requests(</span>
<span id="cb19-31">    texts<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[text],</span>
<span id="cb19-32">    function<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>function,</span>
<span id="cb19-33">    model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>models.GPT_4,</span>
<span id="cb19-34">    system_message<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"You are an NER model. Extract entities from the text."</span>,</span>
<span id="cb19-35">    params<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>models.Parameters(max_tokens<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">512</span>, temperature<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span>),</span>
<span id="cb19-36">)</span>
<span id="cb19-37"></span>
<span id="cb19-38">responses <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> processor.process_api_requests(requests)</span>
<span id="cb19-39"></span>
<span id="cb19-40">results <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [processor.parse_arguments(response<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>r) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> r <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> responses]</span>
<span id="cb19-41"></span>
<span id="cb19-42"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(results[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>])</span></code></pre></div>
<div class="sourceCode" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode json code-with-copy"><code class="sourceCode json"><span id="cb20-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span><span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">'entities'</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span><span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">'name'</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">'BioNTech</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">SE'</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">'label'</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">'ORGANIZATION'</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span><span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">'name'</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">'InstaDeep'</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">'label'</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">'ORGANIZATION'</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span><span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">'name'</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">'Tunis'</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">'label'</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">'LOCATION'</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span><span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">'name'</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">'U.K.'</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">'label'</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">'LOCATION'</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">]</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span></code></pre></div>
<p>texttunnel exposes the JSON schema directly, rather than wrapping it in a Pydantic model. It also returns the complete API response rather than only the extracted structured data. The unique selling point of texttunnel is its efficiency in calling the OpenAI API, as it uses asyncio to make multiple requests in parallel while respecting the individual rate limits of the user’s API key.</p>
<p>✅ Pros:</p>
<ul>
<li>Exposes the JSON schema and API response directly</li>
<li>Efficient async function calling in a convenient wrapper</li>
</ul>
<p>❌ Cons:</p>
<ul>
<li>Only supports OpenAI models</li>
<li>Only supports function calling</li>
<li>JSON schema is verbose and less user-friendly than Pydantic models</li>
<li>Not actively developed</li>
</ul>
</section>
<section id="constrained-token-sampling-for-structured-output" class="level3">
<h3 class="anchored" data-anchor-id="constrained-token-sampling-for-structured-output">Constrained token sampling for structured output</h3>
<p>This approach hooks deeper into the LLM generation process. The user defines constraints as Pydantic models, regular expressions or other means that can be expressed as context-free grammars (<a href="https://en.wikipedia.org/wiki/Context-free_grammar">CFGs</a>). At inference time, the library’s token generator only considers tokens in the output layer that match the constraints.</p>
<p>This approach doesn’t add overhead to the prompt, guarantees valid output and is even more flexible than function calling. It’s also highly efficient because the generator can skip tokens that only have one possible value.</p>
<p>✅ Pros:</p>
<ul>
<li>Guarantees valid output</li>
<li>Clear interchange format</li>
<li>Easy to define constraints</li>
<li>Efficient, skips unnecessary tokens</li>
</ul>
<p>❌ Cons:</p>
<ul>
<li>Requires endpoint integration, which API providers like OpenAI do not support</li>
</ul>
<p>outlines and guidance use this approach.</p>
</section>
<section id="outlines" class="level3">
<h3 class="anchored" data-anchor-id="outlines">outlines</h3>
<div class="sourceCode" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> typing <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> List, Literal</span>
<span id="cb21-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pydantic <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> BaseModel, Field</span>
<span id="cb21-3"></span>
<span id="cb21-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> outlines</span>
<span id="cb21-5"></span>
<span id="cb21-6">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> outlines.models.llamacpp(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"./models/Meta-Llama-3-8B-Instruct.Q8_0.gguf"</span>)</span>
<span id="cb21-7"></span>
<span id="cb21-8"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> Entity(BaseModel):</span>
<span id="cb21-9">    name: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Field(description<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"name of the entity"</span>)</span>
<span id="cb21-10">    label: Literal[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"PERSON"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ORGANIZATION"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"LOCATION"</span>]</span>
<span id="cb21-11"></span>
<span id="cb21-12"></span>
<span id="cb21-13"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> ExtractEntities(BaseModel):</span>
<span id="cb21-14">    entities: List[Entity]</span>
<span id="cb21-15"></span>
<span id="cb21-16"></span>
<span id="cb21-17">generator <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> outlines.generate.json(model, ExtractEntities)</span>
<span id="cb21-18"></span>
<span id="cb21-19">instruction <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Extract all named entities from the input using the labels: PERSON, ORGANIZATION, LOCATION. Input:"</span></span>
<span id="cb21-20">prompt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>instruction<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>text<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span></span>
<span id="cb21-21"></span>
<span id="cb21-22">entities <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> generator(prompt)</span>
<span id="cb21-23"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">repr</span>(entities))</span></code></pre></div>
<div class="sourceCode" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1">ExtractEntities(entities<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[Entity(name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'BioNTech SE'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ORGANIZATION'</span>), Entity(name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Instadeep'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ORGANIZATION'</span>), Entity(name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Tunis'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'LOCATION'</span>), Entity(name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'U.K.'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'LOCATION'</span>)])</span></code></pre></div>
<p>Under the hood outlines translates the Pydantic model to a CFG. It steps through the CFG token by token and generates the output.</p>
<p>✅ Pros:</p>
<ul>
<li>Efficient token generation that adds no overhead and even speeds up inference (see <a href="http://blog.dottxt.co/coalescence.html">article</a>)</li>
<li>Translates Pydantic models, regular expressions, multiple choice questions and Jinja templates to CFGs</li>
<li>Compatible with transformers, llama.cpp and vLLM</li>
</ul>
<p>❌ Cons:</p>
<ul>
<li>Integration with OpenAI is limited, JSON schema is not supported</li>
<li>No support for Anthropic, Cohere or Groq</li>
<li>Cookbook is sparse relative to the wide set of supported workflows, though the available examples are well explained</li>
</ul>
</section>
<section id="guidance" class="level3">
<h3 class="anchored" data-anchor-id="guidance">guidance</h3>
<p>The guidance libary uses its own programming paradigm for constrained generation. Prompts are constructed from functions that define a CFG. Here is an example from the readme, with slight modifications:</p>
<div class="sourceCode" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> re</span>
<span id="cb23-2"></span>
<span id="cb23-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> guidance</span>
<span id="cb23-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> guidance <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> models, gen, select</span>
<span id="cb23-5"></span>
<span id="cb23-6">llm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> models.LlamaCpp(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"./models/Meta-Llama-3-8B-Instruct.Q8_0.gguf"</span>)</span>
<span id="cb23-7"></span>
<span id="cb23-8"></span>
<span id="cb23-9"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@guidance</span>(stateless<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb23-10"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> ner_instruction(lm, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">input</span>):</span>
<span id="cb23-11">    lm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"""</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb23-12"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">    Please tag each word in the input with PER, ORG, LOC, or nothing</span></span>
<span id="cb23-13"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">    ---</span></span>
<span id="cb23-14"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">    Input: John worked at Apple.</span></span>
<span id="cb23-15"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">    Output:</span></span>
<span id="cb23-16"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">    John: PER</span></span>
<span id="cb23-17"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">    worked: </span></span>
<span id="cb23-18"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">    at: </span></span>
<span id="cb23-19"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">    Apple: ORG</span></span>
<span id="cb23-20"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">    .: </span></span>
<span id="cb23-21"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">    ---</span></span>
<span id="cb23-22"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">    Input: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">input</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb23-23"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">    Output:</span></span>
<span id="cb23-24"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb23-25">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> lm</span>
<span id="cb23-26"></span>
<span id="cb23-27"></span>
<span id="cb23-28"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">input</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> text</span>
<span id="cb23-29"></span>
<span id="cb23-30"></span>
<span id="cb23-31"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@guidance</span>(stateless<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb23-32"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> constrained_ner(lm, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">input</span>):</span>
<span id="cb23-33">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Split into words</span></span>
<span id="cb23-34">    words <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [</span>
<span id="cb23-35">        x <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> x <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> re.split(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"([^a-zA-Z0-9])"</span>, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">input</span>) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> x <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">and</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> re.match(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"\s"</span>, x)</span>
<span id="cb23-36">    ]</span>
<span id="cb23-37">    ret <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span></span>
<span id="cb23-38">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> x <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> words:</span>
<span id="cb23-39">        ret <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">": "</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> select([<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"PER"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ORG"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"LOC"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span>]) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span></span>
<span id="cb23-40">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> lm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> ret</span>
<span id="cb23-41"></span>
<span id="cb23-42"></span>
<span id="cb23-43">llm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> ner_instruction(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">input</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> constrained_ner(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">input</span>)</span></code></pre></div>
<p>The <code>constrained_ner()</code> function looks like normal Python, but is actually a CFG that the LLM uses to generate the output. It tokenizes the text and assigns a label to each token that is either PERSON, ORGANIZATION, LOCATION or nothing.</p>
<p>The model returns:</p>
<pre><code>BioNTech: PER
SE: 
is: 
set: 
to: 
acquire: LOC
InstaDeep: ORG
,: 
a: 
Tunis: ORG
-: LOC
born: 
and: 
U: 
.: LOC
K: 
.: LOC
-: 
based: 
artificial: LOC
intelligence: 
(: LOC
AI: 
): LOC
startup: 
,: LOC
for: 
up: 
to: 
£: 
562: 
million: </code></pre>
<p>The simplified tokenization causes inaccurate labels, as terms like “U.K.” are split incorrectly. In addition, Llama-3 falsely labeled “artificial” as a LOCATION.</p>
<p>To fix this, we could use a simplified approach that doesn’t require tokenization. The model could simply list the named entities, like in the other libraries.</p>
<div class="sourceCode" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> guidance</span>
<span id="cb25-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> guidance <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> models, gen, regex</span>
<span id="cb25-3"></span>
<span id="cb25-4">llm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> models.LlamaCpp(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"./models/Meta-Llama-3-8B-Instruct.Q8_0.gguf"</span>)</span>
<span id="cb25-5"></span>
<span id="cb25-6"></span>
<span id="cb25-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># stateless=True indicates this function does not depend on LLM generations</span></span>
<span id="cb25-8"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@guidance</span>(stateless<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb25-9"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> ner_instruction(lm, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">input</span>):</span>
<span id="cb25-10">    lm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"""</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb25-11"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">    Extract named entities from the input using the labels: PERSON, ORGANIZATION, LOCATION.</span></span>
<span id="cb25-12"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">    ---</span></span>
<span id="cb25-13"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">    Input: Jane and John live in San Francisco.</span></span>
<span id="cb25-14"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">    Output:</span></span>
<span id="cb25-15"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">    PERSON: Jane, John</span></span>
<span id="cb25-16"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">    ORGANIZATION:</span></span>
<span id="cb25-17"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">    LOCATION: San Francisco</span></span>
<span id="cb25-18"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">    ---</span></span>
<span id="cb25-19"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">    Input: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">input</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb25-20"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">    Output:</span></span>
<span id="cb25-21"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb25-22">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> lm</span>
<span id="cb25-23"></span>
<span id="cb25-24"></span>
<span id="cb25-25">pattern <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"PERSON:([\w, ]*)</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">ORGANIZATION:([\w, ]*)</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">LOCATION:([\w, ]*)"</span></span>
<span id="cb25-26"></span>
<span id="cb25-27">llm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> ner_instruction(text) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> regex(pattern) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> gen(stop<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"---"</span>)</span></code></pre></div>
<p>The regular expression guarantees that each line in the output begins with a label and a colon, in the order PERSON, ORGANIZATION, LOCATION, even if the input text doesn’t follow this order or doesn’t contain all three types of entities. <code>gen(stop="---")</code> stops the generation when the model outputs the <code>---</code> separator between the input and output.</p>
<p>The model returns:</p>
<pre><code>PERSON:relative
ORGANIZATION:UIButtonTypeCustom BioNTech SE, InstaDeep
LOCATION: Tunis, U.K.</code></pre>
<p>The output has the correct entities, but also contains garbage tokens like “relative” and “UIButtonTypeCustom”. Is this an issue with the model or the constraints? Let’s try pure generation without constraints:</p>
<div class="sourceCode" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1">llm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> ner_instruction(text) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> gen(stop<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"---"</span>)</span></code></pre></div>
<p>Output:</p>
<pre><code>PERSON:
ORGANIZATION: BioNTech SE, InstaDeep
LOCATION: Tunis, U.K.</code></pre>
<p>This works! I don’t know why the regular expression caused the model to output garbage tokens. I looked for a solution to specify the constraints using Pydantic. A Github <a href="https://github.com/guidance-ai/guidance/issues/462">issue</a> linked to a module in LlamaIndex called <a href="https://docs.llamaindex.ai/en/stable/examples/output_parsing/guidance_pydantic_program/">Guidance Pydantic Program</a> which has this feature, however, it doesn’t work with the latest version of guidance.</p>
<p>✅ Pros:</p>
<ul>
<li>Efficient token generation through constrained generation</li>
<li>Flexible prompting system with CFGs which support complex constraints and recursive structures</li>
</ul>
<p>❌ Cons:</p>
<ul>
<li>NER didn’t work as expected with tokenization or regular expressions</li>
<li>No built-in support for Pydantic models</li>
<li>Writing CFGs via regular expressions has a steep learning curve</li>
<li>Most powerful features are not compatible with OpenAI</li>
</ul>
</section>
</section>
<section id="recommendations" class="level2">
<h2 class="anchored" data-anchor-id="recommendations">Recommendations</h2>
<p>In general, constrained generation is superior in terms of efficiency and guaranteed valid output. Function calling is the second best option and has higher compatibility with APIs. Prompting is the least efficient method but compatible with any LLM, local or via API.</p>
<p>The best library for your structured LLM task depends on your surrounding software stack. If you are already using….</p>
<ul>
<li>transformers, llama.cpp or vLLM, meaning you control the token generation process, constrained generation with <a href="https://github.com/outlines-dev/outlines">outlines</a> is the most efficient way to generate structured output. outlines is easier to use than <a href="https://github.com/guidance-ai/guidance">guidance</a>, because it supports Pydantic models.</li>
<li>an API that supports function calling, such as OpenAI’s API, use one of the libraries that support function calling with Pydantic models. Their functionality is quite similar. <a href="https://github.com/prefecthq/marvin">marvin</a> has the simplest syntax and many built-in tasks, though limited customization and it only supports OpenAI. <a href="https://github.com/jxnl/instructor">instructor</a> is focused on structured output and stays as close to the OpenAI Python client as possible. <a href="https://github.com/Mirascope/mirascope">mirascope</a> has a wider scope, adding chaining and other prompt engineering techniques.</li>
<li><a href="https://python.langchain.com/docs/modules/model_io/output_parsers/types/pydantic/">langchain</a> or <a href="https://docs.llamaindex.ai/en/stable/module_guides/querying/structured_outputs/pydantic_program/">llama_index</a>, you can use their Pydantic output parsers for structured output from function calling or prompting too. Either is a decent choice if you prefer a comprehensive library over a specialized one. In my test, llama_index was easier to use.</li>
<li>spaCy, choose <a href="https://github.com/explosion/spacy-llm">spacy-llm</a> because it integrates seamlessly.</li>
</ul>
<p><a href="https://github.com/bananaml/fructose">fructose</a> and <a href="https://github.com/qagentur/texttunnel">texttunnel</a> are not actively developed, so I don’t recommend them for new projects.</p>
<section id="further-reading" class="level3">
<h3 class="anchored" data-anchor-id="further-reading">Further reading</h3>
<ul>
<li><a href="https://huggingface.co/blog/evaluation-structured-outputs">Improving Prompt Consistency with Structured Generations</a> by Will Kurt, Remi Louf and Clémentine Fourrier at Hugging Face.</li>
<li><a href="http://blog.dottxt.co/performance-gsm8k.html">Structured Generation Improves LLM performance: GSM8K Benchmark</a> by the .txt team.</li>
<li><a href="https://pydantic.dev/articles/llm-intro">Steering Large Language Models with Pydantic</a> by Jason Liu, developer of instructor.</li>
<li><a href="https://towardsdatascience.com/the-definitive-guide-to-structured-data-parsing-with-openai-gpt3-5-0e5ea0e52637">The Definitive Guide to Structured Data Parsing with OpenAI GPT 3.5</a> (paywalled) by Marie Stephen Leo. A systematic comparison and benchmark of langchain, instructor, fructose and mirascope.</li>
</ul>


</section>
</section>

 ]]></description>
  <category>Machine Learning</category>
  <category>Python</category>
  <guid>https://simmering.dev/blog/structured_output/</guid>
  <pubDate>Fri, 10 May 2024 22:00:00 GMT</pubDate>
  <media:content url="https://simmering.dev/blog/structured_output/image.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Evaluating an LLM for your use case</title>
  <dc:creator>Paul Simmering</dc:creator>
  <link>https://simmering.dev/blog/llm-eval/</link>
  <description><![CDATA[ 





<p>In the last two months we’ve seen releases of flagship LLMs like <a href="https://llama.meta.com/llama3/">Llama 3</a>, <a href="https://mistral.ai/news/mixtral-8x22b/">Mixtral 8x22B</a>, and <a href="https://www.anthropic.com/news/claude-3-family">Claude 3</a>. The title of Mistral’s announcement summarizes the dynamic well: <em>Cheaper, Better, Faster, Stronger</em>. It’s like neverending Christmas for AI developers! But how do you evaluate these models for your use case? This article is a deep dive into evaluations, covering accuracy, speed, cost, customization, context window, safety, and licensing.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/llm-eval/llm_eval_cropped.png" class="img-fluid figure-img"></p>
<figcaption>Image created with GPT-4</figcaption>
</figure>
</div>
<section id="general-language-understanding-benchmarks" class="level2">
<h2 class="anchored" data-anchor-id="general-language-understanding-benchmarks">General language understanding benchmarks</h2>
<p>General benchmarks are good for ranking models by their general language understanding and reasoning capabilities. The <a href="https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard">Hugging Face Open LLM leaderboard</a> scores models on 6 benchmarks.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/llm-eval/huggingface_open_llm_leaderboard.png" class="img-fluid figure-img"></p>
<figcaption>Hugging Face Open LLM leaderboard</figcaption>
</figure>
</div>
<table class="caption-top table">
<colgroup>
<col style="width: 34%">
<col style="width: 40%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th>Benchmark</th>
<th>Description</th>
<th>Author</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>AI2 Reasoning Challenge</td>
<td>Grade school science multiple choice questions</td>
<td><span class="citation" data-cites="clark2018think">Clark et al. (2018)</span></td>
</tr>
<tr class="even">
<td>HellaSwag</td>
<td>Sentence completion task about everyday situations, using examples that are easy for humans but hard for machines</td>
<td><span class="citation" data-cites="zellers2019hellaswag">Zellers et al. (2019)</span></td>
</tr>
<tr class="odd">
<td>Multi-task language understanding (MMLU)</td>
<td>Multiple choice questions across 57 subjects</td>
<td><span class="citation" data-cites="hendrycks2020measuring">Hendrycks et al. (2020)</span></td>
</tr>
<tr class="even">
<td>TruthfulQA</td>
<td>Multiple choice questions across 38 categories that some humans would answer falsely due to common misconceptions</td>
<td><span class="citation" data-cites="lin2021truthfulqa">Lin, Hilton, and Evans (2021)</span></td>
</tr>
<tr class="odd">
<td>Winogrande</td>
<td>Grammar challenge on pronoun disambiguation using contextual knowledge</td>
<td><span class="citation" data-cites="sakaguchi2021winogrande">Sakaguchi et al. (2021)</span></td>
</tr>
<tr class="even">
<td>GSM8K</td>
<td>Grade school math word problems</td>
<td><span class="citation" data-cites="cobbe2021training">Cobbe et al. (2021)</span></td>
</tr>
</tbody>
</table>
<p>Each benchmark probes a different aspect of language understanding and reasoning. Although no single benchmark perfectly measures a model’s capabilities, together they provide a comprehensive overview of the model’s <em>general</em> abilities. Note that all of them are posed in English by default, though there are translated versions of some benchmarks.</p>
<p>If you intend to use the model for <a href="https://platform.openai.com/docs/guides/function-calling">function calling</a>, the <a href="https://gorilla.cs.berkeley.edu/leaderboard.html">Berkeley Function-Calling Leaderboard</a> is a good benchmark. It consists of 2000 question-function-answer triples across multiple programming languages and REST APIs, including cases where the model needs to select which function to call.</p>
<p>Note that the way a benchmark is administered can affect the results. There are two main levers:</p>
<ol type="1">
<li>Additional prompt engineering, e.g.&nbsp;chain-of-thought prompts. This boosts reasoning ability at the cost of speed.</li>
<li>Few-shot sampling. Rather than asking the model just once, the model generates multiple completions and the most common answer is selected. This boosts robustness at the cost of speed. For example Google Gemini <span class="citation" data-cites="team2023gemini">(Anil et al. 2023)</span> only beats GPT-4 on the 32-shot setting, not in the 5-shot setting.</li>
</ol>
<p>A downside of public benchmarks is that cheating is possible by training a model on the test set. An alternative that can’t be gamed in this way is the <a href="https://chat.lmsys.org/?leaderboard">LLM Arena</a>. It’s a chat-based benchmark where visitors prompt two models at once and vote on the better answer. The relevant metric is an <a href="https://en.wikipedia.org/wiki/Elo_rating_system">Elo rating</a>, like in chess.</p>
<p>However, picking the model with the highest MMLU or Elo rating isn’t always the best choice. The benchmarks are general and may not reflect the specific requirements of your use case and domain. It may not have seen examples of your data and task during training. So general benchmarks are a good starting point, but not the end of the evaluation process.</p>
</section>
<section id="manual-evaluations" class="level2">
<h2 class="anchored" data-anchor-id="manual-evaluations">Manual evaluations</h2>
<p>The easiest way to evaluate a model is to try it out yourself in a chat window. For an unbiased evaluation, you should use the same prompts for all models you’re comparing. At a minimum, I suggest writing down three example prompts and perfect answers to them. This approach has three benefits:</p>
<ol type="1">
<li>you may find issues with the task definition</li>
<li>you can clarify your quality criteria</li>
<li>you can objectively compare model answers to your gold standard answers</li>
</ol>
<p>This is easier for tasks with strictly defined answers, such as text classification tasks. With more generative tasks like summarization, it’s necessary to define more fuzzy quality criteria, such as completeness and the absence of irrelevant information.</p>
<p>The <a href="https://chat.lmsys.org/?leaderboard">LLM Arena</a> has a side by side comparison feature to compare models on your own prompts.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/llm-eval/llm_arena.png" class="img-fluid figure-img"></p>
<figcaption>LLM Arena with the prompt: I have 4 apples today. I ate 3 apples yesterday. How many apples do I have today?</figcaption>
</figure>
</div>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p>LLM Arena saves all prompts and responses and may redistribute them. Don’t put in sensitive information.</p>
</div>
</div>
</section>
<section id="programmatic-evaluations" class="level2">
<h2 class="anchored" data-anchor-id="programmatic-evaluations">Programmatic evaluations</h2>
<p>The downside of manual evaluations is that they are limited to a small number of test cases. More examples are needed to get robust estimates of accuracy. The number depends on the complexity of the task and the desired confidence level. A binary classification task might require 200 examples, while an entity linking task might require 1000 or more examples. I recently published a <a href="../../blog/gold-data/">guide</a> to collecting gold-standard evaluation data.</p>
<p>To administer the test, a script that formats the examples as prompts, receives the model’s responses and compares them to the gold standard is needed. A custom script is the most flexible and lightweight solution, but there are also libraries that can help, such as <a href="https://github.com/openai/evals/tree/main">OpenAI Evals</a>, <a href="https://github.com/confident-ai/deepeval">promptflow</a>, <a href="https://github.com/parea-ai/parea-sdk-py">parea</a>, <a href="https://ragas.io">ragas</a> and <a href="https://github.com/confident-ai/deepeval">deepeval</a>.</p>
<p>In the following section I’ll provide a brief overview of model evaluation metrics. A more comprehensive guide is provided by <span class="citation" data-cites="huang2024">Huang, Li, and Yehdego (2024)</span>.</p>
<p>There are two main types of evaluation: structured and unstructured responses.</p>
</section>
<section id="evaluation-of-structured-responses" class="level2">
<h2 class="anchored" data-anchor-id="evaluation-of-structured-responses">Evaluation of structured responses</h2>
<p>Structured responses consist of a fixed set of possible answers. Examples are multiple choice questions, text classification tasks, and function calling. If a text-to-text model is used, there’s an additional step of verifying that the LLM’s response conforms to the expected structure. Getting the LLM to always follow the format is best done through function calling (e.g.&nbsp;via the <a href="https://github.com/jxnl/instructor">instructor</a> library) or fine-tuning.</p>
<p>Once everything’s in the right format, <a href="https://scikit-learn.org/stable/modules/model_evaluation.html">sklearn-metrics</a> is the standard library to calculate the metrics. The most common metrics are accuracy, precision, recall and F1 score.</p>
</section>
<section id="evaluation-of-free-form-responses" class="level2">
<h2 class="anchored" data-anchor-id="evaluation-of-free-form-responses">Evaluation of free form responses</h2>
<p>A free form response text is harder to evaluate. Examples are summarization, translation and chatbots. Comparing such answers with a gold answer word-by-word is too strict, as the model may use synonyms or rephrase the answer.</p>
<p>In the pre-LLM era, n-gram overlap metrics were used to evaluate free form responses. The most common are:</p>
<ul>
<li>Bilingual Evaluation Understudy (<a href="https://en.wikipedia.org/wiki/BLEU">BLEU</a>) for translation</li>
<li>Recall-Oriented Understudy for Gisting Evaluation (<a href="https://en.wikipedia.org/wiki/BLEU">ROUGE</a>) for summarization</li>
</ul>
<p>They are cheap to compute, but they have well-known limitations: they are sensitive to word order, don’t account for synonyms and don’t measure the writing quality of the generated text.</p>
<p>Recently, LLMs themselves have been used to evaluate LLMs on unstructured tasks. The idea is to ask a second LLM to rate the quality of the first LLM’s response using a pre-defined criterion. In its simplest form, the second LLM is asked to classify the first LLM’s response as good or bad.</p>
<p>Let’s try this out with a simple example of a bot that generates jokes, using Claude 3 Opus as the joke generator and GPT-4 as the joke evaluator.</p>
<ul>
<li><strong>Prompt for Opus</strong>: “Tell me a joke about AI”</li>
<li><strong>Opus</strong>: “Why did the AI cross the road? 🤖🛣️ To get to the other dataset! 📊😄”</li>
<li><strong>Prompt for GPT-4</strong>: “You are a comedian. I asked a model to tell me a joke about AI. This is the joke it told me:”Why did the AI cross the road? 🤖🛣️ To get to the other dataset! 📊😄“. Rate this joke on a scale of 1 to 5. Give a short reason and end your answer with a single number.”</li>
<li><strong>GPT-4</strong>: “This joke plays on the classic”Why did the chicken cross the road?” setup, using a pun related to AI’s data-driven nature. It’s straightforward and mildly amusing but lacks surprise or complexity. Rating: 3”</li>
</ul>
<p>The prompt to GPT-4 uses three prompt engineering techniques: role play, asking for a reason to get better answers and ending the answer with a single number to make it easier to parse. To measure the humor of Opus, one could substitute the subject “AI” with others like “chickens”, “doctors” or “politicians” and aggregate the GPT-4 ratings.</p>
<p>This is a simple example, but can be extended to more complex tasks. More complex criteria such as fluency, relevance, informativeness and coherence offer a more nuanced evaluation. One of the most common use cases where free form responses occur is retrieval-augmented generation. The <a href="https:ragas.io">ragas</a> library offers a comprehensive set of <a href="(https://docs.ragas.io/en/latest/concepts/metrics/index.html)">metrics</a> for LLM-to-LLM evaluation, including optimized prompts for the second LLM.</p>
<p>The downside of LLM-to-LLM evaluation is that the second LLM may not have the ability to judge the quality of the first LLM’s response or have a bias towards certain types of responses.</p>
<p>Practical considerations around deploying the model also come into play: inference speed, cost, customization, safety and licensing. These factors can be more important than the model’s accuracy. The following sections provide an overview of these factors using graphs from <a href="https://artificialanalysis.ai/">artificialanalysis.ai</a>, a site that benchmarks LLMs.</p>
</section>
<section id="inference-speed" class="level2">
<h2 class="anchored" data-anchor-id="inference-speed">Inference speed</h2>
<p>How fast can the model generate responses? This matters most for real-time applications like chatbots. A slow response makes for a poor user experience.</p>
<p>Inference speed is determined by the model, meaning the number and precision of weights. It’s also determined by the hardware used, with higher-end GPUs offering more speed. The efficiency of inference code is also crucial, with libraries like <a href="https://github.com/vllm-project/vllm">vLLM</a> offering a 2x or greater speedup over the baseline implementation. <a href="https://pages.run.ai/hubfs/PDFs/Serving-Large-Language-Models-Run-ai-Benchmarking-Study.pdf">run.ai</a> has an in-depth analysis of throughput across serving engines and models.</p>
<p>Artificialanalysis.ai benchmarks throughput for a variety of models and providers and visualizes it by model and by provider.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/llm-eval/throughput_by_model.png" class="img-fluid figure-img"></p>
<figcaption>Throughput by model, across providers supporting the model</figcaption>
</figure>
</div>
<p>Smaller models, measured by the number of parameters, are faster. Mixture-of-experts models like Mixtral 8x7B have a clever approach to inference: each request only uses a subset of the model, reducing the number of matrix multiplications needed.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/llm-eval/throughput_by_provider.png" class="img-fluid figure-img"></p>
<figcaption>Throughput for llama-3 70B instruct, by provider</figcaption>
</figure>
</div>
<p>The second graph shows throughput for the same model across different providers. The fastest provider offers nearly 10x the throughput of the slowest provider.</p>
</section>
<section id="cost" class="level2">
<h2 class="anchored" data-anchor-id="cost">Cost</h2>
<p>There are two common pricing modes: per-token or per GPU-hour.</p>
<section id="per-token-pricing" class="level4">
<h4 class="anchored" data-anchor-id="per-token-pricing">Per token pricing</h4>
<p>This is typical for models served by an API. The longer the prompt and the response, the greater the cost. Cost for output tokens is typically 2 to 5 times higher than input tokens. Let’s look at an example, using GPT-4 Turbo’s pricing of $10/1M input tokens and $30/1M output tokens.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 21%">
<col style="width: 32%">
<col style="width: 28%">
<col style="width: 17%">
</colgroup>
<thead>
<tr class="header">
<th>Role</th>
<th>Message</th>
<th>Tokens</th>
<th>Cost</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>User</td>
<td>Translate the following text to German: How are you?</td>
<td>11</td>
<td>$0.00011</td>
</tr>
<tr class="even">
<td>Assistant</td>
<td>Wie geht es dir?</td>
<td>5</td>
<td>$0.00015</td>
</tr>
</tbody>
</table>
<p>Note that the cost is per token, not per word. A token is a word or a subword. For simple calculations, multiplying the number of words by 1.33 works. You can try OpenAI’s free <a href="tokenizer">https://platform.openai.com/tokenizer</a> or the <a href="https://github.com/openai/tiktoken">tiktoken</a> library to get the exact token count for a text. Note that models with a different tokenizer will have different token counts for the same prompt.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/llm-eval/tokenizer.png" class="img-fluid figure-img" style="width:65.0%"></p>
<figcaption>OpenAI’s tokenizer</figcaption>
</figure>
</div>
<p>You can save money by using shorter prompts. Fine-tuning can “bake” instructions into a model, foregoing the need to explain the task in each request. However, token prices for fine-tuned models are typically higher than for the base model.</p>
<p>OpenAI recently announced <a href="https://help.openai.com/en/articles/9197833-batch-api-faq">batch inference</a> with 24h turnaround time at 50% off the token price.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/llm-eval/pricing.png" class="img-fluid figure-img"></p>
<figcaption>Input and output token cost by model, median across providers</figcaption>
</figure>
</div>
<p>Per-token costs vary widely across providers and models. Larger models are more expensive, and major cloud providers charge higher prices than smaller providers. There’s a downward trend in pricing over time, given a fixed model size.</p>
</section>
<section id="gpu-hour-pricing" class="level4">
<h4 class="anchored" data-anchor-id="gpu-hour-pricing">GPU hour pricing</h4>
<p>The second case is that you self-host the model. Here, pricing depends on <a href="https://fullstackdeeplearning.com/cloud-gpus/">GPU rent</a> (or depreciation of your own GPU). My currently favored GPU provider is <a href="https://modal.com/pricing">Modal</a>. They offer a generous free tier, pricing is competitive, only actually used GPU time is billed and it’s easy to use.</p>
<p>To figure out the actual cost of your workload it’s normally necessary to run your own cost benchmark. There are too many moving pieces, and each can change the cost by a factor of 2 or more: GPU configuration (model, number of GPUs), the LLM, quantization, inference library, timing of inference (batch or live, long term reservation or on demand) and the geographic region.</p>
</section>
</section>
<section id="customization" class="level2">
<h2 class="anchored" data-anchor-id="customization">Customization</h2>
<p>Open models running on your own infrastructure offer deeper customization than models served from APIs.</p>
<p>There are three main types of customization:</p>
<ol type="1">
<li>Finetuning via SFT, RLHF, DPO or ORPO</li>
<li>Quantization, meaning reducing the precision of the weights to 16-bit or 8-bit</li>
<li>Token sampling settings, such as temperature, top-k, nucleus sampling and beam search. For a full overview, check the Hugging Face <a href="https://huggingface.co/docs/transformers/main_classes/text_generation">GenerationConfig</a> documentation</li>
</ol>
<p>API providers offer only a subset of these options and only for certain models. More knobs to twist is only meaningful if you have the time to actually use them. If your main focus is elsewhere, good presets can be more productive than maximum control. It’s the same reason why many devs choose macOS over Arch Linux.</p>
</section>
<section id="context-window" class="level2">
<h2 class="anchored" data-anchor-id="context-window">Context window</h2>
<p>The context window is the number of input tokens the model can handle in one go. Higher is better, as it allows the model to reason over more information. For reference, an A4 page of text is about 500 words, which is about 665 tokens. The smallest context size found in current models is 4096 tokens, which corresponds to about 6 pages of text.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/llm-eval/context_window.png" class="img-fluid figure-img"></p>
<figcaption>Context window sizes by model</figcaption>
</figure>
</div>
<p>This comes with some caveats:</p>
<ul>
<li>output token limits are significantly lower than input token limits</li>
<li>processing a large number of input tokens is expensive</li>
<li>the model may not be able to actually use the full context, this is referred to the “lost in the middle” problem <span class="citation" data-cites="liu2023lost">(Liu et al. 2023)</span></li>
</ul>
</section>
<section id="safety-and-fairness" class="level2">
<h2 class="anchored" data-anchor-id="safety-and-fairness">Safety and fairness</h2>
<p>Others have written extensively on safety and fairness evaluation of LLMs. <a href="https://www.anthropic.com/news/training-a-helpful-and-harmless-assistant-with-reinforcement-learning-from-human-feedback">Anthropic’s principle</a> “Helpful, Honest and Harmless AI” is industry-leading in this regard. They provide an evaluation <a href="https://huggingface.co/datasets/Anthropic/hh-rlhf">dataset</a> on Hugging Face.</p>
<p>Key questions to ask about a foundation model are:</p>
<ul>
<li>Does the model exhibit biases around gender, race, religion or other protected classes?</li>
<li>Does the model refuse requests to do dangerous or illegal activities?</li>
<li>Can it be goaded into violating its own principles?</li>
</ul>
<p>The documentation by the model providers a good place to start. The abscence of consideration of these factors in a foundation model is a red flag.</p>
<p>The actual risk of a model depends on the task. High-risk tasks such as medical diagnosis, legal advice or loan approval require more scrutiny than tasks such as sentiment analysis or summarization. Situations in which models have free-form interaction with users, such as chatbots carry greater potential for harm and also surface area for prompt injection attacks.</p>
</section>
<section id="licensing" class="level2">
<h2 class="anchored" data-anchor-id="licensing">Licensing</h2>
<p>Broadly, models can be categorized as open source or proprietary. Generally, the more open the better because you can inspect the model, customize it and deploy it on your own infrastructure. In addition, open source models give you ownership of the model, rather than being at the mercy of the provider’s pricing and availability.</p>
<p>The term open source has become muddled in the context of LLMs. The minimum requirement is that the model’s weights are available for download. However, full open source also includes the training data, training code, inference code and documentation. Further, there are a variety of open licenses that can be applied. The <a href="https://opensource.org/license/mit">MIT license</a> and <a href="https://opensource.org/license/apache-2-0">Apache 2.0</a> are the most permissive and place the fewest restrictions and duties on the user. Finally, there are custom licenses. Notably, Meta has released the Llama 3 model under a <a href="https://llama.meta.com/llama3/license/">custom license</a> that requires attribution and requires that organzations with more than 700 million monthly active users (effectively only the largest tech companies) to request a commercial license.</p>
</section>
<section id="llm-evaluation-checklist" class="level2">
<h2 class="anchored" data-anchor-id="llm-evaluation-checklist">LLM Evaluation Checklist</h2>
<p>Evaluating LLMs is a multi-faceted challenge. While benchmarks and case studies are valuable, there’s no substitute for hands-on testing in one’s particular domain. To summarize, here’s a checklist for evaluating an LLM:</p>
<ol type="1">
<li>✅ <strong>Licensing</strong>: Check that the model’s license is compatible with your use case.</li>
<li>✅ <strong>Customization</strong>: Consider the model’s customization options based on the license and your needs.</li>
<li>✅ <strong>Context window</strong>: Check if the model’s context window is large enough to fit your inputs.</li>
<li>✅ <strong>Quality</strong>: Start with general benchmarks, then move to manual and programmatic evaluations. Consider structured and unstructured responses.</li>
<li>✅ <strong>Safety and fairness</strong>: Assess the model’s safety and fairness, especially for use cases involving individual judgments or open-ended interaction.</li>
<li>✅ <strong>Cost</strong>: Analyze the cost per token or GPU hour for your usage patterns.</li>
<li>✅ <strong>Speed</strong>: Benchmark the model’s throughput in your setup, whether self-hosted or served from an API. There is often significant optimization potential here.</li>
</ol>
<p>Being clear about the task and success criteria at every step is key. Writing down arguments and results lets you repeat the analysis for new models and justify your choice in architecture and budget reviews. Sharing benchmark results builds trust by users of your model. Without quantitative tests, their opinion of the model hinges on their first interaction alone.</p>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0">
<div id="ref-team2023gemini" class="csl-entry">
Anil, Rohan, Sebastian Borgeaud, Yonghui Wu, Jean-Baptiste Alayrac, Jiahui Yu, Radu Soricut, Johan Schalkwyk, Andrew M Dai, Anja Hauth, et al. 2023. <span>“Gemini: A Family of Highly Capable Multimodal Models.”</span> <em>arXiv Preprint arXiv:2312.11805</em>. <a href="https://arxiv.org/abs/2312.11805">https://arxiv.org/abs/2312.11805</a>.
</div>
<div id="ref-clark2018think" class="csl-entry">
Clark, Peter, Isaac Cowhey, Oren Etzioni, Tushar Khot, Ashish Sabharwal, Carissa Schoenick, and Oyvind Tafjord. 2018. <span>“Think You Have Solved Question Answering? Try Arc, the Ai2 Reasoning Challenge.”</span> <em>arXiv Preprint arXiv:1803.05457</em>. <a href="https://arxiv.org/abs/1803.05457">https://arxiv.org/abs/1803.05457</a>.
</div>
<div id="ref-cobbe2021training" class="csl-entry">
Cobbe, Karl, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, et al. 2021. <span>“Training Verifiers to Solve Math Word Problems.”</span> <em>arXiv Preprint arXiv:2110.14168</em>. <a href="https://arxiv.org/abs/2110.14168">https://arxiv.org/abs/2110.14168</a>.
</div>
<div id="ref-hendrycks2020measuring" class="csl-entry">
Hendrycks, Dan, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt. 2020. <span>“Measuring Massive Multitask Language Understanding.”</span> <em>arXiv Preprint arXiv:2009.03300</em>. <a href="https://arxiv.org/abs/2009.03300">https://arxiv.org/abs/2009.03300</a>.
</div>
<div id="ref-huang2024" class="csl-entry">
Huang, Jane, Kirk Li, and Daniel Yehdego. 2024. <span>“Evaluating Large Language Model (LLM) Systems: Metrics, Challenges, and Best Practices.”</span> Data Science at Microsoft. 2024. <a href="https://medium.com/data-science-at-microsoft/evaluating-llm-systems-metrics-challenges-and-best-practices-664ac25be7e5">https://medium.com/data-science-at-microsoft/evaluating-llm-systems-metrics-challenges-and-best-practices-664ac25be7e5</a>.
</div>
<div id="ref-lin2021truthfulqa" class="csl-entry">
Lin, Stephanie, Jacob Hilton, and Owain Evans. 2021. <span>“Truthfulqa: Measuring How Models Mimic Human Falsehoods.”</span> <em>arXiv Preprint arXiv:2109.07958</em>. <a href="https://arxiv.org/abs/2109.07958">https://arxiv.org/abs/2109.07958</a>.
</div>
<div id="ref-liu2023lost" class="csl-entry">
Liu, Nelson F., Kevin Lin, John Hewitt, Ashwin Paranjape, Michele Bevilacqua, Fabio Petroni, and Percy Liang. 2023. <span>“Lost in the Middle: How Language Models Use Long Contexts.”</span> <a href="https://arxiv.org/abs/2307.03172">https://arxiv.org/abs/2307.03172</a>.
</div>
<div id="ref-sakaguchi2021winogrande" class="csl-entry">
Sakaguchi, Keisuke, Ronan Le Bras, Chandra Bhagavatula, and Yejin Choi. 2021. <span>“Winogrande: An Adversarial Winograd Schema Challenge at Scale.”</span> <em>Communications of the ACM</em> 64 (9): 99–106. <a href="https://arxiv.org/abs/1907.10641">https://arxiv.org/abs/1907.10641</a>.
</div>
<div id="ref-zellers2019hellaswag" class="csl-entry">
Zellers, Rowan, Ari Holtzman, Yonatan Bisk, Ali Farhadi, and Yejin Choi. 2019. <span>“Hellaswag: Can a Machine Really Finish Your Sentence?”</span> <em>arXiv Preprint arXiv:1905.07830</em>. <a href="https://arxiv.org/abs/1905.07830">https://arxiv.org/abs/1905.07830</a>.
</div>
</div></section></div> ]]></description>
  <category>Machine Learning</category>
  <guid>https://simmering.dev/blog/llm-eval/</guid>
  <pubDate>Sat, 27 Apr 2024 22:00:00 GMT</pubDate>
  <media:content url="https://simmering.dev/blog/llm-eval/llm_eval.webp" medium="image" type="image/webp"/>
</item>
<item>
  <title>How to get gold standard data for NLP</title>
  <dc:creator>Paul Simmering</dc:creator>
  <link>https://simmering.dev/blog/gold-data/</link>
  <description><![CDATA[ 





<p>With the attention on new LLM releases, it’s easy to forget that correctly labeled examples are still a critical factor for accuracy in most NLP tasks. I think they’re the best source of competitive advantage for most teams. Labeled examples will be useful in conjunction with any model that comes out.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/gold-data/vault_cropped.png" class="img-fluid figure-img"></p>
<figcaption>Gold-standard data, image generated with Midjourney</figcaption>
</figure>
</div>
<p>High quality, human-labeled examples are aptly called “gold standard”. This guide will help you accumulate and refine this treasure. It’s based on my five years of experience collecting and refining labeled data for NLP projects, plus a review of the literature.</p>
<section id="fine-tuned-models-outperform-few-shot-and-zero-shot-approaches" class="level2">
<h2 class="anchored" data-anchor-id="fine-tuned-models-outperform-few-shot-and-zero-shot-approaches">Fine-tuned models outperform few-shot and zero-shot approaches</h2>
<p>Zero-shot and few-shot prediction with LLMs promises to let you skip the labeling and training. Just give the model a few examples and it’ll figure out the rest. This is great for a proof of concept, but how do you know that the labels it gives are correct? Checking individual examples by hand is helpful, but not enough proof. Even if the model doesn’t need finetuning, you’ll need at least a test set to evaluate on.</p>
<p>For classic NLP tasks like text classification, named entity recognition and sentiment analysis, fine-tuned models are still by far the most accurate. This is shown in the benchmarks below. Fine-tuned models perform best across all tasks, followed by few-shot instructed models. Zero-shot performance is the least accurate.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/gold-data/benchmarks.png" class="img-fluid figure-img"></p>
<figcaption>Finetuning vs.&nbsp;few-shot vs.&nbsp;zero-shot benchmark results</figcaption>
</figure>
</div>
<p>Benchmarks were done by <span class="citation" data-cites="ziems2023can">Ziems et al. (2023)</span>, <span class="citation" data-cites="qin2023chatgpt">Qin et al. (2023)</span>, <span class="citation" data-cites="wang2023gpt">Wang et al. (2023)</span> and <span class="citation" data-cites="simmering2023large">Simmering and Huoviala (2023)</span>.</p>
</section>
<section id="ways-to-get-training-data" class="level2">
<h2 class="anchored" data-anchor-id="ways-to-get-training-data">Ways to get training data</h2>
<p>I hope that I convinced you that training data is still relevant. So how to acquire it?</p>
<section id="public-sources" class="level3">
<h3 class="anchored" data-anchor-id="public-sources">Public sources</h3>
<p>First, check if there’s a public dataset that fits your needs. Here are some places to look:</p>
<ul>
<li><a href="https://huggingface.co/datasets">Huggingface Hub</a> features more than 100,000 free datasets.</li>
<li><a href="https://www.kaggle.com/datasets">Kaggle</a> has more than 50,000 free datasets.</li>
<li><a href="https://paperswithcode.com/datasets">Papers with Code</a> has more than 2,000 text datasets, covering all popular NLP benchmarks.</li>
<li><a href="https://data.world/datasets/nlp">data.world</a> has 72 free NLP datasets.</li>
<li><a href="https://github.com/niderhoff/nlp-datasets">nlp-datasets Github repository</a> has a curated list of free NLP datasets.</li>
</ul>
<p>If the dataset is popular you may also find pre-trained models for it on Huggingface. They can give you an idea of the accuracy you can expect to reach and the difficulty of the examples. That’s useful information even if you train your own model.</p>
<p>The majority of public NLP datasets are in English. It may be possible to translate a dataset to your language. DeepL and other translation APIs are affordable. Try it with some examples and see if the translations are good enough.</p>
</section>
<section id="using-natural-labels" class="level3">
<h3 class="anchored" data-anchor-id="using-natural-labels">Using natural labels</h3>
<p>Natural labels are signals that are already present in the data. They can be used to train a model without any human labeling. Here are some examples:</p>
<ul>
<li>Star ratings for reviews are a signal for sentiment analysis.</li>
<li>Positive / negative feedback for support answers is a signal for customer satisfaction.</li>
<li>The number of upvotes, likes and shares for social media posts is a signal for popularity.</li>
<li>The upvotes for question answers on Stack Overflow is a signal for correctness.</li>
<li>Open rate of emails is a signal for interest of the subject line.</li>
</ul>
<p>Perhaps there is a dataset in your organization that has natural labels for the task you want to solve.</p>
</section>
<section id="labeling-by-hand" class="level3">
<h3 class="anchored" data-anchor-id="labeling-by-hand">Labeling by hand</h3>
<p>If you’re not lucky enough to find a public dataset or natural labels, creating your own dataset is the way to go. To go beyond a few thousand examples, a team of labelers is necessary. In any case, I suggest you start by labeling a few examples yourself. This will give you a good understanding of the task.</p>
<p>Here are some points to consider when creating a labeled dataset, whether in a team or alone:</p>
<ul>
<li><strong>Annotation guide</strong>: Write a detailed annotation guide with examples. This is a living document that gets updated with details and examples throughout the project.</li>
<li><strong>Iterate on the rules</strong>: Figuring out clear rules is the number one priority at the start. Discuss unclear examples with the team and refine the annotation guide. It can be necessary to change a rule and re-label the examples done until then. The cost increases as the project progresses.</li>
<li><strong>Skip the weirdest examples</strong>: User generated internet content can be wild in terms of content and grammar. It can be better better to skip the weirdest examples than to try to label them. They’re more likely to confuse your model than help it learn and it’s unlikely that they’ll be encountered in practice.</li>
<li><strong>Quality control</strong>: Double annotation and analysis of inter-annotator reliability is a key technique for correct annotation from a team.</li>
<li><strong>Labeling tool</strong>: Good labeling UI and workflow makes a big difference in productivity and quality. It’s worth investing the time to find the right tool and configure it optimally. The tool should also make it easy look at the examples that were already annotated and fix errors.</li>
<li><strong>Simplify the task</strong>: Have reasonable expectations for what a labeler can do. For example, correctly using 20 different labels in a text classification task is not realistic. It’s too easy to forget one of them. Binary labeling is easier and it can be worth it to split a task into subtasks that use fewer labels.</li>
<li><strong>Onboarding</strong>: When a new labeler starts, have a one-to-one onboarding session in which you label some examples together. This is often much more effective than reading the guide. It’s also an opportunity to teach efficient use of the labeling tool.</li>
<li><strong>Quality over quantity</strong>: A small, high quality dataset is preferable to a large, low quality dataset. Falsely labeled examples are misleading for the model and for evaluation. Plus, they increase the time and cost for training.</li>
<li><strong>Diminishing rates of return</strong>: Check the difference that adding more examples to the training set makes on model performance. You can do this by training your model on varying amounts of your labeled data, e.g.&nbsp;with 80%, 90% and 100%. If the last 10% of labeled data make a clear difference, keep annotating more data.</li>
<li><strong>You get what you pay for</strong>: When choosing a contractor or full labeling service, ask for inter-annotator reliability and how labelers are instructed and whether they’re native speakers for the language of the task.</li>
</ul>
<section id="gpt-4-is-more-accurate-than-low-quality-labeling-services" class="level4">
<h4 class="anchored" data-anchor-id="gpt-4-is-more-accurate-than-low-quality-labeling-services">GPT-4 is more accurate than low-quality labeling services</h4>
<p><span class="citation" data-cites="tornberg2023chatgpt">Törnberg (2023)</span> and <span class="citation" data-cites="gilardi2023chatgpt">Gilardi, Alizadeh, and Kubli (2023)</span> compared labeling accuracy of GPT-4 with labels created by Amazon Mechanical Turk workers. They found that GPT-4 with a zero-shot instruction was more accurate on tweet text classification tasks. As a buyer of labeling services, a low-quality service may be a worse deal than using an LLM to label the examples (see next section). Hence, it’s only worth using a labeling service if it’s high quality. The ideal solution is a team of experienced labelers that communicate well, refine the annotation guide and use a highly efficient labeling tool.</p>
</section>
</section>
<section id="synthetic-data-labels" class="level3">
<h3 class="anchored" data-anchor-id="synthetic-data-labels">Synthetic data / labels</h3>
<p>The most capable LLMs like GPT-4 can solve many NLP problems with decent accuracy with a few-shot example prompt. You can kickstart a project by letting it label examples and then training your smaller, more efficient model on them. <span class="citation" data-cites="laurer2024synthetic">Laurer (2024)</span> provides a great deep dive into this approach and its efficiency benefits.</p>
<p>Experiment with the prompt and the examples to get the best performance. An annotation guide with examples as described in the previous section is a great starting point for an effective prompt.</p>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">graph LR
    A[Raw data] --&gt; B[Few-shot prompt]
    C[4 to 10 examples] --&gt; B
    B --&gt;|Instruct| D[LLM]
    D --&gt;|Predict| E[Labels]
    E --&gt;|Manual check| F[Corrected labels]
    F --&gt;|Train| G[Efficient model]
    
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<p>If the model’s few-shot accuracy isn’t good enough, check the examples and correct the labels by hand. The human-in-the-loop step is required to get proper “gold standard” data. It’s still faster than labeling from scratch.</p>
<section id="active-learning" class="level4">
<h4 class="anchored" data-anchor-id="active-learning">Active learning</h4>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">graph LR
    A[Model] --&gt;|Predict| B[Label]
    B --&gt;|Prioritize low confidence predictions| C[Human check]
    C --&gt;|Train| A
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<p>With active learning, the model is trained incrementally as new examples are labeled. A human labeler is presented with the examples that the model is most uncertain about and labels them. This maximizes labeling productivity and also gives insight into the model’s weaknesses. The tool <a href="https://prodi.gy">Prodigy</a> by Explosion AI was a pioneer in this area and is still a popular choice.</p>
</section>
</section>
</section>
<section id="improving-your-labeled-data" class="level2">
<h2 class="anchored" data-anchor-id="improving-your-labeled-data">Improving your labeled data</h2>
<blockquote class="blockquote">
<p>“The biggest alpha in AI is actually looking at your data” - Mark Tenenholtz on <a href="https://twitter.com/marktenenholtz/status/1762179463033278963">X</a></p>
</blockquote>
<p>Better training data makes everything easier, without adding complexity to the model, your code or your infrastructure. There’s no substitute for high quality data. Here are some ways to improve your labeled data:</p>
<section id="stare-at-the-data" class="level3">
<h3 class="anchored" data-anchor-id="stare-at-the-data">Stare at the data</h3>
<p>Ultra simple, but effective. Look at the examples and labels, check that they conform to the annotation guide. Think about what the model will learn from them. This is a high-value activity, worthy of a senior engineer’s time. It doesn’t scale, but it’s worth doing every now and then.</p>
</section>
<section id="perform-all-standard-checks" class="level3">
<h3 class="anchored" data-anchor-id="perform-all-standard-checks">Perform all standard checks</h3>
<p>Here are some standard questions that are always worth asking about your data:</p>
<ol type="1">
<li>Is your training data as diverse as the data you’ll encounter in practice? For example, if you’re doing fake news detection, do you have examples from all political sides?</li>
<li>Are the predicted classes balanced, and if not, does your training and evaluation handle imbalance properly? For example, star ratings for reviews are often biased towards 5 stars.</li>
<li>Do you version your data along with the trained machine learning models? This is critical for reproducibility and debugging.</li>
<li>Do the labels have clear and non-overlapping definitions?</li>
<li>Does the dataset contain outliers or unrealistic values? For example, a review with more than 5 stars.</li>
<li>Are there any duplicates in the data?</li>
<li>Is there overlap between the training and evaluation data?</li>
</ol>
</section>
<section id="fix-errors-in-training-data-by-analyzing-wrong-predictions" class="level3">
<h3 class="anchored" data-anchor-id="fix-errors-in-training-data-by-analyzing-wrong-predictions">Fix errors in training data by analyzing wrong predictions</h3>
<p>Mistaken labels are poison for your model. It learns wrong rules or gets falsely penalized for correct predictions. How do you find and fix them? The model can help with that! One way to find training examples that may be wrong is to train a model on the examples and then run inference on them. If the model gets the label wrong even after having seen it during training, the example may be wrong. The model learned the rule from the other examples, but this example doesn’t follow it. Check those examples and fix the label where necessary.</p>
</section>
<section id="add-high-signal-examples" class="level3">
<h3 class="anchored" data-anchor-id="add-high-signal-examples">Add high-signal examples</h3>
<p>Labels for difficult examples are a stronger signal than labels for easy examples. Once the model has figured out the basic labeling rules from general examples, it doesn’t have as much to learn from them anymore. You can identify difficult examples by checking the model’s confidence when predicting their answers. Classification models typically return a probability distribution over labels, and LLMs can provide next-token probabilities. Label the examples that have a more uniform distribution, meaning low confidence in the chosen solution. These examples will also help you find edge cases for the annotation guide.</p>
</section>
<section id="data-augmentation" class="level3">
<h3 class="anchored" data-anchor-id="data-augmentation">Data augmentation</h3>
<p>You can turn one example into many by slightly changing the wording while keeping the label. <span class="citation" data-cites="chaudhary2020visual">Chaudhary (2020)</span> offers a visual overview of techniques, including:</p>
<ol type="1">
<li>Lexical substitution: Replace words with synonyms.</li>
<li>Back translation: Translate the text to another language and back.</li>
<li>Text surface transformation: Contract expressions e.g.&nbsp;“I am” -&gt; “I’m”.</li>
<li>Random noise injection: Adding spelling mistakes, shuffling sentences, randomly removing words.</li>
<li>Generative methods: Use a generative model to create new examples similar to the original.</li>
</ol>
<p>These variations of the same example can improve robustness and generalization of the model. They can also help to balance the classes. However, they are less valuable than real examples. Only use them for the training set, not for the test set and run experiments to see if they actually improve performance or just slow down training.</p>
</section>
</section>
<section id="models-come-and-go-data-is-forever" class="level2">
<h2 class="anchored" data-anchor-id="models-come-and-go-data-is-forever">Models come and go, data is forever</h2>
<p>New models are released every week and we seem to have a revolution in model architecture about every 3 years. It can be exhausting to keep up, especially if your goal is to serve a customer need rather than conduct research. If you find yourself in this position, prioritizing training and evaluation data over modeling is a good strategy. Your labeled data will likely be compatible with any model that will come out. Even if the model doesn’t need to be trained, it’ll still be good to have an accurate evaluation dataset. By keeping your code as model-agnostic as possible you can ride the waves of new models coming out, reaping the performance improvements, with little model customization on your part. Just plug in the new model and combine it with your real treasure, the labeled data.</p>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0">
<div id="ref-chaudhary2020visual" class="csl-entry">
Chaudhary, Amit. 2020. <span>“A Visual Survey of Data Augmentation in NLP.”</span> <a href="https://amitness.com/2020/05/data-augmentation-for-nlp/">https://amitness.com/2020/05/data-augmentation-for-nlp/</a>.
</div>
<div id="ref-gilardi2023chatgpt" class="csl-entry">
Gilardi, Fabrizio, Meysam Alizadeh, and Maël Kubli. 2023. <span>“ChatGPT Outperforms Crowd Workers for Text-Annotation Tasks.”</span> <em>Proceedings of the National Academy of Sciences</em> 120 (30): e2305016120.
</div>
<div id="ref-laurer2024synthetic" class="csl-entry">
Laurer, Moritz. 2024. <span>“Synthetic Data: Save Money, Time and Carbon with Open Source.”</span> <a href="https://huggingface.co/blog/synthetic-data-save-costs">https://huggingface.co/blog/synthetic-data-save-costs</a>.
</div>
<div id="ref-qin2023chatgpt" class="csl-entry">
Qin, Chengwei, Aston Zhang, Zhuosheng Zhang, Jiaao Chen, Michihiro Yasunaga, and Diyi Yang. 2023. <span>“Is ChatGPT a General-Purpose Natural Language Processing Task Solver?”</span> <em>arXiv Preprint arXiv:2302.06476</em>.
</div>
<div id="ref-simmering2023large" class="csl-entry">
Simmering, Paul F, and Paavo Huoviala. 2023. <span>“Large Language Models for Aspect-Based Sentiment Analysis.”</span> <em>arXiv Preprint arXiv:2310.18025</em>.
</div>
<div id="ref-tornberg2023chatgpt" class="csl-entry">
Törnberg, Petter. 2023. <span>“Chatgpt-4 Outperforms Experts and Crowd Workers in Annotating Political Twitter Messages with Zero-Shot Learning.”</span> <em>arXiv Preprint arXiv:2304.06588</em>.
</div>
<div id="ref-wang2023gpt" class="csl-entry">
Wang, Shuhe, Xiaofei Sun, Xiaoya Li, Rongbin Ouyang, Fei Wu, Tianwei Zhang, Jiwei Li, and Guoyin Wang. 2023. <span>“Gpt-Ner: Named Entity Recognition via Large Language Models.”</span> <em>arXiv Preprint arXiv:2304.10428</em>.
</div>
<div id="ref-ziems2023can" class="csl-entry">
Ziems, Caleb, Omar Shaikh, Zhehao Zhang, William Held, Jiaao Chen, and Diyi Yang. 2023. <span>“Can Large Language Models Transform Computational Social Science?”</span> <em>Computational Linguistics</em>, 1–53.
</div>
</div></section></div> ]]></description>
  <category>Machine Learning</category>
  <guid>https://simmering.dev/blog/gold-data/</guid>
  <pubDate>Sat, 09 Mar 2024 23:00:00 GMT</pubDate>
  <media:content url="https://simmering.dev/blog/gold-data/vault.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>LLM Price Comparison</title>
  <dc:creator>Paul Simmering</dc:creator>
  <link>https://simmering.dev/blog/llm-price-performance/</link>
  <description><![CDATA[ 





<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>This article is about prices as of January 11, 2024. For current prices and more comprehensive analysis, check <a href="https://artificialanalysis.ai">artificialanalysis.ai</a> (not affiliated with me).</p>
</div>
</div>
<p>This is an overview of pricing for large language models from different developers and API providers. The dataset is available on <a href="https://github.com/psimm/website/blob/master/blog/llm-price-performance/data.csv">GitHub</a>. Prices are expressed in USD per 1 million tokens. To learn more about tokens, see the <a href="https://platform.openai.com/tokenizer">Tokenizer</a> by OpenAI.</p>
<section id="price-comparison" class="level2">
<h2 class="anchored" data-anchor-id="price-comparison">Price comparison</h2>
<div id="a490e678" class="cell" data-execution_count="2">
<div class="cell-output cell-output-display">
<div>                            <div id="778847f3-16db-44a6-b236-1ec64c8da3e1" class="plotly-graph-div" style="height:525px; width:100%;"></div>            <script type="text/javascript">                require(["plotly"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById("778847f3-16db-44a6-b236-1ec64c8da3e1")) {                    Plotly.newPlot(                        "778847f3-16db-44a6-b236-1ec64c8da3e1",                        [{"alignmentgroup":"True","customdata":[["mistral-7b-openorca","Anyscale","32k",0.15,0.15],["mistral-7b-instruct","Anyscale","32k",0.15,0.15],["llama-guard-7b","Anyscale","4k",0.15,0.15],["llama-2-7b-chat-hf","Anyscale","4k",0.15,0.15],["llama-2-13b-chat-hf","Anyscale","4k",0.25,0.25],["mixtral-8x7b-instruct","Anyscale","32k",0.5,0.5],["llama2-70b-chat-hf","Anyscale","4k",1.0,1.0]],"hovertemplate":"Model: %{customdata[0]}\u003cbr\u003eProvider: %{customdata[1]}\u003cbr\u003eContext Size: %{customdata[2]}\u003cbr\u003eInput Token $\u002f1M: %{customdata[3]}\u003cbr\u003eOutput Token $\u002f1M: %{customdata[4]}\u003cbr\u003eAvg Price $\u002f1M: %{x}","legendgroup":"Anyscale","marker":{"color":"#636efa","pattern":{"shape":""}},"name":"Anyscale","offsetgroup":"Anyscale","orientation":"h","showlegend":true,"textposition":"auto","x":[0.15,0.15,0.15,0.15,0.25,0.5,1.0],"xaxis":"x","y":["Anyscale-mistral-7b-openorca","Anyscale-mistral-7b-instruct","Anyscale-llama-guard-7b","Anyscale-llama-2-7b-chat-hf","Anyscale-llama-2-13b-chat-hf","Anyscale-mixtral-8x7b-instruct","Anyscale-llama2-70b-chat-hf"],"yaxis":"y","type":"bar"},{"alignmentgroup":"True","customdata":[["mistral-7b-instruct","Mistral","32k",0.14,0.42],["mixtral-8x7b-instruct","Mistral","32k",0.6,1.8],["mistral-medium","Mistral","32k",2.5,7.5]],"hovertemplate":"Model: %{customdata[0]}\u003cbr\u003eProvider: %{customdata[1]}\u003cbr\u003eContext Size: %{customdata[2]}\u003cbr\u003eInput Token $\u002f1M: %{customdata[3]}\u003cbr\u003eOutput Token $\u002f1M: %{customdata[4]}\u003cbr\u003eAvg Price $\u002f1M: %{x}","legendgroup":"Mistral","marker":{"color":"#EF553B","pattern":{"shape":""}},"name":"Mistral","offsetgroup":"Mistral","orientation":"h","showlegend":true,"textposition":"auto","x":[0.28,1.2,5.0],"xaxis":"x","y":["Mistral-mistral-7b-instruct","Mistral-mixtral-8x7b-instruct","Mistral-mistral-medium"],"yaxis":"y","type":"bar"},{"alignmentgroup":"True","customdata":[["cohere-light","AWS","4k",0.3,0.6],["llama-2-chat-13b","AWS","4k",0.75,1.0],["claude-instant","AWS","100k",0.8,2.4],["claude","AWS","100k",0.8,2.4],["titan-text-express","AWS","8k",1.2,2.3],["cohere-command","AWS","4k",1.5,2.0],["llama-2-chat-70b","AWS","4k",1.95,2.56],["jurassic-2-mid","AWS","8k",12.5,12.5],["jurassic-2-ultra","AWS","8k",18.8,18.8]],"hovertemplate":"Model: %{customdata[0]}\u003cbr\u003eProvider: %{customdata[1]}\u003cbr\u003eContext Size: %{customdata[2]}\u003cbr\u003eInput Token $\u002f1M: %{customdata[3]}\u003cbr\u003eOutput Token $\u002f1M: %{customdata[4]}\u003cbr\u003eAvg Price $\u002f1M: %{x}","legendgroup":"AWS","marker":{"color":"#00cc96","pattern":{"shape":""}},"name":"AWS","offsetgroup":"AWS","orientation":"h","showlegend":true,"textposition":"auto","x":[0.45,0.88,1.6,1.6,1.75,1.75,2.26,12.5,18.8],"xaxis":"x","y":["AWS-cohere-light","AWS-llama-2-chat-13b","AWS-claude-instant","AWS-claude","AWS-titan-text-express","AWS-cohere-command","AWS-llama-2-chat-70b","AWS-jurassic-2-mid","AWS-jurassic-2-ultra"],"yaxis":"y","type":"bar"},{"alignmentgroup":"True","customdata":[["gpt-3.5-turbo-1106","OpenAI","16k",1.0,2.0],["gpt-3.5-turbo-turbo-instruct","OpenAI","16k",1.5,2.0],["gpt-4-1106-preview","OpenAI","128k",10.0,30.0],["gpt-4-1106-vision-preview","OpenAI","128k",10.0,30.0],["gpt-4","OpenAI","8k",30.0,60.0],["gpt-4-32k","OpenAI","32k",60.0,120.0]],"hovertemplate":"Model: %{customdata[0]}\u003cbr\u003eProvider: %{customdata[1]}\u003cbr\u003eContext Size: %{customdata[2]}\u003cbr\u003eInput Token $\u002f1M: %{customdata[3]}\u003cbr\u003eOutput Token $\u002f1M: %{customdata[4]}\u003cbr\u003eAvg Price $\u002f1M: %{x}","legendgroup":"OpenAI","marker":{"color":"#ab63fa","pattern":{"shape":""}},"name":"OpenAI","offsetgroup":"OpenAI","orientation":"h","showlegend":true,"textposition":"auto","x":[1.5,1.75,20.0,20.0,45.0,90.0],"xaxis":"x","y":["OpenAI-gpt-3.5-turbo-1106","OpenAI-gpt-3.5-turbo-turbo-instruct","OpenAI-gpt-4-1106-preview","OpenAI-gpt-4-1106-vision-preview","OpenAI-gpt-4","OpenAI-gpt-4-32k"],"yaxis":"y","type":"bar"},{"alignmentgroup":"True","customdata":[["gemini-pro","GCP","32k",1.0,2.0],["palm2","GCP","8k",2.0,2.0]],"hovertemplate":"Model: %{customdata[0]}\u003cbr\u003eProvider: %{customdata[1]}\u003cbr\u003eContext Size: %{customdata[2]}\u003cbr\u003eInput Token $\u002f1M: %{customdata[3]}\u003cbr\u003eOutput Token $\u002f1M: %{customdata[4]}\u003cbr\u003eAvg Price $\u002f1M: %{x}","legendgroup":"GCP","marker":{"color":"#FFA15A","pattern":{"shape":""}},"name":"GCP","offsetgroup":"GCP","orientation":"h","showlegend":true,"textposition":"auto","x":[1.5,2.0],"xaxis":"x","y":["GCP-gemini-pro","GCP-palm2"],"yaxis":"y","type":"bar"},{"alignmentgroup":"True","customdata":[["gpt-3.5-turbo-4k","Azure","4k",1.5,2.0],["gpt-3.5-turbo-16k","Azure","16k",3.0,4.0],["gpt-4-8k","Azure","8k",30.0,60.0],["gpt-4-32k","Azure","32k",60.0,120.0]],"hovertemplate":"Model: %{customdata[0]}\u003cbr\u003eProvider: %{customdata[1]}\u003cbr\u003eContext Size: %{customdata[2]}\u003cbr\u003eInput Token $\u002f1M: %{customdata[3]}\u003cbr\u003eOutput Token $\u002f1M: %{customdata[4]}\u003cbr\u003eAvg Price $\u002f1M: %{x}","legendgroup":"Azure","marker":{"color":"#19d3f3","pattern":{"shape":""}},"name":"Azure","offsetgroup":"Azure","orientation":"h","showlegend":true,"textposition":"auto","x":[1.75,3.5,45.0,90.0],"xaxis":"x","y":["Azure-gpt-3.5-turbo-4k","Azure-gpt-3.5-turbo-16k","Azure-gpt-4-8k","Azure-gpt-4-32k"],"yaxis":"y","type":"bar"}],                        {"template":{"data":{"histogram2dcontour":[{"type":"histogram2dcontour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"choropleth":[{"type":"choropleth","colorbar":{"outlinewidth":0,"ticks":""}}],"histogram2d":[{"type":"histogram2d","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmap":[{"type":"heatmap","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmapgl":[{"type":"heatmapgl","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"contourcarpet":[{"type":"contourcarpet","colorbar":{"outlinewidth":0,"ticks":""}}],"contour":[{"type":"contour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"surface":[{"type":"surface","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"mesh3d":[{"type":"mesh3d","colorbar":{"outlinewidth":0,"ticks":""}}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"parcoords":[{"type":"parcoords","line":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolargl":[{"type":"scatterpolargl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"scattergeo":[{"type":"scattergeo","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolar":[{"type":"scatterpolar","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"scattergl":[{"type":"scattergl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatter3d":[{"type":"scatter3d","line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermapbox":[{"type":"scattermapbox","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterternary":[{"type":"scatterternary","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattercarpet":[{"type":"scattercarpet","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"pie":[{"automargin":true,"type":"pie"}]},"layout":{"autotypenumbers":"strict","colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"hovermode":"closest","hoverlabel":{"align":"left"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"bgcolor":"#E5ECF6","angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"ternary":{"bgcolor":"#E5ECF6","aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]]},"xaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"yaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"geo":{"bgcolor":"white","landcolor":"#E5ECF6","subunitcolor":"white","showland":true,"showlakes":true,"lakecolor":"white"},"title":{"x":0.05},"mapbox":{"style":"light"},"margin":{"b":0,"l":0,"r":0,"t":30}}},"xaxis":{"anchor":"y","domain":[0.0,1.0],"title":{"text":"$\u002f1M tokens"}},"yaxis":{"anchor":"x","domain":[0.0,1.0],"title":{}},"legend":{"title":{"text":"Provider"},"tracegroupgap":0,"traceorder":"reversed"},"barmode":"relative"},                        {"responsive": true}                    ).then(function(){
                            
var gd = document.getElementById('778847f3-16db-44a6-b236-1ec64c8da3e1');
var x = new MutationObserver(function (mutations, observer) {{
        var display = window.getComputedStyle(gd).display;
        if (!display || display === 'none') {{
            console.log([gd, 'removed!']);
            Plotly.purge(gd);
            observer.disconnect();
        }}
}});

// Listen for the removal of the full notebook cells
var notebookContainer = gd.closest('#notebook-container');
if (notebookContainer) {{
    x.observe(notebookContainer, {childList: true});
}}

// Listen for the clearing of the current output cell
var outputEl = gd.closest('.output');
if (outputEl) {{
    x.observe(outputEl, {childList: true});
}}

                        })                };                });            </script>        </div>
</div>
</div>
<p>Hover over bars to see extra information (also available in table below). The prices for input and output tokens were averaged. For AWS, the region us-east-1 was used.</p>
<ul>
<li>Price differences are huge, with a 600x difference between the cheapest and most expensive models ($0.15 vs $90)</li>
<li>GPT-4 is the most expensive model, followed by GPT-3.5 and PaLM2</li>
<li>Prices on Azure and OpenAI are identical</li>
<li>Anyscale is the cheapest provider for large models, serving Mistral’s models at lower prices than Mistral itself</li>
<li>Prices roughly reflect the number of parameters in the models, which again roughly map to their capability</li>
</ul>
<p><a href="https://paperswithcode.com/sota/multi-task-language-understanding-on-mmlu">Papers with Code</a> has a leaderboard for the MMLU (Massive Multitask Language Understanding) benchmark. The <a href="https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard">HuggingFace OpenLLM Leaderboard</a> offers a more detailed ranking of open source models across different benchmarks. These leaderboards don’t have benchmarks for every model listed here.</p>
</section>
<section id="model-table" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="model-table">Model table</h2>
<p>Click on column headers to sort. On mobile, scroll right to see all columns.</p>
<div id="ea6ee759" class="cell page-columns page-full" data-execution_count="3">
<div class="cell-output cell-output-display column-screen">
<style>.itables table td {
    text-overflow: ellipsis;
    overflow: hidden;
}

.itables table th {
    text-overflow: ellipsis;
    overflow: hidden;
}

.itables thead input {
    width: 100%;
    padding: 3px;
    box-sizing: border-box;
}

.itables tfoot input {
    width: 100%;
    padding: 3px;
    box-sizing: border-box;
}
</style>
<div class="itables">

<table id="4434095c-1c67-4c0b-89c5-b77fe8a9c71c" class="display nowrap compact caption-top table table-sm table-striped small" data-quarto-postprocess="true">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th">Model</th>
<th data-quarto-table-cell-role="th">Provider</th>
<th data-quarto-table-cell-role="th">Developer</th>
<th data-quarto-table-cell-role="th">Context size</th>
<th data-quarto-table-cell-role="th">Input $/1M</th>
<th data-quarto-table-cell-role="th">Output $/1M</th>
<th data-quarto-table-cell-role="th">Avg. $/1M</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Loading... (need <a href="https://mwouts.github.io/itables/troubleshooting.html">help</a>?)</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>

<link rel="stylesheet" type="text/css" href="https://cdn.datatables.net/1.13.1/css/jquery.dataTables.min.css">
<script type="module">
    // Import jquery and DataTable
    import 'https://code.jquery.com/jquery-3.6.0.min.js';
    import dt from 'https://cdn.datatables.net/1.12.1/js/jquery.dataTables.mjs';
    dt($);

    // Define the table data
    const data = [["mistral-7b-openorca", "Anyscale", "Mistral", "32k", 0.15, 0.15, 0.15], ["mistral-7b-instruct", "Anyscale", "Mistral", "32k", 0.15, 0.15, 0.15], ["llama-guard-7b", "Anyscale", "Meta", "4k", 0.15, 0.15, 0.15], ["llama-2-7b-chat-hf", "Anyscale", "Meta", "4k", 0.15, 0.15, 0.15], ["llama-2-13b-chat-hf", "Anyscale", "Meta", "4k", 0.25, 0.25, 0.25], ["mistral-7b-instruct", "Mistral", "Mistral", "32k", 0.14, 0.42, 0.28], ["cohere-light", "AWS", "Cohere", "4k", 0.3, 0.6, 0.45], ["mixtral-8x7b-instruct", "Anyscale", "Mistral", "32k", 0.5, 0.5, 0.5], ["llama-2-chat-13b", "AWS", "Meta", "4k", 0.75, 1.0, 0.88], ["llama2-70b-chat-hf", "Anyscale", "Meta", "4k", 1.0, 1.0, 1.0], ["mixtral-8x7b-instruct", "Mistral", "Mistral", "32k", 0.6, 1.8, 1.2], ["gpt-3.5-turbo-1106", "OpenAI", "OpenAI", "16k", 1.0, 2.0, 1.5], ["gemini-pro", "GCP", "Google", "32k", 1.0, 2.0, 1.5], ["claude-instant", "AWS", "Anthropic", "100k", 0.8, 2.4, 1.6], ["claude", "AWS", "Anthropic", "100k", 0.8, 2.4, 1.6], ["gpt-3.5-turbo-turbo-instruct", "OpenAI", "OpenAI", "16k", 1.5, 2.0, 1.75], ["titan-text-express", "AWS", "AWS", "8k", 1.2, 2.3, 1.75], ["cohere-command", "AWS", "Cohere", "4k", 1.5, 2.0, 1.75], ["gpt-3.5-turbo-4k", "Azure", "OpenAI", "4k", 1.5, 2.0, 1.75], ["palm2", "GCP", "Google", "8k", 2.0, 2.0, 2.0], ["llama-2-chat-70b", "AWS", "Meta", "4k", 1.95, 2.56, 2.26], ["gpt-3.5-turbo-16k", "Azure", "OpenAI", "16k", 3.0, 4.0, 3.5], ["mistral-medium", "Mistral", "Mistral", "32k", 2.5, 7.5, 5.0], ["jurassic-2-mid", "AWS", "AI21 Labs", "8k", 12.5, 12.5, 12.5], ["jurassic-2-ultra", "AWS", "AI21 Labs", "8k", 18.8, 18.8, 18.8], ["gpt-4-1106-preview", "OpenAI", "OpenAI", "128k", 10.0, 30.0, 20.0], ["gpt-4-1106-vision-preview", "OpenAI", "OpenAI", "128k", 10.0, 30.0, 20.0], ["gpt-4", "OpenAI", "OpenAI", "8k", 30.0, 60.0, 45.0], ["gpt-4-8k", "Azure", "OpenAI", "8k", 30.0, 60.0, 45.0], ["gpt-4-32k", "OpenAI", "OpenAI", "32k", 60.0, 120.0, 90.0], ["gpt-4-32k", "Azure", "OpenAI", "32k", 60.0, 120.0, 90.0]];

    // Define the dt_args
    let dt_args = {"columnDefs": [{"targets": [3, 4, 5, 6], "className": "dt-right"}, {"targets": [4, 5, 6], "render": $.fn.dataTable.render.number(',', '.', 2)}], "order": [[6, "desc"]], "paging": false, "dom": "tpr"};
    dt_args["data"] = data;

    $(document).ready(function () {
        
        $('#4434095c-1c67-4c0b-89c5-b77fe8a9c71c').DataTable(dt_args);
    });
</script>
</div>
</div>
</div>
</section>
<section id="sources" class="level2">
<h2 class="anchored" data-anchor-id="sources">Sources</h2>
<section id="pricing-pages" class="level3">
<h3 class="anchored" data-anchor-id="pricing-pages">Pricing pages</h3>
<ul>
<li><a href="https://openai.com/pricing">OpenAI Pricing</a></li>
<li><a href="https://docs.mistral.ai/platform/pricing/">Mistral AI Pricing</a></li>
<li><a href="https://docs.endpoints.anyscale.com/pricing/">AnyScale Pricing</a></li>
<li><a href="https://aws.amazon.com/bedrock/pricing/">AWS Bedrock Pricing</a></li>
<li><a href="https://azure.microsoft.com/de-de/pricing/details/cognitive-services/openai-service/">Azure Cognitive Services - OpenAI Service Pricing</a></li>
</ul>
</section>
<section id="context-size-information" class="level3">
<h3 class="anchored" data-anchor-id="context-size-information">Context size information</h3>
<ul>
<li><a href="https://docs.mistral.ai/platform/endpoints/">Mistral AI Endpoints</a></li>
<li><a href="https://www.anthropic.com/index/100k-context-windows">Anthropic 100k Context Windows</a></li>
<li><a href="https://huggingface.co/HuggingFaceH4/zephyr-7b-beta/discussions/13">Zephyr-7B Beta Discussion on HuggingFace</a></li>
<li><a href="https://www.maginative.com/article/mistral-ai-launches-platform-services#:~:text=Mistral%2Dtiny%3A%20The%20most%20cost,where%20cost%20efficiency%20is%20paramount">Mistral AI Launches Platform Services</a></li>
<li><a href="https://aws.amazon.com/bedrock/cohere-command-embed/">AWS Bedrock Cohere Command Embed</a></li>
<li><a href="https://aws.amazon.com/marketplace/pp/prodview-ivk4wjg6gbr26#:~:text=Pre%2Dtrained%20language%20model%20trained,be%20at%20most%208192%20tokens">AWS Marketplace – Pretrained Language Model</a></li>
<li><a href="https://aws.amazon.com/marketplace/ppprodview-irdbpdk5v5p5g#:~:text=This%20model%20has%20a%208192,among%20the%20top%20LLM%20models">AWS Marketplace – Top LLM models</a></li>
<li><a href="https://aws.amazon.com/machine-learning/responsible-machine-learning/titan-text/">AWS Responsible Machine Learning -Titan Text</a></li>
</ul>


</section>
</section>

 ]]></description>
  <category>Machine Learning</category>
  <category>Cloud</category>
  <category>Economics</category>
  <guid>https://simmering.dev/blog/llm-price-performance/</guid>
  <pubDate>Wed, 10 Jan 2024 23:00:00 GMT</pubDate>
  <media:content url="https://simmering.dev/blog/llm-price-performance/image.png" medium="image" type="image/png" height="106" width="144"/>
</item>
<item>
  <title>The Grug Brained Data Scientist</title>
  <dc:creator>Paul Simmering</dc:creator>
  <link>https://simmering.dev/blog/data-grug/</link>
  <description><![CDATA[ 





<p><a href="https://grugbrain.dev">The Grug Brained Developer</a> is a funny essay on advice for software developers. The lessons resonated with me. This is my own version, geared towards data professionals.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/data-grug/grug.png" class="img-fluid figure-img"></p>
<figcaption>grug and the demons - made with DALL-E</figcaption>
</figure>
</div>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>this collection of data science thoughts. good for young grugs that liked The Grug Brained Developer and now want more into data</p>
<p>grug data scientist not understand all but try many thing and fail and learn and do better over time and share what not awful</p>
</section>
<section id="complexity-bad-in-data-science-too" class="level2">
<h2 class="anchored" data-anchor-id="complexity-bad-in-data-science-too">Complexity bad in data science too</h2>
<p>data science much complex. many thing go wrong, invisible to grug</p>
<p>complexity bad, make grug’s brain hurt and cause mistakes that bite grug later</p>
<p>some complexity necessary to solve business problem. that is grug’s job. but grug must not add complexity that not needed</p>
</section>
<section id="data-quality" class="level2">
<h2 class="anchored" data-anchor-id="data-quality">Data quality</h2>
<p>data quality most important. if data bad, model bad. if model bad, prediction bad. if prediction bad, business bad, so no shiny rocks for grug</p>
<p>bad data is demon of data sciencing. is sneaky demon that hides in data and makes grug look bad, or worse, give bad info to business shamans. many shiny rocks lost to bad data</p>
<p>grug likes being close to data. but big brain data tools hide data and make it hard for grug to look at tables. grug like to look at tables. grug finds problems in data by looking at tables</p>
<p>grug work in data warehouse for years and when grug smells a stink, grug look at tables and find problem. when grug ignores stink and not look at tables, grug always regret</p>
<p>but projects have many tables and grug busy. so grug must automate look at tables. data quality framework check if data is missing, is in wrong format, or is out of range and if foreign keys are valid</p>
<p>best guarantee comes from enforced constraints in database. constraints always on guard and never sleep</p>
<p>but analytics databases are too lazy to enforce constraints. so grug must use data quality framework to check data. grug not like this but best grug can do</p>
</section>
<section id="data-problem-needs-data-solution" class="level2">
<h2 class="anchored" data-anchor-id="data-problem-needs-data-solution">Data problem needs data solution</h2>
<p>grugs tempted to use complex methods to fix problem of missing data and other stink. but better to fix at source</p>
<p>if data is bad, fix data</p>
<p>say again: <em>if data is bad, fix data</em></p>
<p>to fix data, grugs need talk other grugs and business shamans. much wait. but must endure and fix data. tempting, use code to fix. very bad idea</p>
</section>
<section id="counting-things" class="level2">
<h2 class="anchored" data-anchor-id="counting-things">Counting things</h2>
<p>grug like to count things. when data quality nice, counting things already good enough to make business shamans happy. grug can count anything: users, orders, clicks, shiny rocks collected and more. grug can also separate counting by time, location, and other things</p>
<p>counting easy to do and fit into brain</p>
</section>
<section id="visualization" class="level2">
<h2 class="anchored" data-anchor-id="visualization">Visualization</h2>
<p>bar chart is grug’s best friend forever. grug can make bar chart of anything. easy for business shamans and grug to understand</p>
<p>complex chart like network graph or tree map or radar chart too hard to understand. message get lost in complexity</p>
<p>pie chart and word cloud look easy but cause misunderstanding. almost always better to use bar chart. sometimes business shamans ask for pie chart, and when pie has few slices, is ok. when pie has many slices, grug must say no</p>
</section>
<section id="machine-learning" class="level2">
<h2 class="anchored" data-anchor-id="machine-learning">Machine learning</h2>
<p>machine learning is powerful tool and unlocker of many shiny rocks. grug understands is not magic and not always best tool for job</p>
<p>big brains use complex machine learning models to solve problem that can be solved with simple model. like to show off big brain</p>
<p>this very bad because big model cost many shiny rocks for train and run. grug can’t look into big model to see what is doing and grug can’t explain big model to business shamans</p>
<p>some hard problem can only be solved with big model. then grug must use big model</p>
<p>grug likes reproducible model training and evaluation. grug and colleagues need to retrain models and compare. easy to forget settings and which data was used. brain limited. better to have tool that logs everything</p>
<p>last few years many big model change grug’s life. grug can now do things that grug could not before. big brains work very fast to make big model better and better. grug very happy about this and grug hope big brains keep doing this</p>
<p>grug prepares for new big model to change. grug knows: model come and go. model is not forever. new model will come and make old model look bad</p>
</section>
<section id="performance-and-productivity" class="level2">
<h2 class="anchored" data-anchor-id="performance-and-productivity">Performance and productivity</h2>
<p>when grug has to wait for model to train or database to query, grug gets bored and grug’s brain wanders. bad for grug’s productivity. make business shamans impatient too</p>
<p>data exploration and model experimentation is more fun when machine goes brrrr rather than when machine goes zzzzz. so when slow, grug uses performance profiling tools to find bottleneck</p>
<p>caching grug’s #2 best friend. grug ask for same thing many times. indexing also good friend</p>
<p>cloud development twisted concept. cloud scales in production - nice! but bad for developer experience. write code on laptop, package, upload, and wait for cloud to run. very slow and tiny bug that grug could fix in 1 minute takes long time. grug look for ways to develop locally or with quick feedback loop. setup can be headache but worth it!</p>
</section>
<section id="expanding-the-grug-brain" class="level2">
<h2 class="anchored" data-anchor-id="expanding-the-grug-brain">Expanding the grug brain</h2>
<p>grug’s brain too small and grug too busy to keep up with all new shiny toys. grug must choose which shiny toys to learn</p>
<p>popular data shamans have new toys every day and promise that new toys will solve all problems. grug not always believe this. but some tools are actually good. so grug must choose wisely</p>
<p>learn evergreen skills - always good idea. grug loves SQL because SQL was good for shiny rock collection for decades and will be good for long time more. many new toys use SQL so grug can use SQL with new toys</p>
<p>grug wants to have brain shaped like letter T. grug wants to know basics of many things and aspires to big brain in one thing</p>
<p>always need data quality and visualization and model evaluation. these are basic demon defense skills that every grug must have. cloud also good</p>
<p>to get more shiny rocks, grug must be extra good at one more thing, like model deepthink or huge data organization or business shaman rituals</p>
<p>some grugs identify by their tools. grug is wary of this. grug is grug, not Spark grug or Snowflake grug or AWS grug. when grug join new shiny rock mine, grug will use tool that other grugs use</p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>good data better than complex pipeline</p>


</section>

 ]]></description>
  <category>Advice</category>
  <guid>https://simmering.dev/blog/data-grug/</guid>
  <pubDate>Fri, 08 Dec 2023 23:00:00 GMT</pubDate>
  <media:content url="https://simmering.dev/blog/data-grug/grug.png" medium="image" type="image/png" height="82" width="144"/>
</item>
<item>
  <title>NLP escalation ladder: Use the simplest NLP model that does the job</title>
  <dc:creator>Paul Simmering</dc:creator>
  <link>https://simmering.dev/blog/nlp-model-escalation/</link>
  <description><![CDATA[ 





<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/nlp-model-escalation/image.jpg" class="img-fluid figure-img"></p>
<figcaption>Image generated with DALL·E 3</figcaption>
</figure>
</div>
<p>With all the hype and breathtaking demos, it’s tempting to see LLMs as the universal tool for every language problem. And yes, GPT-4 in particular will achieve decent to great accuracy on almost all tasks and across languages. But there’s more to consider than accuracy:</p>
<ul>
<li>🕐 <strong>Performance</strong>: How long does it take the model to come up with the answer?</li>
<li>💰 <strong>Inference cost</strong>: How much does it cost to run the model?</li>
<li>🔍 <strong>Explainability</strong>: Can you tell why the model gave a certain answer?</li>
<li>🔗 <strong>Dependency</strong>: Which external APIs am I dependent on and how reliable are they?</li>
<li>☁️ <strong>Deployment</strong>: How complicated is the required cloud infrastructure? Can I run the model on a smartphone or does it require a data center?</li>
<li>🌍 <strong>Environment</strong>: How much electricity does the model consume and what’s the CO2 footprint?</li>
</ul>
<p>The importance of performance, cost and the environmental impact goes up with scale. At just hundreds of inference calls, they don’t really add up to much. At millions or billions of calls, they can become prohibitive.</p>
<p>With these questions in mind, here’s a tier list of models going from “great” on these ratings to “awful”. They also increase in flexibility and a reduction in performance measured in examples per second. The numbers I give are rough and are oriented around the example task of classifying the topic of one social media post.</p>
<ol type="1">
<li><strong>Regular expressions</strong>: Quite a few tasks can be solved just by looking up keyword or extracting strings based on a pattern. For example, regular expressions efficiently extract phone numbers and email addresses, or one could find mentions of companies that match a manually compiled list. Millions of texts can be processed in a few seconds using regular expressions. The downside: They’re not flexible and each rule has to be manually written.</li>
<li><strong>Word count statistics</strong>: Techniques like <a href="https://en.wikipedia.org/wiki/Tf–idf">tf-idf</a> measure the frequency of word use, providing insights about the importance of words. They are useful for search and classification with greater flexibility than regular expressions. Word counts require a tokenization pre-processing step, but once that’s done, they can also be used to analyze millions of texts in seconds.</li>
<li><strong>Regression models</strong>: Statistical models like <a href="https://en.wikipedia.org/wiki/Logistic_regression">Logistic Regression</a> can be used to predict categories based on word count statistics. Taking a step forward in complexity, these have marginally higher resource consumption, but offer a more nuanced understanding of relationships in the text. They build further on tokenization and word count statistics and can be enhanced with word embeddings learned by neural nets. Logistic regression runs on CPUs, can be trained in seconds to minutes and can process hundreds of thousands of examples in seconds.</li>
<li><strong>Small neural nets</strong>: Neural nets take the flexibility of logistic regression further and enable more varied outputs, such as boundaries between named entities. Using non-linear activation functions, convolution layers and dropout, they’re capable learners for a large variety of tasks. The <a href="https://spacy.io">spaCy</a> library offers such <a href="https://spacy.io/usage/models">models</a> in different sizes and for different languages. They run on CPU and can process thousands of examples in seconds.</li>
<li><strong>Transformer models</strong>: Neural nets with an attention layer are capable of understanding word meanings in context. This provides a major boost in accuracy. Further, some transformers have been pretrained in multiple languages at once. Transformer models have been heavily optimized, resulting in efficient models like <a href="https://arxiv.org/abs/1910.01108">DistilBERT</a>. It is possible to train and run these on CPU, but a GPU will provide much better performance. They can handle hundreds of examples in seconds.</li>
<li><strong>Large language models</strong>: GPT-3, GPT-4 and other large language models are capable of virtually any task in NLP, from translation to named entity recognition. The flexibility comes at a price: they have billions of parameters and require multiple GPUs to run. Arguably, using a pre-trained LLM without fine-tuning is simpler than any of the previous standpoints because they don’t require much knowledge of NLP techniques. LLMs are slow, even on the latest GPUs, struggling to handle more than one example per second.</li>
</ol>
<p>To summarize:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Model</th>
<th>Flexibility</th>
<th>Examples per second</th>
<th>Cost per 1000 examples</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Regular expressions</td>
<td>Very low</td>
<td>Millions</td>
<td>Next to nothing</td>
</tr>
<tr class="even">
<td>Word count statistics</td>
<td>Low</td>
<td>Millions</td>
<td>Next to nothing</td>
</tr>
<tr class="odd">
<td>Regression models</td>
<td>Medium</td>
<td>Tens of thousands</td>
<td>Next to nothing</td>
</tr>
<tr class="even">
<td>Small neural nets</td>
<td>Medium to high</td>
<td>Hundreds</td>
<td>Less than a cent</td>
</tr>
<tr class="odd">
<td>Transformer models</td>
<td>High</td>
<td>Dozens</td>
<td>Cents</td>
</tr>
<tr class="even">
<td>Large language models</td>
<td>Very high</td>
<td>Handfuls</td>
<td>Dollars</td>
</tr>
</tbody>
</table>
<p>CO2 footprint roughly scales with cost, driven by hardware needs and electricity consumption.</p>
<p>When thinking through a problem, try to find the simplest solution that does the job.</p>
<p>There’s one more level to this: Some of the complex models can help train the simpler ones. For example, one could get labels for a classification task from GPT-4 and then train a smaller DistilBERT model on the data. Or, one could use the tf-idf statistic to find words that are typical for class and train a logistic regression model that only takes the presence of these words as inputs. There are many paths, and in a large scale project, it’s worth exploring them.</p>
<p>Related articles:</p>
<ul>
<li><a href="https://explosion.ai/blog/against-llm-maximalism">Against LLM maximalism</a></li>
<li><a href="&quot;/blog/one-stop-nlp&quot;">One-stop NLP: Multi-task prompts for LLMs</a></li>
</ul>



 ]]></description>
  <category>Machine Learning</category>
  <category>Advice</category>
  <guid>https://simmering.dev/blog/nlp-model-escalation/</guid>
  <pubDate>Sat, 11 Nov 2023 23:00:00 GMT</pubDate>
  <media:content url="https://simmering.dev/blog/nlp-model-escalation/image.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Large language models for aspect-based sentiment analysis</title>
  <dc:creator>Paul Simmering</dc:creator>
  <link>https://simmering.dev/blog/llms-for-absa/</link>
  <description><![CDATA[ 





<p>A finetuned GPT-3.5 Turbo model achieves state-of-the-art performance in aspect-based sentiment analysis (ABSA). Zero-shot and few-shot settings with GPT-4 and GPT-3.5 reach decent performance too.</p>
<p><strong>The big picture</strong>: In August, OpenAI <a href="https://openai.com/blog/gpt-3-5-turbo-fine-tuning-and-api-updates">announced</a> fine-tuning for GPT-3.5 Turbo. Fine-tuning enables the general model to be optimized for a specific task. My colleague Paavo Huoviala and me tested the performance of a fine-tuned GPT-3.5 Turbo on the <a href="https://aclanthology.org/S14-2004.pdf">SemEval 2014 Task 4</a> joint aspect term extraction and polarity classification task. We found that the model achieves state-of-the-art performance. However, this comes at the price of 1000 times more model parameters and thus increased inference cost. We also tested zero-shot and few-shot settings with GPT-4 and GPT-3.5. These models reach decent performance too, without requiring training data.</p>
<p><strong>Learn more</strong>: My colleague Paavo Huoviala and me recently published an article on <a href="https://arxiv.org/abs/2310.18025">arXiv</a>. The related code is available on <a href="https://github.com/qagentur/absa_llm">Github</a>.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Aspect-based sentiment analysis">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Aspect-based sentiment analysis
</div>
</div>
<div class="callout-body-container callout-body">
<p>In contrast to regular sentiment analysis that assigns one polarity label to an entire text, aspect-based sentiment analysis (ABSA) aims to identify the polarity of individual aspects of a text. For example, in the sentence “The food was great, but the service was terrible”, ABSA would identify the aspect “food” as positive and “service” as negative.</p>
</div>
</div>
<section id="implications-for-practitioners" class="level2">
<h2 class="anchored" data-anchor-id="implications-for-practitioners">Implications for practitioners</h2>
<ol type="1">
<li>Fine-tuning GPT-3.5 isn’t difficult or expensive. In this case, it cost less than $30 to fine-tune on 5572 training examples.</li>
<li>Fine-tuned large language models (LLMs) can achieve better performance in classic NLP tasks than smaller transformer models like RoBERTa.</li>
<li>A fine-tuned model doesn’t seem to benefit from prompt engineering. This reduces the number of input tokens and thus inference cost.</li>
<li>For ad-hoc projects, acceptable performance can be reached with just a few examples. After the proof of concept, more examples can be collected with help from the model.</li>
</ol>


</section>

 ]]></description>
  <category>Machine Learning</category>
  <guid>https://simmering.dev/blog/llms-for-absa/</guid>
  <pubDate>Tue, 31 Oct 2023 23:00:00 GMT</pubDate>
  <media:content url="https://simmering.dev/blog/llms-for-absa/image.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>One-stop NLP: Multi-task prompts for LLMs</title>
  <dc:creator>Paul Simmering</dc:creator>
  <link>https://simmering.dev/blog/one-stop-nlp/</link>
  <description><![CDATA[ 





<p>In NLP, we often want to extract multiple pieces of information from a text. Each extraction task is typically done by one model. For example, we might want to classify the topic of a text, do named entity recognition and extract the sentiment. To build such a pipeline, we need to train three different models.</p>
<p>What if we asked a large language model (LLM) to do it all in one step and return a god-view JSON object with all the structured information we need? That’s the idea I’d like to explore in this article.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/one-stop-nlp/knife.webp" class="img-fluid figure-img"></p>
<figcaption>Illustration generated with DALL·E 3</figcaption>
</figure>
</div>
<p>I’ll use the <a href="https://github.com/jxnl/instructor">instructor</a> package to describe the desired JSON object using a Pydantic model. Then I’ll send the requests to the OpenAI API with the <a href="https://github.com/qagentur/texttunnel">texttunnel</a> package. I’m the main developer of texttunnel.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>This article is an exploration, not a recommendation. Please refer to the last section for a discussion of the pros and cons of this approach.</p>
</div>
</div>
<section id="data-news-articles" class="level2">
<h2 class="anchored" data-anchor-id="data-news-articles">Data: News articles</h2>
<p>Let’s say we are building a news analysis tool.</p>
<p>We’ll use the <a href="https://huggingface.co/datasets/cc_news">cc_news</a> dataset from Hugging Face. It contains 708,241 English language news articles published between January 2017 and December 2019.</p>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> datasets <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> load_dataset</span>
<span id="cb1-2"></span>
<span id="cb1-3">dataset <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> load_dataset(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cc_news"</span>, split<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"train"</span>)</span></code></pre></div>
</div>
<p>We won’t be training a model in this article, so we’ll just use the first 500 unique articles from the training set and run them through a pre-trained LLM. Let’s load the data into a <a href="https://www.pola.rs">Polars</a> dataframe and take a look at the first five rows.</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> polars <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pl</span>
<span id="cb2-2"></span>
<span id="cb2-3">news <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pl.from_arrow(dataset.data.table).unique(subset<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"text"</span>).head(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">500</span>)</span>
<span id="cb2-4"></span>
<span id="cb2-5">news.head(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>)</span>
<span id="cb2-6"></span>
<span id="cb2-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Save to disk for later use</span></span>
<span id="cb2-8">news.write_parquet(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"news.parquet"</span>)</span></code></pre></div>
</div>
</section>
<section id="defining-the-god-view-json" class="level2">
<h2 class="anchored" data-anchor-id="defining-the-god-view-json">Defining the God-View JSON</h2>
<p><a href="https://docs.pydantic.dev/latest/">Pydantic</a> allows us to define a detailed schema for the JSON object we want to get from the LLM.</p>
<p>This is what it looks like:</p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> enum <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Enum</span>
<span id="cb3-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> typing <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> List</span>
<span id="cb3-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pydantic <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> BaseModel</span>
<span id="cb3-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> instructor <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> OpenAISchema</span>
<span id="cb3-5"></span>
<span id="cb3-6"></span>
<span id="cb3-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define the labels for the different tasks</span></span>
<span id="cb3-8"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> TopicLabel(Enum):</span>
<span id="cb3-9">    ARTS <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ARTS"</span></span>
<span id="cb3-10">    BUSINESS <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"BUSINESS"</span></span>
<span id="cb3-11">    ENTERTAINMENT <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ENTERTAINMENT"</span></span>
<span id="cb3-12">    HEALTH <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"HEALTH"</span></span>
<span id="cb3-13">    POLITICS <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"POLITICS"</span></span>
<span id="cb3-14">    SCIENCE <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"SCIENCE"</span></span>
<span id="cb3-15">    SPORTS <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"SPORTS"</span></span>
<span id="cb3-16">    TECHNOLOGY <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"TECHNOLOGY"</span></span>
<span id="cb3-17"></span>
<span id="cb3-18"></span>
<span id="cb3-19"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> SentimentLabel(Enum):</span>
<span id="cb3-20">    POSITIVE <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"POSITIVE"</span></span>
<span id="cb3-21">    NEGATIVE <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"NEGATIVE"</span></span>
<span id="cb3-22">    NEUTRAL <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"NEUTRAL"</span></span>
<span id="cb3-23"></span>
<span id="cb3-24"></span>
<span id="cb3-25"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> NamedEntityLabel(Enum):</span>
<span id="cb3-26">    PERSON <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"PERSON"</span></span>
<span id="cb3-27">    ORG <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ORG"</span></span>
<span id="cb3-28">    PRODUCT <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"PRODUCT"</span></span>
<span id="cb3-29">    LOCATION <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"LOCATION"</span></span>
<span id="cb3-30">    EVENT <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"EVENT"</span></span>
<span id="cb3-31"></span>
<span id="cb3-32"></span>
<span id="cb3-33"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define how named entities are represented</span></span>
<span id="cb3-34"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> NamedEntity(BaseModel):</span>
<span id="cb3-35">    text: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span></span>
<span id="cb3-36">    label: NamedEntityLabel</span>
<span id="cb3-37"></span>
<span id="cb3-38"></span>
<span id="cb3-39"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define the schema for the JSON object that</span></span>
<span id="cb3-40"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># we want the LLM to return</span></span>
<span id="cb3-41"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> News(OpenAISchema):</span>
<span id="cb3-42">    topics: List[TopicLabel]</span>
<span id="cb3-43">    sentiment: SentimentLabel</span>
<span id="cb3-44">    named_entities: List[NamedEntity]</span></code></pre></div>
</div>
<p>Now, how do we get the LLM to return this JSON object?</p>
<p>The OpenAI API has the <a href="https://openai.com/blog/function-calling-and-other-api-updates">function calling</a> feature, which allows us to send a <a href="https://json-schema.org">JSON schema</a> describing a Python function to the API. The model will respond with a JSON object that matches the schema.</p>
<p>The instructor package lets us take a Pydantic model and convert it to a JSON schema that we can send to the OpenAI API.</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pprint</span>
<span id="cb4-2"></span>
<span id="cb4-3">function_schema <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> News.openai_schema</span>
<span id="cb4-4"></span>
<span id="cb4-5">pprint.pprint(function_schema)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{'description': 'Correctly extracted `News` with all the required parameters '
                'with correct types',
 'name': 'News',
 'parameters': {'$defs': {'NamedEntity': {'properties': {'label': {'$ref': '#/$defs/NamedEntityLabel'},
                                                         'text': {'title': 'Text',
                                                                  'type': 'string'}},
                                          'required': ['text', 'label'],
                                          'title': 'NamedEntity',
                                          'type': 'object'},
                          'NamedEntityLabel': {'enum': ['PERSON',
                                                        'ORG',
                                                        'PRODUCT',
                                                        'LOCATION',
                                                        'EVENT'],
                                               'title': 'NamedEntityLabel',
                                               'type': 'string'},
                          'SentimentLabel': {'enum': ['POSITIVE',
                                                      'NEGATIVE',
                                                      'NEUTRAL'],
                                             'title': 'SentimentLabel',
                                             'type': 'string'},
                          'TopicLabel': {'enum': ['ARTS',
                                                  'BUSINESS',
                                                  'ENTERTAINMENT',
                                                  'HEALTH',
                                                  'POLITICS',
                                                  'SCIENCE',
                                                  'SPORTS',
                                                  'TECHNOLOGY'],
                                         'title': 'TopicLabel',
                                         'type': 'string'}},
                'properties': {'named_entities': {'items': {'$ref': '#/$defs/NamedEntity'},
                                                  'title': 'Named Entities',
                                                  'type': 'array'},
                               'sentiment': {'$ref': '#/$defs/SentimentLabel'},
                               'topics': {'items': {'$ref': '#/$defs/TopicLabel'},
                                          'title': 'Topics',
                                          'type': 'array'}},
                'required': ['named_entities', 'sentiment', 'topics'],
                'type': 'object'}}</code></pre>
</div>
</div>
<p>This clearly defines what we want the LLM to return. It uses the <code>enum</code>, <code>required</code> and <code>properties</code> keywords from the JSON schema specification.</p>
</section>
<section id="sending-requests" class="level2">
<h2 class="anchored" data-anchor-id="sending-requests">Sending requests</h2>
<p>Next, we need to send the requests to the OpenAI API. The texttunnel package makes this easy and efficient. We start by defining the requests. Each article is sent as a separate request.</p>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> texttunnel <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> chat, models</span>
<span id="cb6-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> polars <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pl</span>
<span id="cb6-3"></span>
<span id="cb6-4">news <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pl.read_parquet(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"news.parquet"</span>)</span>
<span id="cb6-5"></span>
<span id="cb6-6">requests <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> chat.build_requests(</span>
<span id="cb6-7">    model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>models.GPT_3_5_TURBO,</span>
<span id="cb6-8">    function<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>function_schema,</span>
<span id="cb6-9">    system_message<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Analyze news articles. Strictly stick to the allowed labels."</span>,</span>
<span id="cb6-10">    params<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>models.Parameters(max_tokens<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1024</span>),</span>
<span id="cb6-11">    texts<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>news[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"text"</span>].to_list(),</span>
<span id="cb6-12">    long_text_handling<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"truncate"</span>,</span>
<span id="cb6-13">)</span>
<span id="cb6-14"></span>
<span id="cb6-15"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Built </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(requests)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> requests"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Built 500 requests</code></pre>
</div>
</div>
<p>And how much will it cost to send these requests?</p>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1">cost_usd <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>([x.estimate_cost_usd() <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> x <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> requests])</span>
<span id="cb8-2"></span>
<span id="cb8-3"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Estimated cost: $</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>cost_usd<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.2f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Estimated cost: $1.68</code></pre>
</div>
</div>
<p>Next, let’s set up a cache to store the responses. This way, we can experiment and never have to pay for the same request twice.</p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> aiohttp_client_cache <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> SQLiteBackend</span>
<span id="cb10-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pathlib <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Path</span>
<span id="cb10-3"></span>
<span id="cb10-4">cache <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> SQLiteBackend(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cache.sqlite"</span>, allowed_methods<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"POST"</span>)</span></code></pre></div>
</div>
<p>This will create a file called <code>cache.sqlite</code> in the current directory, which will hold a copy of the responses.</p>
<p>Now we’re ready to actually send the requests.</p>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> texttunnel <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> processor</span>
<span id="cb11-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> logging</span>
<span id="cb11-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pickle</span>
<span id="cb11-4"></span>
<span id="cb11-5">logging.basicConfig(level<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>logging.INFO)</span>
<span id="cb11-6"></span>
<span id="cb11-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Setup logging for the texttunnel package</span></span>
<span id="cb11-8">logging.getLogger(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"texttunnel"</span>).setLevel(logging.INFO)</span>
<span id="cb11-9"></span>
<span id="cb11-10">logging.info(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Sending </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(requests)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> requests to the OpenAI API"</span>)</span>
<span id="cb11-11"></span>
<span id="cb11-12">responses <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> processor.process_api_requests(</span>
<span id="cb11-13">    requests<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>requests,</span>
<span id="cb11-14">    cache<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>cache,</span>
<span id="cb11-15">)</span>
<span id="cb11-16"></span>
<span id="cb11-17"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Save to disk for later use</span></span>
<span id="cb11-18"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">open</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"responses.pickle"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"wb"</span>) <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> f:</span>
<span id="cb11-19">    pickle.dump(responses, f)</span></code></pre></div>
</div>
<p>The texttunnel package sends the requests in parallel and caches the responses.</p>
</section>
<section id="results" class="level2">
<h2 class="anchored" data-anchor-id="results">Results</h2>
<section id="parsing-and-validation" class="level3">
<h3 class="anchored" data-anchor-id="parsing-and-validation">Parsing and validation</h3>
<p>For each request, <code>process_api_requests</code> returned a list containing two dicts: one containing the request, the other the API’s response. Inside the response is the <code>arguments</code> key, which contains a string that should be parseable into a Python dict that matches the schema we defined.</p>
<p>We parse the responses and count the parsing errors.</p>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pickle</span>
<span id="cb12-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> texttunnel <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> processor</span>
<span id="cb12-3"></span>
<span id="cb12-4"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">open</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"responses.pickle"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"rb"</span>) <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> f:</span>
<span id="cb12-5">    responses <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pickle.load(f)</span>
<span id="cb12-6"></span>
<span id="cb12-7">parsing_errors <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb12-8"></span>
<span id="cb12-9"></span>
<span id="cb12-10"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> parse(response):</span>
<span id="cb12-11">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">global</span> parsing_errors</span>
<span id="cb12-12">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">try</span>:</span>
<span id="cb12-13">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> processor.parse_arguments(response)</span>
<span id="cb12-14">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">except</span> <span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">Exception</span>:</span>
<span id="cb12-15">        parsing_errors <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb12-16">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span></span>
<span id="cb12-17"></span>
<span id="cb12-18"></span>
<span id="cb12-19">arguments <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [parse(response) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> response <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> responses]</span>
<span id="cb12-20"></span>
<span id="cb12-21"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Parsing errors: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>parsing_errors<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> out of </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(arguments)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> responses"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Parsing errors: 3 out of 500 responses</code></pre>
</div>
</div>
<p>Next, we verify that they conform to the schema we defined.</p>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pydantic <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> ValidationError</span>
<span id="cb14-2"></span>
<span id="cb14-3"></span>
<span id="cb14-4"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> validate(argument):</span>
<span id="cb14-5">    News.model_validate(argument)</span>
<span id="cb14-6">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> argument</span>
<span id="cb14-7"></span>
<span id="cb14-8"></span>
<span id="cb14-9"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> run_validation(arguments, validation_fun):</span>
<span id="cb14-10">    validation_errors <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb14-11">    out <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb14-12">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> argument <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> arguments:</span>
<span id="cb14-13">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> argument <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb14-14">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># JSON parsing error</span></span>
<span id="cb14-15">            out.append(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>)</span>
<span id="cb14-16">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">continue</span></span>
<span id="cb14-17">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">try</span>:</span>
<span id="cb14-18">            argument <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> validation_fun(argument)</span>
<span id="cb14-19">            out.append(argument)</span>
<span id="cb14-20">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">except</span> ValidationError:</span>
<span id="cb14-21">            validation_errors <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb14-22">            out.append(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>)</span>
<span id="cb14-23"></span>
<span id="cb14-24">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Validation error in </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>validation_errors<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> out of </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(arguments)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> responses"</span>)</span>
<span id="cb14-25"></span>
<span id="cb14-26">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> out</span>
<span id="cb14-27"></span>
<span id="cb14-28"></span>
<span id="cb14-29">valid_arguments <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> run_validation(arguments, validate)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Validation error in 130 out of 500 responses</code></pre>
</div>
</div>
<p>The LLM doesn’t always follow the expected format. It adds extra labels to topics and entities that are not in the schema.</p>
<p>These can be fixed automatically. Let’s try again.</p>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> fix_and_validate(argument):</span>
<span id="cb16-2">    fixed_argument <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> argument.copy()</span>
<span id="cb16-3"></span>
<span id="cb16-4">    topics <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>(TopicLabel.__members__)</span>
<span id="cb16-5"></span>
<span id="cb16-6">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Remove topics that are not in the schema</span></span>
<span id="cb16-7">    fixed_argument[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"topics"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [x <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> x <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> argument[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"topics"</span>] <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> x <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> topics]</span>
<span id="cb16-8"></span>
<span id="cb16-9">    entities <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>(NamedEntityLabel.__members__)</span>
<span id="cb16-10"></span>
<span id="cb16-11">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> argument[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"named_entities"</span>] <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb16-12">        fixed_argument[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"named_entities"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [</span>
<span id="cb16-13">            x <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> x <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> argument[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"named_entities"</span>] <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> x[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"label"</span>] <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> entities</span>
<span id="cb16-14">        ]</span>
<span id="cb16-15"></span>
<span id="cb16-16">    validate(fixed_argument)</span>
<span id="cb16-17">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> fixed_argument</span>
<span id="cb16-18"></span>
<span id="cb16-19"></span>
<span id="cb16-20">valid_arguments <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> run_validation(arguments, fix_and_validate)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Validation error in 0 out of 500 responses</code></pre>
</div>
</div>
<p>Removing the invalid labels fixed all validation errors.</p>
<p>Next, let’s bring the answers into a Polars dataframe.</p>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1">valid_arguments <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [x <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> x <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> valid_arguments <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> x <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>]</span>
<span id="cb18-2">answers <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pl.DataFrame(valid_arguments, orient<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"records"</span>)</span>
<span id="cb18-3"></span>
<span id="cb18-4"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(answers.head(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>shape: (5, 3)
┌────────────────────────────┬───────────┬───────────────────────────────────┐
│ topics                     ┆ sentiment ┆ named_entities                    │
│ ---                        ┆ ---       ┆ ---                               │
│ list[str]                  ┆ str       ┆ list[struct[2]]                   │
╞════════════════════════════╪═══════════╪═══════════════════════════════════╡
│ ["POLITICS", "TECHNOLOGY"] ┆ NEGATIVE  ┆ [{"James Clapper","PERSON"}, {"R… │
│ ["POLITICS", "TECHNOLOGY"] ┆ NEGATIVE  ┆ [{"Canadian troops","ORG"}, {"Ma… │
│ ["BUSINESS"]               ┆ POSITIVE  ┆ [{"Moshe Kahlon","PERSON"}, {"Is… │
│ ["BUSINESS"]               ┆ NEUTRAL   ┆ [{"Bailoy Irrigation Control Sys… │
│ ["SPORTS"]                 ┆ NEUTRAL   ┆ [{"Pep Guardiola","PERSON"}, {"B… │
└────────────────────────────┴───────────┴───────────────────────────────────┘</code></pre>
</div>
</div>
<p>Note that the topics and named entities are now represented as nested elements.</p>
</section>
<section id="visualization" class="level3">
<h3 class="anchored" data-anchor-id="visualization">Visualization</h3>
<p>The LLM’s answers could be used to power a dashboard that shows the most common topics, positive and negative sentiment and the most frequently mentioned named entities. Let’s get a preview of what that could look like.</p>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> plotly.express <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> px</span>
<span id="cb20-2"></span>
<span id="cb20-3">topic_sentiment <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (</span>
<span id="cb20-4">    answers.drop_nulls().explode(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"topics"</span>)</span>
<span id="cb20-5">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Sort for legend</span></span>
<span id="cb20-6">    .sort(</span>
<span id="cb20-7">        pl.when(pl.col(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"sentiment"</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"POSITIVE"</span>)</span>
<span id="cb20-8">        .then(pl.lit(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>))</span>
<span id="cb20-9">        .when(pl.col(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"sentiment"</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"NEUTRAL"</span>)</span>
<span id="cb20-10">        .then(pl.lit(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>))</span>
<span id="cb20-11">        .otherwise(pl.lit(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>))</span>
<span id="cb20-12">    )</span>
<span id="cb20-13">)</span>
<span id="cb20-14"></span>
<span id="cb20-15">sentiment_colors <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb20-16">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"POSITIVE"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"#98FB98"</span>,</span>
<span id="cb20-17">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"NEUTRAL"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"#B0C4DE"</span>,</span>
<span id="cb20-18">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"NEGATIVE"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"#F08080"</span>,</span>
<span id="cb20-19">}</span>
<span id="cb20-20"></span>
<span id="cb20-21">fig <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> px.histogram(</span>
<span id="cb20-22">    data_frame<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>topic_sentiment,</span>
<span id="cb20-23">    x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"topics"</span>,</span>
<span id="cb20-24">    color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"sentiment"</span>,</span>
<span id="cb20-25">    barmode<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"group"</span>,</span>
<span id="cb20-26">    labels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>{<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"topics"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Topic"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"sentiment"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Sentiment"</span>},</span>
<span id="cb20-27">    color_discrete_map<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>sentiment_colors,</span>
<span id="cb20-28">)</span>
<span id="cb20-29"></span>
<span id="cb20-30">fig.update_yaxes(title_text<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Mentions"</span>)</span>
<span id="cb20-31">fig.update_layout(title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Topic and sentiment distribution"</span>)</span>
<span id="cb20-32">fig.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>                            <div id="13087234-cdd9-4df1-a880-1e66c715ef47" class="plotly-graph-div" style="height:525px; width:100%;"></div>            <script type="text/javascript">                require(["plotly"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById("13087234-cdd9-4df1-a880-1e66c715ef47")) {                    Plotly.newPlot(                        "13087234-cdd9-4df1-a880-1e66c715ef47",                        [{"alignmentgroup":"True","bingroup":"x","hovertemplate":"Sentiment=POSITIVE\u003cbr\u003eTopic=%{x}\u003cbr\u003ecount=%{y}\u003cextra\u003e\u003c\u002fextra\u003e","legendgroup":"POSITIVE","marker":{"color":"#98FB98","pattern":{"shape":""}},"name":"POSITIVE","offsetgroup":"POSITIVE","orientation":"v","showlegend":true,"x":["BUSINESS","TECHNOLOGY","POLITICS","ENTERTAINMENT","ARTS","ENTERTAINMENT","BUSINESS","TECHNOLOGY","BUSINESS","POLITICS","BUSINESS","ENTERTAINMENT","BUSINESS","BUSINESS","TECHNOLOGY","BUSINESS","ENTERTAINMENT","BUSINESS","HEALTH","BUSINESS","TECHNOLOGY","ENTERTAINMENT","BUSINESS","HEALTH","ENTERTAINMENT","BUSINESS","ENTERTAINMENT","TECHNOLOGY","SPORTS","ENTERTAINMENT","BUSINESS","BUSINESS","ENTERTAINMENT","ENTERTAINMENT","SPORTS","SPORTS","ENTERTAINMENT","SPORTS","SPORTS","TECHNOLOGY","BUSINESS","BUSINESS","ENTERTAINMENT","BUSINESS","TECHNOLOGY","ENTERTAINMENT","ENTERTAINMENT",null,"SCIENCE","ARTS","ENTERTAINMENT","ARTS","BUSINESS","BUSINESS","ENTERTAINMENT","HEALTH","POLITICS","SCIENCE","SPORTS","TECHNOLOGY","SPORTS","TECHNOLOGY","ENTERTAINMENT","HEALTH","SPORTS","SPORTS","SPORTS","BUSINESS","TECHNOLOGY","SPORTS","SPORTS","SPORTS","BUSINESS","TECHNOLOGY","ENTERTAINMENT","ENTERTAINMENT","BUSINESS","POLITICS",null,"SPORTS","POLITICS",null,"POLITICS","SCIENCE","SPORTS","SPORTS","BUSINESS","ARTS","ENTERTAINMENT","SPORTS","ENTERTAINMENT","ARTS","SPORTS","ENTERTAINMENT","BUSINESS","ENTERTAINMENT","ENTERTAINMENT","SPORTS","SPORTS","BUSINESS",null,"BUSINESS","TECHNOLOGY","ARTS","SPORTS","HEALTH",null,"TECHNOLOGY","SPORTS",null,"ENTERTAINMENT","ENTERTAINMENT","ENTERTAINMENT","SPORTS","POLITICS","ARTS","SPORTS","ENTERTAINMENT","SPORTS","ENTERTAINMENT","ENTERTAINMENT","BUSINESS","ENTERTAINMENT","SPORTS","HEALTH","SCIENCE","ARTS","ENTERTAINMENT","BUSINESS","BUSINESS","ENTERTAINMENT","ENTERTAINMENT","BUSINESS","ENTERTAINMENT","ENTERTAINMENT"],"xaxis":"x","yaxis":"y","type":"histogram"},{"alignmentgroup":"True","bingroup":"x","hovertemplate":"Sentiment=NEUTRAL\u003cbr\u003eTopic=%{x}\u003cbr\u003ecount=%{y}\u003cextra\u003e\u003c\u002fextra\u003e","legendgroup":"NEUTRAL","marker":{"color":"#B0C4DE","pattern":{"shape":""}},"name":"NEUTRAL","offsetgroup":"NEUTRAL","orientation":"v","showlegend":true,"x":["BUSINESS","SPORTS","BUSINESS","POLITICS","POLITICS","ENTERTAINMENT","SPORTS","BUSINESS","HEALTH","SCIENCE","POLITICS","POLITICS","ENTERTAINMENT","POLITICS","HEALTH","POLITICS","ENTERTAINMENT","BUSINESS","POLITICS","SPORTS","ARTS","TECHNOLOGY","POLITICS","SPORTS","ENTERTAINMENT","TECHNOLOGY","ENTERTAINMENT","BUSINESS","TECHNOLOGY",null,"POLITICS","BUSINESS","ENTERTAINMENT","TECHNOLOGY","ENTERTAINMENT","POLITICS","TECHNOLOGY","BUSINESS","TECHNOLOGY","SPORTS","TECHNOLOGY","ENTERTAINMENT","TECHNOLOGY","TECHNOLOGY","SPORTS","POLITICS","BUSINESS","TECHNOLOGY","POLITICS","SPORTS",null,null,"BUSINESS","SPORTS","HEALTH",null,"BUSINESS","TECHNOLOGY","ENTERTAINMENT","TECHNOLOGY","BUSINESS","POLITICS","ENTERTAINMENT","SPORTS","POLITICS","SPORTS","BUSINESS","SPORTS","POLITICS","HEALTH","POLITICS",null,"POLITICS","ARTS","BUSINESS","BUSINESS","TECHNOLOGY","SCIENCE","TECHNOLOGY","HEALTH","POLITICS","SPORTS","BUSINESS","TECHNOLOGY","POLITICS","BUSINESS","ENTERTAINMENT","ENTERTAINMENT","POLITICS","ENTERTAINMENT","SPORTS","ENTERTAINMENT","BUSINESS","ENTERTAINMENT","TECHNOLOGY","BUSINESS","TECHNOLOGY","ENTERTAINMENT","ENTERTAINMENT","BUSINESS","POLITICS","SCIENCE","ENTERTAINMENT","SPORTS","HEALTH","POLITICS","BUSINESS","TECHNOLOGY","ENTERTAINMENT","POLITICS","SPORTS","BUSINESS","BUSINESS","HEALTH","SPORTS","BUSINESS","SPORTS","POLITICS","HEALTH","BUSINESS","TECHNOLOGY","BUSINESS","TECHNOLOGY","POLITICS","SPORTS","POLITICS","TECHNOLOGY","SPORTS","ENTERTAINMENT","BUSINESS","TECHNOLOGY","HEALTH","SCIENCE","BUSINESS","HEALTH",null,"TECHNOLOGY","SPORTS","POLITICS","TECHNOLOGY",null,"BUSINESS","HEALTH","SPORTS","BUSINESS","ARTS","POLITICS","POLITICS","ARTS","ENTERTAINMENT","BUSINESS","SPORTS","HEALTH","TECHNOLOGY","POLITICS","BUSINESS","HEALTH","BUSINESS","BUSINESS","TECHNOLOGY","SPORTS","BUSINESS","POLITICS","BUSINESS","SPORTS","HEALTH","HEALTH","ARTS","ENTERTAINMENT","TECHNOLOGY","TECHNOLOGY","ENTERTAINMENT","SPORTS","BUSINESS","BUSINESS","TECHNOLOGY","BUSINESS","POLITICS","BUSINESS","TECHNOLOGY","BUSINESS","BUSINESS","ENTERTAINMENT","SPORTS","BUSINESS",null,"ENTERTAINMENT","BUSINESS","TECHNOLOGY","ENTERTAINMENT","BUSINESS","SPORTS","BUSINESS","ENTERTAINMENT","BUSINESS","BUSINESS","POLITICS","ARTS",null,"POLITICS","BUSINESS","POLITICS","BUSINESS","BUSINESS","POLITICS",null,"ARTS","BUSINESS","TECHNOLOGY","BUSINESS",null,"BUSINESS","TECHNOLOGY","BUSINESS","TECHNOLOGY","ENTERTAINMENT","SPORTS","SPORTS","TECHNOLOGY","SPORTS","BUSINESS","HEALTH","BUSINESS","TECHNOLOGY",null,null,"SPORTS","BUSINESS","TECHNOLOGY","BUSINESS","TECHNOLOGY","ENTERTAINMENT","BUSINESS","POLITICS","BUSINESS","POLITICS","POLITICS","BUSINESS","BUSINESS","SPORTS","TECHNOLOGY","BUSINESS","POLITICS","SPORTS","BUSINESS","POLITICS","ENTERTAINMENT","POLITICS","POLITICS","HEALTH","BUSINESS","ENTERTAINMENT","TECHNOLOGY","ENTERTAINMENT","HEALTH","TECHNOLOGY","SPORTS","SPORTS","ARTS","BUSINESS","BUSINESS","POLITICS","BUSINESS","SPORTS","SPORTS",null,"SPORTS","BUSINESS","SPORTS","SPORTS",null,"BUSINESS","TECHNOLOGY","SCIENCE","BUSINESS","POLITICS","TECHNOLOGY","BUSINESS","ENTERTAINMENT","BUSINESS","SPORTS","BUSINESS","TECHNOLOGY","BUSINESS","BUSINESS","ARTS","BUSINESS","POLITICS","SPORTS","BUSINESS","BUSINESS","POLITICS","HEALTH","TECHNOLOGY","ENTERTAINMENT","BUSINESS","SPORTS","BUSINESS","POLITICS","SPORTS","SPORTS","HEALTH","POLITICS","ENTERTAINMENT","SPORTS","BUSINESS","POLITICS","BUSINESS","ENTERTAINMENT","BUSINESS","SPORTS","ARTS","SPORTS"],"xaxis":"x","yaxis":"y","type":"histogram"},{"alignmentgroup":"True","bingroup":"x","hovertemplate":"Sentiment=NEGATIVE\u003cbr\u003eTopic=%{x}\u003cbr\u003ecount=%{y}\u003cextra\u003e\u003c\u002fextra\u003e","legendgroup":"NEGATIVE","marker":{"color":"#F08080","pattern":{"shape":""}},"name":"NEGATIVE","offsetgroup":"NEGATIVE","orientation":"v","showlegend":true,"x":["POLITICS","TECHNOLOGY","POLITICS","TECHNOLOGY","POLITICS","ENTERTAINMENT","BUSINESS","POLITICS","ENTERTAINMENT","SPORTS","POLITICS","TECHNOLOGY","SPORTS","BUSINESS","SPORTS",null,"BUSINESS",null,null,"BUSINESS","POLITICS","SPORTS","ARTS","POLITICS","ARTS","BUSINESS","ENTERTAINMENT","BUSINESS","BUSINESS","POLITICS","TECHNOLOGY","BUSINESS","POLITICS","BUSINESS",null,null,"POLITICS",null,"BUSINESS","SPORTS","TECHNOLOGY","SPORTS","POLITICS","HEALTH",null,"POLITICS","BUSINESS",null,"BUSINESS","ENTERTAINMENT","BUSINESS","ENTERTAINMENT","POLITICS","BUSINESS","BUSINESS","POLITICS",null,"POLITICS",null,null,"POLITICS","POLITICS",null,"BUSINESS","POLITICS","SPORTS","POLITICS","BUSINESS","BUSINESS","POLITICS","POLITICS","BUSINESS","POLITICS","HEALTH","SCIENCE","POLITICS",null,"POLITICS",null,"BUSINESS","POLITICS",null,"SPORTS","ARTS","POLITICS","BUSINESS","POLITICS","POLITICS","ENTERTAINMENT","POLITICS","POLITICS","SPORTS","BUSINESS","ENTERTAINMENT","SPORTS",null,null,"ENTERTAINMENT","POLITICS","POLITICS","BUSINESS","BUSINESS","SPORTS",null,"BUSINESS","BUSINESS","POLITICS","POLITICS",null,"BUSINESS","POLITICS","BUSINESS","POLITICS","SPORTS","POLITICS","HEALTH","SPORTS","ENTERTAINMENT","POLITICS","SPORTS","BUSINESS","BUSINESS","ENTERTAINMENT",null,"BUSINESS","BUSINESS","POLITICS","SPORTS","POLITICS","BUSINESS",null,null,"BUSINESS","POLITICS",null,null,null,"BUSINESS","BUSINESS","BUSINESS","BUSINESS",null,"TECHNOLOGY","TECHNOLOGY","BUSINESS","POLITICS","POLITICS","HEALTH","POLITICS","POLITICS","POLITICS","POLITICS","POLITICS","BUSINESS","POLITICS","BUSINESS","ENTERTAINMENT","POLITICS",null,null,"POLITICS","BUSINESS","POLITICS",null],"xaxis":"x","yaxis":"y","type":"histogram"}],                        {"template":{"data":{"histogram2dcontour":[{"type":"histogram2dcontour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"choropleth":[{"type":"choropleth","colorbar":{"outlinewidth":0,"ticks":""}}],"histogram2d":[{"type":"histogram2d","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmap":[{"type":"heatmap","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmapgl":[{"type":"heatmapgl","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"contourcarpet":[{"type":"contourcarpet","colorbar":{"outlinewidth":0,"ticks":""}}],"contour":[{"type":"contour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"surface":[{"type":"surface","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"mesh3d":[{"type":"mesh3d","colorbar":{"outlinewidth":0,"ticks":""}}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"parcoords":[{"type":"parcoords","line":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolargl":[{"type":"scatterpolargl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"scattergeo":[{"type":"scattergeo","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolar":[{"type":"scatterpolar","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"scattergl":[{"type":"scattergl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatter3d":[{"type":"scatter3d","line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermapbox":[{"type":"scattermapbox","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterternary":[{"type":"scatterternary","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattercarpet":[{"type":"scattercarpet","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"pie":[{"automargin":true,"type":"pie"}]},"layout":{"autotypenumbers":"strict","colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"hovermode":"closest","hoverlabel":{"align":"left"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"bgcolor":"#E5ECF6","angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"ternary":{"bgcolor":"#E5ECF6","aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]]},"xaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"yaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"geo":{"bgcolor":"white","landcolor":"#E5ECF6","subunitcolor":"white","showland":true,"showlakes":true,"lakecolor":"white"},"title":{"x":0.05},"mapbox":{"style":"light"}}},"xaxis":{"anchor":"y","domain":[0.0,1.0],"title":{"text":"Topic"}},"yaxis":{"anchor":"x","domain":[0.0,1.0],"title":{"text":"Mentions"}},"legend":{"title":{"text":"Sentiment"},"tracegroupgap":0},"margin":{"t":60},"barmode":"group","title":{"text":"Topic and sentiment distribution"}},                        {"responsive": true}                    ).then(function(){
                            
var gd = document.getElementById('13087234-cdd9-4df1-a880-1e66c715ef47');
var x = new MutationObserver(function (mutations, observer) {{
        var display = window.getComputedStyle(gd).display;
        if (!display || display === 'none') {{
            console.log([gd, 'removed!']);
            Plotly.purge(gd);
            observer.disconnect();
        }}
}});

// Listen for the removal of the full notebook cells
var notebookContainer = gd.closest('#notebook-container');
if (notebookContainer) {{
    x.observe(notebookContainer, {childList: true});
}}

// Listen for the clearing of the current output cell
var outputEl = gd.closest('.output');
if (outputEl) {{
    x.observe(outputEl, {childList: true});
}}

                        })                };                });            </script>        </div>
</div>
</div>
<p>We see that business, technology and politics are the most common topics. Politics topics are most commonly negative, while entertainment topics are most commonly positive.</p>
<div class="cell" data-fig-height="500px" data-execution_count="14">
<div class="sourceCode cell-code" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1">named_entities <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (</span>
<span id="cb21-2">    answers.explode(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"named_entities"</span>)</span>
<span id="cb21-3">    .unnest(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"named_entities"</span>)</span>
<span id="cb21-4">    .group_by(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"text"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"label"</span>)</span>
<span id="cb21-5">    .agg(pl.count(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"label"</span>).alias(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"count"</span>))</span>
<span id="cb21-6">    .sort(by<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"count"</span>)</span>
<span id="cb21-7">    .drop_nulls()</span>
<span id="cb21-8">)</span>
<span id="cb21-9"></span>
<span id="cb21-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Top 5 named entities by label</span></span>
<span id="cb21-11">top_named_entities <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pl.concat(</span>
<span id="cb21-12">    [x.top_k(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, by<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"count"</span>) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> x <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> named_entities.partition_by(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"label"</span>)]</span>
<span id="cb21-13">)</span>
<span id="cb21-14"></span>
<span id="cb21-15">fig <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> px.bar(</span>
<span id="cb21-16">    data_frame<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>top_named_entities,</span>
<span id="cb21-17">    facet_row<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"label"</span>,</span>
<span id="cb21-18">    color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"label"</span>,</span>
<span id="cb21-19">    x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"count"</span>,</span>
<span id="cb21-20">    y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"text"</span>,</span>
<span id="cb21-21">    orientation<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"h"</span>,</span>
<span id="cb21-22">    labels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>{<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"count"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Mentions"</span>},</span>
<span id="cb21-23">)</span>
<span id="cb21-24"></span>
<span id="cb21-25">fig.update_yaxes(matches<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, title_text<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span>, autorange<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"reversed"</span>)</span>
<span id="cb21-26">fig.for_each_annotation(<span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">lambda</span> a: a.update(text<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>a.text.split(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"="</span>)[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]))</span>
<span id="cb21-27">fig.update_layout(showlegend<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>, title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Most frequent named entities by label"</span>)</span>
<span id="cb21-28"></span>
<span id="cb21-29">fig.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>                            <div id="13d9ae16-4c69-4697-b579-21950d0b2bd1" class="plotly-graph-div" style="height:525px; width:100%;"></div>            <script type="text/javascript">                require(["plotly"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById("13d9ae16-4c69-4697-b579-21950d0b2bd1")) {                    Plotly.newPlot(                        "13d9ae16-4c69-4697-b579-21950d0b2bd1",                        [{"alignmentgroup":"True","hovertemplate":"label=PERSON\u003cbr\u003eMentions=%{x}\u003cbr\u003etext=%{y}\u003cextra\u003e\u003c\u002fextra\u003e","legendgroup":"PERSON","marker":{"color":"#636efa","pattern":{"shape":""}},"name":"PERSON","offsetgroup":"PERSON","orientation":"h","showlegend":true,"textposition":"auto","x":[25,5,5,4,3],"xaxis":"x5","y":["Donald Trump","Barack Obama","Trump","Xi Jinping","Prince Harry"],"yaxis":"y5","type":"bar"},{"alignmentgroup":"True","hovertemplate":"label=LOCATION\u003cbr\u003eMentions=%{x}\u003cbr\u003etext=%{y}\u003cextra\u003e\u003c\u002fextra\u003e","legendgroup":"LOCATION","marker":{"color":"#EF553B","pattern":{"shape":""}},"name":"LOCATION","offsetgroup":"LOCATION","orientation":"h","showlegend":true,"textposition":"auto","x":[20,11,11,10,9],"xaxis":"x4","y":["China","New York","United States","Las Vegas","Australia"],"yaxis":"y4","type":"bar"},{"alignmentgroup":"True","hovertemplate":"label=ORG\u003cbr\u003eMentions=%{x}\u003cbr\u003etext=%{y}\u003cextra\u003e\u003c\u002fextra\u003e","legendgroup":"ORG","marker":{"color":"#00cc96","pattern":{"shape":""}},"name":"ORG","offsetgroup":"ORG","orientation":"h","showlegend":true,"textposition":"auto","x":[9,6,5,5,5],"xaxis":"x3","y":["Dodgers","Supreme Court","DRDO","FBI","BJP"],"yaxis":"y3","type":"bar"},{"alignmentgroup":"True","hovertemplate":"label=PRODUCT\u003cbr\u003eMentions=%{x}\u003cbr\u003etext=%{y}\u003cextra\u003e\u003c\u002fextra\u003e","legendgroup":"PRODUCT","marker":{"color":"#ab63fa","pattern":{"shape":""}},"name":"PRODUCT","offsetgroup":"PRODUCT","orientation":"h","showlegend":true,"textposition":"auto","x":[4,4,4,3,3],"xaxis":"x2","y":["The Flash","Instagram","Twitter","Riverdale","Android"],"yaxis":"y2","type":"bar"},{"alignmentgroup":"True","hovertemplate":"label=EVENT\u003cbr\u003eMentions=%{x}\u003cbr\u003etext=%{y}\u003cextra\u003e\u003c\u002fextra\u003e","legendgroup":"EVENT","marker":{"color":"#FFA15A","pattern":{"shape":""}},"name":"EVENT","offsetgroup":"EVENT","orientation":"h","showlegend":true,"textposition":"auto","x":[4,3,3,3,2],"xaxis":"x","y":["Friday","World Cup","Premiership","Championship","constituency projects"],"yaxis":"y","type":"bar"}],                        {"template":{"data":{"histogram2dcontour":[{"type":"histogram2dcontour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"choropleth":[{"type":"choropleth","colorbar":{"outlinewidth":0,"ticks":""}}],"histogram2d":[{"type":"histogram2d","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmap":[{"type":"heatmap","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmapgl":[{"type":"heatmapgl","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"contourcarpet":[{"type":"contourcarpet","colorbar":{"outlinewidth":0,"ticks":""}}],"contour":[{"type":"contour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"surface":[{"type":"surface","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"mesh3d":[{"type":"mesh3d","colorbar":{"outlinewidth":0,"ticks":""}}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"parcoords":[{"type":"parcoords","line":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolargl":[{"type":"scatterpolargl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"scattergeo":[{"type":"scattergeo","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolar":[{"type":"scatterpolar","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"scattergl":[{"type":"scattergl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatter3d":[{"type":"scatter3d","line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermapbox":[{"type":"scattermapbox","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterternary":[{"type":"scatterternary","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattercarpet":[{"type":"scattercarpet","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"pie":[{"automargin":true,"type":"pie"}]},"layout":{"autotypenumbers":"strict","colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"hovermode":"closest","hoverlabel":{"align":"left"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"bgcolor":"#E5ECF6","angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"ternary":{"bgcolor":"#E5ECF6","aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]]},"xaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"yaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"geo":{"bgcolor":"white","landcolor":"#E5ECF6","subunitcolor":"white","showland":true,"showlakes":true,"lakecolor":"white"},"title":{"x":0.05},"mapbox":{"style":"light"}}},"xaxis":{"anchor":"y","domain":[0.0,0.98],"title":{"text":"Mentions"}},"yaxis":{"anchor":"x","domain":[0.0,0.17600000000000002],"title":{"text":""},"autorange":"reversed"},"xaxis2":{"anchor":"y2","domain":[0.0,0.98],"matches":"x","showticklabels":false},"yaxis2":{"anchor":"x2","domain":[0.20600000000000002,0.382],"title":{"text":""},"autorange":"reversed"},"xaxis3":{"anchor":"y3","domain":[0.0,0.98],"matches":"x","showticklabels":false},"yaxis3":{"anchor":"x3","domain":[0.41200000000000003,0.5880000000000001],"title":{"text":""},"autorange":"reversed"},"xaxis4":{"anchor":"y4","domain":[0.0,0.98],"matches":"x","showticklabels":false},"yaxis4":{"anchor":"x4","domain":[0.618,0.794],"title":{"text":""},"autorange":"reversed"},"xaxis5":{"anchor":"y5","domain":[0.0,0.98],"matches":"x","showticklabels":false},"yaxis5":{"anchor":"x5","domain":[0.8240000000000001,1.0],"title":{"text":""},"autorange":"reversed"},"annotations":[{"font":{},"showarrow":false,"text":"EVENT","textangle":90,"x":0.98,"xanchor":"left","xref":"paper","y":0.08800000000000001,"yanchor":"middle","yref":"paper"},{"font":{},"showarrow":false,"text":"PRODUCT","textangle":90,"x":0.98,"xanchor":"left","xref":"paper","y":0.29400000000000004,"yanchor":"middle","yref":"paper"},{"font":{},"showarrow":false,"text":"ORG","textangle":90,"x":0.98,"xanchor":"left","xref":"paper","y":0.5,"yanchor":"middle","yref":"paper"},{"font":{},"showarrow":false,"text":"LOCATION","textangle":90,"x":0.98,"xanchor":"left","xref":"paper","y":0.706,"yanchor":"middle","yref":"paper"},{"font":{},"showarrow":false,"text":"PERSON","textangle":90,"x":0.98,"xanchor":"left","xref":"paper","y":0.912,"yanchor":"middle","yref":"paper"}],"legend":{"title":{"text":"label"},"tracegroupgap":0},"margin":{"t":60},"barmode":"relative","showlegend":false,"title":{"text":"Most frequent named entities by label"}},                        {"responsive": true}                    ).then(function(){
                            
var gd = document.getElementById('13d9ae16-4c69-4697-b579-21950d0b2bd1');
var x = new MutationObserver(function (mutations, observer) {{
        var display = window.getComputedStyle(gd).display;
        if (!display || display === 'none') {{
            console.log([gd, 'removed!']);
            Plotly.purge(gd);
            observer.disconnect();
        }}
}});

// Listen for the removal of the full notebook cells
var notebookContainer = gd.closest('#notebook-container');
if (notebookContainer) {{
    x.observe(notebookContainer, {childList: true});
}}

// Listen for the clearing of the current output cell
var outputEl = gd.closest('.output');
if (outputEl) {{
    x.observe(outputEl, {childList: true});
}}

                        })                };                });            </script>        </div>
</div>
</div>
<p>The most common people are American politicians. Products are dominated by tech products. Events are dominated by Sports events. China stands out as the most commonly mentioned location.</p>
<div class="callout callout-style-default callout-caution callout-titled" title="Unvalidated model">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Unvalidated model
</div>
</div>
<div class="callout-body-container callout-body">
<p>All of this is based on zero shot classification and zero shot named entity recognition. We don’t have a validation set, so we don’t know how accurate the model is. For production use, this would need to be tested.</p>
</div>
</div>
</section>
</section>
<section id="discussion" class="level2">
<h2 class="anchored" data-anchor-id="discussion">Discussion</h2>
<p>The one-stop approach is diametrically opposed to Matthew Honnibal’s article <a href="https://explosion.ai/blog/against-llm-maximalism">“Against LLM Maximalism”</a>.</p>
<blockquote class="blockquote">
<p>They [LLMs] are extremely useful, but if you want to deliver reliable software you can improve over time, you can’t just write a prompt and call it a day</p>
</blockquote>
<p>The alternate pipeline with a modular approach of specialized models could look like this:</p>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">graph LR
    A([Text]) --&gt; B[Tokenization]
    B --&gt; C[Sentence splitting]
    C --&gt; D[Topic classification]
    D --&gt; E[Sentiment classification]
    E --&gt; F[NER]
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<p>The tokenization and sentence splitting don’t require trainable models.</p>
<p>Explosion AI’s <a href="https://spacy.io">spaCy</a> package is excellent for constructing such pipelines. With the extension <a href="https://github.com/explosion/spacy-llm">spacy-llm</a>, it can also feature LLMs in the pipeline and <a href="https://prodi.gy">Prodigy</a> integrates them into the annotation workflow.</p>
<section id="advantages-of-multi-task-prompts-compared-to-pipelines" class="level3">
<h3 class="anchored" data-anchor-id="advantages-of-multi-task-prompts-compared-to-pipelines">Advantages of multi-task prompts compared to pipelines</h3>
<ul>
<li><strong>Simplicity</strong>: No training required and only one model to deploy or call by API. That means less code, infrastructure, and documentation to maintain. It also requires less knowledge about various model architectures. The is article showed that it’s possible to build a multi-task prompt pipeline with just a few lines of code. Note that spaCy also allows training a regular model to perform multiple tasks.</li>
<li><strong>Easy upgrading</strong>: If the LLM gets better, all tasks benefit from it. No need to retrain specialized models. When OpenAI releases GPT-5, one could switch to it with a single line of code.</li>
<li><strong>Easy extension</strong>: If we want to add a new label, we just add it to the schema and we’re done. Same with adding a new task, e.g.&nbsp;summarization.</li>
<li><strong>Cheaper than chained LLM calls</strong>: If we were to call an LLM separately for each step, we’d have to send over the text multiple times. That’s more expensive than sending it once and getting all the analysis in one go. But it may still be more expensive than a chain of specialized models.</li>
</ul>
</section>
<section id="disadvantages-of-multi-task-prompts-compared-to-pipelines" class="level3">
<h3 class="anchored" data-anchor-id="disadvantages-of-multi-task-prompts-compared-to-pipelines">Disadvantages of multi-task prompts compared to pipelines</h3>
<ul>
<li><strong>Tempts to skip validation</strong>: Wouldn’t it be nice to just trust that the LLM gets it right? Unfortunately, we can’t. LLMs still suffer from hallucinations, biases, and other problems.</li>
<li><strong>Lack of modularity</strong>: Can’t reuse one task in another pipeline and can’t use specialized models that others have trained.</li>
<li><strong>New error types</strong>: JSON parsing errors, use of labels that are not in the schema.</li>
<li><strong>Monolithic model</strong>: If you wish to fine-tune the LLM, it must be trained on all tasks at once. Training data must be available for all tasks. If you want to add a new task, you have to retrain the whole model.</li>
<li><strong>High inference cost</strong>: Compared to efficient models like DistilBERT that comfortably run on a single GPU from a few years ago, LLMs are very expensive to run, requiring a cluster of the latest GPUs.</li>
<li><strong>High latency</strong>: LLMs have to do a lot more matrix multiplication than smaller models. That means they take longer to respond, which is a problem for interactive applications.</li>
</ul>
<p>To conclude, I see unvalidated multi-task prompts as a tool for low-stakes exploratory work. If proper validation is added they can be viable in batch processing scenarios where simplicity is valued over modularity and computational efficiency.</p>


</section>
</section>

 ]]></description>
  <category>Machine Learning</category>
  <category>Python</category>
  <guid>https://simmering.dev/blog/one-stop-nlp/</guid>
  <pubDate>Sat, 28 Oct 2023 22:00:00 GMT</pubDate>
  <media:content url="https://simmering.dev/blog/one-stop-nlp/knife.webp" medium="image" type="image/webp"/>
</item>
</channel>
</rss>
