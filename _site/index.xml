<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Paul Simmering&#39;s Blog</title>
<link>https://simmering.dev/</link>
<atom:link href="https://simmering.dev/index.xml" rel="self" type="application/rss+xml"/>
<description>Data science, machine learning and developer productivity.</description>
<language>en</language>
<generator>quarto-1.6.33</generator>
<lastBuildDate>Wed, 01 Jan 2025 23:00:00 GMT</lastBuildDate>
<item>
  <title>ModernBERT vs LLMs for text classification</title>
  <dc:creator>Paul Simmering</dc:creator>
  <link>https://simmering.dev/blog/modernbert-vs-llm/</link>
  <description><![CDATA[ 





<p>HuggingFace recently released ModernBERT (<a href="https://huggingface.co/answerdotai/ModernBERT-base">model</a>, <a href="https://arxiv.org/abs/2412.13663">paper</a>), an updated version of the BERT language model which backports many improvements from LLM research back to the classic 2018 model. In contrast to LLMs, ModernBERT is an encoder-only model that is fitted with a task-specific head outputting probabilities for structured NLP tasks, rather than tokens.</p>
<p>While LLMs with their decoder-only architecture were originally designed for text generation, they have also been used for structured NLP tasks like text classification. They are imbued with a large amount of general knowledge and excel at zero-shot and few-shot learning. Through the proliferation of the LLM ecosystem they are also widely available via APIs and familiar to many developers.</p>
<p>Here, I will compare ModernBERT to an LLM on a text classification task using the dimensions accuracy, speed, cost and ease of use. Text classification is a simple task, yet very common and important in NLP pipelines. It may also be coupled with text generation in a chat bot, such as for intent classification or as a guardrail to prevent undesirable responses.</p>
<section id="task-adverse-event-classification" class="level2">
<h2 class="anchored" data-anchor-id="task-adverse-event-classification">Task: Adverse event classification</h2>
<p>During my work in market research for pharmaceutical companies, I frequently have to monitor data for <strong>adverse events</strong>. An adverse event is any undesirable medical event that occurs during or after treatment with a drug. Examples include side effects, lack of efficacy, and overdoses. It is of utmost importance to identify adverse events and report them to the producing pharmaceutical company. This task is labor intensive, so naturally I‚Äôm interested in automating it. I‚Äôll use the ADE-Benchmark Corpus as an example dataset. It contains 23,500 English medical text sentences describing effects of drugs. Each sentence is classified as 1: adverse drug reaction or 0: no adverse drug reaction. This represents a subtask of the broader task of adverse event monitoring.</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Resource</th>
<th>Link</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>üíª Python code</td>
<td><a href="https://github.com/psimm/website/blob/master/blog/modernbert-vs-llm/experiment.py">GitHub</a></td>
</tr>
<tr class="even">
<td>üìä Experiment results</td>
<td><a href="https://wandb.ai/psimm/modernbert-vs-llm">Weights &amp; Biases project</a></td>
</tr>
<tr class="odd">
<td>üìù Dataset: ADE-Benchmark Corpus</td>
<td><a href="https://huggingface.co/datasets/ade-benchmark-corpus/ade_corpus_v2">Hugging Face Hub</a></td>
</tr>
</tbody>
</table>
<p>All training and inference is done on a single A10G GPU hosted on <a href="https://modal.com">Modal</a>. A Modal account is required to run the code. The free tier is sufficient for this experiment.</p>
</section>
<section id="experiment-setup" class="level2">
<h2 class="anchored" data-anchor-id="experiment-setup">Experiment setup</h2>
<p>The diagram below illustrates three experiment setups: fine-tuning ModernBERT, few-shot learning with Llama 3.2-3B, and fine-tuning Llama 3.2-3B.</p>
<p><img src="https://simmering.dev/blog/modernbert-vs-llm/experiment.svg" class="img-fluid"></p>
<section id="dataset-preparation" class="level3">
<h3 class="anchored" data-anchor-id="dataset-preparation">Dataset preparation</h3>
<p>The dataset on HuggingFace consists of 23,516 sentences. After removing duplicate sentences, 20,896 unique examles are left. The distribution of classes is uneven, with more examples of texts without an adverse events. To balance the classes, I‚Äôm subsampling the negative examples down to 4,271 cases. Balanced classes prevent the models from overfitting to the majority class and let us compare the models using a simple accuracy metric.</p>
<p>Then, the dataset is split into 60% training, 20% validation and 20% test sets. The validation set is used to tune hyperparameters and implement early stopping. Splits are stratified by class to ensure a 50:50 split between positive and negative examples in each split. The final example count is:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Split</th>
<th>Class</th>
<th>Examples</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Training</td>
<td>Adverse Event</td>
<td>2,562</td>
</tr>
<tr class="even">
<td>Training</td>
<td>No Adverse Event</td>
<td>2,562</td>
</tr>
<tr class="odd">
<td>Validation</td>
<td>Adverse Event</td>
<td>855</td>
</tr>
<tr class="even">
<td>Validation</td>
<td>No Adverse Event</td>
<td>855</td>
</tr>
<tr class="odd">
<td>Test</td>
<td>Adverse Event</td>
<td>854</td>
</tr>
<tr class="even">
<td>Test</td>
<td>No Adverse Event</td>
<td>854</td>
</tr>
</tbody>
</table>
</section>
<section id="model-selection" class="level3">
<h3 class="anchored" data-anchor-id="model-selection">Model selection</h3>
<p>I‚Äôm comparing ModernBERT-base as the structured language model and Llama 3.2-3B-instruct as the LLM. There are bigger versions of both, ModernBERT-large and Llama 3.3-70B-instruct, which I expect to perform better. The benefit of smaller models is that they run faster and cheaper.</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Model</th>
<th>Architecture</th>
<th>Parameters</th>
<th>Size at FP32</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><a href="https://huggingface.co/answerdotai/ModernBERT-base">ModernBERT-base</a></td>
<td>Encoder-only: outputs a probability distribution over classes</td>
<td>149M</td>
<td>~0.6GB</td>
</tr>
<tr class="even">
<td><a href="https://huggingface.co/meta-llama/Llama-3.2-3B">Llama 3.2-3B</a></td>
<td>Decoder-only: outputs text</td>
<td>3B</td>
<td>~12GB</td>
</tr>
</tbody>
</table>
<p>For inference, about 1.5 to 2x the model size is required to store the attention cache, calculate layer activations and other intermediate results. The A10G GPU used for this experiment has 24GB memory, so both models fit. The memory footprint can be reduced by half by using FP16 or INT8 precision, which is common for inference.</p>
</section>
<section id="setup-1-fine-tuning-modernbert" class="level3">
<h3 class="anchored" data-anchor-id="setup-1-fine-tuning-modernbert">Setup 1: Fine-tuning ModernBERT</h3>
<p>I‚Äôm using the transformers library to fine-tune ModernBERT on the training set. Philip Schmid from Hugging Face wrote a helpful <a href="https://www.philschmid.de/fine-tune-modern-bert-in-2025">guide</a> which I adapted for use on Modal. Optimized the model on binary cross-entropy loss for 5 epochs.</p>
</section>
<section id="setup-2-few-shot-learning-with-llama-3.2-3b-and-dspy" class="level3">
<h3 class="anchored" data-anchor-id="setup-2-few-shot-learning-with-llama-3.2-3b-and-dspy">Setup 2: Few-shot learning with Llama 3.2-3B and DSPy</h3>
<p>I‚Äôm using <a href="https://dspy.ai">DSPy</a> to automatically select an optimal set of examples for few-shot learning. That‚Äôs a more objective approach than manual prompting and usually results in equally good or better accuracy. In my first trials, DSPy didn‚Äôt manage to write a suitable system prompt as it didn‚Äôt understand the adverse drug reaction task from examples alone. Therefore, I added the prompt: ‚ÄúDetermine if the following sentence is about adverse drug reactions:‚Äù to the examples. This increased the accuracy by about 15 percentage points.</p>
<p>DSPy settings:</p>
<ul>
<li>20 few-shot examples plus 5 bootstrapped (AI generated) examples</li>
<li>Optimized for accuracy using MIPROv2 (minibatch size 50, minibatch full eval steps 10, num trials 3)</li>
<li>25 threads for calls to the LLM, which is hosted using FastAPI and vLLM on Modal</li>
</ul>
<p>The optimized predictor is available as a JSON file in the <a href="https://wandb.ai/psimm/modernbert-vs-llm">Weights &amp; Biases project</a>.</p>
</section>
<section id="setup-3-fine-tuning-llama-3.2-3b" class="level3">
<h3 class="anchored" data-anchor-id="setup-3-fine-tuning-llama-3.2-3b">Setup 3: Fine-tuning Llama 3.2-3B</h3>
<p>I‚Äôm using the torchtune library and a fine-tuning configuration to train a LoRA adapter on the training set. It targets the attention and feed-forward layers of the model. The adapter is a smaller set of weights that are added to the model at inference time. LoRA training incurs less training cost than full fine-tuning of all weights, but may result in worse accuracy.</p>
<p>TODO: Add fine-tuning config TODO: Make files available for fine-tuning TODO: Format as chats for fine-tuning TODO: Add test set evaluation TODO: Add logging to W&amp;B</p>
</section>
</section>
<section id="results" class="level2">
<h2 class="anchored" data-anchor-id="results">Results</h2>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Setup</th>
<th>Accuracy</th>
<th>Precision</th>
<th>Recall</th>
<th>Examples per second</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1: ModernBERT fine-tuned</td>
<td>0.98</td>
<td>0.97</td>
<td>0.99</td>
<td>100</td>
</tr>
<tr class="even">
<td>2: Llama 3.2-3B 10-shot</td>
<td>0.98</td>
<td>0.98</td>
<td>0.98</td>
<td>10</td>
</tr>
<tr class="odd">
<td>3: Llama 3.2-3B fine-tuned</td>
<td>0.98</td>
<td>0.99</td>
<td>0.97</td>
<td>1</td>
</tr>
</tbody>
</table>
<p>TODO: Update with actual results</p>
<p>I‚Äôm measuring the number of examples per second on an Nvidia A10G with 24GB memory. It‚Äôs available on Modal for $1.10/h.</p>
<p>Training cost is negligible for all setups, but can become substantial for fine-tuning larger LLMs. Training ModernBERT-large is still cheap.</p>
<p>TODO: Analyze accuracy, precision, recall TODO: Analyze examples per second TODO: Analyze ease of training TODO: Analyze ease of deployment for inference</p>
<p>Here, I set up training and inference using Modal and open source libraries. This process can be shortened by using a managed service like <a href="https://fireworks.ai">Fireworks</a>, which provides an inference and training API. With LoRA and the increasing abundance of GPU servers, fine-tuning LLMs isn‚Äôt significantly more expensive or difficult than training ModernBERT. Both require training data. If you do not have training data, the few-shot learning approach is a good alternative. It can also be used to bootstrap a training dataset, especially when combined with a full size LLM like Llama-3.1-405B or gpt-4o.</p>
</section>
<section id="discussion" class="level2">
<h2 class="anchored" data-anchor-id="discussion">Discussion</h2>
<p>TODO: Add discussion</p>
<p>Findings of this study may not generalize to general adverse event monitoring and languages other than English.</p>
<hr>
<p>Preview image based on <a href="https://unsplash.com/@magicpattern?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">MagicPattern</a> on <a href="https://unsplash.com/photos/blue-and-white-checkered-pattern-am-yg8wLLIo?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Unsplash</a></p>


</section>

 ]]></description>
  <category>Machine Learning</category>
  <guid>https://simmering.dev/blog/modernbert-vs-llm/</guid>
  <pubDate>Wed, 01 Jan 2025 23:00:00 GMT</pubDate>
  <media:content url="https://simmering.dev/blog/modernbert-vs-llm/image.webp" medium="image" type="image/webp"/>
</item>
<item>
  <title>Diagrams as Code: Supercharged by AI Assistants</title>
  <dc:creator>Paul Simmering</dc:creator>
  <link>https://simmering.dev/blog/diagrams/</link>
  <description><![CDATA[ 





<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/diagrams/diagrams_wide.webp" class="img-fluid figure-img"></p>
<figcaption>D2 code and rendered diagram of a Kafka cluster for a web shop</figcaption>
</figure>
</div>
<p>Diagrams as code are an efficient way to communicate complex ideas and document software architecture. In this post I‚Äôll explain how an AI assistant makes them even better.</p>
<section id="what-is-diagrams-as-code" class="level2">
<h2 class="anchored" data-anchor-id="what-is-diagrams-as-code">What is diagrams as code?</h2>
<p>It‚Äôs a diagram that is generated from markdown-like text. Rather than clicking and dragging, you write the text and the diagram is generated. Elements are automatically positioned and connected using a layout engine. This lets you focus on the content, rather than the look, at the expense of some flexibility. Since the diagrams are text-based, they can be version controlled with Git.</p>
<p>Here‚Äôs a quick example of a diagram as code in <a href="https://d2lang.com/">D2</a>:</p>
<pre><code>shape: sequence_diagram
User -&gt; LLM: How many R's are in the word "strawberry"?
LLM -&gt; User: The word "strawberry" contains 2 instances of the letter "r".</code></pre>
<p>This generates the following diagram:</p>
<p><img src="https://simmering.dev/blog/diagrams/data:image/svg+xml;base64,<?xml version="1.0" encoding="utf-8"?><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" d2Version="0.6.8" preserveAspectRatio="xMinYMin meet" viewBox="0 0 569 328"><svg id="d2-svg" class="d2-2754761364" width="569" height="328" viewBox="1 41 569 328"><rect x="1.000000" y="41.000000" width="569.000000" height="328.000000" rx="0.000000" fill="transparent" stroke-width="0" /><style type="text/css"><![CDATA[
.d2-2754761364 .text {
	font-family: "d2-2754761364-font-regular";
}
@font-face {
	font-family: d2-2754761364-font-regular;
	src: url("data:application/font-woff;base64,d09GRgABAAAAAA1AAAoAAAAAFEwAAguFAAAAAAAAAAAAAAAAAAAAAAAAAABPUy8yAAAA9AAAAGAAAABgXd/Vo2NtYXAAAAFUAAAApwAAAOAEJASwZ2x5ZgAAAfwAAAa9AAAI7LjiuW5oZWFkAAAIvAAAADYAAAA2G4Ue32hoZWEAAAj0AAAAJAAAACQKhAXiaG10eAAACRgAAACAAAAAgDlNBw5sb2NhAAAJmAAAAEIAAABCJkoj/m1heHAAAAncAAAAIAAAACAAOAD2bmFtZQAACfwAAAMjAAAIFAbDVU1wb3N0AAANIAAAAB0AAAAg/9EAMgADAgkBkAAFAAACigJYAAAASwKKAlgAAAFeADIBIwAAAgsFAwMEAwICBGAAAvcAAAADAAAAAAAAAABBREJPAEAAIP//Au7/BgAAA9gBESAAAZ8AAAAAAeYClAAAACAAA3ichM27KkcBAMfxz/mf437c77c6ncVm8AJWA8uJB7CIUkpKnoYkdgblOYwWk8VqMvwUm+X/nT/1RaFUoFZ5RatR6Wm0Nmzasm3Hns6BIyfOXLh0lfDP7OrsO3Ts1PmfyXu+85XPfOQtL3nOUx7zkPvc5TY3uf4996uwbs2KZat6SpUBg4YMGzFqTG3chElTps2YNWfegkVL/AAAAP//AQAA//8AHCy5AHicXFZdbBtZFT73juOJGyfONLbHk9ixZ24yEztOnHjsmSR2x0380ySNY9dOSJO02ZZ063QL1RK0VBXpVlDYrpAQRuqKBySoAKmAkKpdpO4i3gqUwC6gRYgfiQe0D9mVKiQwfkBiM0YzdtJknzzSvfrO933nO+ca2mAVAMfxfaDABg44CS4AmeGZQV6SCK3KqkpYSpUQQ6+iv+tVhOZiFkWxjM88m7l15w46/yq+v/+Zqa9UKr/auHlT//reR3oU/f4jQLAGgKO4Ch0GnoEoM4ThmbUyGl9a0v+Aq/o/Uc/+yyiuvwvQvI/ew1Voa913rZWRH1f33z4DB+f4Nq6CzzzvcbtZWVHUHgM1pqiEpgglEbfbxaxdedXO2i12l33nxcV2yhLbUXdiForGVf17QlYQsgLa2H8ZXQtfH35D/wlaemP4elj/FgBgs0YAV6ELWLNK1O12Oa10D6EIw8hRJR4TCVn7XXorUcw83PjOzRv5Uil/A1fJuczCRUb/ALn0Z2g1dXo61uTsBUAf4yrQBhqJ8y7CfPAU/eMpns/l9h8376w06ngUVw3f2wRRjDMy43S75aiimJ9WK0qnr2vlYHY4nAsWtZfsys419CX9dmFdFNcL6K5+59qOAhhijTp6E9WgFwYAWEGMxxQ1JopEsNKSoshRt4shErFapaiixq1Wl9P95NS5b3ybGR4KzfsCwubUajFDU8I5N9HIrctR+9x0cZnxT5CAc9Id/Oy6/ucpb2hG8N9zJCPBQcBQatTR//Au9EDAZC4RmjCyi27WcpqFDL8EK+1yu1FQmAtQ9EwJ84WhFz6deCGXLCSy/tMkkLLzvijefXLeJ732ufIXtGxlrbgpBBpetunPaKOOHqGa4aXpT8wswNKmNEOGHFVU1mpFJ09vJaeva2NZLuSK+MJZqZwWptwDfNGe3C6WtpMCq/R4IssT5YrPqfp4o9+RRh397UBD0zMTXIrLB2ap8cNC/12/kbishrSApZyhKe8Cdzrpn+yXUmLO/tVbhc9r/b3ln+9PTHqD2bTuZSPliZVNwCb/36IaeMB/TIERLN59wJ7iTasQO/2SlrqiXnwRYf2dtpUcSfT5/IV3kSU1KZ+zn9ouFLe1na1Ozpa/4GIUZz8S5/MF06d+AJTCf2rOL4mr8VjLJyK4XLKLMJdmZrJzbKj7ZJ83U6mg72tt+fkVG52yb+TT+kUTowSA/oJ3wWmm/6CXxoSZfWRKJYrko/kzpfDYYGIQ7z65wkcuX9TfQ8GMJg7qD6DRgCwA/BQ/xqLBCKzg32n2sdSow1/xLjiaTpsxb4n/0Wiw1GWz0HRHu9s+GcdX9+/3MAhpFkuTE/43qgFvcjKG3pB1jBl9+FvK0FRgYXgi5RAXw2fnSuFRJVMKR5QM2suRyHg4GDuge1Z/0Po50I1qLd2tGkd1Z2iKLB4KN8GO6W71+V+oBg7oO9bn47PgcrqRI1FJpSqJ5NVU6moylc+ntMXFVkaT26XidjJTKS9tbS2VKwc92UA1YI5wa6W/SYybDfrYbrvT4U9zaO/8qHJi1mKJavpuawc16uguqkHI9F1SzcjFY6IojeLDjLSoudl+bNB9P7ZBgoHM8NgYL/cJM6HVwsiid4hTAqPD/WN9JDMSLNglr8rxI35OYE908vFgohBgYz2ekJf1uTo6eXVUmhky63sadZTFN4yNavadxFVVNgN52P9ni6dmF05k797lQ5399m5nxL42izq1ttdfT+u1kXGbRaM7mlgA+DHaM7NAHXkDnn9RhBJFY3Jp6rv3lmbbu2hLe7ftbHHBxrRb2h30mcUvX8nZHDZLe/eJDNrTPxTSgpAWEHfkqxe1kczgYJboHwMCeyOCfo32jK4+909Vj5anuvBat8/e3e60BRVHxy+WNzu4DkuH88RK8W0mkn3fapnGbYmRAfSh/h//rMDPBlDnfm1sYcTQNACAfom/ZuDLcQ23VqZ0uEaNIZRdQ5deyyVPDWW8kaF1bfVq+pWF3gnuZ+OXvvmKrOZGApFwvLKc/OK9AracAQTTjTq8A9vG29vcak2s2xwhnIcQO+nzEeLrI0ZuxUYd3cI/Bg4GAVRRoz7BoIti6SMYD2jP8EhgfIxPsJHAsrqwHoiE+9oEThA4jpCnkdmkogSGJv19wwORT81LqYmpmdAfn9dDUESP4If4LeOd75EkmaY3u6nzVDd69PDChYeNhnGOVvFbIBobH2jwwpsHuwl+gPaAav4/KJXQnt4LqPEbPA8qfmxoZY7w9Pj9Ho/fj+d9nKe/38P54P8AAAD//wEAAP//C6fWagAAAAABAAAAAguFVvHI2V8PPPUAAwPoAAAAANhdoKEAAAAA3WYvNv46/tsIbwPIAAAAAwACAAAAAAAAAAEAAAPY/u8AAAiY/jr+OghvAAEAAAAAAAAAAAAAAAAAAAAgAo0AWQDIAAACjABaAeYAWgLXAFoCOQBaAhgAHAKFAFcB+AA0AikAUgHIAC4CKwAvAfAALgEkAB4CIABSAPYARQD/AFIDPQBSAiMAUgIeAC4BWwBSAaMAHAFSABgCzgAYAdMADAHxACQA+QBBAakAJgD5AFABqgBQAPYAUgAA/8kAAAAsACwARABUAIYArgDAAOQBHAFQAX4BsAHkAgYCKAI0AlACggKkAtAC8AMwA1YDkAPAA+oEAAQ4BEgEVARgBHYAAAABAAAAIACMAAwAZgAHAAEAAAAAAAAAAAAAAAAABAADeJyclN1OG1cUhT8H221UNRcVisgNOpdtlYzdCKIErkwJilWEU4/TH6mqNHjGP2I8M/IMUKo+QK/7Fn2LXPU5+hBVr6uzvA02qhSBELDOnL33WWevtQ+wyb9sUKs/BP5q/mC4xnZzz/ADHjWfGt7guPG34fpKTIO48ZvhJl82+oY/4n39D8Mfs1P/2fBDtupHhj/heX3T8Kcbjn8MP2KH9wtcg5f8brjGFoXhB2zyk+ENHmM1a3Ue0zbc4DO2DTfZBgZMqUiZkjHGMWLKmHPmJJSEJMyZMiIhxtGlQ0qlrxmRkGP8v18jQirmRKo4ocKREpISUTKxir8qK+etThxpNbe9DhUTIk6VcUZEhiNnTE5GwpnqVFQU7NGiRclQfAsqSgJKpqQE5MwZ06LHEccMmDClxHGkSp5ZSM6Iiksine8swndmSEJGaazOyYjF04lfouwuxzh6FIpdrXy8VuEpju+U7bnliv2KQL9uhdn6uUs2ERfqZ6qupNq5lIIT7fpzO3wrXLGHu1d/1pl8uEex/leqfMq59I+lVCYmGc5t0SGUg0L3BMeB1l1CdeR7ugx4Q493DLTu0KdPhxMGdHmt3B59HF/T44RDZXSFF3tHcswJP+L4hq5ifO3E+rNQLOEXCnN3KY5z3WNGoZ575oHumuiGd1fYz1C+5o5SOUPNkY900i/TnEWMzRWFGM7Uy6U3SutfbI6Y6S5e25t9Pw0XNnvLKb4i1wx7ty44eeUWjD6kanDLM5f6CYiIyTlVxJCcGS0qrsT7LRHnpDgO1b03mpKKznWOP+dKLkmYiUGXTHXmFPobmW9C4z5c872ztyRWvmd6dn2r+5zi1Ksbjd6pe8u90LqcrCjQMlXzFTcNxTUz7yeaqVX+oXJLvW45z+iTSPVUN7j9DjwnoM0Ou+wz0TlD7VzYG9HWO9HmFfvqwRmJokZydWIVdgl4wS67vOLFWs0OhxzQY/8OHBdZPQ54fWtnXadlFWd1/hSbtvg6nl2vXt5br8/v4MsvNFE3L2Nf2vhuX1i1G/+fEDHzXNzW6p3cE4L/AAAA//8BAAD//wdbTDAAeJxiYGYAg//nGIwYsAAAAAAA//8BAAD//y8BAgMAAAA=");
}
.d2-2754761364 .text-italic {
	font-family: "d2-2754761364-font-italic";
}
@font-face {
	font-family: d2-2754761364-font-italic;
	src: url("data:application/font-woff;base64,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");
}]]></style><style type="text/css"><![CDATA[.shape {
  shape-rendering: geometricPrecision;
  stroke-linejoin: round;
}
.connection {
  stroke-linecap: round;
  stroke-linejoin: round;
}
.blend {
  mix-blend-mode: multiply;
  opacity: 0.5;
}

		.d2-2754761364 .fill-N1{fill:#0A0F25;}
		.d2-2754761364 .fill-N2{fill:#676C7E;}
		.d2-2754761364 .fill-N3{fill:#9499AB;}
		.d2-2754761364 .fill-N4{fill:#CFD2DD;}
		.d2-2754761364 .fill-N5{fill:#DEE1EB;}
		.d2-2754761364 .fill-N6{fill:#EEF1F8;}
		.d2-2754761364 .fill-N7{fill:#FFFFFF;}
		.d2-2754761364 .fill-B1{fill:#0D32B2;}
		.d2-2754761364 .fill-B2{fill:#0D32B2;}
		.d2-2754761364 .fill-B3{fill:#E3E9FD;}
		.d2-2754761364 .fill-B4{fill:#E3E9FD;}
		.d2-2754761364 .fill-B5{fill:#EDF0FD;}
		.d2-2754761364 .fill-B6{fill:#F7F8FE;}
		.d2-2754761364 .fill-AA2{fill:#4A6FF3;}
		.d2-2754761364 .fill-AA4{fill:#EDF0FD;}
		.d2-2754761364 .fill-AA5{fill:#F7F8FE;}
		.d2-2754761364 .fill-AB4{fill:#EDF0FD;}
		.d2-2754761364 .fill-AB5{fill:#F7F8FE;}
		.d2-2754761364 .stroke-N1{stroke:#0A0F25;}
		.d2-2754761364 .stroke-N2{stroke:#676C7E;}
		.d2-2754761364 .stroke-N3{stroke:#9499AB;}
		.d2-2754761364 .stroke-N4{stroke:#CFD2DD;}
		.d2-2754761364 .stroke-N5{stroke:#DEE1EB;}
		.d2-2754761364 .stroke-N6{stroke:#EEF1F8;}
		.d2-2754761364 .stroke-N7{stroke:#FFFFFF;}
		.d2-2754761364 .stroke-B1{stroke:#0D32B2;}
		.d2-2754761364 .stroke-B2{stroke:#0D32B2;}
		.d2-2754761364 .stroke-B3{stroke:#E3E9FD;}
		.d2-2754761364 .stroke-B4{stroke:#E3E9FD;}
		.d2-2754761364 .stroke-B5{stroke:#EDF0FD;}
		.d2-2754761364 .stroke-B6{stroke:#F7F8FE;}
		.d2-2754761364 .stroke-AA2{stroke:#4A6FF3;}
		.d2-2754761364 .stroke-AA4{stroke:#EDF0FD;}
		.d2-2754761364 .stroke-AA5{stroke:#F7F8FE;}
		.d2-2754761364 .stroke-AB4{stroke:#EDF0FD;}
		.d2-2754761364 .stroke-AB5{stroke:#F7F8FE;}
		.d2-2754761364 .background-color-N1{background-color:#0A0F25;}
		.d2-2754761364 .background-color-N2{background-color:#676C7E;}
		.d2-2754761364 .background-color-N3{background-color:#9499AB;}
		.d2-2754761364 .background-color-N4{background-color:#CFD2DD;}
		.d2-2754761364 .background-color-N5{background-color:#DEE1EB;}
		.d2-2754761364 .background-color-N6{background-color:#EEF1F8;}
		.d2-2754761364 .background-color-N7{background-color:#FFFFFF;}
		.d2-2754761364 .background-color-B1{background-color:#0D32B2;}
		.d2-2754761364 .background-color-B2{background-color:#0D32B2;}
		.d2-2754761364 .background-color-B3{background-color:#E3E9FD;}
		.d2-2754761364 .background-color-B4{background-color:#E3E9FD;}
		.d2-2754761364 .background-color-B5{background-color:#EDF0FD;}
		.d2-2754761364 .background-color-B6{background-color:#F7F8FE;}
		.d2-2754761364 .background-color-AA2{background-color:#4A6FF3;}
		.d2-2754761364 .background-color-AA4{background-color:#EDF0FD;}
		.d2-2754761364 .background-color-AA5{background-color:#F7F8FE;}
		.d2-2754761364 .background-color-AB4{background-color:#EDF0FD;}
		.d2-2754761364 .background-color-AB5{background-color:#F7F8FE;}
		.d2-2754761364 .color-N1{color:#0A0F25;}
		.d2-2754761364 .color-N2{color:#676C7E;}
		.d2-2754761364 .color-N3{color:#9499AB;}
		.d2-2754761364 .color-N4{color:#CFD2DD;}
		.d2-2754761364 .color-N5{color:#DEE1EB;}
		.d2-2754761364 .color-N6{color:#EEF1F8;}
		.d2-2754761364 .color-N7{color:#FFFFFF;}
		.d2-2754761364 .color-B1{color:#0D32B2;}
		.d2-2754761364 .color-B2{color:#0D32B2;}
		.d2-2754761364 .color-B3{color:#E3E9FD;}
		.d2-2754761364 .color-B4{color:#E3E9FD;}
		.d2-2754761364 .color-B5{color:#EDF0FD;}
		.d2-2754761364 .color-B6{color:#F7F8FE;}
		.d2-2754761364 .color-AA2{color:#4A6FF3;}
		.d2-2754761364 .color-AA4{color:#EDF0FD;}
		.d2-2754761364 .color-AA5{color:#F7F8FE;}
		.d2-2754761364 .color-AB4{color:#EDF0FD;}
		.d2-2754761364 .color-AB5{color:#F7F8FE;}.appendix text.text{fill:#0A0F25}.md{--color-fg-default:#0A0F25;--color-fg-muted:#676C7E;--color-fg-subtle:#9499AB;--color-canvas-default:#FFFFFF;--color-canvas-subtle:#EEF1F8;--color-border-default:#0D32B2;--color-border-muted:#0D32B2;--color-neutral-muted:#EEF1F8;--color-accent-fg:#0D32B2;--color-accent-emphasis:#0D32B2;--color-attention-subtle:#676C7E;--color-danger-fg:red;}.sketch-overlay-B1{fill:url(#streaks-darker);mix-blend-mode:lighten}.sketch-overlay-B2{fill:url(#streaks-darker);mix-blend-mode:lighten}.sketch-overlay-B3{fill:url(#streaks-bright);mix-blend-mode:darken}.sketch-overlay-B4{fill:url(#streaks-bright);mix-blend-mode:darken}.sketch-overlay-B5{fill:url(#streaks-bright);mix-blend-mode:darken}.sketch-overlay-B6{fill:url(#streaks-bright);mix-blend-mode:darken}.sketch-overlay-AA2{fill:url(#streaks-dark);mix-blend-mode:overlay}.sketch-overlay-AA4{fill:url(#streaks-bright);mix-blend-mode:darken}.sketch-overlay-AA5{fill:url(#streaks-bright);mix-blend-mode:darken}.sketch-overlay-AB4{fill:url(#streaks-bright);mix-blend-mode:darken}.sketch-overlay-AB5{fill:url(#streaks-bright);mix-blend-mode:darken}.sketch-overlay-N1{fill:url(#streaks-darker);mix-blend-mode:lighten}.sketch-overlay-N2{fill:url(#streaks-dark);mix-blend-mode:overlay}.sketch-overlay-N3{fill:url(#streaks-normal);mix-blend-mode:color-burn}.sketch-overlay-N4{fill:url(#streaks-normal);mix-blend-mode:color-burn}.sketch-overlay-N5{fill:url(#streaks-bright);mix-blend-mode:darken}.sketch-overlay-N6{fill:url(#streaks-bright);mix-blend-mode:darken}.sketch-overlay-N7{fill:url(#streaks-bright);mix-blend-mode:darken}.light-code{display: block}.dark-code{display: none}]]></style><g id="User"><g class="shape" ><rect x="12.000000" y="52.000000" width="100.000000" height="66.000000" stroke="#0D32B2" fill="#EDF0FD" class=" stroke-B1 fill-B5" style="stroke-width:2;" /></g><text x="62.000000" y="90.500000" fill="#0A0F25" class="text fill-N1" style="text-anchor:middle;font-size:16px">User</text></g><g id="LLM"><g class="shape" ><rect x="459.000000" y="52.000000" width="100.000000" height="66.000000" stroke="#0D32B2" fill="#EDF0FD" class=" stroke-B1 fill-B5" style="stroke-width:2;" /></g><text x="509.000000" y="90.500000" fill="#0A0F25" class="text fill-N1" style="text-anchor:middle;font-size:16px">LLM</text></g><g id="(User -- )[0]"><path d="M 62.000000 120.000000 L 62.000000 357.000000" stroke="#0D32B2" fill="none" class="connection stroke-B2" style="stroke-width:2;stroke-dasharray:12.000000,11.838767;" mask="url(#d2-2754761364)" /></g><g id="(LLM -- )[0]"><path d="M 509.000000 120.000000 L 509.000000 357.000000" stroke="#0D32B2" fill="none" class="connection stroke-B2" style="stroke-width:2;stroke-dasharray:12.000000,11.838767;" mask="url(#d2-2754761364)" /></g><g id="(User -&gt; LLM)[0]"><marker id="mk-3488378134" markerWidth="10.000000" markerHeight="12.000000" refX="7.000000" refY="6.000000" viewBox="0.000000 0.000000 10.000000 12.000000" orient="auto" markerUnits="userSpaceOnUse"> <polygon points="0.000000,0.000000 10.000000,6.000000 0.000000,12.000000" fill="#0D32B2" class="connection fill-B1" stroke-width="2" /> </marker><path d="M 64.000000 198.000000 L 505.000000 198.000000" stroke="#0D32B2" fill="none" class="connection stroke-B1" style="stroke-width:2;" marker-end="url(#mk-3488378134)" mask="url(#d2-2754761364)" /><text x="285.500000" y="204.000000" fill="#676C7E" class="text-italic fill-N2" style="text-anchor:middle;font-size:16px">How many R&#39;s are in the word &#34;strawberry&#34;?</text></g><g id="(LLM -&gt; User)[0]"><path d="M 507.000000 288.000000 L 66.000000 288.000000" stroke="#0D32B2" fill="none" class="connection stroke-B1" style="stroke-width:2;" marker-end="url(#mk-3488378134)" mask="url(#d2-2754761364)" /><text x="285.500000" y="294.000000" fill="#676C7E" class="text-italic fill-N2" style="text-anchor:middle;font-size:16px">The word &#34;strawberry&#34; contains 2 instances of the letter &#34;r&#34;.</text></g><mask id="d2-2754761364" maskUnits="userSpaceOnUse" x="1" y="41" width="569" height="328">
<rect x="1" y="41" width="569" height="328" fill="white"></rect>
<rect x="47.000000" y="74.500000" width="30" height="21" fill="rgba(0,0,0,0.75)"></rect>
<rect x="496.000000" y="74.500000" width="26" height="21" fill="rgba(0,0,0,0.75)"></rect>
<rect x="141.000000" y="188.000000" width="289" height="21" fill="black"></rect>
<rect x="92.000000" y="278.000000" width="387" height="21" fill="black"></rect>
</mask></svg></svg>
" class="img-fluid" style="width:75.0%"></p>
<p>Diagrams as code are not new, with the <a href="https://en.wikipedia.org/wiki/DOT_language">DOT language</a> being used for <a href="https://graphviz.org/">GraphViz</a> since 1991. They were great all along, but they‚Äôve become even better with the rise of AI assistants.</p>
</section>
<section id="assistants-make-diagrams-effortless" class="level2">
<h2 class="anchored" data-anchor-id="assistants-make-diagrams-effortless">Assistants make diagrams effortless</h2>
<p>Commonly used LLMs like GPT-4o, Claude and Gemini are familiar with text-based diagram syntax. They can turn a quick prompt into diagram code. They can also take the diagram as input and write code to implement it. Diagrams as code are an intermediate step between natural language and code. As assistants take on more coding tasks, this level of abstraction becomes more important for developers.</p>
<p>An AI can assist throughout the diagram lifecycle - from generating initial diagrams from natural language prompts to updating them based on code changes. It can validate diagrams against existing code, convert between different diagram formats, and even suggest structural improvements. For developers new to diagrams as code, the assistant serves as a helpful guide, explaining syntax and best practices. The time savings also make it more convenient to keep diagrams in sync with code, which is a common problem.</p>
<p>The stakes for diagrams are relatively low, so it‚Äôs not necessary to review every generated line. When an assistant makes a mistake, syntax errors will be caught during rendering and content errors are easily spotted during visual review.</p>
</section>
<section id="diagrams-as-code-systems" class="level2">
<h2 class="anchored" data-anchor-id="diagrams-as-code-systems">Diagrams as code systems</h2>
<p>Let‚Äôs take a look at some of the most popular implementations:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Name</th>
<th>Description</th>
<th>Best for</th>
<th>Release</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><a href="https://graphviz.org/">GraphViz</a></td>
<td>Foundational graph visualization technology powering many modern tools. Its DOT language and layout algorithms are widely used as a backend for other visualization software. Provides programmatic generation of structured layouts.</td>
<td>Network topology, dependency trees, and hierarchical data visualization where automated layout is crucial. Often used as an engine rather than directly.</td>
<td>1991</td>
</tr>
<tr class="even">
<td><a href="https://plantuml.com/">PlantUML</a></td>
<td>Supports UML diagrams (class, sequence, use case, activity, etc.), network diagrams, wireframes, Gantt charts, and more. Widely integrated into IDEs, wikis, and documentation tools.</td>
<td>Technical documentation requiring standardized diagrams, especially UML.</td>
<td>2009</td>
</tr>
<tr class="odd">
<td><a href="https://www.drawio.com/">Draw.io</a></td>
<td>Browser-based diagramming tool (also known as diagrams.net) with desktop versions available. Features extensive shape libraries, custom templates, and automatic layouts. Supports offline use, multiple storage backends (Google Drive, OneDrive, GitHub), and collaborative editing.</td>
<td>General-purpose diagramming suitable for both technical and business users.</td>
<td>2012</td>
</tr>
<tr class="even">
<td><a href="https://mermaid.js.org/">Mermaid</a></td>
<td>JavaScript-based diagramming library that renders text definitions into SVG diagrams. Supports flowcharts, sequence diagrams, class diagrams, state diagrams, user journeys, Gantt charts, and pie charts. Widely adopted in documentation platforms and Markdown tools.</td>
<td>Diagrams in documentation, especially in Markdown environments like GitHub and documentation sites.</td>
<td>2014</td>
</tr>
<tr class="odd">
<td><a href="https://d2lang.com/">D2</a></td>
<td>Modern diagram scripting language focusing on developer experience. Features concise syntax, multiple layout engines, and scripting capabilities. Emphasizes version control friendly text-based diagram definitions.</td>
<td>Software architecture and system documentation. Sophisticated custom diagrams.</td>
<td>2022</td>
</tr>
</tbody>
</table>
<p>All of them are free to use and have an extension for VSCode. The website <a href="https://text-to-diagram.com/">text-to-diagram.com</a> has a fantastic comparison of D2, Mermaid, PlantUML and GraphViz.</p>
<p>My favorite is <strong>D2</strong>, as it creates the most aesthetic and readable diagrams using the <a href="https://d2lang.com/tour/elk">ELK layout engine</a>. It also supports many export formats, including SVG, PNG, PDF, and even PowerPoint.</p>
<p>Mermaid is another strong choice, as it offers a wider range of diagram types and can be used as a code blocks in markdown environments like GitHub.</p>
<p>If you‚Äôre using Quarto, like I do for this blog, Mermaid and GraphViz support is <a href="https://quarto.org/docs/authoring/diagrams.html">built-in</a> and D2 support can be added with a <a href="https://github.com/data-intuitive/quarto-d2">plugin</a>. Alternatively, create a separate <code>.d2</code> file and render it to SVG.</p>
</section>
<section id="level-up-your-diagrams" class="level2">
<h2 class="anchored" data-anchor-id="level-up-your-diagrams">Level up your diagrams</h2>
<p>With an assistant, it‚Äôs faster than ever to generate a giant hairball of boxes and arrows. But that‚Äôs not the goal - it‚Äôs about communicating ideas. Let‚Äôs go over some principles that help increase the clarity and usefulness of diagrams. If you agree with them, you may want to copy them into a prompt.</p>
<section id="content-and-layout" class="level3">
<h3 class="anchored" data-anchor-id="content-and-layout">Content and layout</h3>
<ol type="1">
<li><p>Use the appropriate diagram type. Flowcharts are the most common, but there are many others such as <a href="https://d2lang.com/tour/sequence-diagrams/">sequence diagrams</a>, <a href="https://d2lang.com/tour/uml-classes">class diagrams</a>, and <a href="https://mermaid.js.org/syntax/userJourney.html">user journey diagrams</a>.</p></li>
<li><p>Model the key components, rather than every possible detail. Keep the diagram at a single level of abstraction. Use multiple diagrams if needed.</p></li>
</ol>
<blockquote class="blockquote">
<p>My rule of thumb is that you need to be able to print the diagram on a single A4 sheet while keeping things readable. ‚Äì <a href="https://bellekens.com/2012/02/21/uml-best-practice-5-rules-for-better-uml-diagrams/">Geert Bellekens, enterprise architect</a></p>
</blockquote>
<ol start="3" type="1">
<li>Avoid crossing lines. Layout engines do a good job of this. If they fail to find a layout that avoids overlaps, it‚Äôs a sign that the diagram is too complex. Also prefer vertical and horizontal lines over diagonal ones, as they give the diagram a more professional look.</li>
</ol>
</section>
<section id="styling" class="level3">
<h3 class="anchored" data-anchor-id="styling">Styling</h3>
<ol type="1">
<li>Label all components and arrows. A relationship may be obvious to you, but not to others. Use one or two word labels in a sans-serif font at a size readable for aging eyes.</li>
<li>Use consistent shapes, arrows and colors. This helps readers scan the diagram quicker. Use stylistic elements like thicker lines for primary flows and thinner for secondary flows, dotted or dashed lines for optional or future relationships, and different shapes for different types of components.</li>
<li>Use color sparingly and meaningfully, e.g., to highlight critical paths. Don‚Äôt rely on color as the only way information is conveyed. Use labels and shapes to ensure the diagram works in black and white too. 1 in 12 men are <a href="https://www.nei.nih.gov/learn-about-eye-health/eye-conditions-and-diseases/color-blindness">colorblind</a>.</li>
<li>Consider using a <a href="https://d2lang.com/blog/hand-drawn-diagrams">hand-drawn style</a> in early stages of a design. It conveys that the diagram is a draft and not a final product.</li>
</ol>
<p><img src="https://simmering.dev/blog/diagrams/data:image/svg+xml;base64,<?xml version="1.0" encoding="utf-8"?><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" d2Version="0.6.8" preserveAspectRatio="xMinYMin meet" viewBox="0 0 1140 174"><svg id="d2-svg" class="d2-1355680374" width="1140" height="174" viewBox="1 1 1140 174"><rect x="1.000000" y="1.000000" width="1140.000000" height="174.000000" rx="0.000000" fill="transparent" stroke-width="0" /><style type="text/css"><![CDATA[
.d2-1355680374 .text-bold {
	font-family: "d2-1355680374-font-bold";
}
@font-face {
	font-family: d2-1355680374-font-bold;
	src: url("data:application/font-woff;base64,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");
}]]></style><style type="text/css"><![CDATA[.shape {
  shape-rendering: geometricPrecision;
  stroke-linejoin: round;
}
.connection {
  stroke-linecap: round;
  stroke-linejoin: round;
}
.blend {
  mix-blend-mode: multiply;
  opacity: 0.5;
}

		.d2-1355680374 .fill-N1{fill:#0A0F25;}
		.d2-1355680374 .fill-N2{fill:#676C7E;}
		.d2-1355680374 .fill-N3{fill:#9499AB;}
		.d2-1355680374 .fill-N4{fill:#CFD2DD;}
		.d2-1355680374 .fill-N5{fill:#DEE1EB;}
		.d2-1355680374 .fill-N6{fill:#EEF1F8;}
		.d2-1355680374 .fill-N7{fill:#FFFFFF;}
		.d2-1355680374 .fill-B1{fill:#0D32B2;}
		.d2-1355680374 .fill-B2{fill:#0D32B2;}
		.d2-1355680374 .fill-B3{fill:#E3E9FD;}
		.d2-1355680374 .fill-B4{fill:#E3E9FD;}
		.d2-1355680374 .fill-B5{fill:#EDF0FD;}
		.d2-1355680374 .fill-B6{fill:#F7F8FE;}
		.d2-1355680374 .fill-AA2{fill:#4A6FF3;}
		.d2-1355680374 .fill-AA4{fill:#EDF0FD;}
		.d2-1355680374 .fill-AA5{fill:#F7F8FE;}
		.d2-1355680374 .fill-AB4{fill:#EDF0FD;}
		.d2-1355680374 .fill-AB5{fill:#F7F8FE;}
		.d2-1355680374 .stroke-N1{stroke:#0A0F25;}
		.d2-1355680374 .stroke-N2{stroke:#676C7E;}
		.d2-1355680374 .stroke-N3{stroke:#9499AB;}
		.d2-1355680374 .stroke-N4{stroke:#CFD2DD;}
		.d2-1355680374 .stroke-N5{stroke:#DEE1EB;}
		.d2-1355680374 .stroke-N6{stroke:#EEF1F8;}
		.d2-1355680374 .stroke-N7{stroke:#FFFFFF;}
		.d2-1355680374 .stroke-B1{stroke:#0D32B2;}
		.d2-1355680374 .stroke-B2{stroke:#0D32B2;}
		.d2-1355680374 .stroke-B3{stroke:#E3E9FD;}
		.d2-1355680374 .stroke-B4{stroke:#E3E9FD;}
		.d2-1355680374 .stroke-B5{stroke:#EDF0FD;}
		.d2-1355680374 .stroke-B6{stroke:#F7F8FE;}
		.d2-1355680374 .stroke-AA2{stroke:#4A6FF3;}
		.d2-1355680374 .stroke-AA4{stroke:#EDF0FD;}
		.d2-1355680374 .stroke-AA5{stroke:#F7F8FE;}
		.d2-1355680374 .stroke-AB4{stroke:#EDF0FD;}
		.d2-1355680374 .stroke-AB5{stroke:#F7F8FE;}
		.d2-1355680374 .background-color-N1{background-color:#0A0F25;}
		.d2-1355680374 .background-color-N2{background-color:#676C7E;}
		.d2-1355680374 .background-color-N3{background-color:#9499AB;}
		.d2-1355680374 .background-color-N4{background-color:#CFD2DD;}
		.d2-1355680374 .background-color-N5{background-color:#DEE1EB;}
		.d2-1355680374 .background-color-N6{background-color:#EEF1F8;}
		.d2-1355680374 .background-color-N7{background-color:#FFFFFF;}
		.d2-1355680374 .background-color-B1{background-color:#0D32B2;}
		.d2-1355680374 .background-color-B2{background-color:#0D32B2;}
		.d2-1355680374 .background-color-B3{background-color:#E3E9FD;}
		.d2-1355680374 .background-color-B4{background-color:#E3E9FD;}
		.d2-1355680374 .background-color-B5{background-color:#EDF0FD;}
		.d2-1355680374 .background-color-B6{background-color:#F7F8FE;}
		.d2-1355680374 .background-color-AA2{background-color:#4A6FF3;}
		.d2-1355680374 .background-color-AA4{background-color:#EDF0FD;}
		.d2-1355680374 .background-color-AA5{background-color:#F7F8FE;}
		.d2-1355680374 .background-color-AB4{background-color:#EDF0FD;}
		.d2-1355680374 .background-color-AB5{background-color:#F7F8FE;}
		.d2-1355680374 .color-N1{color:#0A0F25;}
		.d2-1355680374 .color-N2{color:#676C7E;}
		.d2-1355680374 .color-N3{color:#9499AB;}
		.d2-1355680374 .color-N4{color:#CFD2DD;}
		.d2-1355680374 .color-N5{color:#DEE1EB;}
		.d2-1355680374 .color-N6{color:#EEF1F8;}
		.d2-1355680374 .color-N7{color:#FFFFFF;}
		.d2-1355680374 .color-B1{color:#0D32B2;}
		.d2-1355680374 .color-B2{color:#0D32B2;}
		.d2-1355680374 .color-B3{color:#E3E9FD;}
		.d2-1355680374 .color-B4{color:#E3E9FD;}
		.d2-1355680374 .color-B5{color:#EDF0FD;}
		.d2-1355680374 .color-B6{color:#F7F8FE;}
		.d2-1355680374 .color-AA2{color:#4A6FF3;}
		.d2-1355680374 .color-AA4{color:#EDF0FD;}
		.d2-1355680374 .color-AA5{color:#F7F8FE;}
		.d2-1355680374 .color-AB4{color:#EDF0FD;}
		.d2-1355680374 .color-AB5{color:#F7F8FE;}.appendix text.text{fill:#0A0F25}.md{--color-fg-default:#0A0F25;--color-fg-muted:#676C7E;--color-fg-subtle:#9499AB;--color-canvas-default:#FFFFFF;--color-canvas-subtle:#EEF1F8;--color-border-default:#0D32B2;--color-border-muted:#0D32B2;--color-neutral-muted:#EEF1F8;--color-accent-fg:#0D32B2;--color-accent-emphasis:#0D32B2;--color-attention-subtle:#676C7E;--color-danger-fg:red;}.sketch-overlay-B1{fill:url(#streaks-darker);mix-blend-mode:lighten}.sketch-overlay-B2{fill:url(#streaks-darker);mix-blend-mode:lighten}.sketch-overlay-B3{fill:url(#streaks-bright);mix-blend-mode:darken}.sketch-overlay-B4{fill:url(#streaks-bright);mix-blend-mode:darken}.sketch-overlay-B5{fill:url(#streaks-bright);mix-blend-mode:darken}.sketch-overlay-B6{fill:url(#streaks-bright);mix-blend-mode:darken}.sketch-overlay-AA2{fill:url(#streaks-dark);mix-blend-mode:overlay}.sketch-overlay-AA4{fill:url(#streaks-bright);mix-blend-mode:darken}.sketch-overlay-AA5{fill:url(#streaks-bright);mix-blend-mode:darken}.sketch-overlay-AB4{fill:url(#streaks-bright);mix-blend-mode:darken}.sketch-overlay-AB5{fill:url(#streaks-bright);mix-blend-mode:darken}.sketch-overlay-N1{fill:url(#streaks-darker);mix-blend-mode:lighten}.sketch-overlay-N2{fill:url(#streaks-dark);mix-blend-mode:overlay}.sketch-overlay-N3{fill:url(#streaks-normal);mix-blend-mode:color-burn}.sketch-overlay-N4{fill:url(#streaks-normal);mix-blend-mode:color-burn}.sketch-overlay-N5{fill:url(#streaks-bright);mix-blend-mode:darken}.sketch-overlay-N6{fill:url(#streaks-bright);mix-blend-mode:darken}.sketch-overlay-N7{fill:url(#streaks-bright);mix-blend-mode:darken}.light-code{display: block}.dark-code{display: none}]]></style><defs><pattern id="streaks-bright" x="0" y="0" width="100" height="100" patternUnits="userSpaceOnUse">
    <path fill="rgba(0, 0, 0, 0.1)" fill-rule="evenodd" clip-rule="evenodd" d="M58.1193 0H58.1703L55.4939 2.67644L58.1193 0ZM45.7725 0H45.811L41.2851 4.61498L42.7191 3.29325L37.0824 8.92997L35.0554 10.9569L32.0719 13.9404L29.6229 16.5017L27.1738 19.0631L25.8089 20.2034L23.2195 22.6244L18.181 27.6068L23.8178 21.97L27.0615 18.9508L33.8666 11.9773L33.1562 12.5194L37.0262 8.87383L40.784 5.11602L38.0299 7.64561L45.7725 0ZM23.1079 0H23.108L21.5814 1.66688L20.3126 2.79534L23.1079 0ZM7.53869 0H7.54254L7.50005 0.035944L7.53869 0ZM2.49995 0H2.52362L0.900245 1.59971L2.49995 0ZM0 3.64398V3.60744L0.278386 3.36559L0 3.64398ZM0 18.6564V18.5398L0.67985 17.8416L3.4459 15.0755L1.15701 17.1333L2.78713 15.6022L6.01437 12.507L8.5168 9.87253L5.15803 13.2313L11.0357 7.25453L10.4926 7.89678L13.6868 4.7686L8.54982 9.90555L7.05177 11.5687L4.68087 13.9396L0.729379 17.8911L3.01827 15.8333L0 18.6564ZM0 69.2431V69.178L1.64651 67.4763L1.46347 67.7796L5.84063 63.4025L4.42167 64.9016L0 69.4007V69.3408L0.247596 68.9955L0 69.2431ZM2.51594 100H2.49238L5.19989 97.2925L7.70071 95.0162L12.8713 89.6772L12.3094 90.0707L15.288 87.3167L18.1542 84.4504L16.0269 86.3532L22.8752 79.6172L18.5364 84.0683L19.6435 83.0734L15.3441 87.3728L13.798 88.9189L11.5224 91.1945L9.66768 93.1615L7.81297 95.1285L6.74529 95.9716L4.75024 97.7983L2.51594 100ZM7.54255 100H7.5387L9.81396 97.884L8.46606 99.2189L7.54255 100ZM45.8189 100H45.7807L46.9912 98.8047L45.8189 100ZM58.1784 100H58.1272L62.2952 95.7511L66.1408 91.9055L63.0037 94.8115L65.2507 92.6635L69.7117 88.3346L73.2165 84.6977L68.5469 89.3673L76.7379 81.0773L75.9634 81.9509L80.3913 77.5889L73.2496 84.7307L71.1346 87.0107L67.8384 90.3069L62.3447 95.8006L65.4818 92.8947L61.2625 96.9159L58.1784 100ZM75.4277 100H75.229L82.1834 92.9039L81.3403 93.5787L86.0063 89.1371L90.5601 84.5833L87.2464 87.6725L98.0937 76.9375L91.1673 83.9761L92.8932 82.3625L86.0625 89.1933L83.6062 91.6496L79.9907 95.265L77.011 98.357L75.4277 100ZM100 18.5398V18.6563L99.9556 18.6979L95.8065 22.847L100 18.5398ZM100 3.60743V3.64398L99.6791 3.9649L99.2094 4.29428L100 3.60743ZM75.4201 0L74.0312 1.4412L72.401 2.84687L69.281 5.79854L63.1812 11.8422L70.0119 5.01151L73.919 1.32893L75.2214 0H75.4201ZM100 69.1858V69.2509L98.059 71.1919L100 69.1858ZM100 69.3486V69.4085L99.8414 69.5698L100 69.3486ZM41.9398 28.8254L53.6223 16.993L52.5215 18.2437L54.7428 16.0575L54.6875 16.0759L54.8008 16.0004L58.842 12.0231L54.9925 15.8726L55.1085 15.7953L54.898 16.0058L54.84 16.0251L48.6523 22.2128L45.6419 25.473L40.9389 30.1759L33.1007 38.0142L37.5866 33.878L31.558 39.6068L23.3278 47.837L33.0257 37.9393L38.5125 32.4525L34.0266 36.5887L37.2369 33.5283L43.6074 27.3576L48.6023 22.1628L41.9398 28.8254ZM41.0977 17.0531L39.718 18.2925L40.312 17.8388L41.0977 17.0531ZM36.875 20.3106L48.1601 7.88137L42.3438 13.7478L36.875 20.3106ZM35.7125 25.8109L34.3328 27.0503L34.9268 26.5966L35.7125 25.8109ZM17.7022 39.7534L19.0819 38.514L18.8092 38.7867L36.7575 21.8045L23.1569 35.3051L13.5771 43.7372L18.1448 39.4154L17.7022 39.7534ZM3.48102 28.9281L1.53562 30.8735L1.22228 31.0465L0.0765686 32.3326L1.60579 30.9437L2.57849 29.971L3.48102 28.9281ZM0.953463 26.2027L19.5702 7.58594L9.31575 18.6078L0.953463 26.2027ZM23.7175 12.11L17.9339 18.0875L21.4622 14.5592L20.8074 15.4725L28.1915 7.95918L30.4791 5.54232L23.4224 12.599L23.7175 12.11ZM43.4641 43.1538L40.7872 46.1552L42.4907 44.4517L42.3285 45.0465L45.8166 41.3421L46.8441 40.0983L43.4371 43.5053L43.4641 43.1538ZM1.32715 48.3271L8.0918 41.5625L4.3657 45.5674L1.32715 48.3271ZM11.1479 31.2556L11.5689 30.975L11.3584 31.1855L11.1479 31.2556ZM11.9898 27.4667L12.2003 27.2562L11.7793 27.5369L11.9898 27.4667ZM11.3585 34.5531L11.148 34.7636L10.9375 34.8338L11.3585 34.5531ZM72.929 28.5457L82.2965 19.0792L81.4043 20.0705L86.4597 15.0811L78.2983 23.2425L75.8697 25.8362L72.1029 29.603L65.8249 35.881L69.3934 32.5437L64.5858 37.1531L57.994 43.745L65.7754 35.8314L70.17 31.4369L66.6015 34.7742L69.1623 32.3125L74.2507 27.3562L78.2653 23.2095L72.929 28.5457ZM82.6674 1.83549L84.3245 0.31872L83.3724 1.27088L82.6674 1.83549ZM64.5872 16.1312L62.9301 17.648L63.6351 17.0834L64.5872 16.1312ZM70.868 9.85044L80.0048 1.1214L74.6221 6.47142L70.868 9.85044ZM90.2409 41.9448L70.7578 61.4279L79.5093 53.4795L90.2409 41.9448ZM91.8088 42.5434L95.3963 38.8357L95.2132 39.139L99.5904 34.7618L98.1714 36.261L93.5912 40.9214L93.9973 40.3549L91.8088 42.5434ZM94.331 12.8233L89.9853 17.1691L89.2853 17.5555L86.7259 20.4284L90.142 17.3258L92.3149 15.1529L94.331 12.8233ZM44.7972 62.3259L76.9824 30.1406L59.2542 49.1955L44.7972 62.3259ZM77.1482 40.321L70.1709 47.5323L70 47.6463L70.0895 47.6164L68.1916 49.5779L70.185 47.5846L70.2105 47.5761L70.421 47.3656L70.37 47.3996L73.6557 44.1139L72.6416 45.5283L84.0768 33.893L87.6194 30.1502L76.6913 41.0783L77.1482 40.321ZM50.5355 34.3137L72.6617 12.1875L60.4955 25.3084L50.5355 34.3137ZM70.2104 44.0681L70.6314 43.7875L70.4209 43.998L70.2104 44.0681ZM71.263 40.0687L70.842 40.3494L71.0525 40.2792L71.263 40.0687ZM55.1084 12.4355L55.3189 12.225L54.8979 12.5056L55.1084 12.4355ZM48.8718 15.5785L60.2075 4.70496L49.4056 15.4006L48.8718 15.5785ZM23.7636 57.4491L29.9099 51.5854L26.1656 55.6123L27.2361 54.8244L23.435 58.6255L22.0681 59.9924L20.0562 62.0042L18.5082 63.8349L16.9601 65.6656L15.8328 66.2277L13.9315 67.7051L10.4821 71.0132L14.2832 67.2121L16.6775 65.383L21.1113 60.5253L20.477 60.7357L23.2937 58.4842L25.8277 55.9502L23.7636 57.4491ZM48.3825 74.1824L44.8832 77.8523L46.9145 75.8211L45.4748 77.4881L43.4493 79.2862L42.4082 80.1568L43.9215 79.0414L42.2487 80.7143L39.3752 83.8151L41.8844 81.3059L43.8473 79.6842L42.334 80.7995L44.7237 78.4098L46.1576 76.976L46.9713 75.8779L50.078 72.7713L48.1093 74.6262L48.3825 74.1824ZM29.2877 62.9906L29.0772 63.2011L28.8667 63.2713L29.2877 62.9906ZM29.7088 59.4823L29.9193 59.2719L29.4983 59.5525L29.7088 59.4823ZM29.0772 66.5687L28.8667 66.7792L28.6562 66.8494L29.0772 66.5687ZM22.9729 68.748L23.1834 68.5375L22.7624 68.8181L22.9729 68.748ZM3.8147e-05 91.7593L13.2499 79.1355L6.5001 86.2595L3.8147e-05 91.7593ZM16.0685 87.9974L17.1375 87.0687L16.5382 87.668L16.0685 87.9974ZM21.7869 79.3344L20.7179 80.263L21.1876 79.9337L21.7869 79.3344ZM12.3607 95.0755L13.4298 94.1469L12.8304 94.7462L12.3607 95.0755ZM42.7176 59.3801L43.2789 58.8187L43.0684 59.1696L42.7877 59.4502L42.2966 59.801L42.5772 59.3801H42.7176ZM26.3124 49.3152L24.3599 51.2676L23.996 51.3918L22.8956 52.732L24.4798 51.3875L25.456 50.4113L26.3124 49.3152ZM39.0689 63.3097L38.5777 63.6606L39.56 62.6782L39.0689 63.3097ZM20.3574 55.8032L19.3751 56.7856L19.8662 56.4347L20.3574 55.8032ZM39.9297 64.195L41.5504 62.3779L41.534 62.5907L43.5967 60.528L42.9746 61.2811L40.8628 63.5238L40.961 63.1637L39.9297 64.195ZM22.3921 55.457L21.3998 56.5696L22.0313 55.9381L21.9711 56.1587L23.2642 54.7854L23.6451 54.3243L22.3821 55.5873L22.3921 55.457ZM40.6473 92.4498L45.0485 88.0485L43.0066 90.4079L40.806 92.6085L37.3463 95.7507L39.9384 92.8412L40.6473 92.4498ZM18.5042 48.7973L11.5457 55.7558L10.4249 56.3746L6.32684 60.9746L11.7967 56.0067L15.2759 52.5275L18.5042 48.7973ZM32.7113 78.139L31.1131 79.7372L30.8432 79.8668L29.9145 80.9358L31.1833 79.8074L31.9823 79.0083L32.7113 78.139ZM21.7577 93.9525L31.2855 84.0344L30.8324 84.8777L42.4999 73.2102L38.7408 77.2295L26.5552 89.6753L27.5914 88.1187L21.7577 93.9525ZM98.5132 90.0591L89.9224 97.9224L93.5769 94.9953L98.5132 90.0591ZM97.8456 80.2105L99.5027 78.6937L98.5506 79.6459L97.8456 80.2105ZM88.5656 56.4599L78.9205 65.7009L82.1262 63.3036L78.1413 67.2885L73.7522 70.8692L74.7195 70.5082L67.717 78.117L63.992 81.0336L58.0146 87.011L63.4289 81.7988L66.3887 79.4454L68.1212 78.5213L70.5757 75.6625L73.0302 72.8038L76.194 69.64L78.3434 67.4906L84.3208 61.5132L82.6575 62.7723L88.5656 56.4599ZM85.1893 67.0375L83.7304 68.356L84.3561 67.8707L85.1893 67.0375ZM90.7969 58.2022L99.2725 50.5418L94.4317 55.3826L90.7969 58.2022ZM79.377 76.2172L77.9182 77.5357L78.5438 77.0504L79.377 76.2172ZM59.4922 91.7253L56.4011 94.1231L60.0049 90.8659L63.6087 87.6087L59.4922 91.7253ZM63.8833 75.4153L46 92.3896L49.6884 89.1193L53.3767 85.8491L63.8833 75.4153ZM71.6063 55.0765L69.6609 57.0219L69.3475 57.1949L68.2018 58.481L69.731 57.0921L70.7037 56.1194L71.6063 55.0765ZM55.1405 71.6857L61.4131 65.4131L57.958 69.1267L55.1405 71.6857ZM65.8396 69.4497L61.7138 73.7138L64.2308 71.1968L63.7637 71.8484L69.0313 66.4886L70.6632 64.7645L65.6292 69.7985L65.8396 69.4497ZM53.0034 65.4955L58.2258 59.8914L58.0558 60.4431L64.5517 53.9472L62.5136 56.2398L55.7841 63.2238L56.2513 62.2475L53.0034 65.4955ZM97.0997 71.2032L79.6514 88.6515L86.7697 80.814L97.0997 71.2032ZM35.1848 56.2513L31.93 59.9006L34.0012 57.8294L33.804 58.5527L38.0451 54.0485L39.2945 52.5361L35.1519 56.6787L35.1848 56.2513ZM66.8712 26.2471L78.1907 14.3099L77.7244 15.394L91.6784 1.4399L87.233 6.29715L72.7096 21.2323L73.8482 19.2701L66.8712 26.2471ZM28.0473 68.2068L20.4355 76.375L25.1695 71.641L24.4884 73.0639L34.297 62.8844L37.2675 59.5429L27.7995 69.0109L28.0473 68.2068ZM8.94067 39.5658L14.1631 33.9617L13.993 34.5134L20.4889 28.0175L18.4509 30.3101L11.7213 37.2941L12.1886 36.3178L8.94067 39.5658ZM99.7403 26L88 37.7404L93.2735 32.9508L99.7403 26ZM1.93388 8.08743L4.77765 5.04974L4.67856 5.34275L8.20743 1.81388L7.09578 3.05481L3.4355 6.84437L3.69832 6.32299L1.93388 8.08743ZM54.4485 44.211L48.5985 50.061L47.6563 50.5813L44.211 54.4485L48.8095 50.272L51.7345 47.347L54.4485 44.211Z" />
</pattern><pattern id="streaks-normal" x="0" y="0" width="100" height="100" patternUnits="userSpaceOnUse">
    <path fill="rgba(0, 0, 0, 0.16)" fill-rule="evenodd" clip-rule="evenodd" d="M58.1193 0H58.1703L55.4939 2.67644L58.1193 0ZM45.7725 0H45.811L41.2851 4.61498L42.7191 3.29325L37.0824 8.92997L35.0554 10.9569L32.0719 13.9404L29.6229 16.5017L27.1738 19.0631L25.8089 20.2034L23.2195 22.6244L18.181 27.6068L23.8178 21.97L27.0615 18.9508L33.8666 11.9773L33.1562 12.5194L37.0262 8.87383L40.784 5.11602L38.0299 7.64561L45.7725 0ZM23.1079 0H23.108L21.5814 1.66688L20.3126 2.79534L23.1079 0ZM7.53869 0H7.54254L7.50005 0.035944L7.53869 0ZM2.49995 0H2.52362L0.900245 1.59971L2.49995 0ZM0 3.64398V3.60744L0.278386 3.36559L0 3.64398ZM0 18.6564V18.5398L0.67985 17.8416L3.4459 15.0755L1.15701 17.1333L2.78713 15.6022L6.01437 12.507L8.5168 9.87253L5.15803 13.2313L11.0357 7.25453L10.4926 7.89678L13.6868 4.7686L8.54982 9.90555L7.05177 11.5687L4.68087 13.9396L0.729379 17.8911L3.01827 15.8333L0 18.6564ZM0 69.2431V69.178L1.64651 67.4763L1.46347 67.7796L5.84063 63.4025L4.42167 64.9016L0 69.4007V69.3408L0.247596 68.9955L0 69.2431ZM2.51594 100H2.49238L5.19989 97.2925L7.70071 95.0162L12.8713 89.6772L12.3094 90.0707L15.288 87.3167L18.1542 84.4504L16.0269 86.3532L22.8752 79.6172L18.5364 84.0683L19.6435 83.0734L15.3441 87.3728L13.798 88.9189L11.5224 91.1945L9.66768 93.1615L7.81297 95.1285L6.74529 95.9716L4.75024 97.7983L2.51594 100ZM7.54255 100H7.5387L9.81396 97.884L8.46606 99.2189L7.54255 100ZM45.8189 100H45.7807L46.9912 98.8047L45.8189 100ZM58.1784 100H58.1272L62.2952 95.7511L66.1408 91.9055L63.0037 94.8115L65.2507 92.6635L69.7117 88.3346L73.2165 84.6977L68.5469 89.3673L76.7379 81.0773L75.9634 81.9509L80.3913 77.5889L73.2496 84.7307L71.1346 87.0107L67.8384 90.3069L62.3447 95.8006L65.4818 92.8947L61.2625 96.9159L58.1784 100ZM75.4277 100H75.229L82.1834 92.9039L81.3403 93.5787L86.0063 89.1371L90.5601 84.5833L87.2464 87.6725L98.0937 76.9375L91.1673 83.9761L92.8932 82.3625L86.0625 89.1933L83.6062 91.6496L79.9907 95.265L77.011 98.357L75.4277 100ZM100 18.5398V18.6563L99.9556 18.6979L95.8065 22.847L100 18.5398ZM100 3.60743V3.64398L99.6791 3.9649L99.2094 4.29428L100 3.60743ZM75.4201 0L74.0312 1.4412L72.401 2.84687L69.281 5.79854L63.1812 11.8422L70.0119 5.01151L73.919 1.32893L75.2214 0H75.4201ZM100 69.1858V69.2509L98.059 71.1919L100 69.1858ZM100 69.3486V69.4085L99.8414 69.5698L100 69.3486ZM41.9398 28.8254L53.6223 16.993L52.5215 18.2437L54.7428 16.0575L54.6875 16.0759L54.8008 16.0004L58.842 12.0231L54.9925 15.8726L55.1085 15.7953L54.898 16.0058L54.84 16.0251L48.6523 22.2128L45.6419 25.473L40.9389 30.1759L33.1007 38.0142L37.5866 33.878L31.558 39.6068L23.3278 47.837L33.0257 37.9393L38.5125 32.4525L34.0266 36.5887L37.2369 33.5283L43.6074 27.3576L48.6023 22.1628L41.9398 28.8254ZM41.0977 17.0531L39.718 18.2925L40.312 17.8388L41.0977 17.0531ZM36.875 20.3106L48.1601 7.88137L42.3438 13.7478L36.875 20.3106ZM35.7125 25.8109L34.3328 27.0503L34.9268 26.5966L35.7125 25.8109ZM17.7022 39.7534L19.0819 38.514L18.8092 38.7867L36.7575 21.8045L23.1569 35.3051L13.5771 43.7372L18.1448 39.4154L17.7022 39.7534ZM3.48102 28.9281L1.53562 30.8735L1.22228 31.0465L0.0765686 32.3326L1.60579 30.9437L2.57849 29.971L3.48102 28.9281ZM0.953463 26.2027L19.5702 7.58594L9.31575 18.6078L0.953463 26.2027ZM23.7175 12.11L17.9339 18.0875L21.4622 14.5592L20.8074 15.4725L28.1915 7.95918L30.4791 5.54232L23.4224 12.599L23.7175 12.11ZM43.4641 43.1538L40.7872 46.1552L42.4907 44.4517L42.3285 45.0465L45.8166 41.3421L46.8441 40.0983L43.4371 43.5053L43.4641 43.1538ZM1.32715 48.3271L8.0918 41.5625L4.3657 45.5674L1.32715 48.3271ZM11.1479 31.2556L11.5689 30.975L11.3584 31.1855L11.1479 31.2556ZM11.9898 27.4667L12.2003 27.2562L11.7793 27.5369L11.9898 27.4667ZM11.3585 34.5531L11.148 34.7636L10.9375 34.8338L11.3585 34.5531ZM72.929 28.5457L82.2965 19.0792L81.4043 20.0705L86.4597 15.0811L78.2983 23.2425L75.8697 25.8362L72.1029 29.603L65.8249 35.881L69.3934 32.5437L64.5858 37.1531L57.994 43.745L65.7754 35.8314L70.17 31.4369L66.6015 34.7742L69.1623 32.3125L74.2507 27.3562L78.2653 23.2095L72.929 28.5457ZM82.6674 1.83549L84.3245 0.31872L83.3724 1.27088L82.6674 1.83549ZM64.5872 16.1312L62.9301 17.648L63.6351 17.0834L64.5872 16.1312ZM70.868 9.85044L80.0048 1.1214L74.6221 6.47142L70.868 9.85044ZM90.2409 41.9448L70.7578 61.4279L79.5093 53.4795L90.2409 41.9448ZM91.8088 42.5434L95.3963 38.8357L95.2132 39.139L99.5904 34.7618L98.1714 36.261L93.5912 40.9214L93.9973 40.3549L91.8088 42.5434ZM94.331 12.8233L89.9853 17.1691L89.2853 17.5555L86.7259 20.4284L90.142 17.3258L92.3149 15.1529L94.331 12.8233ZM44.7972 62.3259L76.9824 30.1406L59.2542 49.1955L44.7972 62.3259ZM77.1482 40.321L70.1709 47.5323L70 47.6463L70.0895 47.6164L68.1916 49.5779L70.185 47.5846L70.2105 47.5761L70.421 47.3656L70.37 47.3996L73.6557 44.1139L72.6416 45.5283L84.0768 33.893L87.6194 30.1502L76.6913 41.0783L77.1482 40.321ZM50.5355 34.3137L72.6617 12.1875L60.4955 25.3084L50.5355 34.3137ZM70.2104 44.0681L70.6314 43.7875L70.4209 43.998L70.2104 44.0681ZM71.263 40.0687L70.842 40.3494L71.0525 40.2792L71.263 40.0687ZM55.1084 12.4355L55.3189 12.225L54.8979 12.5056L55.1084 12.4355ZM48.8718 15.5785L60.2075 4.70496L49.4056 15.4006L48.8718 15.5785ZM23.7636 57.4491L29.9099 51.5854L26.1656 55.6123L27.2361 54.8244L23.435 58.6255L22.0681 59.9924L20.0562 62.0042L18.5082 63.8349L16.9601 65.6656L15.8328 66.2277L13.9315 67.7051L10.4821 71.0132L14.2832 67.2121L16.6775 65.383L21.1113 60.5253L20.477 60.7357L23.2937 58.4842L25.8277 55.9502L23.7636 57.4491ZM48.3825 74.1824L44.8832 77.8523L46.9145 75.8211L45.4748 77.4881L43.4493 79.2862L42.4082 80.1568L43.9215 79.0414L42.2487 80.7143L39.3752 83.8151L41.8844 81.3059L43.8473 79.6842L42.334 80.7995L44.7237 78.4098L46.1576 76.976L46.9713 75.8779L50.078 72.7713L48.1093 74.6262L48.3825 74.1824ZM29.2877 62.9906L29.0772 63.2011L28.8667 63.2713L29.2877 62.9906ZM29.7088 59.4823L29.9193 59.2719L29.4983 59.5525L29.7088 59.4823ZM29.0772 66.5687L28.8667 66.7792L28.6562 66.8494L29.0772 66.5687ZM22.9729 68.748L23.1834 68.5375L22.7624 68.8181L22.9729 68.748ZM3.8147e-05 91.7593L13.2499 79.1355L6.5001 86.2595L3.8147e-05 91.7593ZM16.0685 87.9974L17.1375 87.0687L16.5382 87.668L16.0685 87.9974ZM21.7869 79.3344L20.7179 80.263L21.1876 79.9337L21.7869 79.3344ZM12.3607 95.0755L13.4298 94.1469L12.8304 94.7462L12.3607 95.0755ZM42.7176 59.3801L43.2789 58.8187L43.0684 59.1696L42.7877 59.4502L42.2966 59.801L42.5772 59.3801H42.7176ZM26.3124 49.3152L24.3599 51.2676L23.996 51.3918L22.8956 52.732L24.4798 51.3875L25.456 50.4113L26.3124 49.3152ZM39.0689 63.3097L38.5777 63.6606L39.56 62.6782L39.0689 63.3097ZM20.3574 55.8032L19.3751 56.7856L19.8662 56.4347L20.3574 55.8032ZM39.9297 64.195L41.5504 62.3779L41.534 62.5907L43.5967 60.528L42.9746 61.2811L40.8628 63.5238L40.961 63.1637L39.9297 64.195ZM22.3921 55.457L21.3998 56.5696L22.0313 55.9381L21.9711 56.1587L23.2642 54.7854L23.6451 54.3243L22.3821 55.5873L22.3921 55.457ZM40.6473 92.4498L45.0485 88.0485L43.0066 90.4079L40.806 92.6085L37.3463 95.7507L39.9384 92.8412L40.6473 92.4498ZM18.5042 48.7973L11.5457 55.7558L10.4249 56.3746L6.32684 60.9746L11.7967 56.0067L15.2759 52.5275L18.5042 48.7973ZM32.7113 78.139L31.1131 79.7372L30.8432 79.8668L29.9145 80.9358L31.1833 79.8074L31.9823 79.0083L32.7113 78.139ZM21.7577 93.9525L31.2855 84.0344L30.8324 84.8777L42.4999 73.2102L38.7408 77.2295L26.5552 89.6753L27.5914 88.1187L21.7577 93.9525ZM98.5132 90.0591L89.9224 97.9224L93.5769 94.9953L98.5132 90.0591ZM97.8456 80.2105L99.5027 78.6937L98.5506 79.6459L97.8456 80.2105ZM88.5656 56.4599L78.9205 65.7009L82.1262 63.3036L78.1413 67.2885L73.7522 70.8692L74.7195 70.5082L67.717 78.117L63.992 81.0336L58.0146 87.011L63.4289 81.7988L66.3887 79.4454L68.1212 78.5213L70.5757 75.6625L73.0302 72.8038L76.194 69.64L78.3434 67.4906L84.3208 61.5132L82.6575 62.7723L88.5656 56.4599ZM85.1893 67.0375L83.7304 68.356L84.3561 67.8707L85.1893 67.0375ZM90.7969 58.2022L99.2725 50.5418L94.4317 55.3826L90.7969 58.2022ZM79.377 76.2172L77.9182 77.5357L78.5438 77.0504L79.377 76.2172ZM59.4922 91.7253L56.4011 94.1231L60.0049 90.8659L63.6087 87.6087L59.4922 91.7253ZM63.8833 75.4153L46 92.3896L49.6884 89.1193L53.3767 85.8491L63.8833 75.4153ZM71.6063 55.0765L69.6609 57.0219L69.3475 57.1949L68.2018 58.481L69.731 57.0921L70.7037 56.1194L71.6063 55.0765ZM55.1405 71.6857L61.4131 65.4131L57.958 69.1267L55.1405 71.6857ZM65.8396 69.4497L61.7138 73.7138L64.2308 71.1968L63.7637 71.8484L69.0313 66.4886L70.6632 64.7645L65.6292 69.7985L65.8396 69.4497ZM53.0034 65.4955L58.2258 59.8914L58.0558 60.4431L64.5517 53.9472L62.5136 56.2398L55.7841 63.2238L56.2513 62.2475L53.0034 65.4955ZM97.0997 71.2032L79.6514 88.6515L86.7697 80.814L97.0997 71.2032ZM35.1848 56.2513L31.93 59.9006L34.0012 57.8294L33.804 58.5527L38.0451 54.0485L39.2945 52.5361L35.1519 56.6787L35.1848 56.2513ZM66.8712 26.2471L78.1907 14.3099L77.7244 15.394L91.6784 1.4399L87.233 6.29715L72.7096 21.2323L73.8482 19.2701L66.8712 26.2471ZM28.0473 68.2068L20.4355 76.375L25.1695 71.641L24.4884 73.0639L34.297 62.8844L37.2675 59.5429L27.7995 69.0109L28.0473 68.2068ZM8.94067 39.5658L14.1631 33.9617L13.993 34.5134L20.4889 28.0175L18.4509 30.3101L11.7213 37.2941L12.1886 36.3178L8.94067 39.5658ZM99.7403 26L88 37.7404L93.2735 32.9508L99.7403 26ZM1.93388 8.08743L4.77765 5.04974L4.67856 5.34275L8.20743 1.81388L7.09578 3.05481L3.4355 6.84437L3.69832 6.32299L1.93388 8.08743ZM54.4485 44.211L48.5985 50.061L47.6563 50.5813L44.211 54.4485L48.8095 50.272L51.7345 47.347L54.4485 44.211Z" />
</pattern><pattern id="streaks-dark" x="0" y="0" width="100" height="100" patternUnits="userSpaceOnUse">
    <path fill="rgba(0, 0, 0, 0.32)" fill-rule="evenodd" clip-rule="evenodd" d="M58.1193 0H58.1703L55.4939 2.67644L58.1193 0ZM45.7725 0H45.811L41.2851 4.61498L42.7191 3.29325L37.0824 8.92997L35.0554 10.9569L32.0719 13.9404L29.6229 16.5017L27.1738 19.0631L25.8089 20.2034L23.2195 22.6244L18.181 27.6068L23.8178 21.97L27.0615 18.9508L33.8666 11.9773L33.1562 12.5194L37.0262 8.87383L40.784 5.11602L38.0299 7.64561L45.7725 0ZM23.1079 0H23.108L21.5814 1.66688L20.3126 2.79534L23.1079 0ZM7.53869 0H7.54254L7.50005 0.035944L7.53869 0ZM2.49995 0H2.52362L0.900245 1.59971L2.49995 0ZM0 3.64398V3.60744L0.278386 3.36559L0 3.64398ZM0 18.6564V18.5398L0.67985 17.8416L3.4459 15.0755L1.15701 17.1333L2.78713 15.6022L6.01437 12.507L8.5168 9.87253L5.15803 13.2313L11.0357 7.25453L10.4926 7.89678L13.6868 4.7686L8.54982 9.90555L7.05177 11.5687L4.68087 13.9396L0.729379 17.8911L3.01827 15.8333L0 18.6564ZM0 69.2431V69.178L1.64651 67.4763L1.46347 67.7796L5.84063 63.4025L4.42167 64.9016L0 69.4007V69.3408L0.247596 68.9955L0 69.2431ZM2.51594 100H2.49238L5.19989 97.2925L7.70071 95.0162L12.8713 89.6772L12.3094 90.0707L15.288 87.3167L18.1542 84.4504L16.0269 86.3532L22.8752 79.6172L18.5364 84.0683L19.6435 83.0734L15.3441 87.3728L13.798 88.9189L11.5224 91.1945L9.66768 93.1615L7.81297 95.1285L6.74529 95.9716L4.75024 97.7983L2.51594 100ZM7.54255 100H7.5387L9.81396 97.884L8.46606 99.2189L7.54255 100ZM45.8189 100H45.7807L46.9912 98.8047L45.8189 100ZM58.1784 100H58.1272L62.2952 95.7511L66.1408 91.9055L63.0037 94.8115L65.2507 92.6635L69.7117 88.3346L73.2165 84.6977L68.5469 89.3673L76.7379 81.0773L75.9634 81.9509L80.3913 77.5889L73.2496 84.7307L71.1346 87.0107L67.8384 90.3069L62.3447 95.8006L65.4818 92.8947L61.2625 96.9159L58.1784 100ZM75.4277 100H75.229L82.1834 92.9039L81.3403 93.5787L86.0063 89.1371L90.5601 84.5833L87.2464 87.6725L98.0937 76.9375L91.1673 83.9761L92.8932 82.3625L86.0625 89.1933L83.6062 91.6496L79.9907 95.265L77.011 98.357L75.4277 100ZM100 18.5398V18.6563L99.9556 18.6979L95.8065 22.847L100 18.5398ZM100 3.60743V3.64398L99.6791 3.9649L99.2094 4.29428L100 3.60743ZM75.4201 0L74.0312 1.4412L72.401 2.84687L69.281 5.79854L63.1812 11.8422L70.0119 5.01151L73.919 1.32893L75.2214 0H75.4201ZM100 69.1858V69.2509L98.059 71.1919L100 69.1858ZM100 69.3486V69.4085L99.8414 69.5698L100 69.3486ZM41.9398 28.8254L53.6223 16.993L52.5215 18.2437L54.7428 16.0575L54.6875 16.0759L54.8008 16.0004L58.842 12.0231L54.9925 15.8726L55.1085 15.7953L54.898 16.0058L54.84 16.0251L48.6523 22.2128L45.6419 25.473L40.9389 30.1759L33.1007 38.0142L37.5866 33.878L31.558 39.6068L23.3278 47.837L33.0257 37.9393L38.5125 32.4525L34.0266 36.5887L37.2369 33.5283L43.6074 27.3576L48.6023 22.1628L41.9398 28.8254ZM41.0977 17.0531L39.718 18.2925L40.312 17.8388L41.0977 17.0531ZM36.875 20.3106L48.1601 7.88137L42.3438 13.7478L36.875 20.3106ZM35.7125 25.8109L34.3328 27.0503L34.9268 26.5966L35.7125 25.8109ZM17.7022 39.7534L19.0819 38.514L18.8092 38.7867L36.7575 21.8045L23.1569 35.3051L13.5771 43.7372L18.1448 39.4154L17.7022 39.7534ZM3.48102 28.9281L1.53562 30.8735L1.22228 31.0465L0.0765686 32.3326L1.60579 30.9437L2.57849 29.971L3.48102 28.9281ZM0.953463 26.2027L19.5702 7.58594L9.31575 18.6078L0.953463 26.2027ZM23.7175 12.11L17.9339 18.0875L21.4622 14.5592L20.8074 15.4725L28.1915 7.95918L30.4791 5.54232L23.4224 12.599L23.7175 12.11ZM43.4641 43.1538L40.7872 46.1552L42.4907 44.4517L42.3285 45.0465L45.8166 41.3421L46.8441 40.0983L43.4371 43.5053L43.4641 43.1538ZM1.32715 48.3271L8.0918 41.5625L4.3657 45.5674L1.32715 48.3271ZM11.1479 31.2556L11.5689 30.975L11.3584 31.1855L11.1479 31.2556ZM11.9898 27.4667L12.2003 27.2562L11.7793 27.5369L11.9898 27.4667ZM11.3585 34.5531L11.148 34.7636L10.9375 34.8338L11.3585 34.5531ZM72.929 28.5457L82.2965 19.0792L81.4043 20.0705L86.4597 15.0811L78.2983 23.2425L75.8697 25.8362L72.1029 29.603L65.8249 35.881L69.3934 32.5437L64.5858 37.1531L57.994 43.745L65.7754 35.8314L70.17 31.4369L66.6015 34.7742L69.1623 32.3125L74.2507 27.3562L78.2653 23.2095L72.929 28.5457ZM82.6674 1.83549L84.3245 0.31872L83.3724 1.27088L82.6674 1.83549ZM64.5872 16.1312L62.9301 17.648L63.6351 17.0834L64.5872 16.1312ZM70.868 9.85044L80.0048 1.1214L74.6221 6.47142L70.868 9.85044ZM90.2409 41.9448L70.7578 61.4279L79.5093 53.4795L90.2409 41.9448ZM91.8088 42.5434L95.3963 38.8357L95.2132 39.139L99.5904 34.7618L98.1714 36.261L93.5912 40.9214L93.9973 40.3549L91.8088 42.5434ZM94.331 12.8233L89.9853 17.1691L89.2853 17.5555L86.7259 20.4284L90.142 17.3258L92.3149 15.1529L94.331 12.8233ZM44.7972 62.3259L76.9824 30.1406L59.2542 49.1955L44.7972 62.3259ZM77.1482 40.321L70.1709 47.5323L70 47.6463L70.0895 47.6164L68.1916 49.5779L70.185 47.5846L70.2105 47.5761L70.421 47.3656L70.37 47.3996L73.6557 44.1139L72.6416 45.5283L84.0768 33.893L87.6194 30.1502L76.6913 41.0783L77.1482 40.321ZM50.5355 34.3137L72.6617 12.1875L60.4955 25.3084L50.5355 34.3137ZM70.2104 44.0681L70.6314 43.7875L70.4209 43.998L70.2104 44.0681ZM71.263 40.0687L70.842 40.3494L71.0525 40.2792L71.263 40.0687ZM55.1084 12.4355L55.3189 12.225L54.8979 12.5056L55.1084 12.4355ZM48.8718 15.5785L60.2075 4.70496L49.4056 15.4006L48.8718 15.5785ZM23.7636 57.4491L29.9099 51.5854L26.1656 55.6123L27.2361 54.8244L23.435 58.6255L22.0681 59.9924L20.0562 62.0042L18.5082 63.8349L16.9601 65.6656L15.8328 66.2277L13.9315 67.7051L10.4821 71.0132L14.2832 67.2121L16.6775 65.383L21.1113 60.5253L20.477 60.7357L23.2937 58.4842L25.8277 55.9502L23.7636 57.4491ZM48.3825 74.1824L44.8832 77.8523L46.9145 75.8211L45.4748 77.4881L43.4493 79.2862L42.4082 80.1568L43.9215 79.0414L42.2487 80.7143L39.3752 83.8151L41.8844 81.3059L43.8473 79.6842L42.334 80.7995L44.7237 78.4098L46.1576 76.976L46.9713 75.8779L50.078 72.7713L48.1093 74.6262L48.3825 74.1824ZM29.2877 62.9906L29.0772 63.2011L28.8667 63.2713L29.2877 62.9906ZM29.7088 59.4823L29.9193 59.2719L29.4983 59.5525L29.7088 59.4823ZM29.0772 66.5687L28.8667 66.7792L28.6562 66.8494L29.0772 66.5687ZM22.9729 68.748L23.1834 68.5375L22.7624 68.8181L22.9729 68.748ZM3.8147e-05 91.7593L13.2499 79.1355L6.5001 86.2595L3.8147e-05 91.7593ZM16.0685 87.9974L17.1375 87.0687L16.5382 87.668L16.0685 87.9974ZM21.7869 79.3344L20.7179 80.263L21.1876 79.9337L21.7869 79.3344ZM12.3607 95.0755L13.4298 94.1469L12.8304 94.7462L12.3607 95.0755ZM42.7176 59.3801L43.2789 58.8187L43.0684 59.1696L42.7877 59.4502L42.2966 59.801L42.5772 59.3801H42.7176ZM26.3124 49.3152L24.3599 51.2676L23.996 51.3918L22.8956 52.732L24.4798 51.3875L25.456 50.4113L26.3124 49.3152ZM39.0689 63.3097L38.5777 63.6606L39.56 62.6782L39.0689 63.3097ZM20.3574 55.8032L19.3751 56.7856L19.8662 56.4347L20.3574 55.8032ZM39.9297 64.195L41.5504 62.3779L41.534 62.5907L43.5967 60.528L42.9746 61.2811L40.8628 63.5238L40.961 63.1637L39.9297 64.195ZM22.3921 55.457L21.3998 56.5696L22.0313 55.9381L21.9711 56.1587L23.2642 54.7854L23.6451 54.3243L22.3821 55.5873L22.3921 55.457ZM40.6473 92.4498L45.0485 88.0485L43.0066 90.4079L40.806 92.6085L37.3463 95.7507L39.9384 92.8412L40.6473 92.4498ZM18.5042 48.7973L11.5457 55.7558L10.4249 56.3746L6.32684 60.9746L11.7967 56.0067L15.2759 52.5275L18.5042 48.7973ZM32.7113 78.139L31.1131 79.7372L30.8432 79.8668L29.9145 80.9358L31.1833 79.8074L31.9823 79.0083L32.7113 78.139ZM21.7577 93.9525L31.2855 84.0344L30.8324 84.8777L42.4999 73.2102L38.7408 77.2295L26.5552 89.6753L27.5914 88.1187L21.7577 93.9525ZM98.5132 90.0591L89.9224 97.9224L93.5769 94.9953L98.5132 90.0591ZM97.8456 80.2105L99.5027 78.6937L98.5506 79.6459L97.8456 80.2105ZM88.5656 56.4599L78.9205 65.7009L82.1262 63.3036L78.1413 67.2885L73.7522 70.8692L74.7195 70.5082L67.717 78.117L63.992 81.0336L58.0146 87.011L63.4289 81.7988L66.3887 79.4454L68.1212 78.5213L70.5757 75.6625L73.0302 72.8038L76.194 69.64L78.3434 67.4906L84.3208 61.5132L82.6575 62.7723L88.5656 56.4599ZM85.1893 67.0375L83.7304 68.356L84.3561 67.8707L85.1893 67.0375ZM90.7969 58.2022L99.2725 50.5418L94.4317 55.3826L90.7969 58.2022ZM79.377 76.2172L77.9182 77.5357L78.5438 77.0504L79.377 76.2172ZM59.4922 91.7253L56.4011 94.1231L60.0049 90.8659L63.6087 87.6087L59.4922 91.7253ZM63.8833 75.4153L46 92.3896L49.6884 89.1193L53.3767 85.8491L63.8833 75.4153ZM71.6063 55.0765L69.6609 57.0219L69.3475 57.1949L68.2018 58.481L69.731 57.0921L70.7037 56.1194L71.6063 55.0765ZM55.1405 71.6857L61.4131 65.4131L57.958 69.1267L55.1405 71.6857ZM65.8396 69.4497L61.7138 73.7138L64.2308 71.1968L63.7637 71.8484L69.0313 66.4886L70.6632 64.7645L65.6292 69.7985L65.8396 69.4497ZM53.0034 65.4955L58.2258 59.8914L58.0558 60.4431L64.5517 53.9472L62.5136 56.2398L55.7841 63.2238L56.2513 62.2475L53.0034 65.4955ZM97.0997 71.2032L79.6514 88.6515L86.7697 80.814L97.0997 71.2032ZM35.1848 56.2513L31.93 59.9006L34.0012 57.8294L33.804 58.5527L38.0451 54.0485L39.2945 52.5361L35.1519 56.6787L35.1848 56.2513ZM66.8712 26.2471L78.1907 14.3099L77.7244 15.394L91.6784 1.4399L87.233 6.29715L72.7096 21.2323L73.8482 19.2701L66.8712 26.2471ZM28.0473 68.2068L20.4355 76.375L25.1695 71.641L24.4884 73.0639L34.297 62.8844L37.2675 59.5429L27.7995 69.0109L28.0473 68.2068ZM8.94067 39.5658L14.1631 33.9617L13.993 34.5134L20.4889 28.0175L18.4509 30.3101L11.7213 37.2941L12.1886 36.3178L8.94067 39.5658ZM99.7403 26L88 37.7404L93.2735 32.9508L99.7403 26ZM1.93388 8.08743L4.77765 5.04974L4.67856 5.34275L8.20743 1.81388L7.09578 3.05481L3.4355 6.84437L3.69832 6.32299L1.93388 8.08743ZM54.4485 44.211L48.5985 50.061L47.6563 50.5813L44.211 54.4485L48.8095 50.272L51.7345 47.347L54.4485 44.211Z" />
</pattern><pattern id="streaks-darker" x="0" y="0" width="100" height="100" patternUnits="userSpaceOnUse">
    <path fill="rgba(255, 255, 255, 0.24)" fill-rule="evenodd" clip-rule="evenodd" d="M58.1193 0H58.1703L55.4939 2.67644L58.1193 0ZM45.7725 0H45.811L41.2851 4.61498L42.7191 3.29325L37.0824 8.92997L35.0554 10.9569L32.0719 13.9404L29.6229 16.5017L27.1738 19.0631L25.8089 20.2034L23.2195 22.6244L18.181 27.6068L23.8178 21.97L27.0615 18.9508L33.8666 11.9773L33.1562 12.5194L37.0262 8.87383L40.784 5.11602L38.0299 7.64561L45.7725 0ZM23.1079 0H23.108L21.5814 1.66688L20.3126 2.79534L23.1079 0ZM7.53869 0H7.54254L7.50005 0.035944L7.53869 0ZM2.49995 0H2.52362L0.900245 1.59971L2.49995 0ZM0 3.64398V3.60744L0.278386 3.36559L0 3.64398ZM0 18.6564V18.5398L0.67985 17.8416L3.4459 15.0755L1.15701 17.1333L2.78713 15.6022L6.01437 12.507L8.5168 9.87253L5.15803 13.2313L11.0357 7.25453L10.4926 7.89678L13.6868 4.7686L8.54982 9.90555L7.05177 11.5687L4.68087 13.9396L0.729379 17.8911L3.01827 15.8333L0 18.6564ZM0 69.2431V69.178L1.64651 67.4763L1.46347 67.7796L5.84063 63.4025L4.42167 64.9016L0 69.4007V69.3408L0.247596 68.9955L0 69.2431ZM2.51594 100H2.49238L5.19989 97.2925L7.70071 95.0162L12.8713 89.6772L12.3094 90.0707L15.288 87.3167L18.1542 84.4504L16.0269 86.3532L22.8752 79.6172L18.5364 84.0683L19.6435 83.0734L15.3441 87.3728L13.798 88.9189L11.5224 91.1945L9.66768 93.1615L7.81297 95.1285L6.74529 95.9716L4.75024 97.7983L2.51594 100ZM7.54255 100H7.5387L9.81396 97.884L8.46606 99.2189L7.54255 100ZM45.8189 100H45.7807L46.9912 98.8047L45.8189 100ZM58.1784 100H58.1272L62.2952 95.7511L66.1408 91.9055L63.0037 94.8115L65.2507 92.6635L69.7117 88.3346L73.2165 84.6977L68.5469 89.3673L76.7379 81.0773L75.9634 81.9509L80.3913 77.5889L73.2496 84.7307L71.1346 87.0107L67.8384 90.3069L62.3447 95.8006L65.4818 92.8947L61.2625 96.9159L58.1784 100ZM75.4277 100H75.229L82.1834 92.9039L81.3403 93.5787L86.0063 89.1371L90.5601 84.5833L87.2464 87.6725L98.0937 76.9375L91.1673 83.9761L92.8932 82.3625L86.0625 89.1933L83.6062 91.6496L79.9907 95.265L77.011 98.357L75.4277 100ZM100 18.5398V18.6563L99.9556 18.6979L95.8065 22.847L100 18.5398ZM100 3.60743V3.64398L99.6791 3.9649L99.2094 4.29428L100 3.60743ZM75.4201 0L74.0312 1.4412L72.401 2.84687L69.281 5.79854L63.1812 11.8422L70.0119 5.01151L73.919 1.32893L75.2214 0H75.4201ZM100 69.1858V69.2509L98.059 71.1919L100 69.1858ZM100 69.3486V69.4085L99.8414 69.5698L100 69.3486ZM41.9398 28.8254L53.6223 16.993L52.5215 18.2437L54.7428 16.0575L54.6875 16.0759L54.8008 16.0004L58.842 12.0231L54.9925 15.8726L55.1085 15.7953L54.898 16.0058L54.84 16.0251L48.6523 22.2128L45.6419 25.473L40.9389 30.1759L33.1007 38.0142L37.5866 33.878L31.558 39.6068L23.3278 47.837L33.0257 37.9393L38.5125 32.4525L34.0266 36.5887L37.2369 33.5283L43.6074 27.3576L48.6023 22.1628L41.9398 28.8254ZM41.0977 17.0531L39.718 18.2925L40.312 17.8388L41.0977 17.0531ZM36.875 20.3106L48.1601 7.88137L42.3438 13.7478L36.875 20.3106ZM35.7125 25.8109L34.3328 27.0503L34.9268 26.5966L35.7125 25.8109ZM17.7022 39.7534L19.0819 38.514L18.8092 38.7867L36.7575 21.8045L23.1569 35.3051L13.5771 43.7372L18.1448 39.4154L17.7022 39.7534ZM3.48102 28.9281L1.53562 30.8735L1.22228 31.0465L0.0765686 32.3326L1.60579 30.9437L2.57849 29.971L3.48102 28.9281ZM0.953463 26.2027L19.5702 7.58594L9.31575 18.6078L0.953463 26.2027ZM23.7175 12.11L17.9339 18.0875L21.4622 14.5592L20.8074 15.4725L28.1915 7.95918L30.4791 5.54232L23.4224 12.599L23.7175 12.11ZM43.4641 43.1538L40.7872 46.1552L42.4907 44.4517L42.3285 45.0465L45.8166 41.3421L46.8441 40.0983L43.4371 43.5053L43.4641 43.1538ZM1.32715 48.3271L8.0918 41.5625L4.3657 45.5674L1.32715 48.3271ZM11.1479 31.2556L11.5689 30.975L11.3584 31.1855L11.1479 31.2556ZM11.9898 27.4667L12.2003 27.2562L11.7793 27.5369L11.9898 27.4667ZM11.3585 34.5531L11.148 34.7636L10.9375 34.8338L11.3585 34.5531ZM72.929 28.5457L82.2965 19.0792L81.4043 20.0705L86.4597 15.0811L78.2983 23.2425L75.8697 25.8362L72.1029 29.603L65.8249 35.881L69.3934 32.5437L64.5858 37.1531L57.994 43.745L65.7754 35.8314L70.17 31.4369L66.6015 34.7742L69.1623 32.3125L74.2507 27.3562L78.2653 23.2095L72.929 28.5457ZM82.6674 1.83549L84.3245 0.31872L83.3724 1.27088L82.6674 1.83549ZM64.5872 16.1312L62.9301 17.648L63.6351 17.0834L64.5872 16.1312ZM70.868 9.85044L80.0048 1.1214L74.6221 6.47142L70.868 9.85044ZM90.2409 41.9448L70.7578 61.4279L79.5093 53.4795L90.2409 41.9448ZM91.8088 42.5434L95.3963 38.8357L95.2132 39.139L99.5904 34.7618L98.1714 36.261L93.5912 40.9214L93.9973 40.3549L91.8088 42.5434ZM94.331 12.8233L89.9853 17.1691L89.2853 17.5555L86.7259 20.4284L90.142 17.3258L92.3149 15.1529L94.331 12.8233ZM44.7972 62.3259L76.9824 30.1406L59.2542 49.1955L44.7972 62.3259ZM77.1482 40.321L70.1709 47.5323L70 47.6463L70.0895 47.6164L68.1916 49.5779L70.185 47.5846L70.2105 47.5761L70.421 47.3656L70.37 47.3996L73.6557 44.1139L72.6416 45.5283L84.0768 33.893L87.6194 30.1502L76.6913 41.0783L77.1482 40.321ZM50.5355 34.3137L72.6617 12.1875L60.4955 25.3084L50.5355 34.3137ZM70.2104 44.0681L70.6314 43.7875L70.4209 43.998L70.2104 44.0681ZM71.263 40.0687L70.842 40.3494L71.0525 40.2792L71.263 40.0687ZM55.1084 12.4355L55.3189 12.225L54.8979 12.5056L55.1084 12.4355ZM48.8718 15.5785L60.2075 4.70496L49.4056 15.4006L48.8718 15.5785ZM23.7636 57.4491L29.9099 51.5854L26.1656 55.6123L27.2361 54.8244L23.435 58.6255L22.0681 59.9924L20.0562 62.0042L18.5082 63.8349L16.9601 65.6656L15.8328 66.2277L13.9315 67.7051L10.4821 71.0132L14.2832 67.2121L16.6775 65.383L21.1113 60.5253L20.477 60.7357L23.2937 58.4842L25.8277 55.9502L23.7636 57.4491ZM48.3825 74.1824L44.8832 77.8523L46.9145 75.8211L45.4748 77.4881L43.4493 79.2862L42.4082 80.1568L43.9215 79.0414L42.2487 80.7143L39.3752 83.8151L41.8844 81.3059L43.8473 79.6842L42.334 80.7995L44.7237 78.4098L46.1576 76.976L46.9713 75.8779L50.078 72.7713L48.1093 74.6262L48.3825 74.1824ZM29.2877 62.9906L29.0772 63.2011L28.8667 63.2713L29.2877 62.9906ZM29.7088 59.4823L29.9193 59.2719L29.4983 59.5525L29.7088 59.4823ZM29.0772 66.5687L28.8667 66.7792L28.6562 66.8494L29.0772 66.5687ZM22.9729 68.748L23.1834 68.5375L22.7624 68.8181L22.9729 68.748ZM3.8147e-05 91.7593L13.2499 79.1355L6.5001 86.2595L3.8147e-05 91.7593ZM16.0685 87.9974L17.1375 87.0687L16.5382 87.668L16.0685 87.9974ZM21.7869 79.3344L20.7179 80.263L21.1876 79.9337L21.7869 79.3344ZM12.3607 95.0755L13.4298 94.1469L12.8304 94.7462L12.3607 95.0755ZM42.7176 59.3801L43.2789 58.8187L43.0684 59.1696L42.7877 59.4502L42.2966 59.801L42.5772 59.3801H42.7176ZM26.3124 49.3152L24.3599 51.2676L23.996 51.3918L22.8956 52.732L24.4798 51.3875L25.456 50.4113L26.3124 49.3152ZM39.0689 63.3097L38.5777 63.6606L39.56 62.6782L39.0689 63.3097ZM20.3574 55.8032L19.3751 56.7856L19.8662 56.4347L20.3574 55.8032ZM39.9297 64.195L41.5504 62.3779L41.534 62.5907L43.5967 60.528L42.9746 61.2811L40.8628 63.5238L40.961 63.1637L39.9297 64.195ZM22.3921 55.457L21.3998 56.5696L22.0313 55.9381L21.9711 56.1587L23.2642 54.7854L23.6451 54.3243L22.3821 55.5873L22.3921 55.457ZM40.6473 92.4498L45.0485 88.0485L43.0066 90.4079L40.806 92.6085L37.3463 95.7507L39.9384 92.8412L40.6473 92.4498ZM18.5042 48.7973L11.5457 55.7558L10.4249 56.3746L6.32684 60.9746L11.7967 56.0067L15.2759 52.5275L18.5042 48.7973ZM32.7113 78.139L31.1131 79.7372L30.8432 79.8668L29.9145 80.9358L31.1833 79.8074L31.9823 79.0083L32.7113 78.139ZM21.7577 93.9525L31.2855 84.0344L30.8324 84.8777L42.4999 73.2102L38.7408 77.2295L26.5552 89.6753L27.5914 88.1187L21.7577 93.9525ZM98.5132 90.0591L89.9224 97.9224L93.5769 94.9953L98.5132 90.0591ZM97.8456 80.2105L99.5027 78.6937L98.5506 79.6459L97.8456 80.2105ZM88.5656 56.4599L78.9205 65.7009L82.1262 63.3036L78.1413 67.2885L73.7522 70.8692L74.7195 70.5082L67.717 78.117L63.992 81.0336L58.0146 87.011L63.4289 81.7988L66.3887 79.4454L68.1212 78.5213L70.5757 75.6625L73.0302 72.8038L76.194 69.64L78.3434 67.4906L84.3208 61.5132L82.6575 62.7723L88.5656 56.4599ZM85.1893 67.0375L83.7304 68.356L84.3561 67.8707L85.1893 67.0375ZM90.7969 58.2022L99.2725 50.5418L94.4317 55.3826L90.7969 58.2022ZM79.377 76.2172L77.9182 77.5357L78.5438 77.0504L79.377 76.2172ZM59.4922 91.7253L56.4011 94.1231L60.0049 90.8659L63.6087 87.6087L59.4922 91.7253ZM63.8833 75.4153L46 92.3896L49.6884 89.1193L53.3767 85.8491L63.8833 75.4153ZM71.6063 55.0765L69.6609 57.0219L69.3475 57.1949L68.2018 58.481L69.731 57.0921L70.7037 56.1194L71.6063 55.0765ZM55.1405 71.6857L61.4131 65.4131L57.958 69.1267L55.1405 71.6857ZM65.8396 69.4497L61.7138 73.7138L64.2308 71.1968L63.7637 71.8484L69.0313 66.4886L70.6632 64.7645L65.6292 69.7985L65.8396 69.4497ZM53.0034 65.4955L58.2258 59.8914L58.0558 60.4431L64.5517 53.9472L62.5136 56.2398L55.7841 63.2238L56.2513 62.2475L53.0034 65.4955ZM97.0997 71.2032L79.6514 88.6515L86.7697 80.814L97.0997 71.2032ZM35.1848 56.2513L31.93 59.9006L34.0012 57.8294L33.804 58.5527L38.0451 54.0485L39.2945 52.5361L35.1519 56.6787L35.1848 56.2513ZM66.8712 26.2471L78.1907 14.3099L77.7244 15.394L91.6784 1.4399L87.233 6.29715L72.7096 21.2323L73.8482 19.2701L66.8712 26.2471ZM28.0473 68.2068L20.4355 76.375L25.1695 71.641L24.4884 73.0639L34.297 62.8844L37.2675 59.5429L27.7995 69.0109L28.0473 68.2068ZM8.94067 39.5658L14.1631 33.9617L13.993 34.5134L20.4889 28.0175L18.4509 30.3101L11.7213 37.2941L12.1886 36.3178L8.94067 39.5658ZM99.7403 26L88 37.7404L93.2735 32.9508L99.7403 26ZM1.93388 8.08743L4.77765 5.04974L4.67856 5.34275L8.20743 1.81388L7.09578 3.05481L3.4355 6.84437L3.69832 6.32299L1.93388 8.08743ZM54.4485 44.211L48.5985 50.061L47.6563 50.5813L44.211 54.4485L48.8095 50.272L51.7345 47.347L54.4485 44.211Z" />
</pattern></defs><g id="dataset"><g class="shape" ><path d="M 12 52 C 12 28 62 28 67 28 C 73 28 122 28 122 52 V 122 C 122 146 73 146 67 146 C 62 146 12 146 12 122 V 52 Z" class="shape stroke-B1 fill-AA4" style="stroke-width:2;" /><path d="M10.000089 50.340129 M10.000089 50.340129 C12.963884 27.680246, 63.163171 27.439876, 67.405312 28.857263 M8.269924 49.546535 C11.429286 29.079289, 60.378336 28.661496, 67.490419 26.033797 M67.490419 26.033797 C73.172784 28.488053, 120.839251 29.505631, 122.878905 53.627398 M65.840465 25.110353 C70.813208 29.373630, 123.537822 30.238050, 122.570257 53.920880 M121.938173 54.550467 C122.335115 69.354792, 121.918382 84.082057, 120.850022 120.531127 M121.726982 54.182009 C124.113513 75.056958, 123.017534 95.655449, 122.473743 121.158203 M122.570257 122 C121.596476 147.518251, 72.525848 146.228918, 66.263446 147.836456 M120.683404 121.712535 C123.989807 145.980885, 75.347374 146.104610, 66.780316 146.659546 M66.780316 146.659546 C61.874775 145.279395, 11.718532 147.260766, 11.736186 123.451469 M65.251935 146.187880 C60.492399 147.594156, 13.538052 144.318774, 12.224995 122.739750 M10.917117 122.200341 C9.011733 100.857484, 12.788774 75.611946, 11.646615 53.045551 M12.687773 123.505991 C11.291456 95.230958, 13.033084 67.738274, 11.751067 51.032039 M12.416186 51.825268 C11.908831 51.709839, 10.927929 51.212137, 10.150798 50.212019 M12.202835 51.885032 C11.413902 51.523430, 10.915141 50.909952, 9.951358 50.280753" class="shape stroke-B1 fill-AA4" style="stroke-width:2;" /><path d="M 12 52 C 12 28 62 28 67 28 C 73 28 122 28 122 52 V 122 C 122 146 73 146 67 146 C 62 146 12 146 12 122 V 52 Z" class=" sketch-overlay-AA4" /><path d="M10.000089 50.340129 M10.000089 50.340129 C12.963884 27.680246, 63.163171 27.439876, 67.405312 28.857263 M8.269924 49.546535 C11.429286 29.079289, 60.378336 28.661496, 67.490419 26.033797 M67.490419 26.033797 C73.172784 28.488053, 120.839251 29.505631, 122.878905 53.627398 M65.840465 25.110353 C70.813208 29.373630, 123.537822 30.238050, 122.570257 53.920880 M121.938173 54.550467 C122.335115 69.354792, 121.918382 84.082057, 120.850022 120.531127 M121.726982 54.182009 C124.113513 75.056958, 123.017534 95.655449, 122.473743 121.158203 M122.570257 122 C121.596476 147.518251, 72.525848 146.228918, 66.263446 147.836456 M120.683404 121.712535 C123.989807 145.980885, 75.347374 146.104610, 66.780316 146.659546 M66.780316 146.659546 C61.874775 145.279395, 11.718532 147.260766, 11.736186 123.451469 M65.251935 146.187880 C60.492399 147.594156, 13.538052 144.318774, 12.224995 122.739750 M10.917117 122.200341 C9.011733 100.857484, 12.788774 75.611946, 11.646615 53.045551 M12.687773 123.505991 C11.291456 95.230958, 13.033084 67.738274, 11.751067 51.032039 M12.416186 51.825268 C11.908831 51.709839, 10.927929 51.212137, 10.150798 50.212019 M12.202835 51.885032 C11.413902 51.523430, 10.915141 50.909952, 9.951358 50.280753" class=" sketch-overlay-AA4 sketch-overlay-AA4" /><path d="M 12 52 C 12 76 62 76 67 76 C 73 76 122 76 122 52" class="shape stroke-B1 fill-AA4" style="stroke-width:2;" /><path d="M10.000089 50.340129 M10.000089 50.340129 C12.963884 75.680246, 63.163171 75.439876, 67.405312 76.857263 M8.269924 49.546535 C11.429286 77.079289, 60.378336 76.661496, 67.490419 74.033797 M67.490419 74.033797 C73.172784 76.488053, 120.839251 77.505631, 122.878905 53.627398 M65.840465 73.110353 C70.813208 77.373630, 123.537822 78.238050, 122.570257 53.920880" class="shape stroke-B1 fill-AA4" style="stroke-width:2;" /><path d="M 12 52 C 12 76 62 76 67 76 C 73 76 122 76 122 52" class=" sketch-overlay-AA4" /><path d="M10.000089 50.340129 M10.000089 50.340129 C12.963884 75.680246, 63.163171 75.439876, 67.405312 76.857263 M8.269924 49.546535 C11.429286 77.079289, 60.378336 76.661496, 67.490419 74.033797 M67.490419 74.033797 C73.172784 76.488053, 120.839251 77.505631, 122.878905 53.627398 M65.840465 73.110353 C70.813208 77.373630, 123.537822 78.238050, 122.570257 53.920880" class=" sketch-overlay-AA4 sketch-overlay-AA4" /></g><text x="67.000000" y="104.500000" fill="#0A0F25" class="text-bold fill-N1" style="text-anchor:middle;font-size:16px">Dataset</text></g><g id="split"><g class="shape" ><path d="M 339 133 C 338 133 337 133 336 133 L 193 88 C 191 88 191 87 193 86 L 336 41 C 338 41 340 41 341 41 L 484 86 C 486 86 486 87 484 88 L 342 133 C 341 133 340 133 339 133 Z" class="shape stroke-B1 fill-N4" style="stroke-width:2;" /><path d="M337.000089 131.340129 M337.000089 131.340129 C338.963884 132.680246, 338.163171 132.439876, 336.405312 133.857263 M335.269924 130.546535 C337.429286 134.079289, 335.378336 133.661496, 336.490419 131.033797 M336.978473 129.873048 C287.942870 114.830502, 236.160946 102.135392, 194.536704 86.250566 M335.670024 131.729071 C284.595074 118.012224, 234.413304 102.462717, 193.297677 87.200725 M193 88 C189.531127 88.054625, 191.813753 87.704487, 193.484064 84.279764 M191.313449 88.522259 C190.733199 89.288035, 190.758714 84.895508, 195.473147 87.316002 M196.991399 86.841850 C231.834272 73.807117, 268.300670 63.329133, 336.527637 42.591845 M195.341240 88.041736 C236.591381 72.978705, 278.563874 60.110001, 335.235809 40.764166 M336 41 C336.793919 42.275325, 341.230441 39.655019, 341.179996 41.591800 M336.435913 42.996446 C337.325739 38.748774, 341.101851 43.470075, 339.060602 39.365153 M340.871633 39.618851 C368.909367 49.034236, 404.092196 56.859476, 484.237450 87.975109 M338.618889 39.431594 C384.946108 58.032752, 432.302867 73.436396, 484.617419 85.436314 M484 86 C485.076967 86.275452, 486.347317 88.365202, 484.708439 89.085850 M483.680684 84.343321 C487.659662 84.581013, 485.122225 85.930485, 482.068824 88.249977 M483.852695 89.472483 C447.651714 99.370959, 414.411094 108.821793, 340.505498 131.928189 M482.442301 88.347985 C449.752781 101.071771, 416.602173 110.983009, 341.979859 132.808723 M342 133 C341.173727 131.019360, 340.567213 132.940016, 340.753476 131.085645 M342.559969 131.308489 C340.523667 134.943322, 341.120250 133.611089, 340.399791 132.328261 M340.202503 131.992053 C339.709715 132.038113, 339.010240 131.729962, 336.858896 131.065336 M340.518629 132.278107 C339.410881 132.027085, 338.453839 131.833204, 337.105391 131.426616" class="shape stroke-B1 fill-N4" style="stroke-width:2;" /><path d="M 339 133 C 338 133 337 133 336 133 L 193 88 C 191 88 191 87 193 86 L 336 41 C 338 41 340 41 341 41 L 484 86 C 486 86 486 87 484 88 L 342 133 C 341 133 340 133 339 133 Z" class=" sketch-overlay-N4" /><path d="M337.000089 131.340129 M337.000089 131.340129 C338.963884 132.680246, 338.163171 132.439876, 336.405312 133.857263 M335.269924 130.546535 C337.429286 134.079289, 335.378336 133.661496, 336.490419 131.033797 M336.978473 129.873048 C287.942870 114.830502, 236.160946 102.135392, 194.536704 86.250566 M335.670024 131.729071 C284.595074 118.012224, 234.413304 102.462717, 193.297677 87.200725 M193 88 C189.531127 88.054625, 191.813753 87.704487, 193.484064 84.279764 M191.313449 88.522259 C190.733199 89.288035, 190.758714 84.895508, 195.473147 87.316002 M196.991399 86.841850 C231.834272 73.807117, 268.300670 63.329133, 336.527637 42.591845 M195.341240 88.041736 C236.591381 72.978705, 278.563874 60.110001, 335.235809 40.764166 M336 41 C336.793919 42.275325, 341.230441 39.655019, 341.179996 41.591800 M336.435913 42.996446 C337.325739 38.748774, 341.101851 43.470075, 339.060602 39.365153 M340.871633 39.618851 C368.909367 49.034236, 404.092196 56.859476, 484.237450 87.975109 M338.618889 39.431594 C384.946108 58.032752, 432.302867 73.436396, 484.617419 85.436314 M484 86 C485.076967 86.275452, 486.347317 88.365202, 484.708439 89.085850 M483.680684 84.343321 C487.659662 84.581013, 485.122225 85.930485, 482.068824 88.249977 M483.852695 89.472483 C447.651714 99.370959, 414.411094 108.821793, 340.505498 131.928189 M482.442301 88.347985 C449.752781 101.071771, 416.602173 110.983009, 341.979859 132.808723 M342 133 C341.173727 131.019360, 340.567213 132.940016, 340.753476 131.085645 M342.559969 131.308489 C340.523667 134.943322, 341.120250 133.611089, 340.399791 132.328261 M340.202503 131.992053 C339.709715 132.038113, 339.010240 131.729962, 336.858896 131.065336 M340.518629 132.278107 C339.410881 132.027085, 338.453839 131.833204, 337.105391 131.426616" class=" sketch-overlay-N4 sketch-overlay-N4" /></g><text x="339.000000" y="92.500000" fill="#0A0F25" class="text-bold fill-N1" style="text-anchor:middle;font-size:16px">Train/Test Split</text></g><g id="train"><g class="shape" ><path d="M-1.600310 -0.578379 L158.045551 1.811030 L157.253697 64.234072 L0.925556 67.532483" transform="translate(566.000000 12.000000)" class="shape stroke-B1 fill-B6" style="stroke-width:2;" /><path d="M0.857263 0.963884 C31.080951 0.526830, 62.241287 -2.366506, 156.206405 0.392335 M-0.648665 0.264598 C35.191699 -0.541888, 69.590886 -1.111560, 156.419625 0.752815 M158.536704 -1.749433 C157.489431 15.585410, 158.180967 27.069513, 158.390547 65.130645 M157.297677 -0.799274 C157.657560 16.854002, 156.681091 35.455552, 157.406876 66.352243 M158.052801 65.786559 C124.169849 68.913244, 87.595248 68.369720, 1.836456 65.596476 M156.056573 65.856267 C97.893851 66.623220, 39.759371 66.351756, 0.938949 66.041844 M-0.720604 65.718532 C0.302797 45.542204, -1.429636 28.321166, 0.591800 -1.206080 M0.217956 66.998223 C-1.587850 41.337487, -1.081795 17.082362, 0.440740 0.988030" transform="translate(566.000000 12.000000)" class="shape stroke-B1 fill-B6" style="stroke-width:2;" /><rect width="157.000000" height="66.000000" transform="translate(566.000000 12.000000)" class=" sketch-overlay-B6" /></g><text x="644.500000" y="50.500000" fill="#0A0F25" class="text-bold fill-N1" style="text-anchor:middle;font-size:16px">Training Data</text></g><g id="test"><g class="shape" ><path d="M-1.600310 -0.578379 L127.045551 1.811030 L126.253697 64.234072 L0.925556 67.532483" transform="translate(793.000000 98.000000)" class="shape stroke-B1 fill-B6" style="stroke-width:2;" /><path d="M0.857263 0.963884 C24.880812 0.652477, 49.841009 -2.240859, 125.206405 0.392335 M-0.648665 0.264598 C28.329790 -0.274224, 55.867069 -0.843896, 125.419625 0.752815 M127.536704 -1.749433 C126.489431 15.585410, 127.180967 27.069513, 127.390547 65.130645 M126.297677 -0.799274 C126.657560 16.854002, 125.681091 35.455552, 126.406876 66.352243 M127.052801 65.786559 C99.855696 68.299904, 69.966942 67.756379, 1.836456 65.596476 M125.056573 65.856267 C78.547141 66.552255, 32.065951 66.280791, 0.938949 66.041844 M-0.720604 65.718532 C0.302797 45.542204, -1.429636 28.321166, 0.591800 -1.206080 M0.217956 66.998223 C-1.587850 41.337487, -1.081795 17.082362, 0.440740 0.988030" transform="translate(793.000000 98.000000)" class="shape stroke-B1 fill-B6" style="stroke-width:2;" /><rect width="126.000000" height="66.000000" transform="translate(793.000000 98.000000)" class=" sketch-overlay-B6" /></g><text x="856.000000" y="136.500000" fill="#0A0F25" class="text-bold fill-N1" style="text-anchor:middle;font-size:16px">Test Data</text></g><g id="model"><g class="shape" ><path d="M-1.600310 -0.578379 L121.045551 1.811030 L120.253697 64.234072 L0.925556 67.532483" transform="translate(796.000000 12.000000)" class="shape stroke-B1 fill-B6" style="stroke-width:2;" /><path d="M0.857263 0.963884 C23.680785 0.676795, 47.440955 -2.216540, 119.206405 0.392335 M-0.648665 0.264598 C27.001679 -0.222418, 53.210846 -0.792090, 119.419625 0.752815 M121.536704 -1.749433 C120.489431 15.585410, 121.180967 27.069513, 121.390547 65.130645 M120.297677 -0.799274 C120.657560 16.854002, 119.681091 35.455552, 120.406876 66.352243 M121.052801 65.786559 C95.149731 68.181193, 66.555012 67.637668, 1.836456 65.596476 M119.056573 65.856267 C74.802616 66.538520, 30.576902 66.267056, 0.938949 66.041844 M-0.720604 65.718532 C0.302797 45.542204, -1.429636 28.321166, 0.591800 -1.206080 M0.217956 66.998223 C-1.587850 41.337487, -1.081795 17.082362, 0.440740 0.988030" transform="translate(796.000000 12.000000)" class="shape stroke-B1 fill-B6" style="stroke-width:2;" /><rect width="120.000000" height="66.000000" transform="translate(796.000000 12.000000)" class=" sketch-overlay-B6" /></g><text x="856.000000" y="50.500000" fill="#0A0F25" class="text-bold fill-N1" style="text-anchor:middle;font-size:16px">ML Model</text></g><g id="eval"><g class="shape" ><path d="M-1.600310 -0.578379 L132.045551 1.811030 L131.253697 78.234072 L0.925556 81.532483" transform="translate(999.000000 47.000000)" class="shape stroke-B1 fill-B6" style="stroke-width:2;" /><path d="M0.857263 0.963884 C25.880835 0.632211, 51.841054 -2.261124, 130.206405 0.392335 M-0.648665 0.264598 C29.436550 -0.317395, 58.080587 -0.887068, 130.419625 0.752815 M132.536704 -1.749433 C131.360149 18.630442, 132.051685 33.159578, 132.390547 79.130645 M131.297677 -0.799274 C131.745702 20.611542, 130.769233 42.970633, 131.406876 80.352243 M132.052801 79.786559 C103.777333 82.398830, 72.810217 81.855305, 1.836456 79.596476 M130.056573 79.856267 C81.667578 80.563701, 33.306826 80.292237, 0.938949 80.041844 M-0.720604 79.718532 C0.099591 55.526873, -1.632842 34.290505, 0.591800 -1.206080 M0.217956 80.998223 C-1.760112 50.244759, -1.254057 20.896906, 0.440740 0.988030" transform="translate(999.000000 47.000000)" class="shape stroke-B1 fill-B6" style="stroke-width:2;" /><rect width="131.000000" height="80.000000" transform="translate(999.000000 47.000000)" class=" sketch-overlay-B6" /></g><text x="1064.500000" y="92.500000" fill="#0A0F25" class="text-bold fill-N1" style="text-anchor:middle;font-size:16px">Evaluation</text></g><g id="(dataset -&gt; split)[0]"><marker id="mk-3488378134" markerWidth="10.000000" markerHeight="12.000000" refX="7.000000" refY="6.000000" viewBox="0.000000 0.000000 10.000000 12.000000" orient="auto" markerUnits="userSpaceOnUse"> <polygon points="0.000000,0.000000 10.000000,6.000000 0.000000,12.000000" fill="#0D32B2" class="connection fill-B1" stroke-width="2" /> </marker><path d="M123.000044 87.170064 M122.840168 87.751650 C143.539014 86.414150, 164.239531 87.741200, 187.213518 87.771714 M123.219771 87.576914 C145.346686 87.490893, 167.319440 88.030098, 187.587511 87.769139" fill="none" class="connection stroke-B1" style="stroke-width:2;" mask="url(#d2-1355680374)" /><path d="M-8.527627 -3.097061 L1.749550 0.558791 L-8.562935 4.521533" stroke="none" class="connection fill-B1" style="stroke-width:0;" transform="translate(188.000000 88.000000) rotate(0)" /> <path d="M-10.153731 -4.038897 C-7.293657 -2.964754, -5.552453 -3.126871, 0.222305 -0.654474 M-10.160117 -4.253535 C-7.616436 -2.677663, -5.569656 -2.320404, -0.086565 0.272291 M0.578048 -0.807164 C-2.240460 1.133634, -3.845699 1.135504, -9.579367 4.140709 M-0.217907 -0.322328 C-3.660571 0.941126, -7.003142 2.167050, -10.100296 3.840861 M-9.957758 4.629247 C-9.937438 2.794817, -10.508655 0.509238, -9.330834 -3.522818 M-10.354741 4.285014 C-9.712366 0.996453, -9.805329 -1.235319, -9.648840 -4.366524" fill="none" class="connection stroke-B1" style="stroke-width:2;" transform="translate(188.000000 88.000000) rotate(0)" /></g><g id="(split -&gt; train)[0]"><path d="M439.000030 72.162473 M438.840154 72.744059 C463.381597 71.285261, 487.925329 72.519929, 515.213590 72.475669 M439.219757 72.569323 C465.465696 72.368437, 491.556538 72.808653, 515.587583 72.473094 M516.000072 72.703955 C525.125283 73.215452, 526.615129 73.561220, 526.228103 63.434352 M515.179676 73.399228 C526.393492 71.927365, 526.372097 71.666907, 525.456653 62.270946 M525.466610 62.419278 C525.792491 59.608252, 525.935429 57.919058, 526.191905 54.961094 M525.389523 62.438322 C525.614382 59.855714, 525.798943 57.182310, 525.828031 54.973800 M526 55 C526.795922 44.992354, 526.938949 45.041844, 535.912126 45.263818 M525.868093 55.725734 C525.824082 45.787979, 525.044761 44.705208, 535.921734 44.549622 M536.559397 45.164843 C543.308089 44.985377, 553.036981 44.130828, 561.346061 44.730295 M535.521656 44.405027 C541.659272 44.968106, 546.936466 44.168424, 562.231389 45.383120" fill="none" class="connection stroke-B1" style="stroke-width:2;" mask="url(#d2-1355680374)" /><path d="M-8.527627 -3.097061 L1.749550 0.558791 L-8.562935 4.521533" stroke="none" class="connection fill-B1" style="stroke-width:0;" transform="translate(562.000000 45.000000) rotate(0)" /> <path d="M-10.153731 -4.038897 C-7.293657 -2.964754, -5.552453 -3.126871, 0.222305 -0.654474 M-10.160117 -4.253535 C-7.616436 -2.677663, -5.569656 -2.320404, -0.086565 0.272291 M0.578048 -0.807164 C-2.240460 1.133634, -3.845699 1.135504, -9.579367 4.140709 M-0.217907 -0.322328 C-3.660571 0.941126, -7.003142 2.167050, -10.100296 3.840861 M-9.957758 4.629247 C-9.937438 2.794817, -10.508655 0.509238, -9.330834 -3.522818 M-10.354741 4.285014 C-9.712366 0.996453, -9.805329 -1.235319, -9.648840 -4.366524" fill="none" class="connection stroke-B1" style="stroke-width:2;" transform="translate(562.000000 45.000000) rotate(0)" /></g><g id="(split -&gt; test)[0]"><path d="M440.000029 102.177719 M439.840153 102.759305 C464.062564 101.487237, 488.286031 102.906226, 515.213591 103.066439 M440.219756 102.584569 C466.120657 102.582510, 491.868329 103.220229, 515.587584 103.063864 M516.000073 103.294725 C525.125283 103.882452, 526.615129 104.228220, 526.228103 114.101352 M515.179677 103.989998 C526.393492 102.594365, 526.372097 102.333907, 525.456653 112.937946 M525.467687 113.102332 C525.740448 115.212988, 525.879792 118.567107, 526.212674 120.956883 M525.382258 113.123436 C525.603003 115.927568, 525.786867 118.631324, 525.809419 120.970964 M526 121 C526.795922 130.992354, 526.938949 131.041844, 535.912126 131.263818 M525.868093 121.725734 C525.824082 131.787979, 525.044761 130.705208, 535.921734 130.549622 M536.439199 131.048875 C613.577682 131.484904, 693.134605 130.817668, 788.469327 130.781134 M535.597070 130.432283 C589.268688 129.997016, 642.242072 129.365896, 789.187772 131.310903" fill="none" class="connection stroke-B1" style="stroke-width:2;" mask="url(#d2-1355680374)" /><path d="M-8.527627 -3.097061 L1.749550 0.558791 L-8.562935 4.521533" stroke="none" class="connection fill-B1" style="stroke-width:0;" transform="translate(789.000000 131.000000) rotate(0)" /> <path d="M-10.153731 -4.038897 C-7.293657 -2.964754, -5.552453 -3.126871, 0.222305 -0.654474 M-10.160117 -4.253535 C-7.616436 -2.677663, -5.569656 -2.320404, -0.086565 0.272291 M0.578048 -0.807164 C-2.240460 1.133634, -3.845699 1.135504, -9.579367 4.140709 M-0.217907 -0.322328 C-3.660571 0.941126, -7.003142 2.167050, -10.100296 3.840861 M-9.957758 4.629247 C-9.937438 2.794817, -10.508655 0.509238, -9.330834 -3.522818 M-10.354741 4.285014 C-9.712366 0.996453, -9.805329 -1.235319, -9.648840 -4.366524" fill="none" class="connection stroke-B1" style="stroke-width:2;" transform="translate(789.000000 131.000000) rotate(0)" /></g><g id="(train -&gt; model)[0]"><path d="M724.000044 44.170064 M723.840168 44.751650 C745.499811 43.406921, 767.161124 44.733971, 791.213518 44.771714 M724.219771 44.576914 C747.376201 44.486924, 770.378469 45.026129, 791.587511 44.769139" fill="none" class="connection stroke-B1" style="stroke-width:2;" mask="url(#d2-1355680374)" /><path d="M-8.527627 -3.097061 L1.749550 0.558791 L-8.562935 4.521533" stroke="none" class="connection fill-B1" style="stroke-width:0;" transform="translate(792.000000 45.000000) rotate(0)" /> <path d="M-10.153731 -4.038897 C-7.293657 -2.964754, -5.552453 -3.126871, 0.222305 -0.654474 M-10.160117 -4.253535 C-7.616436 -2.677663, -5.569656 -2.320404, -0.086565 0.272291 M0.578048 -0.807164 C-2.240460 1.133634, -3.845699 1.135504, -9.579367 4.140709 M-0.217907 -0.322328 C-3.660571 0.941126, -7.003142 2.167050, -10.100296 3.840861 M-9.957758 4.629247 C-9.937438 2.794817, -10.508655 0.509238, -9.330834 -3.522818 M-10.354741 4.285014 C-9.712366 0.996453, -9.805329 -1.235319, -9.648840 -4.366524" fill="none" class="connection stroke-B1" style="stroke-width:2;" transform="translate(792.000000 45.000000) rotate(0)" /></g><g id="(model -&gt; eval)[0]"><path d="M917.000044 44.170064 M916.840168 44.751650 C926.970247 43.493671, 937.101998 44.820721, 948.213518 44.771714 M917.219771 44.576914 C928.022024 44.534552, 938.670116 45.073757, 948.587511 44.769139 M949 45 C958.125283 45.549452, 959.615129 45.895220, 959.228103 55.768352 M948.179604 45.695273 C959.393492 44.261365, 959.372097 44.000907, 958.456653 54.604946 M958.470412 54.809925 C958.766994 57.443938, 958.897247 61.628968, 959.265193 64.612235 M958.363886 54.836242 C958.591973 58.335127, 958.774076 61.709416, 958.762357 64.629794 M959 64.666 C959.795922 74.658354, 959.938949 74.707844, 968.912126 74.929818 M958.868093 65.391734 C958.824082 75.453979, 958.044761 74.371208, 968.921734 74.215622 M969.559397 74.830843 C976.308089 74.651377, 986.036981 73.796828, 994.346061 74.396295 M968.521656 74.071027 C974.659272 74.634106, 979.936466 73.834424, 995.231389 75.049120" fill="none" class="connection stroke-B1" style="stroke-width:2;" mask="url(#d2-1355680374)" /><path d="M-8.527627 -3.097061 L1.749550 0.558791 L-8.562935 4.521533" stroke="none" class="connection fill-B1" style="stroke-width:0;" transform="translate(995.000000 74.666000) rotate(0)" /> <path d="M-10.153731 -4.038897 C-7.293657 -2.964754, -5.552453 -3.126871, 0.222305 -0.654474 M-10.160117 -4.253535 C-7.616436 -2.677663, -5.569656 -2.320404, -0.086565 0.272291 M0.578048 -0.807164 C-2.240460 1.133634, -3.845699 1.135504, -9.579367 4.140709 M-0.217907 -0.322328 C-3.660571 0.941126, -7.003142 2.167050, -10.100296 3.840861 M-9.957758 4.629247 C-9.937438 2.794817, -10.508655 0.509238, -9.330834 -3.522818 M-10.354741 4.285014 C-9.712366 0.996453, -9.805329 -1.235319, -9.648840 -4.366524" fill="none" class="connection stroke-B1" style="stroke-width:2;" transform="translate(995.000000 74.666000) rotate(0)" /></g><g id="(test -&gt; eval)[0]"><path d="M920.000044 130.170064 M919.840168 130.751650 C929.009451 129.500900, 938.180404 130.827950, 948.213518 130.771714 M920.219771 130.576914 C929.992509 130.538521, 939.611086 131.077726, 948.587511 130.769139 M949 131 C958.125283 131.549452, 959.615129 131.895220, 959.228103 121.768352 M948.179604 131.695273 C959.393492 130.261365, 959.372097 130.000907, 958.456653 120.604946 M958.469336 120.793897 C958.836262 117.209336, 958.970104 115.054356, 959.244456 111.283439 M958.371140 120.818156 C958.605277 117.524212, 958.788075 114.115235, 958.780939 111.299625 M959 111.333 C959.795922 101.325354, 959.938949 101.374844, 968.912126 101.596818 M958.868093 112.058734 C958.824082 102.120979, 958.044761 101.038208, 968.921734 100.882622 M969.559397 101.497843 C976.308089 101.318377, 986.036981 100.463828, 994.346061 101.063295 M968.521656 100.738027 C974.659272 101.301106, 979.936466 100.501424, 995.231389 101.716120" fill="none" class="connection stroke-B1" style="stroke-width:2;" mask="url(#d2-1355680374)" /><path d="M-8.527627 -3.097061 L1.749550 0.558791 L-8.562935 4.521533" stroke="none" class="connection fill-B1" style="stroke-width:0;" transform="translate(995.000000 101.333000) rotate(0)" /> <path d="M-10.153731 -4.038897 C-7.293657 -2.964754, -5.552453 -3.126871, 0.222305 -0.654474 M-10.160117 -4.253535 C-7.616436 -2.677663, -5.569656 -2.320404, -0.086565 0.272291 M0.578048 -0.807164 C-2.240460 1.133634, -3.845699 1.135504, -9.579367 4.140709 M-0.217907 -0.322328 C-3.660571 0.941126, -7.003142 2.167050, -10.100296 3.840861 M-9.957758 4.629247 C-9.937438 2.794817, -10.508655 0.509238, -9.330834 -3.522818 M-10.354741 4.285014 C-9.712366 0.996453, -9.805329 -1.235319, -9.648840 -4.366524" fill="none" class="connection stroke-B1" style="stroke-width:2;" transform="translate(995.000000 101.333000) rotate(0)" /></g><mask id="d2-1355680374" maskUnits="userSpaceOnUse" x="1" y="1" width="1140" height="174">
<rect x="1" y="1" width="1140" height="174" fill="white"></rect>
<rect x="34.500000" y="88.500000" width="65" height="21" fill="rgba(0,0,0,0.75)"></rect>
<rect x="273.000000" y="76.500000" width="132" height="21" fill="rgba(0,0,0,0.75)"></rect>
<rect x="588.500000" y="34.500000" width="112" height="21" fill="rgba(0,0,0,0.75)"></rect>
<rect x="815.500000" y="120.500000" width="81" height="21" fill="rgba(0,0,0,0.75)"></rect>
<rect x="818.500000" y="34.500000" width="75" height="21" fill="rgba(0,0,0,0.75)"></rect>
<rect x="1021.500000" y="76.500000" width="86" height="21" fill="rgba(0,0,0,0.75)"></rect>
</mask></svg></svg>
" class="img-fluid" style="width:100.0%"></p>
</section>
</section>
<section id="try-it-yourself" class="level2">
<h2 class="anchored" data-anchor-id="try-it-yourself">Try it yourself</h2>
<p>I suggest starting with the <a href="https://play.d2lang.com">D2 playground</a> and any assistant, such as ChatGPT. No installation or magic prompt required. Just ask it to generate the D2 code for a simple diagram.</p>
<p>A more powerful setup is to install D2 locally, index the documentation in Cursor and then use Claude-3.5 Sonnet in a Composer window to generate diagrams.</p>
<hr>
<p>Image background by <a href="https://unsplash.com/@pawel_czerwinski?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Pawel Czerwinski</a> on <a href="https://unsplash.com/photos/background-pattern-C-pmBkHZWQ0?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Unsplash</a></p>


</section>

 ]]></description>
  <category>Productivity</category>
  <guid>https://simmering.dev/blog/diagrams/</guid>
  <pubDate>Fri, 27 Dec 2024 23:00:00 GMT</pubDate>
  <media:content url="https://simmering.dev/blog/diagrams/diagrams.webp" medium="image" type="image/webp"/>
</item>
<item>
  <title>When to use Direct Preference Optimization (DPO)</title>
  <dc:creator>Paul Simmering</dc:creator>
  <link>https://simmering.dev/blog/llm-customization/</link>
  <description><![CDATA[ 





<p>OpenAI recently added the ability to fine-tune their models using direct preference optimization (DPO). They call it <a href="https://platform.openai.com/docs/guides/fine-tuning#preference">preference tuning</a>. Previously, their API only supported supervised fine-tuning (SFT). They join <a href="https://openpipe.ai/blog/announcing-dpo-support">OpenPipe</a> as one of the first pay-per-token APIs to offer DPO. This makes DPO more accessible to developers who don‚Äôt want the complexity of managing the training infrastructure themselves. In this article I will briefly introduce DPO and then discuss its use cases in contrast to SFT.</p>
<section id="what-is-dpo" class="level3">
<h3 class="anchored" data-anchor-id="what-is-dpo">What is DPO?</h3>
<p>Skip to the next section if you‚Äôre already familiar with DPO.</p>
<p>DPO means training an LLM to conform to the preferences of human raters. Each example contains:</p>
<ul>
<li>A user input, e.g.&nbsp;a question</li>
<li>An ideal assistant reply</li>
<li>A worse assistant reply</li>
</ul>
<p>In a training input file, it looks like this:</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode json code-with-copy"><code class="sourceCode json"><span id="cb1-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb1-2">  <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"input"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb1-3">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"messages"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb1-4">      <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb1-5">        <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"role"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"user"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb1-6">        <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"content"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Write a professional email asking for a raise."</span></span>
<span id="cb1-7">      <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb1-8">    <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">]</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb1-9">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">},</span></span>
<span id="cb1-10">  <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"preferred_output"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb1-11">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb1-12">      <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"role"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"assistant"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb1-13">      <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"content"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"I would like to request a salary review. In the past 6 months I have led multiple projects and also assisted colleagues with their tasks."</span></span>
<span id="cb1-14">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb1-15">  <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">]</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb1-16">  <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"non_preferred_output"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb1-17">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb1-18">      <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"role"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"assistant"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb1-19">      <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"content"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"You should increase my salary because I'm doing all the work here."</span></span>
<span id="cb1-20">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb1-21">  <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">]</span></span>
<span id="cb1-22"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span></code></pre></div>
<p>DPO adjusts the model weights such that it is more likely to choose the preferred answers. It‚Äôs graded on how much more likely it is to choose the preferred answer. This teaches it not just to answer more like the preferred answer, but also to avoid answering like the rejected answer. It stands in contrast to SFT, which only teaches it to mimic a single answer.</p>
</section>
<section id="loss-function" class="level3">
<h3 class="anchored" data-anchor-id="loss-function">Loss function</h3>
<p>Mathematically, DPO fine-tunes the LLM by maximizing the margin between the probability of the preferred and rejected response. The loss function is:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/llm-customization/dpo_loss.webp" class="img-fluid figure-img"></p>
<figcaption>DPO loss function</figcaption>
</figure>
</div>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cpi_%5Ctheta(y%7Cx)">: The probability that our model (with parameters Œ∏) assigns to generating response y given input x</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cpi_%7B%5Ctext%7Bref%7D%7D(y%7Cx)">: The probability that a reference model (usually the initial pre-trained model) assigns to the same response</li>
<li><img src="https://latex.codecogs.com/png.latex?y_w">: The preferred, ‚Äúwinning‚Äù response</li>
<li><img src="https://latex.codecogs.com/png.latex?y_l">: The rejected, ‚Äúlosing‚Äù response</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cbeta">: Hyperparameter to regulate the strength of weight updates.</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Csigma">: Sigmoid function that maps the difference to a probability between 0 and 1</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BE%7D">: Expected value over the dataset D of preferences</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BD%7D">: Dataset containing triples of (input, preferred response, rejected response)</li>
</ul>
<p>See the <a href="https://arxiv.org/abs/2305.18290">paper</a> by Rafailov et al.&nbsp;(2023) for details and how this loss is turned into a weight update.</p>
<p>The use of a reference model has two advantages over purely optimizing for a high <img src="https://latex.codecogs.com/png.latex?%5Cpi_%5Ctheta(y_w%7Cx)">:</p>
<ol type="1">
<li>It prevents overfitting to the examples. The derivative of the loss function (see after equation 7 in paper) illustrates that the model gets low weight updates from examples where it already gives more probability to the preferred response.</li>
<li>It takes into account how likely the preferred and rejected responses are to begin with. So teaching the model to prefer a rare response over another rare response won‚Äôt cause an update that breaks common responses.</li>
</ol>
<p>The choice of <img src="https://latex.codecogs.com/png.latex?%5Cbeta"> is key. Higher values result in more conservative updates, preserving previous behavior. Lower values cause more aggressive updates in favor of the preferred answer. This stems from the interaction of the sigmoid function: a higher beta causes the function to saturate (approach 1) from smaller differences in the probability ratios, leading to a smaller weight update.</p>
<p>DPO and its predecessor reinforcement learning from human feedback (RLHF) have been a staple in the training of LLMs that serve as assistants, including open models like the Llama 3 family. They are one of the key separators between different models, which share a lot of common SFT in the form of web scraped texts, papers and code. It‚Äôs what forms the character and mannerisms of an assistant.</p>
</section>
<section id="data-for-dpo" class="level3">
<h3 class="anchored" data-anchor-id="data-for-dpo">Data for DPO</h3>
<p>Collecting DPO data is straightforward. You take the current best model and let it generate multiple answers to a user input at nonzero temperature. Then either a human or a model (a copy of the answering model or a larger, smarter model) judges which answer is superior. This enables a powerful training loop, particularly if an LLM is used as a judge.</p>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">flowchart LR
    A[User Input] --&gt;|Prompt| B[Base model]
    B --&gt;|Generates| C[Multiple responses]
    C --&gt;|Evaluates| D[Human or LLM judge]
    D --&gt;|Selects| G[Preferred response]
    D --&gt;|Rejects| H[Non-preferred response]
    G --&gt; I[DPO training data]
    H --&gt; I
    I --&gt;|Updates| B
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</section>
<section id="when-to-use-dpo" class="level2">
<h2 class="anchored" data-anchor-id="when-to-use-dpo">When to use DPO?</h2>
<p>DPO is best utilized to refine a model that already underwent SFT. By default, OpenAI‚Äôs fine-tuning API bundles SFT with DPO by first using SFT to let models learn from the exact wording of the preferred answers before also learning to prefer them using DPO.</p>
<section id="when-prompting-isnt-sufficient" class="level4">
<h4 class="anchored" data-anchor-id="when-prompting-isnt-sufficient">1. When prompting isn‚Äôt sufficient</h4>
<p>If the desired behavior can be achieved by a prompt, you don‚Äôt need to implement DPO. Prompts are easier to change and different instances of a model can run with different system prompts. However, prompts add tokens on every call, which makes them slower, more expensive and fills up the context window. They‚Äôre also more limited in what behaviors they can achieve and may be ignored by the model. In those cases, DPO is a more robust solution and can of course be be combined with prompts.</p>
</section>
<section id="when-you-cant-generate-optimal-answers-at-scale" class="level4">
<h4 class="anchored" data-anchor-id="when-you-cant-generate-optimal-answers-at-scale">2. When you can‚Äôt generate optimal answers at scale</h4>
<p>Humans typically have an easier time determining which of two answers is better than developing the best answer on their own. This is especially true for complex outputs, multi-turn conversations, and all matters of style where there are multiple acceptable answers. As an example, it‚Äôs faster to judge which of two email texts sounds better than writing the perfect email.</p>
</section>
<section id="when-you-want-to-preserve-previous-behavior" class="level4">
<h4 class="anchored" data-anchor-id="when-you-want-to-preserve-previous-behavior">3. When you want to preserve previous behavior</h4>
<p>DPO is a more measured treatment than SFT and can be regulated with the <img src="https://latex.codecogs.com/png.latex?%5Cbeta"> hyperparameter. This makes it a good choice if the model is already trained and you only want to make small changes. In contrast, SFT is a more aggressive treatment that overrides previous behavior, for example, a model trained on a named entity recognition task would start speaking JSON rather than English.</p>
</section>
<section id="use-cases" class="level3">
<h3 class="anchored" data-anchor-id="use-cases">Use cases</h3>
<p>Let‚Äôs consider common LLM use cases and the criteria listed above to decide between SFT+DPO and SFT only.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 17%">
<col style="width: 11%">
<col style="width: 70%">
</colgroup>
<thead>
<tr class="header">
<th>Use Case</th>
<th>Method</th>
<th>Reasoning</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Summarization</td>
<td>SFT+DPO</td>
<td>Humans can easily compare summaries for quality, but writing the perfect summary is harder. Multiple valid summaries exist.</td>
</tr>
<tr class="even">
<td>Code generation</td>
<td>SFT+DPO</td>
<td>Different coding styles and approaches can be valid. Humans can better judge which implementation is more readable/maintainable. SFT can suffice for SQL generation.</td>
</tr>
<tr class="odd">
<td>Question answering</td>
<td>SFT+DPO</td>
<td>Multiple valid answers may exist with varying levels of helpfulness and clarity. Comparing answers is easier than writing the perfect one.</td>
</tr>
<tr class="even">
<td>Writing assistance</td>
<td>SFT+DPO</td>
<td>Writing quality is subjective and context-dependent. Humans can better evaluate style and tone by comparison.</td>
</tr>
<tr class="odd">
<td>Chatbot responses</td>
<td>SFT+DPO</td>
<td>Natural conversation has many valid responses. Comparing helps optimize for engagement and helpfulness.</td>
</tr>
<tr class="even">
<td>Information extraction</td>
<td>SFT only</td>
<td>Tasks like text classification, named entity recognition, relationship extraction, web scraping, and others have one correct answer. DPO is unnecessary.</td>
</tr>
<tr class="odd">
<td>Tool calling</td>
<td>SFT only</td>
<td>Unlike code generation, calls to APIs, data fetching functions and similar are limited in variation and a given user request is usually translated into one optimal set of tool calls.</td>
</tr>
<tr class="even">
<td>Mathematical computation</td>
<td>SFT only</td>
<td>Mathematical problems typically have one correct answer. DPO would be a poor way to teach right and wrong solutions, but may make sense to teach a style of presentation.</td>
</tr>
</tbody>
</table>
<p>Tasks that fully leverage LLM‚Äôs free-form input and output tend to benefit most from DPO.</p>
</section>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further reading</h2>
<ul>
<li>To see DPO in action, I suggest reading Anyscale‚Äôs article <a href="https://www.anyscale.com/blog/direct-preference-optimization-with-synthetic-data">Direct Preference Optimization with Synthetic Data</a> which walks through DPO for summarization using synthetic data and LLM as a judge.</li>
<li>If you want to get started with your own project, I suggest <a href="https://pytorch.org/torchtune/stable/recipes/dpo.html">torchtune</a> for training on your own infrastructure and the <a href="https://platform.openai.com/docs/guides/fine-tuning#preference">OpenAI API</a> for a managed service.</li>
<li>If you want to learn more details about DPO, I suggest reading the <a href="https://arxiv.org/abs/2305.18290">paper</a> by Rafailov et al.&nbsp;(2023). There is also a <a href="https://www.youtube.com/live/vuWbJlBePPA?si=18sGG8Vn7D6yykeD">YouTube video</a> of a lecture by one of the authors, Christopher Manning.</li>
<li>Read about variants of DPO in a <a href="https://huggingface.co/blog/pref-tuning">blog post</a> on HuggingFace.</li>
</ul>
<p>Photo by <a href="https://unsplash.com/@max_williams?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Max Williams</a> on <a href="https://unsplash.com/photos/multicolored-wallpaper-_OoK2W7OPRM?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Unsplash</a></p>


</section>

 ]]></description>
  <category>Machine Learning</category>
  <guid>https://simmering.dev/blog/llm-customization/</guid>
  <pubDate>Sat, 21 Dec 2024 23:00:00 GMT</pubDate>
  <media:content url="https://simmering.dev/blog/llm-customization/image.webp" medium="image" type="image/webp"/>
</item>
<item>
  <title>Type-safe LLM agents with PydanticAI</title>
  <dc:creator>Paul Simmering</dc:creator>
  <link>https://simmering.dev/blog/pydantic-ai/</link>
  <description><![CDATA[ 





<p>Pydantic AI is a new agent framework by the company behind Pydantic, the popular data validation library. Pydantic has transformed how I write Python, so I‚Äôm excited for their take on agents. In this article I‚Äôll walk through an example app and comment on my experience developing with PydanticAI.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
PydanticAI version 0.0.13
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>PydanticAI is in beta. This article is based on version 0.0.13. Code examples may not work with future versions. Limitations that are mentioned may be lifted in future versions.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
What is an agent?
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The term ‚Äúagent‚Äù in the context of LLMs refers to a while loop that calls an LLM to solve a problem. The LLM may be equipped with tools, meaning functions that it can supply arguments to and receive results from. To cut through the marketing hype, I suggest just reading the <a href="https://github.com/pydantic/pydantic-ai/blob/0475da82d5956a2d65678d464328c8f8f8be2bf1/pydantic_ai_slim/pydantic_ai/agent.py#L244">code</a> for PydanticAI‚Äôs <code>Agent.run()</code> method.</p>
</div>
</div>
</div>
<p>As an agent framework, PydanticAI lets developers define workflows wherein an LLM interprets a user‚Äôs query and can use tools in multiple steps to answer the question or perform a task. Type safety is a big deal in agent development - the LLM has to call tools with the correct arguments and the tools have to return the correct data type. PydanticAI brings the type safety of Pydantic to this space. This also speeds up development, because type checkers like mypy and pyright can catch errors before the code is run.</p>
<p>In addition to type safety, PydanticAI offers:</p>
<ul>
<li>streaming responses, including structured responses</li>
<li>support for async tool calling</li>
<li>support for multiple LLM providers, including OpenAI, Groq, Anthropic, Gemini, Ollama and Mistral, with more to come</li>
<li>optional integration with <a href="https://pydantic.dev/logfire">Logfire</a>, a commercial service by the Pydantic team for logging LLM calls</li>
</ul>
<section id="example-app-market-research-knowledge-manager" class="level2">
<h2 class="anchored" data-anchor-id="example-app-market-research-knowledge-manager">Example app: Market research knowledge manager</h2>
<p>Large companies conduct market research to understand their customers, competition and market trends. Over time, they amass a library of thousands of reports, tables and transcripts. Knowledge management becomes a challenge, because teams are not aware of existing research.</p>
<p>Let‚Äôs build an example agent that answers questions based on information in a database with multiple tables. Our final agentic RAG system will enable an interaction like this:</p>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">%%{init: {
  'theme': 'base',
  'themeVariables': {
    'primaryColor': '#ffffff',
    'primaryTextColor': '#2d3748',
    'primaryBorderColor': '#90cdf4',
    'lineColor': '#64748b',
    'secondaryColor': '#ffffff',
    'tertiaryColor': '#ffffff',
    'fontSize': '22px',
    'labelFontSize': '18px',
    'edgeLabelFontSize': '18px'
  }
}}%%
graph LR
    %% Define styles
    classDef default fill:#ffffff,stroke:#90cdf4,stroke-width:2px
    classDef highlight fill:#fdf2f8,stroke:#ed64a6,stroke-width:3px
    classDef api fill:#ffffff,stroke:#4fd1c5,stroke-width:2px

    User([User]) --&gt; |"What reports do we have about electric vehicles?"| Agent
    Agent --&gt; |"Analyze user query"| Groq[LLM Provider Groq]
    Groq --&gt; |"Tool selection"| Agent
    
    Agent --&gt; |"Search topic='Automotive'"| Tool1[tool: search_reports_by_field]
    Agent --&gt; |"Search 'electric vehicles'"| Tool2[tool: search_reports_by_title_similarity]
    
    Tool1 --&gt; |"Query"| DB[(DuckDB)]
    Tool2 --&gt; |"Vector similarity"| DB
    
    Tool1 --&gt; |"Found 2 reports"| Agent
    Tool2 --&gt; |"Found similar titles"| Agent
    
    Agent --&gt; |"There are 2 reports about EVs:
    1. German EV Market Analysis 2024
    2. EV Adoption in Asia"| User

    %% Apply styles
    class Groq api
    class DB highlight

    %% Links between nodes
    linkStyle default stroke:#64748b,stroke-width:2px
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<section id="database" class="level3">
<h3 class="anchored" data-anchor-id="database">Database</h3>
<p>I‚Äôm using <a href="https://duckdb.org">DuckDB</a> to create an in-memory database which will be made available to the agent.</p>
<div id="8332ed09" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="annotated-cell-1" style="background: #f1f3f5;"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> duckdb</span>
<span id="annotated-cell-1-2"></span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-1" data-target-annotation="1">1</button><span id="annotated-cell-1-3" class="code-annotation-target">con <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> duckdb.<span class="ex" style="color: null;
background-color: null;
font-style: inherit;">connect</span>()</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-hidden code-annotation-container-grid">
<dt data-target-cell="annotated-cell-1" data-target-annotation="1">1</dt>
<dd>
<span data-code-cell="annotated-cell-1" data-code-lines="3" data-code-annotation="1">Create a local database. In production you‚Äôd want to use a persistent database.</span>
</dd>
</dl>
</div>
</div>
<p>I‚Äôll insert a set of reports into the database. The data included is fictional and was generated by an LLM. The data consists of 40 reports like this:</p>
<div id="1554a29c" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> polars <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pl</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> great_tables <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> GT</span>
<span id="cb1-3"></span>
<span id="cb1-4">reports <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pl.read_csv(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"data/reports.csv"</span>)</span>
<span id="cb1-5">GT(reports.head(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>))</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="4">
<div id="ylufodktok" style="padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>
#ylufodktok table {
          font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;
          -webkit-font-smoothing: antialiased;
          -moz-osx-font-smoothing: grayscale;
        }

#ylufodktok thead, tbody, tfoot, tr, td, th { border-style: none; }
 tr { background-color: transparent; }
#ylufodktok p { margin: 0; padding: 0; }
 #ylufodktok .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; }
 #ylufodktok .gt_caption { padding-top: 4px; padding-bottom: 4px; }
 #ylufodktok .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; }
 #ylufodktok .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; }
 #ylufodktok .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; }
 #ylufodktok .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; }
 #ylufodktok .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; }
 #ylufodktok .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; }
 #ylufodktok .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; }
 #ylufodktok .gt_column_spanner_outer:first-child { padding-left: 0; }
 #ylufodktok .gt_column_spanner_outer:last-child { padding-right: 0; }
 #ylufodktok .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; }
 #ylufodktok .gt_spanner_row { border-bottom-style: hidden; }
 #ylufodktok .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; }
 #ylufodktok .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; }
 #ylufodktok .gt_from_md> :first-child { margin-top: 0; }
 #ylufodktok .gt_from_md> :last-child { margin-bottom: 0; }
 #ylufodktok .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; }
 #ylufodktok .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; }
 #ylufodktok .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; }
 #ylufodktok .gt_row_group_first td { border-top-width: 2px; }
 #ylufodktok .gt_row_group_first th { border-top-width: 2px; }
 #ylufodktok .gt_striped { background-color: rgba(128,128,128,0.05); }
 #ylufodktok .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; }
 #ylufodktok .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; }
 #ylufodktok .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; text-align: left; }
 #ylufodktok .gt_left { text-align: left; }
 #ylufodktok .gt_center { text-align: center; }
 #ylufodktok .gt_right { text-align: right; font-variant-numeric: tabular-nums; }
 #ylufodktok .gt_font_normal { font-weight: normal; }
 #ylufodktok .gt_font_bold { font-weight: bold; }
 #ylufodktok .gt_font_italic { font-style: italic; }
 #ylufodktok .gt_super { font-size: 65%; }
 #ylufodktok .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; }
 #ylufodktok .gt_asterisk { font-size: 100%; vertical-align: 0; }
 
</style>

<table class="gt_table caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-quarto-disable-processing="false" data-quarto-bootstrap="false">
<thead>
<tr class="gt_col_headings header">
<th id="id" class="gt_col_heading gt_columns_bottom_border gt_right" data-quarto-table-cell-role="th" scope="col">id</th>
<th id="year" class="gt_col_heading gt_columns_bottom_border gt_right" data-quarto-table-cell-role="th" scope="col">year</th>
<th id="institute" class="gt_col_heading gt_columns_bottom_border gt_left" data-quarto-table-cell-role="th" scope="col">institute</th>
<th id="country" class="gt_col_heading gt_columns_bottom_border gt_left" data-quarto-table-cell-role="th" scope="col">country</th>
<th id="topic" class="gt_col_heading gt_columns_bottom_border gt_left" data-quarto-table-cell-role="th" scope="col">topic</th>
<th id="title" class="gt_col_heading gt_columns_bottom_border gt_left" data-quarto-table-cell-role="th" scope="col">title</th>
</tr>
</thead>
<tbody class="gt_table_body">
<tr class="odd">
<td class="gt_row gt_right">1</td>
<td class="gt_row gt_right">2018</td>
<td class="gt_row gt_left">Research DNA GmbH</td>
<td class="gt_row gt_left">Germany</td>
<td class="gt_row gt_left">Automotive</td>
<td class="gt_row gt_left">Global Electric Vehicle Market Outlook 2018-2023</td>
</tr>
<tr class="even">
<td class="gt_row gt_right">2</td>
<td class="gt_row gt_right">2018</td>
<td class="gt_row gt_left">Market Insights Inc.</td>
<td class="gt_row gt_left">USA</td>
<td class="gt_row gt_left">Healthcare</td>
<td class="gt_row gt_left">Digital Health Market Size and Growth Analysis</td>
</tr>
<tr class="odd">
<td class="gt_row gt_right">3</td>
<td class="gt_row gt_right">2018</td>
<td class="gt_row gt_left">Global Trends Research</td>
<td class="gt_row gt_left">UK</td>
<td class="gt_row gt_left">FMCG</td>
<td class="gt_row gt_left">Premium Beauty and Personal Care Market Trends</td>
</tr>
<tr class="even">
<td class="gt_row gt_right">4</td>
<td class="gt_row gt_right">2018</td>
<td class="gt_row gt_left">Data Analytics Group</td>
<td class="gt_row gt_left">Canada</td>
<td class="gt_row gt_left">Electronics</td>
<td class="gt_row gt_left">Smartphone Industry Competitive Analysis</td>
</tr>
<tr class="odd">
<td class="gt_row gt_right">5</td>
<td class="gt_row gt_right">2018</td>
<td class="gt_row gt_left">Innovative Solutions Ltd.</td>
<td class="gt_row gt_left">Australia</td>
<td class="gt_row gt_left">Insurance</td>
<td class="gt_row gt_left">Insurtech Market Landscape and Opportunities</td>
</tr>
</tbody>
</table>


</div>
        
</div>
</div>
<p>To make the title searchable, I‚Äôll embed it using an <a href="https://platform.openai.com/docs/guides/embeddings">OpenAI embedding endpoint</a>. The result will be stored in a new column with 1536 dimensions.</p>
<div id="56ef65bc" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> openai <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> OpenAI</span>
<span id="cb2-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> tqdm <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> tqdm</span>
<span id="cb2-3"></span>
<span id="cb2-4"></span>
<span id="cb2-5"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> embed_text(text: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span>]:</span>
<span id="cb2-6">    client <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> OpenAI()</span>
<span id="cb2-7">    model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"text-embedding-3-small"</span></span>
<span id="cb2-8">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> client.embeddings.create(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">input</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>text, model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>model).data[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].embedding</span>
<span id="cb2-9"></span>
<span id="cb2-10"></span>
<span id="cb2-11">title_embeddings <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [embed_text(title) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> title <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> tqdm(reports[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"title"</span>])]</span>
<span id="cb2-12"></span>
<span id="cb2-13">reports <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> reports.with_columns(</span>
<span id="cb2-14">    pl.Series(</span>
<span id="cb2-15">        name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"title_embedding"</span>,</span>
<span id="cb2-16">        values<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>title_embeddings,</span>
<span id="cb2-17">        dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>pl.Array(inner<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>pl.Float64, shape<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1536</span>),</span>
<span id="cb2-18">    )</span>
<span id="cb2-19">)</span></code></pre></div>
</div>
<p>Now, I‚Äôll insert the data including the embeddings into the database. The embeddings are stored in a fixed-size <code>ARRAY</code> column. The co-location of the structured data and the embeddings in the same table is convenient for our use case.</p>
<div id="8f1bb9e3" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="annotated-cell-4" style="background: #f1f3f5;"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-4-1">con.execute(</span>
<span id="annotated-cell-4-2">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="annotated-cell-4-3"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    CREATE OR REPLACE TABLE reports AS</span></span>
<span id="annotated-cell-4-4"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    SELECT</span></span>
<span id="annotated-cell-4-5"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        id::integer AS id,</span></span>
<span id="annotated-cell-4-6"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        year::integer AS year,</span></span>
<span id="annotated-cell-4-7"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        institute::varchar AS institute,</span></span>
<span id="annotated-cell-4-8"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        country::varchar AS country,</span></span>
<span id="annotated-cell-4-9"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        topic::varchar AS topic,</span></span>
<span id="annotated-cell-4-10"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        title::varchar AS title,</span></span>
<span id="annotated-cell-4-11"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        title_embedding::float[1536] AS title_embedding</span></span>
<span id="annotated-cell-4-12"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    FROM reports;</span></span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-4" data-target-annotation="1">1</button><span id="annotated-cell-4-13" class="code-annotation-target"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="annotated-cell-4-14">)</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-hidden code-annotation-container-grid">
<dt data-target-cell="annotated-cell-4" data-target-annotation="1">1</dt>
<dd>
<span data-code-cell="annotated-cell-4" data-code-lines="13" data-code-annotation="1">This works because DuckDB can read from a Polars DataFrame.</span>
</dd>
</dl>
</div>
</div>
<div id="e1503c45" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">con.execute(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"INSTALL vss;"</span>)</span>
<span id="cb3-2">con.execute(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"LOAD vss;"</span>)</span>
<span id="cb3-3"></span>
<span id="cb3-4">con.execute(</span>
<span id="cb3-5">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"CREATE INDEX titles_hnsw_index ON reports USING HNSW(title_embedding) WITH (metric='cosine');"</span></span>
<span id="cb3-6">)</span></code></pre></div>
</div>
<p>I also create a hierarchical navigable small world (HNSW) index on the title embeddings. This enables approximate nearest neighbor search in O(log n). It‚Äôs enabled by the <a href="https://duckdb.org/docs/extensions/vss">vss</a> extension. Note that persistence to disk is experimental, so I wouldn‚Äôt recommend it for production yet.</p>
</section>
<section id="agent" class="level3">
<h3 class="anchored" data-anchor-id="agent">Agent</h3>
<p>Let‚Äôs set up an agent powered by the <a href="https://groq.com">Groq</a> inference API. It serves a range of open source models. Specifically, I‚Äôll use the <code>llama-3.3-70b-versatile</code> model released by Meta on December 6th. Artificial Analysis has a detailed <a href="https://artificialanalysis.ai/models/llama-3-3-instruct-70b/providers">report</a> showing that it advanced the speed-accuracy trade-off. The model has tool calling capabilities, which are critical for our use case.</p>
<div id="6c615539" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="annotated-cell-6" style="background: #f1f3f5;"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-6-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pydantic_ai <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Agent</span>
<span id="annotated-cell-6-2"></span>
<span id="annotated-cell-6-3">agent <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Agent(</span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-6" data-target-annotation="1">1</button><span id="annotated-cell-6-4" class="code-annotation-target">    model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"groq:llama-3.3-70b-versatile"</span>,</span>
<span id="annotated-cell-6-5">    system_prompt<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"You are a market research expert and answer questions using a database of reports."</span>,</span>
<span id="annotated-cell-6-6">)</span>
<span id="annotated-cell-6-7"></span>
<span id="annotated-cell-6-8">result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> agent.run_sync(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Who are you?"</span>)</span>
<span id="annotated-cell-6-9"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(result.data)</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-hidden code-annotation-container-grid">
<dt data-target-cell="annotated-cell-6" data-target-annotation="1">1</dt>
<dd>
<span data-code-cell="annotated-cell-6" data-code-lines="4" data-code-annotation="1">See the <a href="https://ai.pydantic.dev/api/models/base/#pydantic_ai.models.KnownModelName">KnownModelName</a> documentation for a list of supported models.</span>
</dd>
</dl>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>I am a market research expert, providing insights and analysis based on a vast database of reports and studies. My expertise spans various industries, including consumer goods, technology, healthcare, and finance. I can help answer questions, provide data-driven insights, and offer market trends and analysis to support business decisions.

My database includes reports from reputable sources, such as market research firms, academic institutions, and industry associations. I can access a wide range of topics, including market size and growth, consumer behavior, competitor analysis, and emerging trends.

What specific area of market research would you like to explore?</code></pre>
</div>
</div>
</section>
<section id="tools" class="level3">
<h3 class="anchored" data-anchor-id="tools">Tools</h3>
<p>The agent‚Äôs job will be to answer questions based on the reports in the database. It needs a way to access the database. We can give it a tool, meaning a function that it can call, to query the database. First, it needs a database connection.</p>
<div id="1b732c95" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="annotated-cell-7" style="background: #f1f3f5;"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-7-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> dataclasses <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> dataclass</span>
<span id="annotated-cell-7-2"></span>
<span id="annotated-cell-7-3"></span>
<span id="annotated-cell-7-4"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@dataclass</span></span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-7" data-target-annotation="1">1</button><span id="annotated-cell-7-5" class="code-annotation-target"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> AgentDependencies:</span>
<span id="annotated-cell-7-6">    db: duckdb.DuckDBPyConnection</span>
<span id="annotated-cell-7-7"></span>
<span id="annotated-cell-7-8"></span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-7" data-target-annotation="2">2</button><span id="annotated-cell-7-9" class="code-annotation-target">deps <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> AgentDependencies(db<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>con)</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-hidden code-annotation-container-grid">
<dt data-target-cell="annotated-cell-7" data-target-annotation="1">1</dt>
<dd>
<span data-code-cell="annotated-cell-7" data-code-lines="5" data-code-annotation="1">A dataclass that contains dependencies needed by the agent. Additional dependencies can be added as needed.</span>
</dd>
<dt data-target-cell="annotated-cell-7" data-target-annotation="2">2</dt>
<dd>
<span data-code-cell="annotated-cell-7" data-code-lines="9" data-code-annotation="2">This is the connection that has the connection to the in-memory DuckDBdatabase.</span>
</dd>
</dl>
</div>
</div>
<p>Next, let‚Äôs give the agent a tool to search the database of reports. Based on the user‚Äôs question, it can choose which field to search. The result is always a markdown-formatted table with one row per report.</p>
<div id="4aa0faf3" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="annotated-cell-8" style="background: #f1f3f5;"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-8-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> json</span>
<span id="annotated-cell-8-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> typing <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Literal</span>
<span id="annotated-cell-8-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pydantic_ai <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> RunContext</span>
<span id="annotated-cell-8-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pydantic <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> validate_call, Field</span>
<span id="annotated-cell-8-5"></span>
<span id="annotated-cell-8-6"></span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-8" data-target-annotation="1">1</button><span id="annotated-cell-8-7" class="code-annotation-target"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> df_to_str(df: pl.DataFrame) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>:</span>
<span id="annotated-cell-8-8">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> json.dumps(df.to_dicts())</span>
<span id="annotated-cell-8-9"></span>
<span id="annotated-cell-8-10"></span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-8" data-target-annotation="2">2</button><span id="annotated-cell-8-11" class="code-annotation-target"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@agent.tool</span></span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-8" data-target-annotation="3">3</button><span id="annotated-cell-8-12" class="code-annotation-target"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@validate_call</span>(config<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>{<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"arbitrary_types_allowed"</span>: <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>})</span>
<span id="annotated-cell-8-13"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> search_reports_by_field(</span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-8" data-target-annotation="4">4</button><span id="annotated-cell-8-14" class="code-annotation-target">    ctx: RunContext[AgentDependencies],</span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-8" data-target-annotation="5">5</button><span id="annotated-cell-8-15" class="code-annotation-target">    field: Literal[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"id"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"year"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"institute"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"country"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"topic"</span>],</span>
<span id="annotated-cell-8-16">    value: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Field(</span>
<span id="annotated-cell-8-17">        description<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"The value to search for in the field. Case insensitive."</span></span>
<span id="annotated-cell-8-18">    ),</span>
<span id="annotated-cell-8-19">) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>:</span>
<span id="annotated-cell-8-20">    base_query <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="annotated-cell-8-21"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        SELECT id, year, institute, country, topic, title </span></span>
<span id="annotated-cell-8-22"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        FROM reports </span></span>
<span id="annotated-cell-8-23"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        WHERE </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{}</span></span>
<span id="annotated-cell-8-24"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="annotated-cell-8-25"></span>
<span id="annotated-cell-8-26">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> field <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"id"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"year"</span>]:</span>
<span id="annotated-cell-8-27">        value <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(value)</span>
<span id="annotated-cell-8-28">        where_clause <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>field<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> = ?"</span></span>
<span id="annotated-cell-8-29">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="annotated-cell-8-30">        where_clause <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"lower(</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>field<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">) = lower(?)"</span></span>
<span id="annotated-cell-8-31"></span>
<span id="annotated-cell-8-32">    final_query <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> base_query.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">format</span>(where_clause)</span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-8" data-target-annotation="6">6</button><span id="annotated-cell-8-33" class="code-annotation-target">    df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ctx.deps.db.execute(final_query, [value]).pl()</span>
<span id="annotated-cell-8-34"></span>
<span id="annotated-cell-8-35">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> df.shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>:</span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-8" data-target-annotation="7">7</button><span id="annotated-cell-8-36" class="code-annotation-target">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"No reports found. Try a different field or value, or use the title similarity tool."</span></span>
<span id="annotated-cell-8-37">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> df_to_str(df)</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-hidden code-annotation-container-grid">
<dt data-target-cell="annotated-cell-8" data-target-annotation="1">1</dt>
<dd>
<span data-code-cell="annotated-cell-8" data-code-lines="7" data-code-annotation="1">A record-oriented JSON representation of the data frame is understand by an LLM.</span>
</dd>
<dt data-target-cell="annotated-cell-8" data-target-annotation="2">2</dt>
<dd>
<span data-code-cell="annotated-cell-8" data-code-lines="11" data-code-annotation="2">Use the <code>@agent.tool</code> decorator to register the function as a tool.</span>
</dd>
<dt data-target-cell="annotated-cell-8" data-target-annotation="3">3</dt>
<dd>
<span data-code-cell="annotated-cell-8" data-code-lines="12" data-code-annotation="3">Use the <code>@validate_call</code> decorator to enable type checking of the function arguments. This makes sure that only the fields present in the database can be used. <code>arbitrary_types_allowed</code> is required because the <code>RunContext</code> type is not a standard type.</span>
</dd>
<dt data-target-cell="annotated-cell-8" data-target-annotation="4">4</dt>
<dd>
<span data-code-cell="annotated-cell-8" data-code-lines="14" data-code-annotation="4">The <code>RunContext</code> type hint is required for the tool to access the dependencies.</span>
</dd>
<dt data-target-cell="annotated-cell-8" data-target-annotation="5">5</dt>
<dd>
<span data-code-cell="annotated-cell-8" data-code-lines="15" data-code-annotation="5">Tell the model about the available fields in the database and validate that only those are selected.</span>
</dd>
<dt data-target-cell="annotated-cell-8" data-target-annotation="6">6</dt>
<dd>
<span data-code-cell="annotated-cell-8" data-code-lines="33" data-code-annotation="6">The database query returns a polars DataFrame.</span>
</dd>
<dt data-target-cell="annotated-cell-8" data-target-annotation="7">7</dt>
<dd>
<span data-code-cell="annotated-cell-8" data-code-lines="36" data-code-annotation="7">Provide a clear message if no reports are found and hint that another function (which will be introduced later) can be used for fuzzy matching.</span>
</dd>
</dl>
</div>
</div>
<p>This lets the agent execute searches based on the exact match of a field.</p>
<div id="5f301a90" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">deps <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> AgentDependencies(db<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>con)</span>
<span id="cb5-2">result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> agent.run_sync(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Which reports do we have from Germany?"</span>, deps<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>deps)</span>
<span id="cb5-3"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(result.data)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>We have four reports from Germany:

1. "Global Electric Vehicle Market Outlook 2018-2023" by Research DNA GmbH (2018) - Automotive topic
2. "Digital Advertising Spend Analysis" by Tech Innovations Ltd. (2020) - Media topic
3. "Beverage Market Competitive Analysis" by Research DNA GmbH (2022) - FMCG topic
4. "Medical Imaging Equipment Market Size" by Tech Innovations Ltd. (2024) - Healthcare topic

Let me know if you'd like more information about any of these reports.</code></pre>
</div>
</div>
<p>It works, the agent found the 4 reports from Germany. Let‚Äôs check the exact tool call:</p>
<div id="1e729fc6" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1">agent.last_run_messages</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="12">
<pre><code>[ModelRequest(parts=[SystemPromptPart(content='You are a market research expert and answer questions using a database of reports.', part_kind='system-prompt'), UserPromptPart(content='Which reports do we have from Germany?', timestamp=datetime.datetime(2024, 12, 18, 17, 38, 58, 663721, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'),
 ModelResponse(parts=[ToolCallPart(tool_name='search_reports_by_field', args=ArgsJson(args_json='{"field": "country", "value": "Germany"}'), tool_call_id='call_be61', part_kind='tool-call')], timestamp=datetime.datetime(2024, 12, 18, 17, 38, 58, tzinfo=datetime.timezone.utc), kind='response'),
 ModelRequest(parts=[ToolReturnPart(tool_name='search_reports_by_field', content='[{"id": 1, "year": 2018, "institute": "Research DNA GmbH", "country": "Germany", "topic": "Automotive", "title": "Global Electric Vehicle Market Outlook 2018-2023"}, {"id": 12, "year": 2020, "institute": "Tech Innovations Ltd.", "country": "Germany", "topic": "Media", "title": "Digital Advertising Spend Analysis"}, {"id": 21, "year": 2022, "institute": "Research DNA GmbH", "country": "Germany", "topic": "FMCG", "title": "Beverage Market Competitive Analysis"}, {"id": 32, "year": 2024, "institute": "Tech Innovations Ltd.", "country": "Germany", "topic": "Healthcare", "title": "Medical Imaging Equipment Market Size"}]', tool_call_id='call_be61', timestamp=datetime.datetime(2024, 12, 18, 17, 38, 59, 27429, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request'),
 ModelResponse(parts=[TextPart(content='We have four reports from Germany:\n\n1. "Global Electric Vehicle Market Outlook 2018-2023" by Research DNA GmbH (2018) - Automotive topic\n2. "Digital Advertising Spend Analysis" by Tech Innovations Ltd. (2020) - Media topic\n3. "Beverage Market Competitive Analysis" by Research DNA GmbH (2022) - FMCG topic\n4. "Medical Imaging Equipment Market Size" by Tech Innovations Ltd. (2024) - Healthcare topic\n\nLet me know if you\'d like more information about any of these reports.', part_kind='text')], timestamp=datetime.datetime(2024, 12, 18, 17, 38, 59, tzinfo=datetime.timezone.utc), kind='response')]</code></pre>
</div>
</div>
<p>Here, the model correctly translated the user‚Äôs question into the tool call with the arguments <code>{"field": "country", "value": "Germany"}</code>.</p>
<p>To make it easier to evaluate the agent‚Äôs output and also make its results useable by other tools, we can create a response model that includes the ids of the identified reports.</p>
<div id="9dc4de41" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="annotated-cell-11" style="background: #f1f3f5;"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-11-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pydantic <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> BaseModel</span>
<span id="annotated-cell-11-2"></span>
<span id="annotated-cell-11-3"></span>
<span id="annotated-cell-11-4"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> AgentResponse(BaseModel):</span>
<span id="annotated-cell-11-5">    text: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Field(</span>
<span id="annotated-cell-11-6">        description<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Answer to the user's question in informal language. Don't include the report ids."</span></span>
<span id="annotated-cell-11-7">    )</span>
<span id="annotated-cell-11-8">    relevant_report_ids: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">set</span>[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Field(</span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-11" data-target-annotation="1">1</button><span id="annotated-cell-11-9" class="code-annotation-target">        description<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Set of 'id' integer values of the reports that are relevant to the user's question. Only include ids retrieved by the search tools. Never make up ids. Not all ids returned by the search tools are relevant."</span></span>
<span id="annotated-cell-11-10">    )</span>
<span id="annotated-cell-11-11"></span>
<span id="annotated-cell-11-12"></span>
<span id="annotated-cell-11-13">typed_agent <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Agent(</span>
<span id="annotated-cell-11-14">    model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"groq:llama-3.3-70b-versatile"</span>,</span>
<span id="annotated-cell-11-15">    system_prompt<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"You are a market research expert and answer questions using a database of reports."</span>,</span>
<span id="annotated-cell-11-16">    result_type<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>AgentResponse,</span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-11" data-target-annotation="2">2</button><span id="annotated-cell-11-17" class="code-annotation-target">    result_retries<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>,</span>
<span id="annotated-cell-11-18">)</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-hidden code-annotation-container-grid">
<dt data-target-cell="annotated-cell-11" data-target-annotation="1">1</dt>
<dd>
<span data-code-cell="annotated-cell-11" data-code-lines="9" data-code-annotation="1">This description fixes a common mistake: the LLM would answer with made up ids like 123, 456 when it didn‚Äôt find any reports.</span>
</dd>
<dt data-target-cell="annotated-cell-11" data-target-annotation="2">2</dt>
<dd>
<span data-code-cell="annotated-cell-11" data-code-lines="17" data-code-annotation="2">Give the agent a chance to retry if it doesn‚Äôt return a valid structured output on the first try.</span>
</dd>
</dl>
</div>
</div>
<p>The <code>AgentResponse</code> model is used to validate the agent‚Äôs output. It will always include a set of integer ids. In an app, these could be used to provide links to the reports.</p>
<div id="837e1955" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1">result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> typed_agent.run_sync(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Which reports do we have from Germany? Tell me their titles and ids"</span>, deps<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>deps)</span>
<span id="cb9-2"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(result.data)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>text='The reports from Germany are titled Global Electric Vehicle Market Outlook 2018-2023, Digital Advertising Spend Analysis, Beverage Market Competitive Analysis and Medical Imaging Equipment Market Size.' relevant_report_ids={32, 1, 12, 21}</code></pre>
</div>
</div>
<p>Now we have an agent that returns a type-checked structured response. Note that I‚Äôve omitted the re-registration of the tool to the new agent instance for brevity.</p>
<p>However, requests may not exactly match the fields in the database, so let‚Äôs also add the ability to search for similar titles.</p>
<div id="c0d28b41" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="annotated-cell-13" style="background: #f1f3f5;"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-13-1"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@typed_agent.tool</span></span>
<span id="annotated-cell-13-2"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@validate_call</span>(config<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>{<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"arbitrary_types_allowed"</span>: <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>})</span>
<span id="annotated-cell-13-3"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> search_reports_by_title_similarity(</span>
<span id="annotated-cell-13-4">    ctx: RunContext[AgentDependencies],</span>
<span id="annotated-cell-13-5">    title: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Field(</span>
<span id="annotated-cell-13-6">        description<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"The title of the report to search for with vector similarity."</span></span>
<span id="annotated-cell-13-7">    ),</span>
<span id="annotated-cell-13-8">) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>:</span>
<span id="annotated-cell-13-9">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Embed the title given by the user</span></span>
<span id="annotated-cell-13-10">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">try</span>:</span>
<span id="annotated-cell-13-11">        title_embedding <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> embed_text(title)</span>
<span id="annotated-cell-13-12">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">except</span> <span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">Exception</span> <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> e:</span>
<span id="annotated-cell-13-13">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Error embedding title: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>e<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span></span>
<span id="annotated-cell-13-14"></span>
<span id="annotated-cell-13-15">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Search for similar titles</span></span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-13" data-target-annotation="1">1</button><span id="annotated-cell-13-16" class="code-annotation-target">    title_embedding_str <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"["</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">","</span>.join(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">map</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>, title_embedding)) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"]"</span></span>
<span id="annotated-cell-13-17">    query <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="annotated-cell-13-18"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        SELECT id, year, institute, country, topic, title</span></span>
<span id="annotated-cell-13-19"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        FROM reports</span></span>
<span id="annotated-cell-13-20"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        ORDER BY array_distance(title_embedding, ?::FLOAT[1536])  </span></span>
<span id="annotated-cell-13-21"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        LIMIT 5;</span></span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-13" data-target-annotation="2">2</button><span id="annotated-cell-13-22" class="code-annotation-target"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="annotated-cell-13-23">    df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ctx.deps.db.execute(query, [title_embedding_str]).pl()</span>
<span id="annotated-cell-13-24"></span>
<span id="annotated-cell-13-25">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> (</span>
<span id="annotated-cell-13-26">        df_to_str(df)</span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-13" data-target-annotation="3">3</button><span id="annotated-cell-13-27" class="code-annotation-target">        <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;"> These reports have titles similar to the query, but may not be relevant to the user's question."</span></span>
<span id="annotated-cell-13-28">    )</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-hidden code-annotation-container-grid">
<dt data-target-cell="annotated-cell-13" data-target-annotation="1">1</dt>
<dd>
<span data-code-cell="annotated-cell-13" data-code-lines="16" data-code-annotation="1">The title is embedded and formatted as a DuckDB array.</span>
</dd>
<dt data-target-cell="annotated-cell-13" data-target-annotation="2">2</dt>
<dd>
<span data-code-cell="annotated-cell-13" data-code-lines="22" data-code-annotation="2">The <code>array_distance</code> function computes the cosine similarity between the query embedding and the title embeddings in the database.</span>
</dd>
<dt data-target-cell="annotated-cell-13" data-target-annotation="3">3</dt>
<dd>
<span data-code-cell="annotated-cell-13" data-code-lines="27" data-code-annotation="3">The note about relevance is added to make it clear that these are just the most similar, not necessarily relevant. Otherwise the agent would return all reports with similar titles.</span>
</dd>
</dl>
</div>
</div>
<p>Let‚Äôs ask the agent about a topic that is not in the database to see how it uses the title similarity tool.</p>
<div id="2b25b6e8" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1">result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> agent.run_sync(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Do we have reports about quantum computing?"</span>, deps<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>deps)</span>
<span id="cb11-2"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(result.data)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;function=search_reports_by_field {"field": "topic", "value": "quantum computing"}&lt;/function&gt;</code></pre>
</div>
</div>
<p>That worked as expected.</p>
</section>
</section>
<section id="evals" class="level2">
<h2 class="anchored" data-anchor-id="evals">Evals</h2>
<p>Automated evaluations are necessary to ensure that an agent is working as expected, and to switch out models, prompts and tools without breaking the app. PydanticAI offers <a href="https://ai.pydantic.dev/testing-evals/">tools</a> for testing the code (without running a model) and for evaluations. Let‚Äôs set up a simple evaluation that checks whether the agent correctly answers questions about the database. We measure the precision (how many of the results found are relevant) and recall (how many of the relevant results are found).</p>
<div id="2d105a1d" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1">examples <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [</span>
<span id="cb13-2">    {</span>
<span id="cb13-3">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"question"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"How many reports do we have from Germany?"</span>,</span>
<span id="cb13-4">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"relevant_report_ids"</span>: {<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">21</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">32</span>},</span>
<span id="cb13-5">    },</span>
<span id="cb13-6">    {</span>
<span id="cb13-7">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"question"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"For which countries to we have reports mentioning electric vehicles?"</span>,</span>
<span id="cb13-8">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"relevant_report_ids"</span>: {<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">25</span>},</span>
<span id="cb13-9">    },</span>
<span id="cb13-10">    {</span>
<span id="cb13-11">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"question"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"What reports do we have about the gaming industry?"</span>,</span>
<span id="cb13-12">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"relevant_report_ids"</span>: {<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">22</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">30</span>},</span>
<span id="cb13-13">    },</span>
<span id="cb13-14">    {</span>
<span id="cb13-15">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"question"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"What reports do we have about the pet care industry?"</span>,</span>
<span id="cb13-16">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"relevant_report_ids"</span>: {<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">27</span>},</span>
<span id="cb13-17">    },</span>
<span id="cb13-18">    {</span>
<span id="cb13-19">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"question"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Which reports discuss cyber security insurance?"</span>,</span>
<span id="cb13-20">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"relevant_report_ids"</span>: {<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">29</span>},</span>
<span id="cb13-21">    },</span>
<span id="cb13-22">    {</span>
<span id="cb13-23">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"question"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"What healthcare reports were published in 2024?"</span>,</span>
<span id="cb13-24">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"relevant_report_ids"</span>: {<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">32</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">38</span>},</span>
<span id="cb13-25">    },</span>
<span id="cb13-26">    {</span>
<span id="cb13-27">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"question"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Which reports are about the smartphone or mobile phone market?"</span>,</span>
<span id="cb13-28">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"relevant_report_ids"</span>: {<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">40</span>},</span>
<span id="cb13-29">    },</span>
<span id="cb13-30">    {</span>
<span id="cb13-31">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"question"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"What reports do we have from Market Insights Inc.?"</span>,</span>
<span id="cb13-32">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"relevant_report_ids"</span>: {<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">22</span>},</span>
<span id="cb13-33">    },</span>
<span id="cb13-34">]</span></code></pre></div>
</div>
<div id="3db50b93" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="annotated-cell-16" style="background: #f1f3f5;"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-16-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> collections <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Counter</span>
<span id="annotated-cell-16-2"></span>
<span id="annotated-cell-16-3"></span>
<span id="annotated-cell-16-4"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> eval_example(</span>
<span id="annotated-cell-16-5">    example: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">dict</span>[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">|</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">set</span>[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>]], print_errors: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">bool</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span></span>
<span id="annotated-cell-16-6">) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">dict</span>[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>]:</span>
<span id="annotated-cell-16-7">    result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> typed_agent.run_sync(example[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"question"</span>], deps<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>deps)</span>
<span id="annotated-cell-16-8">    act, exp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> result.data.relevant_report_ids, example[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"relevant_report_ids"</span>]</span>
<span id="annotated-cell-16-9">    metrics <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Counter(</span>
<span id="annotated-cell-16-10">        {</span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-16" data-target-annotation="1">1</button><span id="annotated-cell-16-11" class="code-annotation-target">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"tp"</span>: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(act <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&amp;</span> exp),</span>
<span id="annotated-cell-16-12">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"fp"</span>: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(act <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> exp),</span>
<span id="annotated-cell-16-13">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"fn"</span>: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(exp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> act),</span>
<span id="annotated-cell-16-14">        }</span>
<span id="annotated-cell-16-15">    )</span>
<span id="annotated-cell-16-16"></span>
<span id="annotated-cell-16-17">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> print_errors <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">and</span> (metrics[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"fp"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">or</span> metrics[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"fn"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>):</span>
<span id="annotated-cell-16-18">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Error in evaluation:"</span>)</span>
<span id="annotated-cell-16-19">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"  Question: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>example[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'question'</span>]<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="annotated-cell-16-20">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"  Found: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>act<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="annotated-cell-16-21">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"  Expected: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>exp<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="annotated-cell-16-22"></span>
<span id="annotated-cell-16-23">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> metrics</span>
<span id="annotated-cell-16-24"></span>
<span id="annotated-cell-16-25"></span>
<span id="annotated-cell-16-26">metric_totals <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Counter()</span>
<span id="annotated-cell-16-27"></span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-16" data-target-annotation="2">2</button><span id="annotated-cell-16-28" class="code-annotation-target"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> example <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> tqdm(examples):</span>
<span id="annotated-cell-16-29">    metrics <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> eval_example(example)</span>
<span id="annotated-cell-16-30">    metric_totals <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> metrics</span>
<span id="annotated-cell-16-31"></span>
<span id="annotated-cell-16-32">precision <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> metric_totals[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"tp"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> (metric_totals[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"tp"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> metric_totals[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"fp"</span>])</span>
<span id="annotated-cell-16-33">recall <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> metric_totals[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"tp"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> (metric_totals[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"tp"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> metric_totals[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"fn"</span>])</span>
<span id="annotated-cell-16-34"></span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-16" data-target-annotation="3">3</button><span id="annotated-cell-16-35" class="code-annotation-target"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Precision: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>precision<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.2f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">, Recall: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>recall<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.2f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-hidden code-annotation-container-grid">
<dt data-target-cell="annotated-cell-16" data-target-annotation="1">1</dt>
<dd>
<span data-code-cell="annotated-cell-16" data-code-lines="11" data-code-annotation="1">Use set operations to compare the expected and found ids.</span>
</dd>
<dt data-target-cell="annotated-cell-16" data-target-annotation="2">2</dt>
<dd>
<span data-code-cell="annotated-cell-16" data-code-lines="28" data-code-annotation="2">This should be parallelized if the number of examples is large.</span>
</dd>
<dt data-target-cell="annotated-cell-16" data-target-annotation="3">3</dt>
<dd>
<span data-code-cell="annotated-cell-16" data-code-lines="35" data-code-annotation="3">Precision and recall could also be combined into the F1 score, which is their harmonic mean.</span>
</dd>
</dl>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>  0%|          | 0/8 [00:00&lt;?, ?it/s] 12%|‚ñà‚ñé        | 1/8 [00:00&lt;00:05,  1.19it/s] 25%|‚ñà‚ñà‚ñå       | 2/8 [00:07&lt;00:24,  4.02s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 3/8 [00:18&lt;00:37,  7.43s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 4/8 [00:34&lt;00:43, 10.85s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5/8 [00:50&lt;00:37, 12.51s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 6/8 [01:05&lt;00:26, 13.41s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 7/8 [01:27&lt;00:16, 16.16s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [01:39&lt;00:00, 14.97s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [01:39&lt;00:00, 12.44s/it]</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Precision: 1.00, Recall: 0.62</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code></code></pre>
</div>
</div>
<p>This is a joint evaluation of the agent, the tools and the database. What‚Äôs missing is an evaluation of the generated text. In a real RAG system, you‚Äôd also want separate evaluations of retrieval and result ranking.</p>
</section>
<section id="discussion" class="level2">
<h2 class="anchored" data-anchor-id="discussion">Discussion</h2>
<section id="comparison-to-other-libraries" class="level3">
<h3 class="anchored" data-anchor-id="comparison-to-other-libraries">Comparison to other libraries</h3>
<p>PydanticAI is a late entrant to the agent framework space. It joins several established libraries including:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Library</th>
<th>Description</th>
<th style="text-align: right;">Github Stars ‚≠ê</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><a href="https://github.com/Significant-Gravitas/AutoGPT">AutoGPT</a></td>
<td>AI automation platform with frontend, server and monitoring</td>
<td style="text-align: right;">169k</td>
</tr>
<tr class="even">
<td><a href="https://github.com/langchain-ai/langchain">LangChain</a></td>
<td>Package ecosystem for LLM applications</td>
<td style="text-align: right;">96k</td>
</tr>
<tr class="odd">
<td><a href="https://github.com/microsoft/autogen">autogen</a></td>
<td>Multi-agent AI chat framework by Microsoft</td>
<td style="text-align: right;">36k</td>
</tr>
<tr class="even">
<td><a href="https://github.com/crewAIInc/crewai">crewAI</a></td>
<td>Framework for orchestrating role-based AI agents</td>
<td style="text-align: right;">22k</td>
</tr>
<tr class="odd">
<td><a href="https://github.com/openai/swarm">swarm</a></td>
<td>Educational framework for multi-agent apps by OpenAI</td>
<td style="text-align: right;">17k</td>
</tr>
<tr class="even">
<td><a href="https://github.com/phidatahq/phidata">phidata</a></td>
<td>Multi-agent backend and chat frontend</td>
<td style="text-align: right;">16k</td>
</tr>
</tbody>
</table>
<p>There are dozens of other libraries with fewer stars. In addition, there are libraries specialized for RAG like <a href="https://github.com/run-llama/llama_index">LlamaIndex</a> and <a href="https://github.com/deepset-ai/haystack">Haystack</a>. The competition landscape doesn‚Äôt show signs of consolidation or slowing down.</p>
</section>
<section id="development-team" class="level3">
<h3 class="anchored" data-anchor-id="development-team">Development team</h3>
<p>Pydantic Services, the company behind Pydantic, has raised a $12.5m <a href="https://www.crunchbase.com/funding_round/pydantic-services-series-a--ddd115fb">Series A</a> in October 2024. This is great news for the project: funding pays for full time developers. It also raises the question of how Pydantic will make money, and the answer to that is Logfire subscriptions. This is a good model that gives long-term stability to the project and follows the lead of LangChain with its commercial product, <a href="https://www.langchain.com/langsmith">LangSmith</a>. I just hope that the integration remains optional. While Logfire looks great, my team already uses <a href="https://wandb.ai/site/weave/">Weave</a> by Weights &amp; Biases, and having to switch would be a barrier to adopting PydanticAI.</p>
</section>
<section id="review" class="level3">
<h3 class="anchored" data-anchor-id="review">Review</h3>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Pros ‚úÖ</strong></p>
<ul>
<li>Sensible abstractions that don‚Äôt get in the way and enable coding in a Pythonic style.</li>
<li>Type safety and integration with Pydantic.</li>
<li>Support for streaming responses and async tool calling. This is critical for live chat applications.</li>
<li>Pydantic is familiar to many Python developers who will have an easier time learning PydanticAI.</li>
<li>High quality documentation and examples that also cover tests and evals.</li>
<li>Strong reputation of the Pydantic team and high responsiveness in Github issues.</li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>Cons ‚ùå</strong></p>
<ul>
<li>Launches into a competitive market with many established libraries.</li>
<li>Early stage of development, so expect breaking changes.</li>
<li>Many concepts to learn, but mild compared to langchain which invented its own domain-specific language LCEL.</li>
<li>No support for multimodal (image, audio, video) inputs and out yet, but it‚Äôs <a href="https://github.com/pydantic/pydantic-ai/issues/126">planned</a>.</li>
<li>Economic incentives to lock users into Logfire. This hasn‚Äôt happened but is a risk.</li>
</ul>
</div>
</div>
<p>I‚Äôm looking forward to an opportunity to build a full-scale application with PydanticAI. The best place to get started is the <a href="https://ai.pydantic.dev/">PydanticAI documentation</a>.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Not every app needs an agent framework
</div>
</div>
<div class="callout-body-container callout-body">
<p>A lot can be accomplished by single API calls or by specifying a fixed sequence of calls. That would also work for the example app shown in this article. Unless you truly need the flexibility of an agent framework, you may be better off with plain Python. If all you need is Pydantic + LLM calls, you can use <a href="https://github.com/jxnl/instructor">instructor</a>. <a href="https://openai.com/index/introducing-structured-outputs-in-the-api/">OpenAI</a> even supports structured outputs based on Pydantic models without an additional library.</p>
</div>
</div>
<hr>
<p>Preview photo by <a href="https://unsplash.com/@magicpattern?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">MagicPattern</a> on <a href="https://unsplash.com/photos/purple-and-black-polka-dot-textile-eHH_5rn3xnU?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Unsplash</a></p>


</section>
</section>

 ]]></description>
  <category>Machine Learning</category>
  <category>Python</category>
  <guid>https://simmering.dev/blog/pydantic-ai/</guid>
  <pubDate>Sun, 15 Dec 2024 23:00:00 GMT</pubDate>
  <media:content url="https://simmering.dev/blog/pydantic-ai/image.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Constrained by Context, Not Reasoning</title>
  <dc:creator>Paul Simmering</dc:creator>
  <link>https://simmering.dev/blog/context-constrained/</link>
  <description><![CDATA[ 





<p>Frontier LLMs rarely give completely wrong answers. Even when their responses aren‚Äôt exactly what we need, they‚Äôre usually logical given the information provided.</p>
<p>Recent advances in chain-of-thought reasoning, such as in models like <a href="https://openai.com/index/learning-to-reason-with-llms/">OpenAI‚Äôs o1</a> and <a href="https://www.alibabacloud.com/blog/alibaba-cloud-unveils-open-source-ai-reasoning-model-qwq-and-new-image-editing-tool_601813">Alibaba‚Äôs QwQ</a>, have led to remarkable achievements. These models now outperform most humans on complex tasks like competition mathematics (AIME 2024) and PhD-level science questions (GPQA Diamond).</p>
<p>Yet here‚Äôs the paradox: despite this impressive reasoning capability, LLMs often struggle to provide immediately useful outputs for everyday professional tasks. Usually, their output has to be edited or the prompt rewritten multiple times to produce a copy-pasteable result. This leads to my thesis: <strong>The real-world effectiveness of LLMs is now limited more by their awareness of context than by their reasoning capabilities</strong>.</p>
<p>Think of an LLM as a brilliant but newly hired colleague who hasn‚Äôt been properly onboarded. While they can tackle complex problems, they miss crucial contextual details required to fit their work into the existing workflows. The challenge isn‚Äôt their intelligence‚Äîit‚Äôs their need for situational awareness.</p>
<section id="context-makes-outputs-more-useful" class="level2">
<h2 class="anchored" data-anchor-id="context-makes-outputs-more-useful">Context makes outputs more useful</h2>
<p>Here are some examples of how adding context lets LLMs produce outputs that are more readily applicable:</p>
<ul>
<li>When summarizing a technical document, telling the model ‚ÄúThis is for marketing executives who need to understand the business implications‚Äù yields very different (and more useful) results than just asking for a summary</li>
<li>For educational content, specifying ‚ÄúExplain this for a high school student‚Äù versus ‚ÄúExplain this for a graduate student‚Äù completely changes the depth and terminology used</li>
<li>In correspondence, sharing details like ‚ÄúThis is for a long-time client who prefers informal communication‚Äù helps create more appropriately-toned messages For social media, providing examples of past successful posts or a company style guide helps the model match the preferred tone</li>
<li>In software development, showing the model your existing codebase helps it suggest solutions that integrate seamlessly with your architecture</li>
<li>During translation work, specifying ‚ÄúThis is medical documentation‚Äù versus ‚ÄúThis is marketing material‚Äù ensures appropriate terminology and tone</li>
</ul>
</section>
<section id="infusing-context-actively-and-passively" class="level2">
<h2 class="anchored" data-anchor-id="infusing-context-actively-and-passively">Infusing context actively and passively</h2>
<p>It‚Äôs tedious to write a detailed briefing each time, just like you wouldn‚Äôt want to repeat onboarding of a colleague. Here are ways to reuse prompts or passively infuse context:</p>
<ul>
<li>Write a persistent system prompt that‚Äôs automatically applied to all conversations. In ChatGPT, you can do this by creating a custom GPT.</li>
<li>Enable chat history to be able to copy-paste successful prompts into new conversations.</li>
<li>Turn on features that let the model learn from past interactions (if not dealing with sensitive data).</li>
<li>When writing in an editor enhanced by AI, prefer one long document over spreading content across many shorter documents.</li>
<li>Work with developer tools like GitHub Copilot or Cursor that read your code base rather than copy-pasting snippets into a separate chat window. This also works for non-coding tasks, such as writing articles.</li>
<li>Use dictation to speak your prompt effortlessly. Speak about the situation and the task in a stream of consciousness.</li>
<li>Share your screen with an assistant. This <a href="https://beebom.com/how-you-can-try-google-project-astra-stream-realtime/">feature</a> was added to Google Gemini in December 2024. While my experience testing it was mixed, I think this could become an effective way to continuously share context. It makes most sense with apps that don‚Äôt have their own built-in assistant.</li>
</ul>
<hr>
<p>Preview photo by <a href="https://unsplash.com/@magicpattern?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">MagicPattern</a> on <a href="https://unsplash.com/photos/purple-and-pink-letter-blocks-jbywvpa9vH8?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Unsplash</a></p>


</section>

 ]]></description>
  <category>Productivity</category>
  <category>Machine Learning</category>
  <guid>https://simmering.dev/blog/context-constrained/</guid>
  <pubDate>Fri, 13 Dec 2024 23:00:00 GMT</pubDate>
  <media:content url="https://simmering.dev/blog/context-constrained/image.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Aspect-based Sentiment Analysis with DSPy</title>
  <dc:creator>Paul Simmering</dc:creator>
  <link>https://simmering.dev/blog/absa-with-dspy/</link>
  <description><![CDATA[ 





<p>Last year, my colleague Paavo Huoviala and I explored prompting and fine-tuning large language models for aspect-based sentiment analysis (ABSA) <span class="citation" data-cites="simmering2023large">(Simmering and Huoviala 2023)</span>. Like many researchers at the time, we spent considerable effort manually crafting prompts and selecting few-shot examples. But what if we could automate this process? Enter DSPy - a Python library that automatically optimizes LLM prompts. In this article, I‚Äôll revisit our ABSA experiments using DSPy‚Äôs automated approach instead of manual prompt engineering.</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Resource</th>
<th>Link</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>üíª Code</td>
<td><a href="https://github.com/psimm/website/blob/master/blog/absa-with-dspy/index.qmd">GitHub</a></td>
</tr>
<tr class="even">
<td>üìä Experiments</td>
<td><a href="https://wandb.ai/psimm/absa-dspy">Weights &amp; Biases project</a></td>
</tr>
<tr class="odd">
<td>üìù Dataset</td>
<td><a href="https://huggingface.co/datasets/psimm/absa-semeval2014-alpaca">Hugging Face Hub</a></td>
</tr>
</tbody>
</table>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
DSPy version 2.5.32
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>DSPy is in rapid development. I‚Äôve encountered outdated tutorials, dead links in the documentation and deprecation warnings. The code of this article may not work with future versions.</p>
</div>
</div>
</div>
<section id="dspy-programming-not-prompting-llms" class="level2">
<h2 class="anchored" data-anchor-id="dspy-programming-not-prompting-llms">DSPy: Programming ‚Äî not prompting ‚Äî LLMs</h2>
<p><img src="https://simmering.dev/blog/absa-with-dspy/dspy_logo.webp" class="img-fluid" style="width:50.0%"></p>
<p><a href="https://dspy.ai">DSPy</a> is a Python library developed by Stanford NLP. Rather than manually crafting prompts and seeing them break whenever something changes elsewhere in the pipeline, DSPy automates the process of finding the optimal prompts. The documentation has an <a href="https://dspy.ai/learn/">overview</a> of the main building blocks of the library. In this article, I‚Äôll introduce the elements needed to optimize a structured prediction task, using ABSA as an example.</p>
<section id="experiment-setup" class="level3">
<h3 class="anchored" data-anchor-id="experiment-setup">Experiment setup</h3>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">%%{init: {
  'theme': 'base',
  'themeVariables': {
    'primaryColor': '#ffffff',
    'primaryTextColor': '#2d3748',
    'primaryBorderColor': '#90cdf4',
    'lineColor': '#64748b',
    'secondaryColor': '#ffffff',
    'tertiaryColor': '#ffffff',
    'fontSize': '22px',
    'labelFontSize': '18px',
    'edgeLabelFontSize': '18px'
  }
}}%%
graph TB
    %% Define styles
    classDef default fill:#ffffff,stroke:#90cdf4,stroke-width:2px
    classDef highlight fill:#fdf2f8,stroke:#ed64a6,stroke-width:3px
    classDef api fill:#ffffff,stroke:#4fd1c5,stroke-width:2px
    
    subgraph Data ["1Ô∏è‚É£ Data"]
        D1[SemEval Dataset] --&gt; |"Transform"| D2[DSPy Examples]
    end
    
    subgraph Definition ["2Ô∏è‚É£ Model Definition"]
        M2[Pydantic Models] --&gt; |"Define Structure"| M1[DSPy Signature]
        M1 --&gt; |"Initialize"| M3[Predictor]
        M4[Language Models] --&gt; |"Power"| M3
        A1[OpenAI API] --&gt; |"Provide"| M4
        A2[Fireworks.ai API] --&gt; |"Provide"| M4
    end
    
    subgraph Optimization ["3Ô∏è‚É£ Optimization"]
        O1[Evaluation Function] --&gt; |"Guide"| O2[MIPROv2 Optimizer]
        M3 --&gt; |"Optimize"| O2
        D2 --&gt; |"Train"| O2
        O2 --&gt; |"Output"| O3[Optimized Predictor]
    end
    
    subgraph Evaluation ["4Ô∏è‚É£ Evaluation"]
        O3 --&gt; |"Test"| E1[Test Set Evaluation]
        O1 --&gt; |"Measure"| E1
        E1 --&gt; |"Log"| E2[Weights &amp; Biases]
    end

    %% Apply styles
    class O2 highlight
    class A1,A2,E2 api
    
    %% Links between subgraphs
    linkStyle default stroke:#64748b,stroke-width:2px
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<p>The steps will be explained in the following sections.</p>
</section>
</section>
<section id="dataset-for-aspect-based-sentiment-analysis" class="level2">
<h2 class="anchored" data-anchor-id="dataset-for-aspect-based-sentiment-analysis">Dataset for Aspect-based Sentiment Analysis</h2>
<p>The goal of ABSA is to analyze a review and extract the discussed aspects of a product or service and the sentiment towards each aspect. For example, the review ‚ÄúThe pizza was great, but the service was terrible‚Äù contains two aspects: ‚Äúpizza‚Äù (positive) and ‚Äúservice‚Äù (negative). There are more advanced variants of ABSA, but for this article I‚Äôll focus on the basic task. I will also let a single model handle the extraction and the classification.</p>
<section id="semeval-2014-task-4" class="level3">
<h3 class="anchored" data-anchor-id="semeval-2014-task-4">SemEval 2014 Task 4</h3>
<p>I‚Äôm using the SemEval 2014 Task 4 dataset by <span class="citation" data-cites="pontiki_semeval">Pontiki et al. (2014)</span>. The <a href="https://huggingface.co/datasets/psimm/absa-semeval2014-alpaca">dataset</a> is available on Hugging Face. This is a cleaned version of the original XML files consisting of train and test splits. The small number of examples with the ‚Äúconflict‚Äù label are excluded, as is common in the literature.</p>
<div id="c9a578ab" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> polars <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pl</span>
<span id="cb1-2"></span>
<span id="cb1-3">url <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"hf://datasets/psimm/absa-semeval2014-alpaca"</span></span>
<span id="cb1-4"></span>
<span id="cb1-5">train <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pl.read_parquet(url <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"/data/train-00000-of-00001.parquet"</span>)</span>
<span id="cb1-6">test <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pl.read_parquet(url <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"/data/test-00000-of-00001.parquet"</span>)</span></code></pre></div>
</div>
<div id="b21443cd" class="cell" data-execution_count="2">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> great_tables <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> GT</span>
<span id="cb2-2"></span>
<span id="cb2-3">overview <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (</span>
<span id="cb2-4">    train.vstack(test)</span>
<span id="cb2-5">    .group_by([<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"split"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"domain"</span>])</span>
<span id="cb2-6">    .agg(examples<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>pl.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>())</span>
<span id="cb2-7">    .sort(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"split"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"domain"</span>, descending<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb2-8">)</span>
<span id="cb2-9">GT(overview).tab_header(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"SemEval 2014 Task 4 Dataset"</span>).cols_label(</span>
<span id="cb2-10">    split<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Split"</span>,</span>
<span id="cb2-11">    domain<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Domain"</span>,</span>
<span id="cb2-12">    examples<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Examples"</span>,</span>
<span id="cb2-13">).cols_align(align<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"right"</span>, columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"examples"</span>])</span></code></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="2">
<div id="oykrqaoiln" style="padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>
#oykrqaoiln table {
          font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;
          -webkit-font-smoothing: antialiased;
          -moz-osx-font-smoothing: grayscale;
        }

#oykrqaoiln thead, tbody, tfoot, tr, td, th { border-style: none; }
 tr { background-color: transparent; }
#oykrqaoiln p { margin: 0; padding: 0; }
 #oykrqaoiln .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; }
 #oykrqaoiln .gt_caption { padding-top: 4px; padding-bottom: 4px; }
 #oykrqaoiln .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; }
 #oykrqaoiln .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; }
 #oykrqaoiln .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; }
 #oykrqaoiln .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; }
 #oykrqaoiln .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; }
 #oykrqaoiln .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; }
 #oykrqaoiln .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; }
 #oykrqaoiln .gt_column_spanner_outer:first-child { padding-left: 0; }
 #oykrqaoiln .gt_column_spanner_outer:last-child { padding-right: 0; }
 #oykrqaoiln .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; }
 #oykrqaoiln .gt_spanner_row { border-bottom-style: hidden; }
 #oykrqaoiln .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; }
 #oykrqaoiln .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; }
 #oykrqaoiln .gt_from_md> :first-child { margin-top: 0; }
 #oykrqaoiln .gt_from_md> :last-child { margin-bottom: 0; }
 #oykrqaoiln .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; }
 #oykrqaoiln .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; }
 #oykrqaoiln .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; }
 #oykrqaoiln .gt_row_group_first td { border-top-width: 2px; }
 #oykrqaoiln .gt_row_group_first th { border-top-width: 2px; }
 #oykrqaoiln .gt_striped { background-color: rgba(128,128,128,0.05); }
 #oykrqaoiln .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; }
 #oykrqaoiln .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; }
 #oykrqaoiln .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; text-align: left; }
 #oykrqaoiln .gt_left { text-align: left; }
 #oykrqaoiln .gt_center { text-align: center; }
 #oykrqaoiln .gt_right { text-align: right; font-variant-numeric: tabular-nums; }
 #oykrqaoiln .gt_font_normal { font-weight: normal; }
 #oykrqaoiln .gt_font_bold { font-weight: bold; }
 #oykrqaoiln .gt_font_italic { font-style: italic; }
 #oykrqaoiln .gt_super { font-size: 65%; }
 #oykrqaoiln .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; }
 #oykrqaoiln .gt_asterisk { font-size: 100%; vertical-align: 0; }
 
</style>

<table class="gt_table caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-quarto-disable-processing="false" data-quarto-bootstrap="false">
<thead>
<tr class="gt_heading header">
<th colspan="3" class="gt_heading gt_title gt_font_normal">SemEval 2014 Task 4 Dataset</th>
</tr>
<tr class="gt_col_headings even">
<th id="Split" class="gt_col_heading gt_columns_bottom_border gt_left" data-quarto-table-cell-role="th" scope="col">Split</th>
<th id="Domain" class="gt_col_heading gt_columns_bottom_border gt_left" data-quarto-table-cell-role="th" scope="col">Domain</th>
<th id="Examples" class="gt_col_heading gt_columns_bottom_border gt_right" data-quarto-table-cell-role="th" scope="col">Examples</th>
</tr>
</thead>
<tbody class="gt_table_body">
<tr class="odd">
<td class="gt_row gt_left">train</td>
<td class="gt_row gt_left">restaurants</td>
<td class="gt_row gt_right">2957</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">train</td>
<td class="gt_row gt_left">laptops</td>
<td class="gt_row gt_right">3002</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">test</td>
<td class="gt_row gt_left">restaurants</td>
<td class="gt_row gt_right">786</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">test</td>
<td class="gt_row gt_left">laptops</td>
<td class="gt_row gt_right">786</td>
</tr>
</tbody>
</table>


</div>
        
</div>
</div>
<p>The dataset contains a similar number of restaurant and laptop reviews.</p>
<p>The goal is to choose the optimal prompt and few-shot examples to maximize the F1 score of the aspect extraction and classification. To achieve this, DSPy needs to be able to evaluate the metrics and a training set to learn from.</p>
</section>
</section>
<section id="model-definition" class="level2">
<h2 class="anchored" data-anchor-id="model-definition">Model Definition</h2>
<section id="pydantic-models-for-absa" class="level3">
<h3 class="anchored" data-anchor-id="pydantic-models-for-absa">Pydantic models for ABSA</h3>
<p>We create classes to represent the input and output of the task using the data validation library <a href="https://docs.pydantic.dev/latest/">Pydantic</a>. This helps with validating the data and provides a structured output format for predictor. The <code>Field</code> class is used to describe the expected data type. Their descriptions match the ones used in <span class="citation" data-cites="simmering2023large">(Simmering and Huoviala 2023)</span>. This is a form of prompting, but DSPy also supports automatically setting the structure‚Äôs descriptions using the <a href="https://dspy.ai/learn/8-typed_predictors/?h=typed#optimizing-typed-predictors"><code>optimize_signature</code></a> optimizer. In this experiment I‚Äôll stick with the original descriptions and only vary the normal prompt and few-shot examples.</p>
<div id="fa24fc6d" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> typing <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Literal</span>
<span id="cb3-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pydantic <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> BaseModel, Field</span>
<span id="cb3-3"></span>
<span id="cb3-4"></span>
<span id="cb3-5"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> Input(BaseModel):</span>
<span id="cb3-6">    text: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Field()</span>
<span id="cb3-7"></span>
<span id="cb3-8"></span>
<span id="cb3-9"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> Aspect(BaseModel):</span>
<span id="cb3-10">    term: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Field(</span>
<span id="cb3-11">        description<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"An aspect term, which is a verbatim text snippet. Single or multiword terms naming particular aspects of the reviewed product or service."</span></span>
<span id="cb3-12">    )</span>
<span id="cb3-13">    polarity: Literal[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"positive"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"neutral"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"negative"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Field(</span>
<span id="cb3-14">        description<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"The polarity expressed towards the aspect term. Valid polarities are ‚Äòpositive‚Äô, ‚Äòneutral‚Äô, ‚Äònegative'."</span></span>
<span id="cb3-15">    )</span>
<span id="cb3-16"></span>
<span id="cb3-17">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__hash__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>):</span>
<span id="cb3-18">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb3-19"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Make the aspect hashable to enable set operations in evaluation.</span></span>
<span id="cb3-20"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Hash is case-insensitive.</span></span>
<span id="cb3-21"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb3-22">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">hash</span>((<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.term.lower(), <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.polarity.lower()))</span>
<span id="cb3-23"></span>
<span id="cb3-24">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__eq__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, other):</span>
<span id="cb3-25">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb3-26"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Define equality for case-insensitive comparison.</span></span>
<span id="cb3-27"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb3-28">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">isinstance</span>(other, Aspect):</span>
<span id="cb3-29">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span></span>
<span id="cb3-30">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> (</span>
<span id="cb3-31">            <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.term.lower() <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> other.term.lower()</span>
<span id="cb3-32">            <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">and</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.polarity.lower() <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> other.polarity.lower()</span>
<span id="cb3-33">        )</span>
<span id="cb3-34"></span>
<span id="cb3-35"></span>
<span id="cb3-36"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> Aspects(BaseModel):</span>
<span id="cb3-37">    aspects: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>[Aspect] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Field(</span>
<span id="cb3-38">        description<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"An array of aspects and their polarities. If no aspects are mentioned in the text, use an empty array."</span></span>
<span id="cb3-39">    )</span></code></pre></div>
</div>
<p>The <code>__hash__</code> and <code>__eq__</code> methods will be helpful for evaluation, because they allow for use of set operations to compare gold and predicted aspects.</p>
</section>
<section id="transform-dataset-to-dspy-examples" class="level3">
<h3 class="anchored" data-anchor-id="transform-dataset-to-dspy-examples">Transform dataset to DSPy examples</h3>
<p>Each row in the dataset needs to be turned into an instance of the <code>dspy.Example</code> class. The <code>with_inputs</code> method is used to tell DSPy which column contains the input. Other columns are used as expected model outputs.</p>
<div id="ba082b2b" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> json</span>
<span id="cb4-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> dspy</span>
<span id="cb4-3"></span>
<span id="cb4-4"></span>
<span id="cb4-5"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> to_example(row):</span>
<span id="cb4-6">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> dspy.Example(</span>
<span id="cb4-7">        text<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>row[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"input"</span>],</span>
<span id="cb4-8">        aspects<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>Aspects(aspects<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>json.loads(row[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"output"</span>])[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"aspects"</span>]),</span>
<span id="cb4-9">    ).with_inputs(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"text"</span>)</span>
<span id="cb4-10"></span>
<span id="cb4-11"></span>
<span id="cb4-12">trainset <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [to_example(row) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> row <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> train.to_dicts()]</span>
<span id="cb4-13">testset <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [to_example(row) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> row <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> test.to_dicts()]</span></code></pre></div>
</div>
<p>Let‚Äôs look at the first example.</p>
<div id="ee11a3cc" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">trainset[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>Example({'text': 'I charge it at night and skip taking the cord with me because of the good battery life.', 'aspects': Aspects(aspects=[Aspect(term='cord', polarity='neutral'), Aspect(term='battery life', polarity='positive')])}) (input_keys={'text'})</code></pre>
</div>
</div>
</section>
<section id="creating-a-dspy-typed-predictor" class="level3">
<h3 class="anchored" data-anchor-id="creating-a-dspy-typed-predictor">Creating a DSPy typed predictor</h3>
<p>In DSPy, a module is a language model and a way of prompting. They can also consist of multiple requests and also include external tools such as a vector database for retrieval augmented generation. In this example, we have a single request using few-shot examples and chain of thought.</p>
<p>In order to be able to parse the output as a dictionary, the LLM must output valid JSON. Therefore I‚Äôll use a <a href="https://dspy.ai/learn/8-typed_predictors/?h=typed">Typed Predictor</a> in DSPy, which is similar to structured outputs via instructor or a similar library.</p>
<div id="01bdde17" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> AbsaSignature(dspy.Signature):</span>
<span id="cb7-2">    text: Input <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dspy.InputField()</span>
<span id="cb7-3">    aspects: Aspects <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dspy.OutputField()</span>
<span id="cb7-4"></span>
<span id="cb7-5"></span>
<span id="cb7-6">predictor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dspy.ChainOfThought(AbsaSignature)</span></code></pre></div>
</div>
<p>We also need to choose a language model. DSPy works with OpenAI, Anthropic, Ollama, vllm and other OpenAI-compatible platforms and libraries. This is powered by <a href="https://github.com/BerriAI/litellm">litellm</a> under the hood.</p>
<p>For this article, I‚Äôll use OpenAI‚Äôs gpt-4o-mini as well as the 70B version of Meta‚Äôs Llama 3.1 hosted on <a href="https://fireworks.ai">fireworks.ai</a>. Fireworks.ai generously supplied me with credits as part of the <a href="https://maven.com/parlance-labs/fine-tuning?utm_campaign=d45fef&amp;utm_medium=partner&amp;utm_source=instructor">Mastering LLMs For Developers &amp; Data Scientists</a> course.</p>
<div id="9ba79829" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># FIREWORKS_AI_API_KEY environment variable must be set.</span></span>
<span id="cb8-2"></span>
<span id="cb8-3">lm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dspy.LM(</span>
<span id="cb8-4">    api_base<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"https://api.fireworks.ai/inference/v1/"</span>,</span>
<span id="cb8-5">    model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"fireworks_ai/accounts/fireworks/models/llama-v3p1-70b-instruct"</span>,</span>
<span id="cb8-6">    temperature<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span>,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># best for structured outputs</span></span>
<span id="cb8-7">    cache<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb8-8">    max_tokens<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">250</span>,</span>
<span id="cb8-9">)</span>
<span id="cb8-10">dspy.configure(lm<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>lm)</span></code></pre></div>
</div>
</section>
</section>
<section id="optimization" class="level2">
<h2 class="anchored" data-anchor-id="optimization">Optimization</h2>
<p>Let‚Äôs run a single example to check that everything is working.</p>
<div id="dcddfe3d" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1">predictor(text<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"The pizza was great, but the service was terrible"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>Prediction(
    rationale='We produce the aspects by identifying the terms "pizza" and "service" as aspects and determining their polarities based on the context. The term "pizza" is associated with the positive sentiment "great", while the term "service" is associated with the negative sentiment "terrible".',
    aspects=Aspects(aspects=[Aspect(term='pizza', polarity='positive'), Aspect(term='service', polarity='negative')])
)</code></pre>
</div>
</div>
<p>That‚Äôs a good start. I‚Äôm a fan of <a href="https://hamel.dev/blog/posts/prompt/">Hamel Husain‚Äôs advice</a> to always demand: ‚ÄúShow me the prompt‚Äù, so let‚Äôs check what DSPy actually sent to OpenAI:</p>
<div id="35504bec" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1">lm.inspect_history(n<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>



[2024-11-27T08:58:15.497789]

System message:

Your input fields are:
1. `text` (Input)

Your output fields are:
1. `rationale` (str): ${produce the aspects}. We ...
2. `aspects` (Aspects)

All interactions will be structured in the following way, with the appropriate values filled in.

[[ ## text ## ]]
{text}

[[ ## rationale ## ]]
{rationale}

[[ ## aspects ## ]]
{aspects}        # note: the value you produce must be pareseable according to the following JSON schema: {"type": "object", "$defs": {"Aspect": {"type": "object", "properties": {"polarity": {"type": "string", "description": "The polarity expressed towards the aspect term. Valid polarities are ‚Äòpositive‚Äô, ‚Äòneutral‚Äô, ‚Äònegative'.", "enum": ["positive", "neutral", "negative"], "title": "Polarity"}, "term": {"type": "string", "description": "An aspect term, which is a verbatim text snippet. Single or multiword terms naming particular aspects of the reviewed product or service.", "title": "Term"}}, "required": ["term", "polarity"], "title": "Aspect"}}, "properties": {"aspects": {"type": "array", "description": "An array of aspects and their polarities. If no aspects are mentioned in the text, use an empty array.", "items": {"$ref": "#/$defs/Aspect"}, "title": "Aspects"}}, "required": ["aspects"], "title": "Aspects"}

[[ ## completed ## ]]

In adhering to this structure, your objective is: 
        Given the fields `text`, produce the fields `aspects`.


User message:

[[ ## text ## ]]
The pizza was great, but the service was terrible

Respond with the corresponding output fields, starting with the field `[[ ## rationale ## ]]`, then `[[ ## aspects ## ]]` (must be formatted as a valid Python Aspects), and then ending with the marker for `[[ ## completed ## ]]`.


Response:

[[ ## rationale ## ]]
We produce the aspects by identifying the terms "pizza" and "service" as aspects and determining their polarities based on the context. The term "pizza" is associated with the positive sentiment "great", while the term "service" is associated with the negative sentiment "terrible".

[[ ## aspects ## ]]
{"aspects": [{"term": "pizza", "polarity": "positive"}, {"term": "service", "polarity": "negative"}]}

[[ ## completed ## ]]




</code></pre>
</div>
</div>
<p>Verbose but it works. It doesn‚Äôt use function calling or a different way to get structured outputs, so there is some chance of getting an invalid JSON.</p>
<section id="specify-the-evaluation-function" class="level3">
<h3 class="anchored" data-anchor-id="specify-the-evaluation-function">Specify the evaluation function</h3>
<p>An evaluation function takes an example and a prediction and returns an F1 score. A true positive is a predicted aspect that is also in the gold answer, a false positive is a predicted aspect that is not in the gold answer, and a false negative is a gold answer aspect that is not predicted. Here are the precision, recall, and F1 score functions.</p>
<div id="2a060d62" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> precision(tp: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>, fp: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span>:</span>
<span id="cb13-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Handle division by zero</span></span>
<span id="cb13-3">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> tp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> fp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span> tp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> (tp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> fp)</span>
<span id="cb13-4"></span>
<span id="cb13-5"></span>
<span id="cb13-6"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> recall(tp: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>, fn: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span>:</span>
<span id="cb13-7">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> tp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> fn <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span> tp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> (tp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> fn)</span>
<span id="cb13-8"></span>
<span id="cb13-9"></span>
<span id="cb13-10"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> f1_score(tp: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>, fp: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>, fn: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span>:</span>
<span id="cb13-11">    prec <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> precision(tp, fp)</span>
<span id="cb13-12">    rec <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> recall(tp, fn)</span>
<span id="cb13-13">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> prec <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> rec <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> (prec <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> rec) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> (prec <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> rec)</span></code></pre></div>
</div>
<p>Next is the evaluation function which compares the gold and predicted aspects. To count as a true positive, both the term and the polarity have to be correct. As it is conventional on this benchmark, the case where both the gold answers and the prediction are empty is treated as a correct prediction of no aspects.</p>
<div id="a5bf9cf4" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> evaluate_absa(example: dspy.Example, prediction: Aspects, trace<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span>:</span>
<span id="cb14-2">    gold_aspects <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">set</span>(example.aspects.aspects)</span>
<span id="cb14-3">    pred_aspects <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">set</span>(prediction.aspects.aspects)</span>
<span id="cb14-4"></span>
<span id="cb14-5">    tp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(gold_aspects <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&amp;</span> pred_aspects)</span>
<span id="cb14-6">    fp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(pred_aspects <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> gold_aspects)</span>
<span id="cb14-7">    fn <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(gold_aspects <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> pred_aspects)</span>
<span id="cb14-8"></span>
<span id="cb14-9">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(gold_aspects) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">and</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(pred_aspects) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>:</span>
<span id="cb14-10">        tp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># correct prediction of no aspects</span></span>
<span id="cb14-11"></span>
<span id="cb14-12">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> f1_score(tp, fp, fn)</span></code></pre></div>
</div>
<p>Let‚Äôs try the evaluation function with a single example. We expect the F1 score to be 1.0, because the prediction matches the gold answer exactly.</p>
<div id="0bc42ba9" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1">example <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dspy.Example(</span>
<span id="cb15-2">    text<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"The pizza was great, but the service was terrible"</span>,</span>
<span id="cb15-3">    aspects<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>Aspects(</span>
<span id="cb15-4">        aspects<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[</span>
<span id="cb15-5">            Aspect(term<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"pizza"</span>, polarity<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"positive"</span>),</span>
<span id="cb15-6">            Aspect(term<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"service"</span>, polarity<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"negative"</span>),</span>
<span id="cb15-7">        ]</span>
<span id="cb15-8">    ),</span>
<span id="cb15-9">).with_inputs(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"text"</span>)</span>
<span id="cb15-10">prediction <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> predictor(text<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>example.text)</span>
<span id="cb15-11">evaluate_absa(example, prediction)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="12">
<pre><code>1.0</code></pre>
</div>
</div>
</section>
<section id="optimizers" class="level3">
<h3 class="anchored" data-anchor-id="optimizers">Optimizers</h3>
<p>DSPy has a variety of <a href="https://dspy.ai/learn/optimization/optimizers/?h=optimizers">optimizers</a>, loops that change the prompt and/or few-shot examples and evaluate the performance. They‚Äôre analogous to optimizers like SGD and Adam in PyTorch. The choice of optimizer depends on the task, the amount of labeled data and the computational resources available. As we have a large labeled dataset, it‚Äôs not necessary to have the model bootstrap artificial examples. Our 2023 paper found that fine-tuning yields the best results, but the goal of this article is to showcase DSPy‚Äôs prompt optimization.</p>
<p>The most powerful optimizer available for a prompting approach for this task is <a href="[Multiprompt Instruction PRoposal Optimizer Version 2](https://dspy.ai/deep-dive/optimizers/miprov2/?h=miprov)">MIPROv2</a> (Multiprompt Instruction PRoposal Optimizer Version 2) by <span class="citation" data-cites="opsahlong2024optimizinginstructionsdemonstrationsmultistage">Opsahl-Ong et al. (2024)</span>. MIPROv2 uses Bayesian optimization to find an optimal combination of few-shot examples and prompt instructions.</p>
<div id="556aaa52" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1">optimizer_settings <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">dict</span>(</span>
<span id="cb17-2">    metric<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>evaluate_absa,</span>
<span id="cb17-3">    num_threads<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># make parallel requests to Fireworks.ai</span></span>
<span id="cb17-4">    max_errors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># keep going even when invalid JSON is returned</span></span>
<span id="cb17-5">)</span>
<span id="cb17-6">optimizer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dspy.teleprompt.MIPROv2(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>optimizer_settings)</span></code></pre></div>
</div>
<p>The final step is to call the <code>compile</code> method, which starts the optimization process. After about 5 minutes, the best prompt and few-shot examples are saved to a JSON file.</p>
<div id="c003b7c7" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define settings for the comilation step of the optimizer.</span></span>
<span id="cb18-2">compile_settings <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">dict</span>(</span>
<span id="cb18-3">    minibatch_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># evaluate changes on a subset of the validation set</span></span>
<span id="cb18-4">    minibatch_full_eval_steps<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># evaluate on the full validation set after every 10 steps</span></span>
<span id="cb18-5">    max_labeled_demos<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># the number of few-shot examples to use</span></span>
<span id="cb18-6">    max_bootstrapped_demos<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># not required because we have labeled examples, but setting it to 0 causes an error during sampling</span></span>
<span id="cb18-7">    num_trials<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># how many combinations of few-shot examples and prompt instructions to try</span></span>
<span id="cb18-8">    seed<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># for reproducibility</span></span>
<span id="cb18-9">    requires_permission_to_run<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># skip confirmation dialog</span></span>
<span id="cb18-10">)</span></code></pre></div>
</div>
<p>We save the optimized predictor to a JSON file. It‚Äôs a small config file listing the chosen few-shot examples and the optimized prompt.</p>
<div class="sourceCode" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1">optimized_predictor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> optimizer.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">compile</span>(</span>
<span id="cb19-2">    student<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>predictor, trainset<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>trainset, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>compile_settings</span>
<span id="cb19-3">)</span>
<span id="cb19-4">optimized_predictor.save(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"configs/absa_model.json"</span>)</span></code></pre></div>
<p>Let‚Äôs check if we can load it again:</p>
<div id="08ac763f" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1">optimized_predictor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dspy.ChainOfThought(signature<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>AbsaSignature)</span>
<span id="cb20-2">optimized_predictor.load(path<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"configs/absa_model.json"</span>)</span></code></pre></div>
</div>
<p>Again: ‚ÄúShow me the prompt‚Äù.</p>
<div id="eaed34bf" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(optimized_predictor.extended_signature.instructions)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>You are a product reviewer tasked with analyzing customer feedback for laptops and netbooks. Given the fields `text`, which contains a customer review, produce the fields `aspects`, which should include the specific features or aspects of the laptop or netbook mentioned in the review, along with their corresponding sentiment or polarity.</code></pre>
</div>
</div>
<p>and show me the chosen few-shot examples:</p>
<div id="e49e8c57" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> demo <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> optimized_predictor.demos[:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>]:  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># first 3 examples</span></span>
<span id="cb23-2">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(demo[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"text"</span>])</span>
<span id="cb23-3">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(demo[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"aspects"</span>])</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>-Called headquarters again, they report that TFT panel is broken, should be fixed by the end of the week (week 3).
{"aspects":[{"term":"TFT panel","polarity":"negative"}]}
But we had paid for bluetooth, and there was none.
{"aspects":[{"term":"bluetooth","polarity":"negative"}]}
The powerpoint opened seamlessly in the apple and the mac hooked up to the projector so easily it was almost scary.
{"aspects":[{"term":"powerpoint","polarity":"positive"}]}</code></pre>
</div>
</div>
</section>
</section>
<section id="evaluation" class="level2">
<h2 class="anchored" data-anchor-id="evaluation">Evaluation</h2>
<p>So far, we‚Äôve only evaluated on the validation part of the training set (this was automatically done by DSPy). Let‚Äôs evaluate the optimized predictor on the test set.</p>
<div id="9ebae982" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1">evaluator <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dspy.Evaluate(</span>
<span id="cb25-2">    devset<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>testset,</span>
<span id="cb25-3">    metric<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>evaluate_absa,</span>
<span id="cb25-4">    display_progress<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb25-5">    num_threads<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>,</span>
<span id="cb25-6">)</span></code></pre></div>
</div>
<div id="aab61074" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1">score <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> evaluator(optimized_predictor)</span></code></pre></div>
</div>
<p>The first run yields an F1 score of 47.6. That‚Äôs rather poor, but the compiler settings only allow for 4 labeled examples and 1 bootstrapped example and only 3 trials.</p>
</section>
<section id="hyperparameter-optimization" class="level2">
<h2 class="anchored" data-anchor-id="hyperparameter-optimization">Hyperparameter optimization</h2>
<p>What would happen if we changed the hyperparameters? Let‚Äôs do a grid search over the number of few-shot examples and the number of trials, as well as try different models.</p>
<div id="d029a7bb" class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> itertools</span>
<span id="cb27-2"></span>
<span id="cb27-3">max_labeled_demos <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">40</span>]</span>
<span id="cb27-4">num_trials <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">15</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">30</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">60</span>]</span>
<span id="cb27-5">chain_of_thought <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>]</span>
<span id="cb27-6"></span>
<span id="cb27-7">default_lm_settings <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">dict</span>(</span>
<span id="cb27-8">    temperature<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span>,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># best for structured outputs, no creativity needed</span></span>
<span id="cb27-9">    cache<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb27-10">    max_tokens<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">250</span>,</span>
<span id="cb27-11">)</span>
<span id="cb27-12"></span>
<span id="cb27-13">lm_settings <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [</span>
<span id="cb27-14">    {</span>
<span id="cb27-15">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"model"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"fireworks_ai/accounts/fireworks/models/llama-v3p1-70b-instruct"</span>,</span>
<span id="cb27-16">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"api_base"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"https://api.fireworks.ai/inference/v1/"</span>,</span>
<span id="cb27-17">        <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>default_lm_settings,</span>
<span id="cb27-18">    },</span>
<span id="cb27-19">    {</span>
<span id="cb27-20">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"model"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"gpt-4o-mini-2024-07-18"</span>,</span>
<span id="cb27-21">        <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>default_lm_settings,</span>
<span id="cb27-22">    },</span>
<span id="cb27-23">]</span>
<span id="cb27-24"></span>
<span id="cb27-25">grid <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>(</span>
<span id="cb27-26">    itertools.product(max_labeled_demos, num_trials, chain_of_thought, lm_settings)</span>
<span id="cb27-27">)</span></code></pre></div>
</div>
<p>This results in a grid with 48 combinations. Next, we iterate over the grid, perform the optimization run and save the results to Weights &amp; Biases.</p>
<div id="d4cf55fc" class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb28" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> os</span>
<span id="cb28-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> copy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> deepcopy</span>
<span id="cb28-3"></span>
<span id="cb28-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> wandb</span>
<span id="cb28-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> tqdm <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> tqdm</span>
<span id="cb28-6"></span>
<span id="cb28-7"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">assert</span> os.getenv(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"FIREWORKS_AI_API_KEY"</span>) <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"FIREWORKS_AI_API_KEY is not set."</span></span>
<span id="cb28-8"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">assert</span> os.getenv(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"OPENAI_API_KEY"</span>) <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"OPENAI_API_KEY is not set."</span></span>
<span id="cb28-9"></span>
<span id="cb28-10"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> max_labeled_demos, num_trials, chain_of_thought, lm_settings <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> tqdm(grid):</span>
<span id="cb28-11"></span>
<span id="cb28-12">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate a filename for the run</span></span>
<span id="cb28-13">    modelname <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> lm_settings[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"model"</span>].replace(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"/"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"_"</span>)</span>
<span id="cb28-14">    cot_name <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cot"</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> chain_of_thought <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"predict"</span></span>
<span id="cb28-15">    run_name <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>modelname<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">_</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>max_labeled_demos<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">_</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>num_trials<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">_</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>cot_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span></span>
<span id="cb28-16">    filepath <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"configs/"</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> run_name <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">".json"</span></span>
<span id="cb28-17"></span>
<span id="cb28-18">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> os.path.exists(filepath):</span>
<span id="cb28-19">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Skipping </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>run_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> because it already exists."</span>)</span>
<span id="cb28-20">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">continue</span></span>
<span id="cb28-21">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb28-22">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Running </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>run_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">."</span>)</span>
<span id="cb28-23"></span>
<span id="cb28-24">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create fresh copies of settings for this run</span></span>
<span id="cb28-25">    run_compile_settings <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> deepcopy(compile_settings)</span>
<span id="cb28-26">    run_optimizer_settings <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> deepcopy(optimizer_settings)</span>
<span id="cb28-27"></span>
<span id="cb28-28">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Update settings</span></span>
<span id="cb28-29">    run_compile_settings[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"max_labeled_demos"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> max_labeled_demos</span>
<span id="cb28-30">    run_compile_settings[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"num_trials"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> num_trials</span>
<span id="cb28-31"></span>
<span id="cb28-32">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> chain_of_thought:</span>
<span id="cb28-33">        predictor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dspy.ChainOfThought(AbsaSignature)</span>
<span id="cb28-34">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb28-35">        predictor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dspy.Predict(AbsaSignature)</span>
<span id="cb28-36"></span>
<span id="cb28-37">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Do an optimization run and evaluate the resulting model</span></span>
<span id="cb28-38">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">try</span>:</span>
<span id="cb28-39">        dspy.configure(lm<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>dspy.LM(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>lm_settings))</span>
<span id="cb28-40">        optimizer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dspy.teleprompt.MIPROv2(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>run_optimizer_settings)</span>
<span id="cb28-41">        optimized_predictor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> optimizer.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">compile</span>(</span>
<span id="cb28-42">            student<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>predictor, trainset<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>trainset, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>run_compile_settings</span>
<span id="cb28-43">        )</span>
<span id="cb28-44">        score <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> evaluator(optimized_predictor)</span>
<span id="cb28-45">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">except</span> <span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">Exception</span> <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> e:</span>
<span id="cb28-46">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(</span>
<span id="cb28-47">            <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Failed run with settings: max_labeled_demos=</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>max_labeled_demos<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">, "</span></span>
<span id="cb28-48">            <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"num_trials=</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>num_trials<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">, model=</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>lm_settings[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'model'</span>]<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span></span>
<span id="cb28-49">        )</span>
<span id="cb28-50">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Error: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>(e)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb28-51">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">continue</span></span>
<span id="cb28-52"></span>
<span id="cb28-53">    optimized_predictor.save(filepath)</span>
<span id="cb28-54"></span>
<span id="cb28-55">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Log experiment to W&amp;B</span></span>
<span id="cb28-56">    config <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb28-57">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"output_schema"</span>: Aspects.model_json_schema(),</span>
<span id="cb28-58">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"compile_settings"</span>: run_compile_settings,</span>
<span id="cb28-59">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"optimizer_settings"</span>: run_optimizer_settings,</span>
<span id="cb28-60">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"lm_settings"</span>: lm_settings,</span>
<span id="cb28-61">    }</span>
<span id="cb28-62"></span>
<span id="cb28-63">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> wandb.init(project<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"absa-dspy"</span>, config<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>config, name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>run_name) <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> run:</span>
<span id="cb28-64">        wandb.log({<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"f1"</span>: score})</span>
<span id="cb28-65">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Save config to artifact</span></span>
<span id="cb28-66">        artifact <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> wandb.Artifact(</span>
<span id="cb28-67">            name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"dspy_config_</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>run_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>,</span>
<span id="cb28-68">            <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">type</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"config"</span>, </span>
<span id="cb28-69">            description<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Config file for </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>run_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span></span>
<span id="cb28-70">        )</span>
<span id="cb28-71">        artifact.add_file(filepath)</span>
<span id="cb28-72">        run.log_artifact(artifact)</span></code></pre></div>
</div>
</section>
<section id="comparison-with-manual-prompts" class="level2">
<h2 class="anchored" data-anchor-id="comparison-with-manual-prompts">Comparison with manual prompts</h2>
<p>In the 2023 paper, co-author and I manually crafted prompts and chose few-shot examples that, in our opinion, illustrated the task well. Inference was done using the OpenAI API and using function calling to ensure structured outputs. To make the comparison fair, we‚Äôll now use the same prompts within DSPy.</p>
<p>The manual prompts and few-shot examples are available on <a href="https://github.com/psimm/website/blob/master/blog/absa-with-dspy/configs/manual_prompt.json">Github</a>.</p>
<p>The models <code>gpt-4-0613</code> and <code>gpt-3.5-turbo-0613</code> that were used in the 2023 paper are no longer available on the OpenAI API. Therefore, we use the closest substitutes here.</p>
<div id="88dcd13e" class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb29" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1">models <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [</span>
<span id="cb29-2">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"gpt-4o-2024-11-20"</span>,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># similar to gpt-4-0613</span></span>
<span id="cb29-3">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"gpt-3.5-turbo-0125"</span>,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># similar to gpt-3.5-turbo-0613</span></span>
<span id="cb29-4">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"gpt-4o-mini-2024-07-18"</span>,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># reference</span></span>
<span id="cb29-5">]</span>
<span id="cb29-6"></span>
<span id="cb29-7">manual_predictor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dspy.Predict(AbsaSignature)</span>
<span id="cb29-8">manual_predictor.load(path<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"configs/manual_prompt.json"</span>)</span>
<span id="cb29-9"></span>
<span id="cb29-10"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> model <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> models:</span>
<span id="cb29-11">    lm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dspy.LM(</span>
<span id="cb29-12">        model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>model,</span>
<span id="cb29-13">        temperature<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,</span>
<span id="cb29-14">        cache<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb29-15">        max_tokens<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">250</span>,</span>
<span id="cb29-16">    )</span>
<span id="cb29-17">    dspy.configure(lm<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>lm)</span>
<span id="cb29-18">    score <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> evaluator(manual_predictor)</span>
<span id="cb29-19">    runname <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>model<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">_manual_prompt"</span></span>
<span id="cb29-20"></span>
<span id="cb29-21">    config <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb29-22">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"output_schema"</span>: Aspects.model_json_schema(),</span>
<span id="cb29-23">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"compile_settings"</span>: {</span>
<span id="cb29-24">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"max_labeled_demos"</span>: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(manual_predictor.demos),</span>
<span id="cb29-25">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"max_bootstrapped_demos"</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,</span>
<span id="cb29-26">        },</span>
<span id="cb29-27">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"lm_settings"</span>: {</span>
<span id="cb29-28">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"model"</span>: model,</span>
<span id="cb29-29">        },</span>
<span id="cb29-30">    }</span>
<span id="cb29-31"></span>
<span id="cb29-32">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> wandb.init(project<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"absa-dspy"</span>, name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>runname, config<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>config) <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> run:</span>
<span id="cb29-33">        wandb.log({<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"f1"</span>: score})</span>
<span id="cb29-34">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Save manual prompt to artifact</span></span>
<span id="cb29-35">        artifact <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> wandb.Artifact(</span>
<span id="cb29-36">            name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"dspy_config_</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>runname<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>,</span>
<span id="cb29-37">            <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">type</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"model"</span>,</span>
<span id="cb29-38">            description<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Manual prompt configuration"</span></span>
<span id="cb29-39">        )</span>
<span id="cb29-40">        artifact.add_file(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"configs/manual_prompt.json"</span>)</span>
<span id="cb29-41">        run.log_artifact(artifact)</span></code></pre></div>
</div>
</section>
<section id="results-and-discussion" class="level2">
<h2 class="anchored" data-anchor-id="results-and-discussion">Results and discussion</h2>
<p>We load the results from the Weights &amp; Biases project and show the most relevant columns for a comparison of the runs.</p>
<div id="a36f5554" class="cell" data-execution_count="23">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb30" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> wandb</span>
<span id="cb30-2"></span>
<span id="cb30-3">api <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> wandb.Api()</span>
<span id="cb30-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get all runs from the project</span></span>
<span id="cb30-5">runs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> api.runs(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"psimm/absa-dspy"</span>)</span>
<span id="cb30-6"></span>
<span id="cb30-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Convert to DataFrame</span></span>
<span id="cb30-8">results <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb30-9"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> run <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> runs:</span>
<span id="cb30-10">    results.append(</span>
<span id="cb30-11">        {</span>
<span id="cb30-12">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"run_name"</span>: run.name,</span>
<span id="cb30-13">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"model"</span>: run.config[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"lm_settings"</span>][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"model"</span>],</span>
<span id="cb30-14">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"max_demos"</span>: run.config[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"compile_settings"</span>][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"max_labeled_demos"</span>],</span>
<span id="cb30-15">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"max_bootstrapped_demos"</span>: run.config[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"compile_settings"</span>][</span>
<span id="cb30-16">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"max_bootstrapped_demos"</span></span>
<span id="cb30-17">            ],</span>
<span id="cb30-18">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"num_trials"</span>: run.config.get(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"compile_settings"</span>, {}).get(</span>
<span id="cb30-19">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"num_trials"</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span></span>
<span id="cb30-20">            ),</span>
<span id="cb30-21">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"chain_of_thought"</span>: run.config[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"chain_of_thought"</span>],</span>
<span id="cb30-22">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"f1"</span>: run.summary[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"f1"</span>],</span>
<span id="cb30-23">        }</span>
<span id="cb30-24">    )</span>
<span id="cb30-25"></span>
<span id="cb30-26">results_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pl.DataFrame(results)</span>
<span id="cb30-27"></span>
<span id="cb30-28">table_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (</span>
<span id="cb30-29">    results_df.with_columns(</span>
<span id="cb30-30">        method<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>pl.when(pl.col(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"run_name"</span>).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>.contains(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"manual"</span>))</span>
<span id="cb30-31">        .then(pl.lit(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Manual (2023)"</span>))</span>
<span id="cb30-32">        .otherwise(pl.lit(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"DSPy"</span>)),</span>
<span id="cb30-33">        model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>pl.col(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"model"</span>).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>.replace(</span>
<span id="cb30-34">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"fireworks_ai/accounts/fireworks/models/"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span></span>
<span id="cb30-35">        ),</span>
<span id="cb30-36">        demos<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>pl.when(pl.col(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"max_bootstrapped_demos"</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb30-37">        .then(pl.col(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"max_demos"</span>).cast(pl.Utf8))</span>
<span id="cb30-38">        .otherwise(</span>
<span id="cb30-39">            pl.col(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"max_demos"</span>).cast(pl.Utf8)</span>
<span id="cb30-40">            <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">" + "</span></span>
<span id="cb30-41">            <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> pl.col(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"max_bootstrapped_demos"</span>).cast(pl.Utf8)</span>
<span id="cb30-42">        ),</span>
<span id="cb30-43">        chain_of_thought<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>pl.when(pl.col(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"chain_of_thought"</span>))</span>
<span id="cb30-44">        .then(pl.lit(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"‚úÖ"</span>))</span>
<span id="cb30-45">        .otherwise(pl.lit(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"‚ùå"</span>)),</span>
<span id="cb30-46">    )</span>
<span id="cb30-47">    .sort(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"f1"</span>, descending<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb30-48">    .select(</span>
<span id="cb30-49">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"model"</span>,</span>
<span id="cb30-50">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"method"</span>,</span>
<span id="cb30-51">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"num_trials"</span>,</span>
<span id="cb30-52">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"demos"</span>,</span>
<span id="cb30-53">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"chain_of_thought"</span>,</span>
<span id="cb30-54">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"f1"</span>,</span>
<span id="cb30-55">    )</span>
<span id="cb30-56">)</span>
<span id="cb30-57"></span>
<span id="cb30-58">GT(table_df).tab_header(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"SemEval 2014 Task 4 1+2 Few-Shot Predictors"</span>).cols_label(</span>
<span id="cb30-59">    model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Model"</span>,</span>
<span id="cb30-60">    method<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Method"</span>,</span>
<span id="cb30-61">    demos<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Examples¬π"</span>,</span>
<span id="cb30-62">    num_trials<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Trials"</span>,</span>
<span id="cb30-63">    chain_of_thought<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"CoT"</span>,</span>
<span id="cb30-64">    f1<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"F1"</span>,</span>
<span id="cb30-65">).cols_align(align<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"right"</span>, columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"demos"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"num_trials"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"f1"</span>]).fmt_number(</span>
<span id="cb30-66">    columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"f1"</span>], decimals<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span></span>
<span id="cb30-67">).tab_source_note(</span>
<span id="cb30-68">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"¬π Bootstrapped + labeled examples. Notes: Limited Llama 3.1 70B non-CoT runs due to API constraints. Manual prompt runs use 10 examples vs. 6 in original paper."</span></span>
<span id="cb30-69">)</span></code></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="20">
<div id="fhjsfutory" style="padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>
#fhjsfutory table {
          font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;
          -webkit-font-smoothing: antialiased;
          -moz-osx-font-smoothing: grayscale;
        }

#fhjsfutory thead, tbody, tfoot, tr, td, th { border-style: none; }
 tr { background-color: transparent; }
#fhjsfutory p { margin: 0; padding: 0; }
 #fhjsfutory .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; }
 #fhjsfutory .gt_caption { padding-top: 4px; padding-bottom: 4px; }
 #fhjsfutory .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; }
 #fhjsfutory .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; }
 #fhjsfutory .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; }
 #fhjsfutory .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; }
 #fhjsfutory .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; }
 #fhjsfutory .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; }
 #fhjsfutory .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; }
 #fhjsfutory .gt_column_spanner_outer:first-child { padding-left: 0; }
 #fhjsfutory .gt_column_spanner_outer:last-child { padding-right: 0; }
 #fhjsfutory .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; }
 #fhjsfutory .gt_spanner_row { border-bottom-style: hidden; }
 #fhjsfutory .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; }
 #fhjsfutory .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; }
 #fhjsfutory .gt_from_md> :first-child { margin-top: 0; }
 #fhjsfutory .gt_from_md> :last-child { margin-bottom: 0; }
 #fhjsfutory .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; }
 #fhjsfutory .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; }
 #fhjsfutory .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; }
 #fhjsfutory .gt_row_group_first td { border-top-width: 2px; }
 #fhjsfutory .gt_row_group_first th { border-top-width: 2px; }
 #fhjsfutory .gt_striped { background-color: rgba(128,128,128,0.05); }
 #fhjsfutory .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; }
 #fhjsfutory .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; }
 #fhjsfutory .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; text-align: left; }
 #fhjsfutory .gt_left { text-align: left; }
 #fhjsfutory .gt_center { text-align: center; }
 #fhjsfutory .gt_right { text-align: right; font-variant-numeric: tabular-nums; }
 #fhjsfutory .gt_font_normal { font-weight: normal; }
 #fhjsfutory .gt_font_bold { font-weight: bold; }
 #fhjsfutory .gt_font_italic { font-style: italic; }
 #fhjsfutory .gt_super { font-size: 65%; }
 #fhjsfutory .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; }
 #fhjsfutory .gt_asterisk { font-size: 100%; vertical-align: 0; }
 
</style>

<table class="gt_table caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-quarto-disable-processing="false" data-quarto-bootstrap="false">
<thead>
<tr class="gt_heading header">
<th colspan="6" class="gt_heading gt_title gt_font_normal">SemEval 2014 Task 4 1+2 Few-Shot Predictors</th>
</tr>
<tr class="gt_col_headings even">
<th id="Model" class="gt_col_heading gt_columns_bottom_border gt_left" data-quarto-table-cell-role="th" scope="col">Model</th>
<th id="Method" class="gt_col_heading gt_columns_bottom_border gt_left" data-quarto-table-cell-role="th" scope="col">Method</th>
<th id="Trials" class="gt_col_heading gt_columns_bottom_border gt_right" data-quarto-table-cell-role="th" scope="col">Trials</th>
<th id="Examples¬π" class="gt_col_heading gt_columns_bottom_border gt_right" data-quarto-table-cell-role="th" scope="col">Examples¬π</th>
<th id="CoT" class="gt_col_heading gt_columns_bottom_border gt_left" data-quarto-table-cell-role="th" scope="col">CoT</th>
<th id="F1" class="gt_col_heading gt_columns_bottom_border gt_right" data-quarto-table-cell-role="th" scope="col">F1</th>
</tr>
</thead>
<tbody class="gt_table_body">
<tr class="odd">
<td class="gt_row gt_left">gpt-4o-2024-11-20</td>
<td class="gt_row gt_left">Manual (2023)</td>
<td class="gt_row gt_right">None</td>
<td class="gt_row gt_right">10</td>
<td class="gt_row gt_left">‚ùå</td>
<td class="gt_row gt_right">71.28</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">15</td>
<td class="gt_row gt_right">40 + 1</td>
<td class="gt_row gt_left">‚ùå</td>
<td class="gt_row gt_right">62.83</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">llama-v3p1-70b-instruct</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">60</td>
<td class="gt_row gt_right">5 + 1</td>
<td class="gt_row gt_left">‚ùå</td>
<td class="gt_row gt_right">61.49</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">60</td>
<td class="gt_row gt_right">10 + 1</td>
<td class="gt_row gt_left">‚ùå</td>
<td class="gt_row gt_right">61.34</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">15</td>
<td class="gt_row gt_right">20 + 1</td>
<td class="gt_row gt_left">‚ùå</td>
<td class="gt_row gt_right">60.87</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">30</td>
<td class="gt_row gt_right">20 + 1</td>
<td class="gt_row gt_left">‚ùå</td>
<td class="gt_row gt_right">60.87</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">60</td>
<td class="gt_row gt_right">20 + 1</td>
<td class="gt_row gt_left">‚ùå</td>
<td class="gt_row gt_right">60.87</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">llama-v3p1-70b-instruct</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">15</td>
<td class="gt_row gt_right">40 + 1</td>
<td class="gt_row gt_left">‚ùå</td>
<td class="gt_row gt_right">60.32</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">llama-v3p1-70b-instruct</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">60</td>
<td class="gt_row gt_right">5 + 1</td>
<td class="gt_row gt_left">‚úÖ</td>
<td class="gt_row gt_right">60.27</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">60</td>
<td class="gt_row gt_right">40 + 1</td>
<td class="gt_row gt_left">‚úÖ</td>
<td class="gt_row gt_right">59.80</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">15</td>
<td class="gt_row gt_right">20 + 1</td>
<td class="gt_row gt_left">‚úÖ</td>
<td class="gt_row gt_right">59.68</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">30</td>
<td class="gt_row gt_right">20 + 1</td>
<td class="gt_row gt_left">‚úÖ</td>
<td class="gt_row gt_right">59.68</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">60</td>
<td class="gt_row gt_right">20 + 1</td>
<td class="gt_row gt_left">‚úÖ</td>
<td class="gt_row gt_right">59.68</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">30</td>
<td class="gt_row gt_right">40 + 1</td>
<td class="gt_row gt_left">‚úÖ</td>
<td class="gt_row gt_right">59.60</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">15</td>
<td class="gt_row gt_right">40 + 1</td>
<td class="gt_row gt_left">‚úÖ</td>
<td class="gt_row gt_right">59.32</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">60</td>
<td class="gt_row gt_right">5 + 1</td>
<td class="gt_row gt_left">‚ùå</td>
<td class="gt_row gt_right">58.83</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">llama-v3p1-70b-instruct</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">30</td>
<td class="gt_row gt_right">10 + 1</td>
<td class="gt_row gt_left">‚ùå</td>
<td class="gt_row gt_right">58.79</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">llama-v3p1-70b-instruct</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">60</td>
<td class="gt_row gt_right">10 + 1</td>
<td class="gt_row gt_left">‚ùå</td>
<td class="gt_row gt_right">58.79</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">llama-v3p1-70b-instruct</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">30</td>
<td class="gt_row gt_right">5 + 1</td>
<td class="gt_row gt_left">‚ùå</td>
<td class="gt_row gt_right">58.36</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">llama-v3p1-70b-instruct</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">60</td>
<td class="gt_row gt_right">20 + 1</td>
<td class="gt_row gt_left">‚ùå</td>
<td class="gt_row gt_right">57.98</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">llama-v3p1-70b-instruct</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">30</td>
<td class="gt_row gt_right">20 + 1</td>
<td class="gt_row gt_left">‚ùå</td>
<td class="gt_row gt_right">57.84</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">gpt-3.5-turbo-0125</td>
<td class="gt_row gt_left">Manual (2023)</td>
<td class="gt_row gt_right">None</td>
<td class="gt_row gt_right">10</td>
<td class="gt_row gt_left">‚ùå</td>
<td class="gt_row gt_right">57.45</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">llama-v3p1-70b-instruct</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">60</td>
<td class="gt_row gt_right">40 + 1</td>
<td class="gt_row gt_left">‚úÖ</td>
<td class="gt_row gt_right">56.46</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">Manual (2023)</td>
<td class="gt_row gt_right">None</td>
<td class="gt_row gt_right">10</td>
<td class="gt_row gt_left">‚ùå</td>
<td class="gt_row gt_right">55.67</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">llama-v3p1-70b-instruct</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">15</td>
<td class="gt_row gt_right">20 + 1</td>
<td class="gt_row gt_left">‚ùå</td>
<td class="gt_row gt_right">54.90</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">llama-v3p1-70b-instruct</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">60</td>
<td class="gt_row gt_right">10 + 1</td>
<td class="gt_row gt_left">‚úÖ</td>
<td class="gt_row gt_right">54.33</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">llama-v3p1-70b-instruct</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">15</td>
<td class="gt_row gt_right">40 + 1</td>
<td class="gt_row gt_left">‚úÖ</td>
<td class="gt_row gt_right">54.09</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">llama-v3p1-70b-instruct</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">30</td>
<td class="gt_row gt_right">40 + 1</td>
<td class="gt_row gt_left">‚úÖ</td>
<td class="gt_row gt_right">54.09</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">15</td>
<td class="gt_row gt_right">5 + 1</td>
<td class="gt_row gt_left">‚ùå</td>
<td class="gt_row gt_right">53.70</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">30</td>
<td class="gt_row gt_right">5 + 1</td>
<td class="gt_row gt_left">‚ùå</td>
<td class="gt_row gt_right">53.70</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">llama-v3p1-70b-instruct</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">30</td>
<td class="gt_row gt_right">5 + 1</td>
<td class="gt_row gt_left">‚úÖ</td>
<td class="gt_row gt_right">53.05</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">60</td>
<td class="gt_row gt_right">10 + 1</td>
<td class="gt_row gt_left">‚úÖ</td>
<td class="gt_row gt_right">52.64</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">15</td>
<td class="gt_row gt_right">10 + 1</td>
<td class="gt_row gt_left">‚ùå</td>
<td class="gt_row gt_right">51.19</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">30</td>
<td class="gt_row gt_right">10 + 1</td>
<td class="gt_row gt_left">‚ùå</td>
<td class="gt_row gt_right">51.19</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">15</td>
<td class="gt_row gt_right">5 + 1</td>
<td class="gt_row gt_left">‚úÖ</td>
<td class="gt_row gt_right">51.16</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">30</td>
<td class="gt_row gt_right">5 + 1</td>
<td class="gt_row gt_left">‚úÖ</td>
<td class="gt_row gt_right">51.16</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">60</td>
<td class="gt_row gt_right">5 + 1</td>
<td class="gt_row gt_left">‚úÖ</td>
<td class="gt_row gt_right">51.16</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">llama-v3p1-70b-instruct</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">30</td>
<td class="gt_row gt_right">20 + 1</td>
<td class="gt_row gt_left">‚úÖ</td>
<td class="gt_row gt_right">50.90</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">llama-v3p1-70b-instruct</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">60</td>
<td class="gt_row gt_right">20 + 1</td>
<td class="gt_row gt_left">‚úÖ</td>
<td class="gt_row gt_right">50.90</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">30</td>
<td class="gt_row gt_right">10 + 1</td>
<td class="gt_row gt_left">‚úÖ</td>
<td class="gt_row gt_right">49.97</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">15</td>
<td class="gt_row gt_right">10 + 1</td>
<td class="gt_row gt_left">‚úÖ</td>
<td class="gt_row gt_right">49.74</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">llama-v3p1-70b-instruct</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">15</td>
<td class="gt_row gt_right">20 + 1</td>
<td class="gt_row gt_left">‚úÖ</td>
<td class="gt_row gt_right">49.47</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">llama-v3p1-70b-instruct</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">15</td>
<td class="gt_row gt_right">10 + 1</td>
<td class="gt_row gt_left">‚ùå</td>
<td class="gt_row gt_right">48.63</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">llama-v3p1-70b-instruct</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">15</td>
<td class="gt_row gt_right">5 + 1</td>
<td class="gt_row gt_left">‚úÖ</td>
<td class="gt_row gt_right">47.73</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">llama-v3p1-70b-instruct</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">30</td>
<td class="gt_row gt_right">10 + 1</td>
<td class="gt_row gt_left">‚úÖ</td>
<td class="gt_row gt_right">47.30</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">llama-v3p1-70b-instruct</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">15</td>
<td class="gt_row gt_right">5 + 1</td>
<td class="gt_row gt_left">‚ùå</td>
<td class="gt_row gt_right">46.46</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">llama-v3p1-70b-instruct</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">15</td>
<td class="gt_row gt_right">10 + 1</td>
<td class="gt_row gt_left">‚úÖ</td>
<td class="gt_row gt_right">46.31</td>
</tr>
</tbody><tfoot class="gt_sourcenotes">
<tr class="odd">
<td colspan="6" class="gt_sourcenote">¬π Bootstrapped + labeled examples. Notes: Limited Llama 3.1 70B non-CoT runs due to API constraints. Manual prompt runs use 10 examples vs. 6 in original paper.</td>
</tr>
</tfoot>

</table>


</div>
        
</div>
</div>
<section id="comparison-to-the-2023-manual-prompts" class="level3">
<h3 class="anchored" data-anchor-id="comparison-to-the-2023-manual-prompts">Comparison to the 2023 manual prompts</h3>
<p>The DSPy runs are competitive with the manually crafted prompts from the 2023 paper. In contrast to the manual prompt, DSPy instructions are relatively short and emphasize the use of few-shot examples to illustrate the task.</p>
</section>
<section id="impact-of-hyperparameters" class="level3">
<h3 class="anchored" data-anchor-id="impact-of-hyperparameters">Impact of hyperparameters</h3>
<p>To understand which factors significantly influence the F1 score, we‚Äôll run a simple linear regression analysis. The manual runs are excluded. To analyze the impact of the model choice, we‚Äôll create a boolean variable for <code>gpt-4o-mini</code> and treat <code>llama-v3p1-70b-instruct</code> as the baseline.</p>
<div id="6973a37c" class="cell" data-execution_count="24">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb31" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> statsmodels.api <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> sm</span>
<span id="cb31-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb31-3"></span>
<span id="cb31-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Prepare data for regression</span></span>
<span id="cb31-5">reg_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> results_df.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">filter</span>(</span>
<span id="cb31-6">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">~</span>pl.col(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"run_name"</span>).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>.contains(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"manual"</span>),</span>
<span id="cb31-7">    pl.col(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"model"</span>).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>.contains(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"gpt-4o-mini"</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">|</span> pl.col(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"model"</span>).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>.contains(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"llama"</span>),</span>
<span id="cb31-8">).with_columns(  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># exclude manual prompts</span></span>
<span id="cb31-9">    pl.col(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"model"</span>).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>.contains(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"gpt-4o-mini"</span>).alias(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"is_gpt4_mini"</span>),</span>
<span id="cb31-10">)</span>
<span id="cb31-11"></span>
<span id="cb31-12"></span>
<span id="cb31-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Convert to pandas and ensure numeric types</span></span>
<span id="cb31-14">X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> reg_df.select(</span>
<span id="cb31-15">    [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"max_demos"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"chain_of_thought"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"num_trials"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"is_gpt4_mini"</span>]</span>
<span id="cb31-16">).to_pandas()</span>
<span id="cb31-17"></span>
<span id="cb31-18"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Convert boolean columns to int</span></span>
<span id="cb31-19">bool_columns <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"chain_of_thought"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"is_gpt4_mini"</span>]</span>
<span id="cb31-20"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> col <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> bool_columns:</span>
<span id="cb31-21">    X[col] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> X[col].astype(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>)</span>
<span id="cb31-22"></span>
<span id="cb31-23">y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> reg_df.select(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"f1"</span>).to_pandas()</span>
<span id="cb31-24"></span>
<span id="cb31-25"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Add constant for intercept</span></span>
<span id="cb31-26">X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> sm.add_constant(X)</span>
<span id="cb31-27"></span>
<span id="cb31-28"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Fit regression</span></span>
<span id="cb31-29">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> sm.OLS(y, X).fit()</span>
<span id="cb31-30">n <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(reg_df)</span>
<span id="cb31-31">r2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.rsquared</span>
<span id="cb31-32"></span>
<span id="cb31-33"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Print results using GT</span></span>
<span id="cb31-34">df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame(</span>
<span id="cb31-35">    model.summary().tables[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>],</span>
<span id="cb31-36">    columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[</span>
<span id="cb31-37">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Parameter"</span>,</span>
<span id="cb31-38">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Coefficient"</span>,</span>
<span id="cb31-39">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Std Error"</span>,</span>
<span id="cb31-40">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"t"</span>,</span>
<span id="cb31-41">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"p&gt;|t|"</span>,</span>
<span id="cb31-42">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"[0.025"</span>,</span>
<span id="cb31-43">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"0.975]"</span>,</span>
<span id="cb31-44">    ],</span>
<span id="cb31-45">)</span>
<span id="cb31-46"></span>
<span id="cb31-47">df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df.iloc[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>:]  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># remove row with repeated column names</span></span>
<span id="cb31-48"></span>
<span id="cb31-49">GT(df).tab_header(</span>
<span id="cb31-50">    title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Hyperparameter Analysis"</span>, subtitle<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Dependent variable: F1 score"</span></span>
<span id="cb31-51">).cols_align(align<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"right"</span>).tab_source_note(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"n=</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>n<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> runs, R¬≤=</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>r2<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.2f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span></code></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="21">
<div id="weybrcaczr" style="padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>
#weybrcaczr table {
          font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;
          -webkit-font-smoothing: antialiased;
          -moz-osx-font-smoothing: grayscale;
        }

#weybrcaczr thead, tbody, tfoot, tr, td, th { border-style: none; }
 tr { background-color: transparent; }
#weybrcaczr p { margin: 0; padding: 0; }
 #weybrcaczr .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; }
 #weybrcaczr .gt_caption { padding-top: 4px; padding-bottom: 4px; }
 #weybrcaczr .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; }
 #weybrcaczr .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; }
 #weybrcaczr .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; }
 #weybrcaczr .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; }
 #weybrcaczr .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; }
 #weybrcaczr .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; }
 #weybrcaczr .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; }
 #weybrcaczr .gt_column_spanner_outer:first-child { padding-left: 0; }
 #weybrcaczr .gt_column_spanner_outer:last-child { padding-right: 0; }
 #weybrcaczr .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; }
 #weybrcaczr .gt_spanner_row { border-bottom-style: hidden; }
 #weybrcaczr .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; }
 #weybrcaczr .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; }
 #weybrcaczr .gt_from_md> :first-child { margin-top: 0; }
 #weybrcaczr .gt_from_md> :last-child { margin-bottom: 0; }
 #weybrcaczr .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; }
 #weybrcaczr .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; }
 #weybrcaczr .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; }
 #weybrcaczr .gt_row_group_first td { border-top-width: 2px; }
 #weybrcaczr .gt_row_group_first th { border-top-width: 2px; }
 #weybrcaczr .gt_striped { background-color: rgba(128,128,128,0.05); }
 #weybrcaczr .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; }
 #weybrcaczr .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; }
 #weybrcaczr .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; text-align: left; }
 #weybrcaczr .gt_left { text-align: left; }
 #weybrcaczr .gt_center { text-align: center; }
 #weybrcaczr .gt_right { text-align: right; font-variant-numeric: tabular-nums; }
 #weybrcaczr .gt_font_normal { font-weight: normal; }
 #weybrcaczr .gt_font_bold { font-weight: bold; }
 #weybrcaczr .gt_font_italic { font-style: italic; }
 #weybrcaczr .gt_super { font-size: 65%; }
 #weybrcaczr .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; }
 #weybrcaczr .gt_asterisk { font-size: 100%; vertical-align: 0; }
 
</style>

<table class="gt_table caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-quarto-disable-processing="false" data-quarto-bootstrap="false">
<thead>
<tr class="gt_heading header">
<th colspan="7" class="gt_heading gt_title gt_font_normal">Hyperparameter Analysis</th>
</tr>
<tr class="gt_heading even">
<th colspan="7" class="gt_heading gt_subtitle gt_font_normal gt_bottom_border">Dependent variable: F1 score</th>
</tr>
<tr class="gt_col_headings header">
<th id="Parameter" class="gt_col_heading gt_columns_bottom_border gt_right" data-quarto-table-cell-role="th" scope="col">Parameter</th>
<th id="Coefficient" class="gt_col_heading gt_columns_bottom_border gt_right" data-quarto-table-cell-role="th" scope="col">Coefficient</th>
<th id="Std Error" class="gt_col_heading gt_columns_bottom_border gt_right" data-quarto-table-cell-role="th" scope="col">Std Error</th>
<th id="t" class="gt_col_heading gt_columns_bottom_border gt_right" data-quarto-table-cell-role="th" scope="col">t</th>
<th id="p&amp;gt;|t|" class="gt_col_heading gt_columns_bottom_border gt_right" data-quarto-table-cell-role="th" scope="col">p&gt;|t|</th>
<th id="[0.025" class="gt_col_heading gt_columns_bottom_border gt_right" data-quarto-table-cell-role="th" scope="col">[0.025</th>
<th id="0.975]" class="gt_col_heading gt_columns_bottom_border gt_right" data-quarto-table-cell-role="th" scope="col">0.975]</th>
</tr>
</thead>
<tbody class="gt_table_body">
<tr class="odd">
<td class="gt_row gt_right">const</td>
<td class="gt_row gt_right">49.3654</td>
<td class="gt_row gt_right">1.457</td>
<td class="gt_row gt_right">33.885</td>
<td class="gt_row gt_right">0.000</td>
<td class="gt_row gt_right">46.419</td>
<td class="gt_row gt_right">52.312</td>
</tr>
<tr class="even">
<td class="gt_row gt_right">max_demos</td>
<td class="gt_row gt_right">0.2021</td>
<td class="gt_row gt_right">0.042</td>
<td class="gt_row gt_right">4.794</td>
<td class="gt_row gt_right">0.000</td>
<td class="gt_row gt_right">0.117</td>
<td class="gt_row gt_right">0.287</td>
</tr>
<tr class="odd">
<td class="gt_row gt_right">chain_of_thought</td>
<td class="gt_row gt_right">-4.3317</td>
<td class="gt_row gt_right">1.038</td>
<td class="gt_row gt_right">-4.172</td>
<td class="gt_row gt_right">0.000</td>
<td class="gt_row gt_right">-6.432</td>
<td class="gt_row gt_right">-2.232</td>
</tr>
<tr class="even">
<td class="gt_row gt_right">num_trials</td>
<td class="gt_row gt_right">0.1062</td>
<td class="gt_row gt_right">0.027</td>
<td class="gt_row gt_right">3.892</td>
<td class="gt_row gt_right">0.000</td>
<td class="gt_row gt_right">0.051</td>
<td class="gt_row gt_right">0.161</td>
</tr>
<tr class="odd">
<td class="gt_row gt_right">is_gpt4_mini</td>
<td class="gt_row gt_right">2.2964</td>
<td class="gt_row gt_right">1.016</td>
<td class="gt_row gt_right">2.260</td>
<td class="gt_row gt_right">0.029</td>
<td class="gt_row gt_right">0.241</td>
<td class="gt_row gt_right">4.351</td>
</tr>
</tbody><tfoot class="gt_sourcenotes">
<tr class="odd">
<td colspan="7" class="gt_sourcenote">n=44 runs, R¬≤=0.56</td>
</tr>
</tfoot>

</table>


</div>
        
</div>
</div>
</section>
<section id="few-shot-examples" class="level3">
<h3 class="anchored" data-anchor-id="few-shot-examples">Few-shot examples</h3>
<p>More examples are generally better, as indicated by the positive coefficient in the regression. However, the top runs didn‚Äôt use more than 20 examples, indicating that there are diminishing returns.</p>
</section>
<section id="chain-of-thought-cot" class="level3">
<h3 class="anchored" data-anchor-id="chain-of-thought-cot">Chain of thought (CoT)</h3>
<p>Runs where the model was instructed to perform an intermediate reasoning step yielded worse results than those without. This is an unusual result - typically CoT helps LLMs achieve better results, for example the main advantage of OpenAI‚Äôs <code>o1-preview</code> over <code>gpt-4o</code> is the advanced CoT that is built into it. However, on this structured task and using DSPy‚Äôs <code>Predictor</code> and <code>ChainOfThought</code> classes, CoT seems to be detrimental.</p>
</section>
<section id="model-choice" class="level3">
<h3 class="anchored" data-anchor-id="model-choice">Model choice</h3>
<ul>
<li><code>gpt-4o-mini-2024-07-18</code> seems to have an edge over <code>llama-v3p1-70b-instruct</code>, but the confidence interval is wide.</li>
<li><code>gpt-4o-2024-11-20</code> performs better than the other models that were tested. I expect that performance of similar sized models such as <code>Llama 3.1 405B</code> will be similar. Due to cost considerations, I‚Äôve skipped the optimization of a large model with DSPy.</li>
<li><code>gpt-3.5-turbo-0125</code> performed better than <code>gpt-4o-mini-2024-07-18</code>, but worse than the deprecated <code>gpt-3.5-turbo-0613</code> performed during the experiments for the 2023 paper (57.45 vs.&nbsp;65.65 F1 Score).</li>
</ul>
</section>
<section id="number-of-trials" class="level3">
<h3 class="anchored" data-anchor-id="number-of-trials">Number of trials</h3>
<p>Using more trials is associated with higher F1 scores. However, the table also shows setups with identical results at 15, 30 and 60 trials. Going beyond 60 trials isn‚Äôt likely to be helpful.</p>
</section>
</section>
<section id="review-of-dspy" class="level2">
<h2 class="anchored" data-anchor-id="review-of-dspy">Review of DSPy</h2>
<p>Here are my conclusions based on this experiment.</p>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Pros ‚úÖ</strong></p>
<ul>
<li>Creates prompts that are as good as or better than manually crafted prompts.</li>
<li>No need to manually craft prompts, leading to faster iteration speed.</li>
<li>Able to deal with multi-step workflows.</li>
<li>Naturally encourages a structured approach focused on evaluation.</li>
<li>Supports many LLMs, via APIs and locally.</li>
<li>Lightweight JSON export of the optimized prompts.</li>
<li>Supports custom evaluation metrics.</li>
<li>Built-in threading and caching, which saved me time and money.</li>
<li>Actively developed and has a large community.</li>
<li>Lots of <a href="https://github.com/stanfordnlp/dspy/tree/main/examples">tutorial notebooks</a>.</li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>Cons ‚ùå</strong></p>
<ul>
<li>Generated prompts seem too short to explain the nuances of the task, placing a lot of burden on the few-shot examples. They need to implicitly explain the annotation rules and cover all relevant cases.</li>
<li>Loss of control over the exact prompt. But arguably, if you want to control the prompt DSPy is not the approach to go for anyway.</li>
<li>Adds a layer of abstraction to a stack that‚Äôs already complex.</li>
<li>Structured output is not guaranteed, because it‚Äôs based on prompting only. Integration with function calling, JSON mode or constrained generation APIs and libraries would improve the reliability of the format.</li>
<li>Steep learning curve with many concepts to understand.</li>
<li>I encountered some bugs and deprecated functions and tutorials.</li>
</ul>
</div>
</div>
<p>DSPy is a great alternative to manual prompting, especially for tasks that have a clear evaluation metric and are demonstrable using few-shot examples. The high variability in the results of my grid search experiment indicates that it‚Äôs necessary to run DSPy multiple times with different settings to find the best performing configuration.</p>
<p>A feature that I haven‚Äôt explored here is the fine-tuning <a href="https://dspy.ai/learn/optimization/optimizers/?h=fine#automatic-finetuning">optimizer</a> of DSPy that actually modifies the model weights. It‚Äôs promising for this task, as a fine-tuned <code>gpt-3.5-turbo-0613</code> is still the <a href="https://paperswithcode.com/sota/aspect-based-sentiment-analysis-on-semeval-6">record holder</a> at an F1 score of 83.76.</p>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0">
<div id="ref-opsahlong2024optimizinginstructionsdemonstrationsmultistage" class="csl-entry">
Opsahl-Ong, Krista, Michael J Ryan, Josh Purtell, David Broman, Christopher Potts, Matei Zaharia, and Omar Khattab. 2024. <span>‚ÄúOptimizing Instructions and Demonstrations for Multi-Stage Language Model Programs.‚Äù</span> <a href="https://arxiv.org/abs/2406.11695">https://arxiv.org/abs/2406.11695</a>.
</div>
<div id="ref-pontiki_semeval" class="csl-entry">
Pontiki, Maria, Dimitris Galanis, John Pavlopoulos, Harris Papageorgiou, Ion Androutsopoulos, and Suresh Manandhar. 2014. <span>‚Äú<span>SemEval</span>-2014 <span>Task</span> 4: <span>Aspect</span> <span>Based</span> <span>Sentiment</span> <span>Analysis</span>.‚Äù</span> In <em>Proceedings of the 8th <span>International</span> <span>Workshop</span> on <span>Semantic</span> <span>Evaluation</span> (<span>SemEval</span> 2014)</em>, 27‚Äì35. Dublin, Ireland: Association for Computational Linguistics. <a href="https://doi.org/10.3115/v1/S14-2004">https://doi.org/10.3115/v1/S14-2004</a>.
</div>
<div id="ref-simmering2023large" class="csl-entry">
Simmering, Paul F., and Paavo Huoviala. 2023. <span>‚ÄúLarge Language Models for Aspect-Based Sentiment Analysis.‚Äù</span> <a href="https://arxiv.org/abs/2310.18025">https://arxiv.org/abs/2310.18025</a>.
</div>
</div></section></div> ]]></description>
  <category>Machine Learning</category>
  <category>Python</category>
  <guid>https://simmering.dev/blog/absa-with-dspy/</guid>
  <pubDate>Sat, 23 Nov 2024 23:00:00 GMT</pubDate>
  <media:content url="https://simmering.dev/blog/absa-with-dspy/image.webp" medium="image" type="image/webp"/>
</item>
<item>
  <title>From 5-7-5 to Thousand Lines: The Case for Longer Prompts</title>
  <dc:creator>Paul Simmering</dc:creator>
  <link>https://simmering.dev/blog/long-prompts/</link>
  <description><![CDATA[ 





<p>Prompts are the key to guide LLMs for any task, from a chatbot to a text classifier. Longer prompts are usually better than shorter ones, as I‚Äôll argue below. There is a tradeoff, though: each interaction with a long prompt has a longer input sequence, which increases inference cost and latency. Further, a long prompt takes up more of the model‚Äôs context window, leaving less for user interaction. But both of these concerns are becoming less relevant with recent developments.</p>
<section id="long-prompts-are-getting-cheaper" class="level2">
<h2 class="anchored" data-anchor-id="long-prompts-are-getting-cheaper">Long prompts are getting cheaper</h2>
<p>There are two developments that keep bringing down the cost of long prompts:</p>
<ol type="1">
<li><p><strong>Decrease in input token cost</strong> on API platforms like OpenAI, Anthropic and others. At launch of gpt-3.5-turbo in March 2023, OpenAI charged $2 for 1 million input tokens. By August 2024, it‚Äôs $0.15 for gpt-4o-mini, a more capable model. This is a 92.5% reduction in cost. It reflects the fierce competition and the increasing efficiency of inference software, a fall in GPU prices and advances in quantization. Similar trends can be observed in inference cost for open source models, though it‚Äôs harder to reach the same economies of scale as the big platforms.</p></li>
<li><p><strong>Context caching</strong>, meaning that the model doesn‚Äôt have to recompute the prefix of the prompt for each interaction. This is also called prompt caching. It uses a KV cache (see a good explanation by <span class="citation" data-cites="log2023kvcache">Log (2023)</span>) to skip the calculation of the attention keys and values for cached tokens. Originally, this was only used within a single generation task to avoid having to re-read all tokens for each additional token generated. However, it can also be used across different generations. It‚Äôs integrated in <a href="https://docs.vllm.ai/en/stable/automatic_prefix_caching/apc.html">vLLM</a> <span class="citation" data-cites="kwon2023efficientmemorymanagementlarge">(Kwon et al. 2023)</span>, an inference library that can serve many popular open source models. Since June 2024, three API platforms have also added this feature: <a href="https://platform.deepseek.com/api-docs/news/news0802/">DeepSeek</a>, <a href="https://ai.google.dev/gemini-api/docs/caching?lang=python">Google Gemini</a> and <a href="https://www.anthropic.com/news/prompt-caching">Anthropic</a>.</p></li>
</ol>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/long-prompts/kv_cache_example.JPEG" class="img-fluid figure-img"></p>
<figcaption>Context caching lets subsequent requests with the same prefix use a cache. Image from <a href="platform">DeepSeek</a>.</figcaption>
</figure>
</div>
<table class="caption-top table">
<colgroup>
<col style="width: 11%">
<col style="width: 20%">
<col style="width: 16%">
<col style="width: 33%">
<col style="width: 16%">
</colgroup>
<thead>
<tr class="header">
<th>Platform</th>
<th>Model</th>
<th>Regular price</th>
<th>Caching price</th>
<th>Savings</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>DeepSeek</td>
<td>deepseek-chat</td>
<td>$0.14 / Mtok</td>
<td>$0.014 / Mtok for cache read</td>
<td>90%</td>
</tr>
<tr class="even">
<td>Anthropic</td>
<td>Claude 3.5 Sonnet</td>
<td>$3.00 / Mtok</td>
<td>$3.75 / MTok for cache write, $0.30 /Mtok for cache hits</td>
<td>90%</td>
</tr>
<tr class="odd">
<td>Gemini</td>
<td>Gemini 1.5 Pro</td>
<td>$3.50 / Mtok</td>
<td>Free cache read, $4.50 / Mtok per hour for storage</td>
<td>Variable</td>
</tr>
</tbody>
</table>
<p>The table above compares the cost savings from prompt caching on different platforms. Mtok stands for million tokens.</p>
<p>The pricing models are quite different. DeepSeek offers the best savings at 90% reduction on cache hit and no storage fees. Keep in mind that this is not a frontier model. The documentation says the cache is cleared after a few hours. Further, the feature is active by default and doesn‚Äôt require a change in code. This is different at Anthropic where the cache has to be explicitly enabled and writing to it carries a higher cost than a normal input token. As of August 31, the cache only has a 5 minute time to live (TTL), making it only useful apps with high frequency of the same prompt. Gemini charges for storage and gives control over the TTL with a default of one hour and requires explicit enabling.</p>
<p>Why is it so expensive to store 1 million tokens for one hour? The reason is that the KV cache takes a surprising amount of memory. The formula for the memory per token is:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7Bmemory%7D%20=%20n_%7Btokens%7D%20*%202%20*%20n_%7Bheads%7D%20*%20d_%7Bhead%7D%20*%20n_%7Blayers%7D%20*%20%5Ctext%7Bprecision%20(bytes)%7D%0A"></p>
<p>The 2 represents the key and value vectors, <img src="https://latex.codecogs.com/png.latex?n_%7Bheads%7D"> is the number of attention heads, <img src="https://latex.codecogs.com/png.latex?d_%7Bhead%7D"> is the dimension of the attention head, <img src="https://latex.codecogs.com/png.latex?n_%7Blayers%7D"> is the number of layers and precision is the number of bytes used to store a single weight. Note that this doesn‚Äôt include optimizations like sparsity, quantizastion or grouped query attention <span class="citation" data-cites="ainslie2023gqatraininggeneralizedmultiquery">(Ainslie et al. 2023)</span>.</p>
<p>For a 1024 token sequence on a 175B GPT-3 model with 96 heads with 128 dimensions and 96 layers at FP16 precision, this results in</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A1024%20*%202%20*%2096%20*%20128%20*%2096%20*%2016%20%5Ctext%7B%20bytes%7D%20=%2038.65%20%5Ctext%7B%20GB%7D%0A"></p>
<p>This has to be stored in GPU memory to be accessible for the model.</p>
<p>But while $4.5 / Mtok might seem expensive for just one hour, if that input token is used at least twice in that hour, it‚Äôs already cheaper than the regular input token price. The savings are multiplied with each additional use. For use of open models on your own GPUs, this means that allocating a portion of your GPU memory to cache can be an excellent investment. It also means that for same-y inference requests, GPU memory matters more than its speed.</p>
</section>
<section id="context-sizes-are-getting-larger" class="level2">
<h2 class="anchored" data-anchor-id="context-sizes-are-getting-larger">Context sizes are getting larger</h2>
<p>Current frontier models have a context length of at least 128,000 tokens - equivalent to roughly 100,000 words or a 400 page novel.</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Provider</th>
<th>Model</th>
<th>Context size</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Google</td>
<td>Gemini 1.5 Pro</td>
<td>2m</td>
</tr>
<tr class="even">
<td>Anthropic</td>
<td>Claude 3.5 Sonnet</td>
<td>200k</td>
</tr>
<tr class="odd">
<td>Alibaba</td>
<td>Qwen2 72B</td>
<td>128k</td>
</tr>
<tr class="even">
<td>Meta</td>
<td>Llama 3.1 Instruct 405B</td>
<td>128k</td>
</tr>
<tr class="odd">
<td>Mistral</td>
<td>Mistral Large 2</td>
<td>128k</td>
</tr>
<tr class="even">
<td>OpenAI</td>
<td>GPT-4o</td>
<td>128k</td>
</tr>
</tbody>
</table>
<p>Source: <a href="https://artificialanalysis.ai">Artificialanalysis.ai</a></p>
<p>In contrast, early models like gpt-3.5-turbo in March 2023 only had a context size of 4096 tokens. In a RAG context, this means that more text chunks can be included in the prompt and in a chat context, more questions and answers can be included before the oldest ones are evicted. The problem that a prompt doesn‚Äôt fit into the context window is effectively solved for almost all applications.</p>
</section>
<section id="longer-prompts-are-often-better" class="level2">
<h2 class="anchored" data-anchor-id="longer-prompts-are-often-better">Longer prompts are often better</h2>
<p>Ok, so long prompts are getting cheaper. But how does a longer prompt help?</p>
<section id="more-detailed-guidelines" class="level3">
<h3 class="anchored" data-anchor-id="more-detailed-guidelines">1. More detailed guidelines</h3>
<p>A longer prompt can provide more context to the model, letting it perform a task more accurately or represent a brand or character more faithfully. Consider including information like this:</p>
<ul>
<li>Background information about the website, app or task that the model is embedded in.</li>
<li>Behavioral constraints, like not using certain words or phrases. For example telling the prompt to avoid starting answers with ‚ÄúCertainly!‚Äù, to make it sound less AI-like.</li>
<li>Style guidelines, like using a certain tone or level of formality, whether to address the user by first or last name, or to use emojis.</li>
<li>Characterization, giving the model a personality or role to play. For example, a chatbot for a bank could be characterized as a friendly and professional customer service agent.</li>
<li>A more detailed task description, like a list of steps to follow or a description of the desired output.</li>
<li>Information about the user, like their name, location, or preferences.</li>
<li>A translation glossary, if the model is used in a multilingual setting.</li>
</ul>
<p>If you‚Äôre looking for inspiration for a chatbot prompt, check the recently revealed prompts for Anthropic‚Äôs <a href="https://docs.anthropic.com/en/release-notes/system-prompts#july-12th-2024">Claude</a>.</p>
</section>
<section id="many-shot-in-context-learning" class="level3">
<h3 class="anchored" data-anchor-id="many-shot-in-context-learning">2. Many-shot in-context learning</h3>
<p>Few-shot examples can be included in the prompt for in-context learning (ICL). These examples can teach the model about the rules for the task, the desired output format, intermediate reasoning steps and handling of edge cases. Commonly this is done with 1 to 5 examples, but with prefix caching it‚Äôs possible to include 50, 100 or even more examples.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/long-prompts/many_shot_learning.png" class="img-fluid figure-img"></p>
<figcaption>Many-shot in-context learning. Image from Agarwal et al.&nbsp;(2024)</figcaption>
</figure>
</div>
<p><span class="citation" data-cites="agarwal2024manyshotincontextlearning">Agarwal et al. (2024)</span> ran this experiment with Gemini 1.5 Pro across several tasks. Many-shot ICL outperformed few-shot learning in all cases. For sentiment analysis they went as far as 2048 examples in the prompt, achieving an increase in 18.2 percentage points over a 32-shot prompt. In many of their experiments the limiting factor wasn‚Äôt the context size, but the number of available examples.</p>
<p>This allows a prompting approach become closer to fine-tuning, but without the need for training or a model store. <span class="citation" data-cites="bertsch2024incontextlearninglongcontextmodels">Bertsch et al. (2024)</span> made the comparison between many-shot ICL and LoRA <span class="citation" data-cites="hu2021loralowrankadaptationlarge">(Hu et al. 2021)</span> on 5 classification tasks and conclude that ‚Äúfinetuning is more data-hungry than ICL‚Äù. In their experiments with Llama2-7b, many-shot prompting outperformed fine-tuning up to about 1000 examples (see figure 2 of their paper).</p>
</section>
<section id="more-rag-context" class="level3">
<h3 class="anchored" data-anchor-id="more-rag-context">3. More RAG context</h3>
<p>A key design parameter in retrieval augmented generation (RAG) is the number of text chunks to retrieve from a source. With a larger context size, more and longer text chunks can be included in the prompt. This increases the likelihood that the information required to answer the query is present in the prompt.</p>
<p><span class="citation" data-cites="leng2024longcontextrag">Leng et al. (2024)</span> tested RAG answer correctness on 13 open source and proprietary LLMs.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/long-prompts/long_context_performance.png" class="img-fluid figure-img"></p>
<figcaption>Long context performance of GPT, Claude, Llama, Mistral and DBRX models on 4 curated RAG datasets (Databricks DocsQA, FinanceBench, HotPotQA and Natural Questions), from Leng et al.&nbsp;(2024).</figcaption>
</figure>
</div>
<p>As the graph above shows, answer correctness increased with longer context all models up to 4k tokens and up to 32k tokens for most models. This is driven by the boost in retrieval (see experiment 1 in the article).</p>
<p>However, the ‚Äúlost in the middle‚Äù problem can occur, a phenomemon first found by <span class="citation" data-cites="liu2023lostmiddlelanguagemodels">(Liu et al. 2023)</span>, where information presented in the middle is not used as well as information presented at the beginning or end. It can be measured by the ‚Äúneedle in a haystack‚Äù method, meaning that a piece of information is hidden in a long text and the model has to find it. The longer the text, the harder it is to find the information. The RULER benchmark by <span class="citation" data-cites="hsieh2024rulerwhatsrealcontext">(Hsieh et al. 2024)</span> extended this to more complex tasks and introduced the concept of an effective context length, which is shorter than the technical context length of a model.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/long-prompts/lost_in_the_middle.png" class="img-fluid figure-img" style="width:50.0%"></p>
<figcaption>Lost in the middle problem. Image from Liu et al.&nbsp;(2023)</figcaption>
</figure>
</div>
<p>Retrieving more information also increases the risk of including irrelevant information. If chunk ranking works correctly, lower ranking chunks are less likely to be relevant and adding them reduces the density of relevant information. <span class="citation" data-cites="levy2024tasktokensimpactinput">Levy, Jacoby, and Goldberg (2024)</span> found that irrelevant information isn‚Äôt neutral, it‚Äôs detrimental to model performance on a question-answering task.</p>
</section>
<section id="more-functions-for-agentic-models" class="level3">
<h3 class="anchored" data-anchor-id="more-functions-for-agentic-models">4. More functions for agentic models</h3>
<p>Models used as agents are given function signatures in a JSON schema. Each of these has to be sent to the model as part of the prompt. The more functions and the more arguments they have, the longer the prompt. With lower prompt costs, it‚Äôs becoming more economical to have agents with many different and more detailed functions in their repertoire.</p>
<p>Common functions include:</p>
<ul>
<li>Send a task to a sub-agent</li>
<li>Web search</li>
<li>Query a database by using text-to-SQL</li>
<li>Redirect to a human agent</li>
<li>Call a REST API, e.g.&nbsp;to send an email or schedule a meeting</li>
<li>Execute code in Python, JavaScript or another language</li>
</ul>
<p>The Berkeley function calling leaderboard <span class="citation" data-cites="berkeley-function-calling-leaderboard">(Yan et al. 2024)</span> offers detailed benchmarks for a variety of function calling tasks.</p>
</section>
</section>
<section id="conclusion-revisit-your-prompts" class="level2">
<h2 class="anchored" data-anchor-id="conclusion-revisit-your-prompts">Conclusion: revisit your prompts</h2>
<p>In 2023, the cost of long prompts was a major concern. Each input token was precious. This has changed with the introduction of prompt caching and a massive reduction in input token cost. It‚Äôs worth reevaluating prompts and consider whether adding more information would benefit the application.</p>
<p>About the title: 5-7-5 refers to the syllable count in a haiku, a form of short poetry from Japan.</p>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0">
<div id="ref-agarwal2024manyshotincontextlearning" class="csl-entry">
Agarwal, Rishabh, Avi Singh, Lei M. Zhang, Bernd Bohnet, Luis Rosias, Stephanie Chan, Biao Zhang, et al. 2024. <span>‚ÄúMany-Shot in-Context Learning.‚Äù</span> <a href="https://arxiv.org/abs/2404.11018">https://arxiv.org/abs/2404.11018</a>.
</div>
<div id="ref-ainslie2023gqatraininggeneralizedmultiquery" class="csl-entry">
Ainslie, Joshua, James Lee-Thorp, Michiel de Jong, Yury Zemlyanskiy, Federico Lebr√≥n, and Sumit Sanghai. 2023. <span>‚ÄúGQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints.‚Äù</span> <a href="https://arxiv.org/abs/2305.13245">https://arxiv.org/abs/2305.13245</a>.
</div>
<div id="ref-bertsch2024incontextlearninglongcontextmodels" class="csl-entry">
Bertsch, Amanda, Maor Ivgi, Uri Alon, Jonathan Berant, Matthew R. Gormley, and Graham Neubig. 2024. <span>‚ÄúIn-Context Learning with Long-Context Models: An in-Depth Exploration.‚Äù</span> <a href="https://arxiv.org/abs/2405.00200">https://arxiv.org/abs/2405.00200</a>.
</div>
<div id="ref-hsieh2024rulerwhatsrealcontext" class="csl-entry">
Hsieh, Cheng-Ping, Simeng Sun, Samuel Kriman, Shantanu Acharya, Dima Rekesh, Fei Jia, Yang Zhang, and Boris Ginsburg. 2024. <span>‚ÄúRULER: What‚Äôs the Real Context Size of Your Long-Context Language Models?‚Äù</span> <a href="https://arxiv.org/abs/2404.06654">https://arxiv.org/abs/2404.06654</a>.
</div>
<div id="ref-hu2021loralowrankadaptationlarge" class="csl-entry">
Hu, Edward J., Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. 2021. <span>‚ÄúLoRA: Low-Rank Adaptation of Large Language Models.‚Äù</span> <a href="https://arxiv.org/abs/2106.09685">https://arxiv.org/abs/2106.09685</a>.
</div>
<div id="ref-kwon2023efficientmemorymanagementlarge" class="csl-entry">
Kwon, Woosuk, Zhuohan Li, Siyuan Zhuang, Ying Sheng, Lianmin Zheng, Cody Hao Yu, Joseph E. Gonzalez, Hao Zhang, and Ion Stoica. 2023. <span>‚ÄúEfficient Memory Management for Large Language Model Serving with PagedAttention.‚Äù</span> <a href="https://arxiv.org/abs/2309.06180">https://arxiv.org/abs/2309.06180</a>.
</div>
<div id="ref-leng2024longcontextrag" class="csl-entry">
Leng, Quinn, Jacob Portes, Sam Havens, Matei Zaharia, and Michael Carbin. 2024. <span>‚ÄúLong Context RAG Performance of LLMs.‚Äù</span> <a href="https://www.databricks.com/blog/long-context-rag-performance-llms" class="uri">https://www.databricks.com/blog/long-context-rag-performance-llms</a>.
</div>
<div id="ref-levy2024tasktokensimpactinput" class="csl-entry">
Levy, Mosh, Alon Jacoby, and Yoav Goldberg. 2024. <span>‚ÄúSame Task, More Tokens: The Impact of Input Length on the Reasoning Performance of Large Language Models.‚Äù</span> <a href="https://arxiv.org/abs/2402.14848">https://arxiv.org/abs/2402.14848</a>.
</div>
<div id="ref-liu2023lostmiddlelanguagemodels" class="csl-entry">
Liu, Nelson F., Kevin Lin, John Hewitt, Ashwin Paranjape, Michele Bevilacqua, Fabio Petroni, and Percy Liang. 2023. <span>‚ÄúLost in the Middle: How Language Models Use Long Contexts.‚Äù</span> <a href="https://arxiv.org/abs/2307.03172">https://arxiv.org/abs/2307.03172</a>.
</div>
<div id="ref-log2023kvcache" class="csl-entry">
Log, Matt. 2023. <span>‚ÄúWhat Is the KV Cache?‚Äù</span> https://mett29.github.io/posts/kv-cache/.
</div>
<div id="ref-berkeley-function-calling-leaderboard" class="csl-entry">
Yan, Fanjia, Huanzhi Mao, Charlie Cheng-Jie Ji, Tianjun Zhang, Shishir G. Patil, Ion Stoica, and Joseph E. Gonzalez. 2024. <span>‚ÄúBerkeley Function Calling Leaderboard.‚Äù</span> In. <a href="https://gorilla.cs.berkeley.edu/blogs/8_berkeley_function_calling_leaderboard.html" class="uri">https://gorilla.cs.berkeley.edu/blogs/8_berkeley_function_calling_leaderboard.html</a>.
</div>
</div></section></div> ]]></description>
  <category>Machine Learning</category>
  <guid>https://simmering.dev/blog/long-prompts/</guid>
  <pubDate>Sat, 31 Aug 2024 22:00:00 GMT</pubDate>
  <media:content url="https://simmering.dev/blog/long-prompts/image.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>OpenAI‚Äôs structured output vs.¬†instructor and outlines</title>
  <dc:creator>Paul Simmering</dc:creator>
  <link>https://simmering.dev/blog/openai_structured_output/</link>
  <description><![CDATA[ 





<p>On August 6 OpenAI released <a href="https://openai.com/index/introducing-structured-outputs-in-the-api/">structured outputs</a> in their API. Is structured outputs a replacement for instructor, outlines and other libraries that provide structured outputs for language models? Let‚Äôs compare them.</p>
<p>OpenAI‚Äôs structured outputs makes the following code possible:</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> json</span>
<span id="cb1-2"></span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pydantic <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> BaseModel</span>
<span id="cb1-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> openai <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> OpenAI</span>
<span id="cb1-5"></span>
<span id="cb1-6"></span>
<span id="cb1-7"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> Ingredient(BaseModel):</span>
<span id="cb1-8">    name: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span></span>
<span id="cb1-9">    amount: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span></span>
<span id="cb1-10">    kcal: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span></span>
<span id="cb1-11"></span>
<span id="cb1-12"></span>
<span id="cb1-13"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> Recipe(BaseModel):</span>
<span id="cb1-14">    ingredients: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>[Ingredient]</span>
<span id="cb1-15">    instructions: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span></span>
<span id="cb1-16"></span>
<span id="cb1-17"></span>
<span id="cb1-18">client <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> OpenAI()</span>
<span id="cb1-19"></span>
<span id="cb1-20">completion <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> client.beta.chat.completions.parse(</span>
<span id="cb1-21">    model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"gpt-4o-2024-08-06"</span>,</span>
<span id="cb1-22">    messages<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[{<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"role"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"user"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"content"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Write an apple pie recipe"</span>}],</span>
<span id="cb1-23">    response_format<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>Recipe,</span>
<span id="cb1-24">)</span>
<span id="cb1-25"></span>
<span id="cb1-26">apple_pie_recipe <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Recipe(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>json.loads(completion.choices[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].message.content))</span></code></pre></div>
<p>It‚Äôs guaranteed that the output will be JSON that can be parsed into a <code>Recipe</code> object. The code looks very similar to the code you‚Äôd write with any of the <a href="../../blog/structured_output/">10 libraries</a> I compared in May.</p>
<p>Besides removing the need for a library, structured output works quite differently from function calling under the hood. With function calling the model is trained to follow an instruction given as a JSON schema and is likely but not guaranteed to follow it. At any token position it‚Äôs still free to output a token that doesn‚Äôt fit the schema. With structured output, the output of the model is constrained to fit the schema. This is the same approach as the <a href="https://github.com/outlines-dev/outlines">outlines</a> library uses for open source models.</p>
<section id="pros-and-cons" class="level2">
<h2 class="anchored" data-anchor-id="pros-and-cons">Pros and cons</h2>
<p>The structured output feature has several advantages over function calling:</p>
<ol type="1">
<li>‚úÖ The definition of the output format doesn‚Äôt count as input tokens, making it significantly cheaper, especially for short input messages and complex output formats.</li>
<li>‚úÖ The output is 100% guaranteed to follow the structure, in contrast to JSON mode and function calling which are just very likely to follow the structure.</li>
<li>‚úÖ It doesn‚Äôt slow down the generation process, rather it speeds it up because tokens with no alternatives can be automatically placed rather than generated by the model.</li>
</ol>
<p>But also some downsides:</p>
<ol type="1">
<li>‚ùå OpenAI‚Äôs implementation only works with its own models.</li>
<li>‚ùå It only supports a subset of JSON schema. In particular, they don‚Äôt support <code>minLength</code> and <code>maxLength</code> constraints. See their <a href="https://platform.openai.com/docs/guides/structured-outputs">docs</a>. These are supported by outlines and instructor.</li>
<li>‚ùå The first API call with a schema has a higher latency than subsequent calls because the schema has to be compiled.</li>
</ol>
<p>I expect that the first two downsides will be addressed in the future. Thanks to the outlines library, the implementation of structured outputs is already available for open source models. Perhaps providers like Fireworks AI and Groq will adopt it with the same API specification as OpenAI. They‚Äôve done this with function calling. In turn, platform-agnostic libraries like mirascope, marvin and instructor may adopt it as well.</p>
</section>
<section id="are-instructor-and-other-structured-output-libraries-obsolete" class="level2">
<h2 class="anchored" data-anchor-id="are-instructor-and-other-structured-output-libraries-obsolete">Are instructor and other structured output libraries obsolete?</h2>
<p>Right after the announcement, Jason Liu, author of instructor posted:</p>
<blockquote class="blockquote">
<p>They solved instructor.</p>
</blockquote>
<p>on <a href="https://x.com/jxnlco/status/1820880349288595629">X</a>. Later he added a longer <a href="https://x.com/jxnlco/status/1820976130096074940">post</a> with his thoughts.</p>
<p>Yes, the core value proposition of: ‚Äúgive me a Pydantic model and I‚Äôll use function calling to guarantee the output fits the schema‚Äù is now covered for OpenAI models, but only for OpenAI models. If you‚Äôre using other models or want to stay flexible, structured output libraries are still useful. Each library also comes with additional features, as I‚Äôve covered in my <a href="../../blog/structured_output/">comparison</a>. Examples are multiple provider support, error handling, caching, chaining and more.</p>
<p>So in short: no, they‚Äôre not obsolete, but their space is getting squeezed.</p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>If you‚Äôre exclusively using OpenAI models and only need basic structured responses, I recommend using OpenAI‚Äôs structured outputs. It‚Äôs the most convenient, secure and cheapest method. If you prefer other LLM providers or want your code to be provider-agnostic, I recommend sticking with outlines (if self-hosting) or instructor (if using API providers).</p>


</section>

 ]]></description>
  <category>Machine Learning</category>
  <category>Python</category>
  <guid>https://simmering.dev/blog/openai_structured_output/</guid>
  <pubDate>Fri, 09 Aug 2024 22:00:00 GMT</pubDate>
  <media:content url="https://simmering.dev/blog/openai_structured_output/image.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Levels of Abstraction in the LLM Stack</title>
  <dc:creator>Paul Simmering</dc:creator>
  <link>https://simmering.dev/blog/abstractions/</link>
  <description><![CDATA[ 





<p>Training and serving LLMs requires a tall software stack. You can engage with this stack at different levels of abstraction, from low-level frameworks like CUDA to ready-to-go inference APIs like the OpenAI API. The aim of this article is to provide an overview of the abstraction levels and help you choose the right one for your project. Typical questions are:</p>
<ul>
<li>‚Äú<em>Should I use OpenAI‚Äôs GPT models or an open source model?</em>‚Äù</li>
<li>‚Äú<em>Should I use HuggingFace transformers or load the model into PyTorch directly?</em>‚Äù</li>
<li>‚Äú<em>Should I use AWS SageMaker or rent plain EC2 instances and manage everything myself?</em>‚Äù</li>
</ul>
<p>The choice depends on you and your project, but this overview and the decision criteria at the end may help you decide. I‚Äôll discuss 3 levels of abstraction:</p>
<ol type="1">
<li>Open source tools and frameworks</li>
<li>Managed LLM services, e.g.&nbsp;AWS SageMaker</li>
<li>Cloud APIs, e.g.&nbsp;OpenAI</li>
</ol>
<section id="open-source-llm-stack" class="level2">
<h2 class="anchored" data-anchor-id="open-source-llm-stack">1. Open source LLM stack</h2>
<p>The open source LLM stack is the most flexible and customizable option and what is underlying the other two options. It consists of several layers. The list below has examples of tools at each level. I‚Äôve not included optional MLOps tools like experiment tracking, monitoring, model store etc. which are not on the critical path for training and serving LLMs.</p>
<p>The term open source is not accurate for the lowest levels: hardware is proprietary and Nvidia holds a near-monopoly on GPUs for machine learning. Cloud providers are also proprietary, but there are many to choose from and they allow running open source software.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 17%">
<col style="width: 33%">
<col style="width: 48%">
</colgroup>
<thead>
<tr class="header">
<th>Level</th>
<th>Description</th>
<th>Examples</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1. Hardware</td>
<td>Physical graphics processors with high VRAM</td>
<td>Nvidia H100, AMD MI350, Intel Gaudi 3</td>
</tr>
<tr class="even">
<td>2. Cloud Providers</td>
<td>Platforms offering rentable GPU resources for LLM training and inference</td>
<td>AWS, Google Cloud, Azure, Modal, Lambda Labs</td>
</tr>
<tr class="odd">
<td>3. Acceleration Framework</td>
<td>Software interfaces for efficient use of GPUs for machine learning</td>
<td>CUDA, ROCm</td>
</tr>
<tr class="even">
<td>4. Distributed Computing</td>
<td>Libraries for distributing training workloads across multiple GPUs and machines</td>
<td>DeepSpeed, horovod, Ray, accelerate</td>
</tr>
<tr class="odd">
<td>5. Low-level Frameworks</td>
<td>Core libraries for building and training large language models</td>
<td>PyTorch, TensorFlow, JAX</td>
</tr>
<tr class="even">
<td>6. High-level Frameworks</td>
<td>Libraries that build on top of low-level frameworks to simplify common uses</td>
<td>Hugging Face Transformers, PyTorch Lightning, Axolotl</td>
</tr>
<tr class="odd">
<td>7. Inference Engine</td>
<td>Software for efficient LLM execution and serving</td>
<td>vLLM, llama.cpp, TorchServe, ONNX</td>
</tr>
<tr class="even">
<td>8. LLM Orchestration</td>
<td>Tools for prompting and chaining LLM calls, constraining and censoring output. These are also compatible with managed ML services and inference APIs</td>
<td>LangChain, llamaindex, litellm, instructor, outlines, guardrails</td>
</tr>
</tbody>
</table>
<p>To illustrate, let‚Äôs compare the type of code you‚Äôd write at the low and high levels of abstraction.</p>
<p>Creating a simple neural network in PyTorch:</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch.nn <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> nn</span>
<span id="cb1-3"></span>
<span id="cb1-4"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> MyModel(nn.Module):</span>
<span id="cb1-5">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>):</span>
<span id="cb1-6">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">super</span>().<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>()</span>
<span id="cb1-7">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.l1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.Linear(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">768</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">512</span>)</span>
<span id="cb1-8">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.l2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.Linear(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">512</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">256</span>)</span>
<span id="cb1-9">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.l3 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.Linear(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">256</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb1-10"></span>
<span id="cb1-11">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> forward(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, x):</span>
<span id="cb1-12">        x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.relu(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.l1(x))</span>
<span id="cb1-13">        x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.relu(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.l2(x))</span>
<span id="cb1-14">        x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.l3(x)</span>
<span id="cb1-15">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> x</span></code></pre></div>
<p>Loading a pre-trained transformer model from Hugging Face:</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> transformers <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> BertTokenizer, BertForSequenceClassification</span>
<span id="cb2-2"></span>
<span id="cb2-3">tokenizer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> BertTokenizer.from_pretrained(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'bert-base-uncased'</span>)</span>
<span id="cb2-4">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> BertForSequenceClassification.from_pretrained(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'bert-base-uncased'</span>)</span></code></pre></div>
<p>PyTorch confronts you with the details of layers, their sizes, activation functions and more. Hugging Face abstracts them away.</p>
<section id="more-alternatives-at-higher-levels" class="level3">
<h3 class="anchored" data-anchor-id="more-alternatives-at-higher-levels">More alternatives at higher levels</h3>
<p>There tend to be more alternatives the higher you go in the stack. Recently, I‚Äôve <a href="../../blog/structured_output/">compared</a> 10 different libraries for structured LLM outputs, all at the highest level of abstraction. In contrast, there is no widely used alternative to Nvidia GPUs and CUDA for the hardware and acceleration levels.</p>
</section>
<section id="too-much-abstraction" class="level3">
<h3 class="anchored" data-anchor-id="too-much-abstraction">Too much abstraction?</h3>
<p>There is such a thing as too many layers of abstractions. Hamel Husain put it well in his article: <a href="https://hamel.dev/blog/posts/prompt/">‚ÄúFuck You, Show Me The Prompt‚Äù</a>. Make sure you know which tokens are actually being sent to the LLM, and whether there‚Äôs more than one round-trip involved in getting a response. For education, too many layers can also hinder understanding. Andrej Karpathy is known for re-implementing the GPT architecture for education, for example <a href="https://github.com/karpathy/nanoGPT">nanoGPT</a>, which is GPT2 in ~600 lines of Python.</p>
</section>
<section id="fine-tune-dont-train-from-scratch" class="level3">
<h3 class="anchored" data-anchor-id="fine-tune-dont-train-from-scratch">Fine-tune, don‚Äôt train from scratch</h3>
<p>Training LLMs from scratch is almost never worth it for organizations whose main business isn‚Äôt providing foundation models for others. It requires far too much training data and GPU hours. As an example, even the smallest of Meta‚Äôs Llama 3.1 models was trained for 1.46M GPU hours (<a href="https://huggingface.co/blog/llama31#:~:text=The%20Llama%203.1%20models%20were%20trained%20on%20over,for%208B%2C%207.0M%20for%2070B%2C%2030.84M%20for%20405B%29.">source</a>). In contrast, fine-tuning a LoRA adapter for that model can be done in less than 1 GPU hour on an H100.</p>
<p>When working with lower-level libraries like PyTorch, it‚Äôs therefore necessary to start by copying the architecture of an existing LLM and loading its weights. Tweaks like a new output layer must be done carefully in order to preserve the usefulness of the learned weights. This is in contrast to less compute-intensive machine learning models, where training one‚Äôs own model from scratch is common. For these reasons, starting from a high-level framework like Hugging Face Transformers is more common for working with LLMs.</p>
</section>
</section>
<section id="managed-ml-services" class="level2">
<h2 class="anchored" data-anchor-id="managed-ml-services">2. Managed ML services</h2>
<p>AWS SageMaker, Google Cloud AI Platform, and Azure Machine Learning are examples of managed LLM services. They wrap the DIY stack in their cloud infrastructure, providing a unified interface for training, serving and monitoring models. Essentially, these services bundle the DIY stack into a single product, freeing you from having to manage the details. You still have a selection of open source models to fine-tuned with your own data.</p>
<p>This approach caters to enterprises with large-scale ML needs and tight security requirements. They‚Äôre typically already using the cloud provider for other services and want to keep everything in one place.</p>
</section>
<section id="inference-apis" class="level2">
<h2 class="anchored" data-anchor-id="inference-apis">3. Inference APIs</h2>
<p>Pre-trained LLMs are offered via API by OpenAI, Anthropic and many others including cloud providers with services like AWS Bedrock. These APIs are the highest level of abstraction, letting you directly connect your app to a powerful LLM without any setup or training. The downside is that you have the least control over the model and your data.</p>
<p>Some inference API providers, like Fireworks.ai also offer fine-tuning, getting close to the level of control you‚Äôd have with a managed service.</p>
</section>
<section id="choosing-the-right-level-of-abstraction" class="level2">
<h2 class="anchored" data-anchor-id="choosing-the-right-level-of-abstraction">Choosing the right level of abstraction</h2>
<p>Which level of abstraction do you want to work at?</p>
<section id="high-level-of-abstraction" class="level3">
<h3 class="anchored" data-anchor-id="high-level-of-abstraction">High level of abstraction</h3>
<p>Choose a higher level of abstraction if you:</p>
<ul>
<li>Are a beginner seeking quick first successes</li>
<li>Work at a startup focused on product-market fit</li>
<li>Are a researcher in a different field wishing to use LLMs</li>
<li>Want to integrate LLMs without deep ML expertise</li>
<li>Are already committed to a specific cloud ecosystem</li>
<li>Have no need for deep customization of models (you‚Äôd know if you did)</li>
</ul>
<p>The danger of choosing a too high level of abstraction is that you may hit a wall when you need to do something the tool doesn‚Äôt support. For example, OpenAI‚Äôs API doesn‚Äôt support reinforcement learning from human feedback (RLHF), only supervised fine-tuning. If you need RLHF, you‚Äôd have to switch to a lower level of abstraction.</p>
</section>
<section id="low-level-of-abstraction" class="level3">
<h3 class="anchored" data-anchor-id="low-level-of-abstraction">Low level of abstraction</h3>
<p>Opt for a lower level of abstraction if you:</p>
<ul>
<li>Are a researcher or engineer pushing LLM boundaries</li>
<li>Require fine-grained control over the model</li>
<li>Need on-premises or on-device deployment</li>
<li>Desire a deep understanding of the underlying technology</li>
<li>Prioritize code and model portability</li>
<li>Have engineers familiar with distributed systems and GPU programming</li>
</ul>
<p>The danger of choosing a too low level of abstraction is that you may spend too much time on infrastructure and not enough on the actual problem you‚Äôre trying to solve. For example, if you‚Äôre building a prototype for a meeting summarization chatbot, your time is better spent talking to project managers than optimizing your distributed training setup.</p>
</section>
<section id="cost-can-go-both-ways" class="level3">
<h3 class="anchored" data-anchor-id="cost-can-go-both-ways">Cost can go both ways</h3>
<p>High level tools can add a tax, but prices have been decreasing quickly. Managed services and API providers can leverage economies of scale and have highly optimized infrastructure. This can be difficult to achieve with a DIY stack. For example, a privately owned GPU deployed for inference may be underutilized outside of business hours, while a GPU at a cloud provider services other customers.</p>
</section>
<section id="keep-your-training-data-portable" class="level3">
<h3 class="anchored" data-anchor-id="keep-your-training-data-portable">Keep your training data portable</h3>
<p>The linear progression from low to high abstraction is a simplification. As the ecosystem matures, interoperability increases. For example, Hugging Face Transformers abstracts away the model architecture, but you can still access the PyTorch model and adjust it. Then that model can be deployed to AWS SageMaker. Not all combinations are possible though - for example a GPT model fine-tuned on OpenAI‚Äôs API can only run on that account. When it‚Äôs cheap to do so, use solutions that have as little lock-in as possible. Especially your training data should remain portable. In a time where research labs one-up each other weekly with better base models, being able to switch to a new model quickly is an advantage.</p>


</section>
</section>

 ]]></description>
  <category>Machine Learning</category>
  <guid>https://simmering.dev/blog/abstractions/</guid>
  <pubDate>Wed, 07 Aug 2024 22:00:00 GMT</pubDate>
  <media:content url="https://simmering.dev/blog/abstractions/image.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Less stress, more focus: How to handle waiting times in development</title>
  <dc:creator>Paul Simmering</dc:creator>
  <link>https://simmering.dev/blog/waiting/</link>
  <description><![CDATA[ 





<p>It‚Äôs unfortunate, but there are many waiting times in data science. Dealing with them well can make work more productive and enjoyable. Common waiting times include:</p>
<ul>
<li>model is training</li>
<li>data pipeline is running</li>
<li>report is rendering</li>
<li>Docker image is building</li>
<li>tests are running</li>
<li>someone else is reviewing your code</li>
<li>huge upload/download</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/waiting/compiling.png" class="img-fluid figure-img"></p>
<figcaption>Waiting isn‚Äôt new in software development. <a href="https://xkcd.com/303/">XKCD 303</a></figcaption>
</figure>
</div>
<p>These waits range from seconds to days.</p>
<p>Ideally, there would not be any waiting times. Many can be eliminated or reduced Here are the top strategies, ranked by effectiveness in my experience:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 29%">
<col style="width: 44%">
<col style="width: 26%">
</colgroup>
<thead>
<tr class="header">
<th>Strategy</th>
<th>Effectiveness</th>
<th>Downsides</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Caching results</td>
<td>Very high, cuts wait times to zero</td>
<td>Stale data</td>
</tr>
<tr class="even">
<td>Indexing databases</td>
<td>High, can massively speed up queries</td>
<td>Not always possible, slows down writes</td>
</tr>
<tr class="odd">
<td>Mocking dependencies</td>
<td>High, can speed up tests</td>
<td>Adds complexity</td>
</tr>
<tr class="even">
<td>Running with smaller inputs</td>
<td>High, can speed up debugging</td>
<td>Not the real result</td>
</tr>
<tr class="odd">
<td>Writing more efficient code</td>
<td>Medium, can speed up code</td>
<td>It‚Äôs hard</td>
</tr>
<tr class="even">
<td>Parallelizing code</td>
<td>Medium, can speed up code</td>
<td>Hard and adds complexity</td>
</tr>
<tr class="odd">
<td>Using faster hardware</td>
<td>Medium, can speed up code</td>
<td>Expensive, not always effective</td>
</tr>
</tbody>
</table>
<p>It‚Äôs very easy to lose 50% or more of one‚Äôs productivity to waiting times. The most common form is an inefficient debug cycle: change code, wait for build, run code, wait for results, repeat. Bonus points if the code is a CI/CD pipeline.</p>
<p>Eliminating a waiting time in a workflow is a huge win, especially when multiple people are using the same workflow.</p>
<p>However, many waiting times are unavoidable, especially when working with large language models. Given that these wait times occur regularly, it makes sense to put together a little plan for what to do with them.</p>
<p>I suggest spending the time in a way that guards focus and short-term memory of the work at hand. Else, you‚Äôre effectively doing this:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/waiting/focus.jpeg" class="img-fluid figure-img"></p>
<figcaption>Programmer focus (from Monkeyuser.com)</figcaption>
</figure>
</div>
<p>Except the interruptions are self-inflicted.</p>
<p>The longer the wait is, the more it‚Äôs worth to switch context. Here‚Äôs a rough, opinionated guide based on my experience and research by <a href="http://www.chrisparnin.me/pdf/parnin-sqj11.pdf">Parnin and Rugaber (2010)</a>. The authors measure <em>edit lag</em>, the time between a developer returning to a task and making the first edit. In a study of 10,000 Java developers, they measured these edit lags:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/waiting/edit_lag.png" class="img-fluid figure-img"></p>
<figcaption>Edit lag, Parning and Rugaber (2010)</figcaption>
</figure>
</div>
<p>For difficult tasks, the edit lag after an interruption can easily exceed the length of the interruption itself. Let‚Äôs get to the tactics to handle waiting times.</p>
<section id="seconds-to-minutes" class="level2">
<h2 class="anchored" data-anchor-id="seconds-to-minutes">Seconds to minutes</h2>
<p>These wait times can turn into interruptions, but they don‚Äôt have to. It‚Äôs tempting to fill smaller breaks with social media or news. However, this floods the short-term memory with new information, replacing the context of the work you were doing. Plus, scrolling is addictive and tends to exceed the actual wait time.</p>
<p>If possible, resist the urge to switch context. It‚Äôs ok to just wait for a moment. Look out the window, stretch, take a sip of water, breathe. If you must do something, I suggest doing a physical task like tidying up your desk or making a cup of tea, rather than a computer task.</p>
</section>
<section id="minutes-to-an-hour" class="level2">
<h2 class="anchored" data-anchor-id="minutes-to-an-hour">Minutes to an hour</h2>
<p>This is too long to just do nothing. Before switching context, try to leave an intentional cue for yourself to pick up where you left off, such as a TODO comment that lets you pick up the thread. Keep the IDE open with the file you were working on.</p>
<p>Ideally, pick a little task that is still relevant to your main task. Read through the code, write a comment, plan your next steps, write another test or refactor a small piece of code. Alternatively take a little break or knock out some easy tasks, such as answering emails.</p>
<p>Starting a new big task is not worth it, as it would take a ramp-up time to get back into the context of that task first. This is one of the main points behind Paul Graham‚Äôs <a href="http://www.paulgraham.com/makersschedule.html">Maker‚Äôs Schedule, Manager‚Äôs Schedule</a>.</p>
</section>
<section id="hours-to-days" class="level2">
<h2 class="anchored" data-anchor-id="hours-to-days">Hours to days</h2>
<p>Outside of training large models or running simulations, waiting times this long shouldn‚Äôt occur for technical reasons. If they do, it‚Äôs a sign that a process is not well-optimized. Fix the process, don‚Äôt suffer this wait time too often.</p>
<p>For processes involving humans this sort of wait time is normal though. There the best strategy is to have a plan for what to do during the wait time. When allocating tasks in a team I suggest that every developer has one or more backup tasks that can be worked on when waiting on something on the main task.</p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>Waiting times are a fact of life in data science. They can be reduced, but not eliminated. It‚Äôs worth having a plan for how to spend the time to avoid losing focus and short-term memory. This can make work not just more productive but also more enjoyable, as the stress of re-finding context is reduced.</p>


</section>

 ]]></description>
  <category>Productivity</category>
  <guid>https://simmering.dev/blog/waiting/</guid>
  <pubDate>Sat, 27 Jul 2024 22:00:00 GMT</pubDate>
  <media:content url="https://simmering.dev/blog/waiting/clocks.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Text Tournament: Rank Marketing Copy with LLMs</title>
  <dc:creator>Paul Simmering</dc:creator>
  <link>https://simmering.dev/blog/text-tournament/</link>
  <description><![CDATA[ 





<p>The launch of the <a href="../../projects/aspectwise/index.html">review analysis project</a> has me working on various marketing tasks. Naturally, I built a tool to let LLMs help with the creative process. It‚Äôs called Text Tournament and the purpose is to compare ideas for company names, taglines, product descriptions and ad copy in a tournament-style competition. The project is available on <a href="https://github.com/psimm/text-tournament">GitHub</a> under the MIT license.</p>
<p>This is the companion blog post to the project which explains my thought process and technical details.</p>
<section id="the-tournament" class="level2">
<h2 class="anchored" data-anchor-id="the-tournament">The Tournament</h2>
<p>The user gives a set of competitors and a set of attributes. Each competitor is paired with every other competitor on each aspect. For example, if there are three name choices for a Spotify competitor, say ‚ÄòStreamio‚Äô, ‚ÄòMelodiX‚Äô and ‚ÄòSoundWave‚Äô and two attributes ‚Äòmemorability‚Äô and ‚Äòpronounceability‚Äô, the tournament would look like this:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Competitor 1</th>
<th>Competitor 2</th>
<th>Attribute</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Streamio</td>
<td>MelodiX</td>
<td>memorability</td>
</tr>
<tr class="even">
<td>Streamio</td>
<td>SoundWave</td>
<td>memorability</td>
</tr>
<tr class="odd">
<td>MelodiX</td>
<td>SoundWave</td>
<td>memorability</td>
</tr>
<tr class="even">
<td>Streamio</td>
<td>MelodiX</td>
<td>pronounceability</td>
</tr>
<tr class="odd">
<td>Streamio</td>
<td>SoundWave</td>
<td>pronounceability</td>
</tr>
<tr class="even">
<td>MelodiX</td>
<td>SoundWave</td>
<td>pronounceability</td>
</tr>
</tbody>
</table>
<p>Each of these pairings is turned into a prompt for the LLM, like ‚ÄúCompare the company names Streamio and MelodiX. Which one is more memorable?‚Äù</p>
<p>Each pairing is run twice, once as A vs.&nbsp;B and once as B vs.&nbsp;A. The reason is that LLMs tend to have a bias towards picking the first option <span class="citation" data-cites="dominguezolmedo2024questioningsurveyresponseslarge">(Dominguez-Olmedo, Hardt, and Mendler-D√ºnner 2024)</span>.</p>
</section>
<section id="structured-output-reasoning" class="level2">
<h2 class="anchored" data-anchor-id="structured-output-reasoning">Structured output &amp; reasoning</h2>
<p>To make sure that the LLM‚Äôs answer is interpretable, I used <a href="https://github.com/jxnl/instructor">instructor</a>. Further, I asked the model to not just pick the winner but also to provide a reason. This is done with a simple Pydantic model:</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> Rating(BaseModel):</span>
<span id="cb1-2">    reason: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span></span>
<span id="cb1-3">    preferred: Literal[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>]</span></code></pre></div>
<p>By asking for the reason first, the tokens generated as the reason are influencing the token chosen for the ‚Äúpreferred‚Äù field. This makes use of the auto-regressive nature of the model.</p>
<p>The benefit of the reason is that it typically improves the model‚Äôs thinking and it also provides an inspectable record. For example, here are two outputs from the tournament above:</p>
<p>Streamio vs MelodiX on pronounceability:</p>
<blockquote class="blockquote">
<p>Streamio is straightforward to pronounce with a clear phonetic structure, while MelodiX may cause hesitation due to the unusual capital ‚ÄòX‚Äô at the end.</p>
</blockquote>
<p>MelodiX vs SoundWave on memorability:</p>
<blockquote class="blockquote">
<p>The name ‚ÄòMelodiX‚Äô is unique and contains a playful twist with the ‚ÄòX‚Äô at the end, making it more distinctive and easier to remember. The name ‚ÄòSoundWave‚Äô is more generic and can be easily confused with other similar terms in the tech and music industry.</p>
</blockquote>
</section>
<section id="ranking-competitors-with-the-bradley-terry-model" class="level2">
<h2 class="anchored" data-anchor-id="ranking-competitors-with-the-bradley-terry-model">Ranking competitors with the Bradley-Terry model</h2>
<p>The simplest approach is to count the number of wins for each competitor. However, this doesn‚Äôt take into account the strength of the competitors. A competitor that has only faced weak competitors might have a high win count but not be the best choice. I considered two ranking methods that account for this: the Elo <span class="citation" data-cites="elo1978rating">(Elo and Sloan 1978)</span> model and the Bradley-Terry <span class="citation" data-cites="bradley1952rank">(Bradley and Terry 1952)</span> model.</p>
<p>Elo is better known due to the popularity of ranking method in Chess. Many people are familiar with the concept of a player‚Äôs Elo rating and how it changes after a match.</p>
<p>The downside of Elo in this context is that ordering of the matches matters. Thce results of the LLM calls are coming in all at once. I‚Äôd have to artificially order the matches to use Elo. This is not ideal.</p>
<p>The Bradley-Terry model is a better fit for this situation. It‚Äôs a probabilistic model that estimates the strength of competitors based on the outcomes of matches.</p>
<p>The probability of competitor <img src="https://latex.codecogs.com/png.latex?i"> beating competitor <img src="https://latex.codecogs.com/png.latex?j"> is given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(i%20%5Ctext%7B%20beats%20%7D%20j)%20=%20%5Cfrac%7Br_i%7D%7Br_i%20+%20r_j%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?r_i"> is the strength of competitor <img src="https://latex.codecogs.com/png.latex?i">. The model is fit by modifying the strengths <code>r</code> to maximize the likelihood of the observed outcomes.</p>
<p>The Bradley-Terry model is also the basis for Direct Preference Optimization <span class="citation" data-cites="rafailov2024direct">(Rafailov et al. 2024)</span>. So I‚Äôm asking an LLM that was likely trained with DPO to do be a ranking model itself. So meta. This also means that the outputs of the ranking could be used as inputs to the DPO model. For example, a larger model could be used to teach a smaller model how to rank the competitors.</p>
</section>
<section id="results" class="level2">
<h2 class="anchored" data-anchor-id="results">Results</h2>
<p>I ran a tournament with more name options and additional attributes to compare them on. Here is the overall result:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/text-tournament/ranking.png" class="img-fluid figure-img"></p>
<figcaption>Tournament results</figcaption>
</figure>
</div>
<p>Does it match your preferences?</p>
<p>The full results with rankings on each attribute are available on this <a href="">Github page</a>.</p>
</section>
<section id="validity" class="level2">
<h2 class="anchored" data-anchor-id="validity">Validity</h2>
<p>The rankings produced by the tournament are not a replacement for tests with real users and human judgment. LLMs are known to be politically biased, may give random answers, and are heavily influenced by how a question is posed. The rankings are a tool to help with the creative process, not a definitive answer. If you decide to use it, I suggest starting with a low-stakes use case like the title of a blog post.</p>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0">
<div id="ref-bradley1952rank" class="csl-entry">
Bradley, Ralph Allan, and Milton E Terry. 1952. <span>‚ÄúRank Analysis of Incomplete Block Designs: I. The Method of Paired Comparisons.‚Äù</span> <em>Biometrika</em> 39 (3/4): 324‚Äì45.
</div>
<div id="ref-dominguezolmedo2024questioningsurveyresponseslarge" class="csl-entry">
Dominguez-Olmedo, Ricardo, Moritz Hardt, and Celestine Mendler-D√ºnner. 2024. <span>‚ÄúQuestioning the Survey Responses of Large Language Models.‚Äù</span> <a href="https://arxiv.org/abs/2306.07951">https://arxiv.org/abs/2306.07951</a>.
</div>
<div id="ref-elo1978rating" class="csl-entry">
Elo, Arpad E, and Sam Sloan. 1978. <span>‚ÄúThe Rating of Chessplayers: Past and Present.‚Äù</span>
</div>
<div id="ref-rafailov2024direct" class="csl-entry">
Rafailov, Rafael, Archit Sharma, Eric Mitchell, Christopher D Manning, Stefano Ermon, and Chelsea Finn. 2024. <span>‚ÄúDirect Preference Optimization: Your Language Model Is Secretly a Reward Model.‚Äù</span> <em>Advances in Neural Information Processing Systems</em> 36.
</div>
</div></section></div> ]]></description>
  <category>Machine Learning</category>
  <category>Python</category>
  <category>Marketing</category>
  <guid>https://simmering.dev/blog/text-tournament/</guid>
  <pubDate>Mon, 22 Jul 2024 22:00:00 GMT</pubDate>
  <media:content url="https://simmering.dev/blog/text-tournament/tournament.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Let Research Settle Before Consuming It</title>
  <dc:creator>Paul Simmering</dc:creator>
  <link>https://simmering.dev/blog/settled-knowledge/</link>
  <description><![CDATA[ 





<p>The pace of publishing in machine learning is extremely high. There were 242,290 AI publications in 2022. That‚Äôs 663 per day, or one every two minutes. Based on comments on X, Reddit and Discord, I can see that many people feel FOMO, overwhelmed or inadequate because they can‚Äôt keep up, even in subfields they‚Äôre supposed to be experts in.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/settled-knowledge/publications.png" class="img-fluid figure-img"></p>
<figcaption>Number of AI publications by year, Source: <a href="https://aiindex.stanford.edu/report/">Stanford University AI Index 2024</a></figcaption>
</figure>
</div>
<p>For those who can afford it, the antidote is to deliberately let research settle before consuming it. This means holding off on reading papers and waiting for the ideas to be integrated into textbooks, video courses and libraries, or at least wait to see which papers are getting cited more than others. This has advantages:</p>
<ul>
<li><strong>Higher quality learning materials</strong>: The initial paper is rarely the best explanation or fullest version of an idea. It necessarily doesn‚Äôt have as many real world examples as later explanations. It comes from the single perspective of an author with the intent to communicate to peers that are equally deep in the field. Later explanations are written by people with a teaching background and have been refined by feedback and real world experiences. They also have more accessible formats. Most people find it easier to learn from a video course or a textbook than from a collection of papers.</li>
<li><strong>Higher quality software implementations</strong>: Software behind research papers is often brittle and not suitable for production. Waiting for a library to implement the idea means you get a more robust and better documented implementation. It‚Äôs also more likely to be compatible with other tools you‚Äôre using and easier to install.</li>
<li><strong>Less likely to be wrong or irrelevant</strong>: The initial paper may have a mistake or a result that‚Äôs not replicable with other datasets. It may be a theoretical dead end or be quickly surpassed by other research. Waiting a while lets the community sort out what actually works.</li>
</ul>
<p>Time for learning is precious. Spending it on debugging software or deciphering a paper that is later proven wrong is a waste. By delaying consumption of research your learning is more efficient so you can learn more and more long-term valuable skills in the same time.</p>
<p>Of course, waiting is a luxury that those in research can‚Äôt afford because they‚Äôd be scooped and forever behind the curve. Let‚Äôs rank roles in the ecosystem by how close they have to be to the cutting edge:</p>
<ol type="1">
<li>Research scientist in university or industry lab</li>
<li>Research engineer developing platforms for researchers</li>
<li>Novel software developer creating cutting-edge products</li>
<li>Consultant advising on business integration</li>
<li>General developer at a company that uses ML but not at the cutting edge</li>
<li>Developer in slow-moving industry exploring ML adoption</li>
</ol>
<p>The lower you are on the list, the longer you can afford to wait before consuming research. The dropoff is steep. A researcher needs to be up to date with the latest papers within weeks, while a developer in a slow-moving industry can wait multiple years before an idea could become relevant in their work.</p>
<p>Staying at the bleeding edge carries a cost in learning efficiency and stress. If your role permits it, consider letting research settle more before consuming it.</p>



 ]]></description>
  <category>Advice</category>
  <category>Machine Learning</category>
  <guid>https://simmering.dev/blog/settled-knowledge/</guid>
  <pubDate>Fri, 19 Jul 2024 22:00:00 GMT</pubDate>
  <media:content url="https://simmering.dev/blog/settled-knowledge/spiral.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>The World is Large and Very Detailed</title>
  <dc:creator>Paul Simmering</dc:creator>
  <link>https://simmering.dev/blog/detailed-world/</link>
  <description><![CDATA[ 





<p><img src="https://simmering.dev/blog/detailed-world/world.jpg" class="img-fluid"></p>
<p>It‚Äôs easy to underestimate how vast and heterogeneous the world is. For entrepreneurs and developers this has two implications:</p>
<ol type="1">
<li>There are many niches to exploit.</li>
<li>It‚Äôs hard to scale.</li>
</ol>
<section id="detail-creates-opportunities" class="level2">
<h2 class="anchored" data-anchor-id="detail-creates-opportunities">Detail creates opportunities</h2>
<p>Some examples of detail: geography, languages, currencies, time zones, cultural norms, consumer preferences, age groups, currencies, laws, corporate structures, payment systems and so on. The detail is layered, like geographical features: countries contain states, which contain cities, which contain neighborhoods. Each combination of details creates a different environment for businesses to carve out their niche.</p>
<p>This puts a natural dampener on monopolies. The existence of an incumbent doesn‚Äôt mean that there is no room for a new player. This is most obvious in local businesses: just because there is a hairdresser in town doesn‚Äôt mean that there isn‚Äôt room for another in a different neighborhood. In digital businesses, this is less obvious but still true. Some examples:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>General incumbent</th>
<th>Competitor</th>
<th>Niche</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Zoom</td>
<td>Tuple</td>
<td>Remote pair programming</td>
</tr>
<tr class="even">
<td>Google</td>
<td>DuckDuckGo</td>
<td>Privacy-first search</td>
</tr>
<tr class="odd">
<td>AWS</td>
<td>Modal</td>
<td>Dev-friendly serverless platform</td>
</tr>
<tr class="even">
<td>Word</td>
<td>iA Writer</td>
<td>Distraction-free writing</td>
</tr>
<tr class="odd">
<td>Excel</td>
<td>AirTable</td>
<td>Linked records</td>
</tr>
<tr class="even">
<td>PowerPoint</td>
<td>Pitch</td>
<td>Pitch decks</td>
</tr>
<tr class="odd">
<td>VSCode</td>
<td>Cursor</td>
<td>AI-powered code completion</td>
</tr>
<tr class="even">
<td>Indeed</td>
<td>RemoteOK</td>
<td>Remote job board</td>
</tr>
<tr class="odd">
<td>Yelp</td>
<td>HappyCow</td>
<td>Vegan restaurant search</td>
</tr>
<tr class="even">
<td>Audible</td>
<td>Blinkist</td>
<td>Audio book summaries</td>
</tr>
</tbody>
</table>
<p>In each of these cases the job can be done using the general incumbent, but the competitors offer better experiences within their niches.</p>
<p>Even seemingly standardized technologies like SQL (officially <a href="https://blog.ansi.org/sql-standard-iso-iec-9075-2023-ansi-x3-135/">standardized</a> in 1986) have a huge number of <a href="https://db-engines.com/en/ranking">implementations</a>. Why? Because no single database covers every use case.</p>
<p>The level of detail of the world also provides a natural moat for employees against automation and offshoring.</p>
<ul>
<li>Self-driving cars have been in works for decades, but there are still millions of truck drivers. Why? Trucking is a detailed task that involves driving in all sorts of conditions, loading and unloading cargo and dealing with customers.</li>
<li>Remote work has been a thing for more than 10 years, but software companies still have expensive offices in the Bay Area populated by highly paid developers. Why? Because they have inertia, culture, social networks and talent density that only exist in that particular place.</li>
<li>Figma released its new <a href="https://www.figma.com/ai/">AI</a>. Does this mean that designers will be out of a job? No, because the AI doesn‚Äôt have the context and communication skills that a designer has.</li>
</ul>
</section>
<section id="detail-is-the-enemy-of-scaling" class="level2">
<h2 class="anchored" data-anchor-id="detail-is-the-enemy-of-scaling">Detail is the enemy of scaling</h2>
<p>In the same way that detail creates niches, it also inhibits scaling because each new detail requires a new solution. If the world is infinitely detailed, a given solution only applies to an infinitesimally small part of the world.</p>
<p>But the practical level of detail is not infinite: the further you zoom out the more systems and standards become visible. The laws of physics are the same everywhere. A microprocessor works the same way in Paris as in Tokyo. More than 5.4 billion people have a <a href="https://www.weforum.org/agenda/2023/04/charted-there-are-more-phones-than-people-in-the-world/">mobile phone</a>.</p>
<p>This unlocks huge economies of scale: technology that is applicable in many conditions can be invented once, mass-manufactured or copy-pasted millions of times, and used by millions of people. That is why technology companies are the <a href="https://companiesmarketcap.com">most valuable companies</a> in the world.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/detailed-world/marketcap.png" class="img-fluid figure-img"></p>
<figcaption>Largest companies by market cap. From companiesmarketcap.com, July 13 2024</figcaption>
</figure>
</div>
<p>Standardization can turn to natural monopolies when network effects come into play. The more people use a communication platform or a marketplace, the more valuable it becomes. This is why Facebook, Google and Amazon are so dominant. Standardization can also create monopolies to due scale, hence the dominance of TSMC in the semiconductor space.</p>
<p>But it‚Äôs also easy to overestimate how much can be standardized. Recently, a friend of mine who works in finance cautioned me about specializing in machine learning. He argued that the field is essentially solved because an LLM can answer any question. The economy needs one research company to develop the model and everyone else just uses their API. Applied LLM developers <a href="https://applied-llms.org/#enough-0-to-1-demos-its-time-for-1-to-n-products">disagree</a>. Building an LLM demo is easy, but real products must meet a much higher bar.</p>
<div class="grid">
<div class="g-col-6">
<p>It‚Äôs at this stage that the details of the world painfully intrude. Real world data is often incomplete, noisy, biased, inaccessible or in the wrong format. Predictions may be inaccurate or lack context of the business. The standard chat interface is not suitable for most actual use cases. This is why there is an army of data scientists and <a href="https://www.nytimes.com/2024/06/26/technology/ai-consultants.html">consultants</a> working as ‚Äútechnology sherpas‚Äù on the last-mile problems of LLMs. Realizing the economic benefits of LLMs may well require more consultants and software developers than actual ML researchers.</p>
</div>
<div class="g-col-6">
<p><img src="https://simmering.dev/blog/detailed-world/llm_needs.png" class="img-fluid"></p>
</div>
</div>
<p>But my friend isn‚Äôt all wrong. Hundreds of startups are building on top of OpenAI‚Äôs models. Smartly, OpenAI is leaving the last-mile problems to others and focusing on the core, scalable, and in a way less detailed, technology.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/detailed-world/openai.png" class="img-fluid figure-img" style="width:75.0%"></p>
<figcaption>OpenAI as a platform for companies serving niches</figcaption>
</figure>
</div>
<p>This positioning as the default source of intelligence is lucrative, but requires enormous upfront investment and must be defended against competition. By now, 01 AI, Anthropic, Google, Nvidia and others have released models that have <a href="https://chat.lmsys.org/?leaderboard">surpassed</a> the original GPT-4 model. It models are only measured by their arena benchmark, it‚Äôs hard to differentiate. More detail-oriented niches offer more ways to differentiate and are generally less competitive.</p>
</section>
<section id="strategy" class="level2">
<h2 class="anchored" data-anchor-id="strategy">Strategy</h2>
<p>Scalability and detail can be seen in a matrix:</p>
<p><img src="https://simmering.dev/blog/detailed-world/matrix.png" class="img-fluid" style="width:75.0%"></p>
<ul>
<li><strong>New Platforms</strong>: A new technology or business model emerged and has catapulted a company to the top. Their offering is basic but scalable. Examples: OpenAI in 2023, Zoom in 2020, Google in 2000. Naming the year is required because this position is not stable, unless it‚Äôs a natural monopoly.</li>
<li><strong>Mature Platforms</strong>: Over time, the platform has added more features and detail to cater to more niches. Examples: AWS, Facebook, MS Office, Stripe. In software, this carries the risk of becoming bloated.</li>
<li><strong>Consulting &amp; bespoke software</strong>: Dealing with each client‚Äôs needs separately. Scale is achieved by hiring more people or working more hours. Examples: Accenture, Capgemini, Infosys, freelancers, local businesses.</li>
<li><strong>Failure</strong>: The company has an undifferentiated offering and hasn‚Äôt achieved scale. It‚Äôs unlikely to survive in the long term.</li>
</ul>
<p>There are plenty of niches to exploit and the existence of an incumbent can be taken as a signal that there is a market, rather than that the market is saturated. The hard part isn‚Äôt to find just any niche, but a niche large enough and amenable to scaling.</p>
<p>Questions for entrepreneurs and investors:</p>
<ul>
<li>Where do general incumbents fail to meet the needs of a niche?</li>
<li>What types of scale does the niche support?</li>
<li>Which details can I safely ignore or fix later?</li>
</ul>


</section>

 ]]></description>
  <category>Economics</category>
  <guid>https://simmering.dev/blog/detailed-world/</guid>
  <pubDate>Fri, 12 Jul 2024 22:00:00 GMT</pubDate>
  <media:content url="https://simmering.dev/blog/detailed-world/world.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Rich Personal Wiki in Quarto</title>
  <dc:creator>Paul Simmering</dc:creator>
  <link>https://simmering.dev/blog/quarto-wiki/</link>
  <description><![CDATA[ 





<p>Machine learning is a deep and constantly evolving field. In an applied project, the details of models are typically compressed into a few lines of a configuration file. Take this excerpt from a configuration file for an LLM training run using <a href="https://github.com/OpenAccess-AI-Collective/axolotl">Axolotl</a>:</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode yaml code-with-copy"><code class="sourceCode yaml"><span id="cb1-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">adapter</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> lora</span></span>
<span id="cb1-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">lora_r</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">32</span></span>
<span id="cb1-3"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">lora_alpha</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">16</span></span>
<span id="cb1-4"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">lora_dropout</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.05</span></span>
<span id="cb1-5"></span>
<span id="cb1-6"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">gradient_accumulation_steps</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span></span>
<span id="cb1-7"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">micro_batch_size</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span></span>
<span id="cb1-8"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">num_epochs</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span></span>
<span id="cb1-9"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">optimizer</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> adamw_bnb_8bit</span></span>
<span id="cb1-10"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">lr_scheduler</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> cosine</span></span>
<span id="cb1-11"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">learning_rate</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0002</span></span></code></pre></div>
<p>There are so many concepts packed into just 10 lines: low-rank adapters, backpropagation, batching, quantization, optimizers. Each of these decomposes into sub-concepts and sub-sub-concepts. The further you go down, the closer you get to pure mathematics. In this case, matrix factorization, calculus, binary arithmetic and trigonometry.</p>
<p>I‚Äôve understood each of these at some point in the last 10 years, but I‚Äôm not ‚Äúexam-ready‚Äù on all of them at all times. A year ago I started writing a set of notes that form a personal wiki for machine learning topics. In this article I‚Äôll share the software and workflow I use.</p>
<p>This project helped calm some of my anxiety about forgetting. I can‚Äôt remember everything, but I can remember where to find it. Re-learning from a note I‚Äôve written myself is much faster than learning from other sources.</p>
<section id="beware-of-pseudowork" class="level2">
<h2 class="anchored" data-anchor-id="beware-of-pseudowork">Beware of pseudowork</h2>
<p>Before I get into the details, I feel obliged to warn about <em>pseudowork</em>. Setting up note taking systems, reading books about learning, reading advice from successful academics, all of these feel productive but don‚Äôt accomplish the main goal: understanding and retaining the material. Endless tweaking of the system can be a form of procrastination.</p>
<p>In other words, don‚Äôt go too midwit:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/quarto-wiki/notes_midwit.png" class="img-fluid figure-img" style="width:75.0%"></p>
<figcaption>Notes Midwit Meme</figcaption>
</figure>
</div>
<p>With that warning out of the way, I‚Äôll try to convince you that using Quarto for studying <em>is</em> worthwhile, even though it‚Äôs a little more complex than Apple Notes.</p>
</section>
<section id="quarto-website-as-a-personal-wiki" class="level2">
<h2 class="anchored" data-anchor-id="quarto-website-as-a-personal-wiki">Quarto website as a personal wiki</h2>
<p>A personal wiki is a repository of documents that are linked to each other.</p>
<section id="section" class="level3">
<h3 class="anchored" data-anchor-id="section"></h3>
<p align="center">
<img src="https://simmering.dev/blog/quarto-wiki/quarto.png" class="img-fluid">
</p>
<p><a href="https://quarto.org">Quarto</a> is a scientific publishing system that is based on Markdown and supports code execution in Python, R and other languages. It can be used to create reports, books, slides and <a href="https://quarto.org/docs/websites/">websites</a> (including this one üòÑ). I use it to create a personal wiki for machine learning. It‚Äôs a collection of <code>.qmd</code> files that contain text, code snippets, formulas and interactive visualizations. The files are rendered to HTML and can be viewed in a browser. Notes (web pages) can be <a href="https://quarto.org/docs/websites/#linking">linked</a> to each other.</p>
</section>
<section id="file-structure" class="level3">
<h3 class="anchored" data-anchor-id="file-structure">File structure</h3>
<p>Each concept gets its own file. For example, to learn about quantization I‚Äôve created three files in the <code>notes</code> folder:</p>
<ol type="1">
<li><code>notes/binary_numbers.qmd</code></li>
<li><code>notes/quantization.qmd</code></li>
<li><code>notes/qlora.qmd</code></li>
</ol>
<p>In <code>binary_numbers.qmd</code>, I‚Äôve written about the binary number system starting with integers and then moving on to floating-point numbers. Hugging Face has an excellent guide on the <a href="https://huggingface.co/blog/hf-bitsandbytes-integration">topic</a> from which I‚Äôve copied visualizations.</p>
<p>In <code>quantization.qmd</code> I‚Äôve written about how reducing the number of bits used to represent weights reduces the memory footprint and computational cost of neural networks. It has a link to <code>binary_numbers.qmd</code> because binary numbers are used in quantization. The <code>qlora.qmd</code> connects it to LoRA adapters.</p>
<div class="grid">
<div class="g-col-6">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/quarto-wiki/files.png" class="img-fluid figure-img" style="width:60.0%"></p>
<figcaption>Note files</figcaption>
</figure>
</div>
</div>
<div class="g-col-6">
<p>When I come across a new concept or find myself unsure of an old one, I create a new file. Starting with a basic definition, I summarize the topic. The last time I had to manually calculate something using the chain rule was in 2017, so recently I refreshed the topic by writing a detailed <code>chain_rule.md</code> note.</p>
</div>
</div>
</section>
<section id="notes" class="level3">
<h3 class="anchored" data-anchor-id="notes">Notes</h3>
<p>Notes are a weave of Markdown, code snippets and images. If you‚Äôre familiar with Jupyter notebooks or R Markdown, you‚Äôll feel right at home. Quarto‚Äôs <a href="https://quarto.org/docs/get-started/hello/jupyter.html">tutorial</a> is a great place to start.</p>
<p>Here‚Äôs an example of a note about derivatives:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/quarto-wiki/derivatives.png" class="img-fluid figure-img"></p>
<figcaption>Example file derivatives.qmd</figcaption>
</figure>
</div>
<p>I end every note with a sources section, e.g.&nbsp;</p>
<pre><code>## Sources

- [Stackoverflow AI in your pocket](https://stackoverflow.blog/2023/08/23/fitting-ai-models-in-your-pocket-with-quantization/)
- [Transformers Quantization Documentation](https://huggingface.co/docs/transformers/quantization)
- [Quantization](https://huggingface.co/blog/merve/quantization)
- [4bit transformers](https://huggingface.co/blog/4bit-transformers-bitsandbytes)
- [A Gentle Introduction to 8-bit Matrix Multiplication for transformers at scale using Hugging Face Transformers, Accelerate and bitsandbytes](https://huggingface.co/blog/hf-bitsandbytes-integration)
- [LLM-Model-VRAM-Calculator](https://huggingface.co/spaces/NyxKrage/LLM-Model-VRAM-Calculator)</code></pre>
<p>in <code>quantization.qmd</code>. These can be links to blog posts, books, papers, documentation, YouTube videos or anything else that helped me understand the topic, like the <a href="https://huggingface.co/spaces/NyxKrage/LLM-Model-VRAM-Calculator">VRAM-calculator</a> in the last link.</p>
</section>
<section id="website" class="level3">
<h3 class="anchored" data-anchor-id="website">Website</h3>
<p>To turn this collection of files into a website, two additional files are needed:</p>
<p>index.qmd:</p>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode yaml code-with-copy"><code class="sourceCode yaml"><span id="cb3-1"><span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">---</span></span>
<span id="cb3-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">title</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Study Wiki"</span></span>
<span id="cb3-3"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">listing</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span></span>
<span id="cb3-4"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">  </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">contents</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> notes</span></span>
<span id="cb3-5"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">  </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sort</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"date desc"</span></span>
<span id="cb3-6"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">  </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">type</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> default</span></span>
<span id="cb3-7"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">  </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sort-ui</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">true</span></span>
<span id="cb3-8"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">  </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">filter-ui</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">true</span></span>
<span id="cb3-9"><span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">---</span></span></code></pre></div>
<p>and <code>_quarto.yml</code>:</p>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode yaml code-with-copy"><code class="sourceCode yaml"><span id="cb4-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">project</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span></span>
<span id="cb4-2"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">  </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">type</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> website</span></span>
<span id="cb4-3"></span>
<span id="cb4-4"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">website</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span></span>
<span id="cb4-5"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">  </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">title</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Study wiki"</span></span>
<span id="cb4-6"></span>
<span id="cb4-7"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">format</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span></span>
<span id="cb4-8"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">  </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">html</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span></span>
<span id="cb4-9"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">    </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">theme</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> darkly</span></span>
<span id="cb4-10"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">    </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">toc</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">true</span></span></code></pre></div>
<p>The overall structure looks like this:</p>
<pre><code>_quarto.yml
index.qmd
notes/
  binary_numbers.qmd
  quantization.qmd
  qlora.qmd</code></pre>
<p>To render the website, run <code>quarto render</code> in the terminal. The website is then available in <code>_site/index.html</code> and can be opened in a browser. Typically, I render individual notes using the <code>render</code> button rather than the whole website.</p>
<p>And this is what the website looks like:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/quarto-wiki/wiki.png" class="img-fluid figure-img"></p>
<figcaption>Personal wiki website, please excuse the mix of German and English</figcaption>
</figure>
</div>
<p>It has sorting and search functionality.</p>
<p>And this is what a note looks like:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/quarto-wiki/batching.png" class="img-fluid figure-img"></p>
<figcaption>Rendered note about batching</figcaption>
</figure>
</div>
<p>It has a table of contents and references to sources. Quarto can be <a href="https://quarto.org/docs/output-formats/html-themes.html">themed</a>, here with the darkly theme.</p>
</section>
<section id="ide-and-extensions" class="level3">
<h3 class="anchored" data-anchor-id="ide-and-extensions">IDE and extensions</h3>
<p>I use Quarto with <a href="https://code.visualstudio.com">VSCode</a> and the <a href="https://marketplace.visualstudio.com/items?itemName=quarto.quarto">Quarto extension</a>. I find <a href="https://plotly.com/python/">Plotly</a> to be the best for these notes because it‚Äôs interactive (tooltips, zoom, filter) without a need for customization.</p>
</section>
</section>
<section id="copilots-are-great-at-formulas-and-visualizations" class="level2">
<h2 class="anchored" data-anchor-id="copilots-are-great-at-formulas-and-visualizations">Copilots are great at formulas and visualizations</h2>
<p><a href="https://github.com/features/copilot">Github Copilot</a> and other code completers like <a href="https://www.tabnine.com">TabNine</a> and <a href="https://supermaven.com">Supermaven</a> can generate LaTeX formulas and interactive Plotly visualizations.</p>
<p>Using a copilot, you can fly through creating notes and illustrate them beautifully.</p>
<p>For example, if you‚Äôre writing a note about linear regression, you might ask Copilot for the formula:</p>
<blockquote class="blockquote">
<p>Formula for linear regression:</p>
</blockquote>
<p>and Copilot will generate:</p>
<pre><code>$$ y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \ldots + \beta_n x_n $$</code></pre>
<p>which renders as:</p>
<p><img src="https://latex.codecogs.com/png.latex?%20y%20=%20%5Cbeta_0%20+%20%5Cbeta_1%20x_1%20+%20%5Cbeta_2%20x_2%20+%20%5Cldots%20+%20%5Cbeta_n%20x_n%20"></p>
<p>or ask for a visualization:</p>
<blockquote class="blockquote">
<p>Visualization of linear regression using a sample dataset:</p>
</blockquote>
<p>and Copilot might generate:</p>
<div id="1d90c91c" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> plotly.express <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> px</span>
<span id="cb7-2"></span>
<span id="cb7-3">df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> px.data.tips()</span>
<span id="cb7-4">fig <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> px.scatter(df, x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"total_bill"</span>, y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"tip"</span>, trendline<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ols"</span>, height<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">250</span>, width<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">600</span>)</span>
<span id="cb7-5">fig.data[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].line.color <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"red"</span></span>
<span id="cb7-6"></span>
<span id="cb7-7">fig.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>                            <div id="2743f3fa-a0e7-4b9a-9006-5ce693514382" class="plotly-graph-div" style="height:250px; width:600px;"></div>            <script type="text/javascript">                require(["plotly"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById("2743f3fa-a0e7-4b9a-9006-5ce693514382")) {                    Plotly.newPlot(                        "2743f3fa-a0e7-4b9a-9006-5ce693514382",                        [{"hovertemplate":"total_bill=%{x}\u003cbr\u003etip=%{y}\u003cextra\u003e\u003c\u002fextra\u003e","legendgroup":"","marker":{"color":"#636efa","symbol":"circle"},"mode":"markers","name":"","orientation":"v","showlegend":false,"x":[16.99,10.34,21.01,23.68,24.59,25.29,8.77,26.88,15.04,14.78,10.27,35.26,15.42,18.43,14.83,21.58,10.33,16.29,16.97,20.65,17.92,20.29,15.77,39.42,19.82,17.81,13.37,12.69,21.7,19.65,9.55,18.35,15.06,20.69,17.78,24.06,16.31,16.93,18.69,31.27,16.04,17.46,13.94,9.68,30.4,18.29,22.23,32.4,28.55,18.04,12.54,10.29,34.81,9.94,25.56,19.49,38.01,26.41,11.24,48.27,20.29,13.81,11.02,18.29,17.59,20.08,16.45,3.07,20.23,15.01,12.02,17.07,26.86,25.28,14.73,10.51,17.92,27.2,22.76,17.29,19.44,16.66,10.07,32.68,15.98,34.83,13.03,18.28,24.71,21.16,28.97,22.49,5.75,16.32,22.75,40.17,27.28,12.03,21.01,12.46,11.35,15.38,44.3,22.42,20.92,15.36,20.49,25.21,18.24,14.31,14.0,7.25,38.07,23.95,25.71,17.31,29.93,10.65,12.43,24.08,11.69,13.42,14.26,15.95,12.48,29.8,8.52,14.52,11.38,22.82,19.08,20.27,11.17,12.26,18.26,8.51,10.33,14.15,16.0,13.16,17.47,34.3,41.19,27.05,16.43,8.35,18.64,11.87,9.78,7.51,14.07,13.13,17.26,24.55,19.77,29.85,48.17,25.0,13.39,16.49,21.5,12.66,16.21,13.81,17.51,24.52,20.76,31.71,10.59,10.63,50.81,15.81,7.25,31.85,16.82,32.9,17.89,14.48,9.6,34.63,34.65,23.33,45.35,23.17,40.55,20.69,20.9,30.46,18.15,23.1,15.69,19.81,28.44,15.48,16.58,7.56,10.34,43.11,13.0,13.51,18.71,12.74,13.0,16.4,20.53,16.47,26.59,38.73,24.27,12.76,30.06,25.89,48.33,13.27,28.17,12.9,28.15,11.59,7.74,30.14,12.16,13.42,8.58,15.98,13.42,16.27,10.09,20.45,13.28,22.12,24.01,15.69,11.61,10.77,15.53,10.07,12.6,32.83,35.83,29.03,27.18,22.67,17.82,18.78],"xaxis":"x","y":[1.01,1.66,3.5,3.31,3.61,4.71,2.0,3.12,1.96,3.23,1.71,5.0,1.57,3.0,3.02,3.92,1.67,3.71,3.5,3.35,4.08,2.75,2.23,7.58,3.18,2.34,2.0,2.0,4.3,3.0,1.45,2.5,3.0,2.45,3.27,3.6,2.0,3.07,2.31,5.0,2.24,2.54,3.06,1.32,5.6,3.0,5.0,6.0,2.05,3.0,2.5,2.6,5.2,1.56,4.34,3.51,3.0,1.5,1.76,6.73,3.21,2.0,1.98,3.76,2.64,3.15,2.47,1.0,2.01,2.09,1.97,3.0,3.14,5.0,2.2,1.25,3.08,4.0,3.0,2.71,3.0,3.4,1.83,5.0,2.03,5.17,2.0,4.0,5.85,3.0,3.0,3.5,1.0,4.3,3.25,4.73,4.0,1.5,3.0,1.5,2.5,3.0,2.5,3.48,4.08,1.64,4.06,4.29,3.76,4.0,3.0,1.0,4.0,2.55,4.0,3.5,5.07,1.5,1.8,2.92,2.31,1.68,2.5,2.0,2.52,4.2,1.48,2.0,2.0,2.18,1.5,2.83,1.5,2.0,3.25,1.25,2.0,2.0,2.0,2.75,3.5,6.7,5.0,5.0,2.3,1.5,1.36,1.63,1.73,2.0,2.5,2.0,2.74,2.0,2.0,5.14,5.0,3.75,2.61,2.0,3.5,2.5,2.0,2.0,3.0,3.48,2.24,4.5,1.61,2.0,10.0,3.16,5.15,3.18,4.0,3.11,2.0,2.0,4.0,3.55,3.68,5.65,3.5,6.5,3.0,5.0,3.5,2.0,3.5,4.0,1.5,4.19,2.56,2.02,4.0,1.44,2.0,5.0,2.0,2.0,4.0,2.01,2.0,2.5,4.0,3.23,3.41,3.0,2.03,2.23,2.0,5.16,9.0,2.5,6.5,1.1,3.0,1.5,1.44,3.09,2.2,3.48,1.92,3.0,1.58,2.5,2.0,3.0,2.72,2.88,2.0,3.0,3.39,1.47,3.0,1.25,1.0,1.17,4.67,5.92,2.0,2.0,1.75,3.0],"yaxis":"y","type":"scatter"},{"hovertemplate":"\u003cb\u003eOLS trendline\u003c\u002fb\u003e\u003cbr\u003etip = 0.105025 * total_bill + 0.92027\u003cbr\u003eR\u003csup\u003e2\u003c\u002fsup\u003e=0.456617\u003cbr\u003e\u003cbr\u003etotal_bill=%{x}\u003cbr\u003etip=%{y} \u003cb\u003e(trend)\u003c\u002fb\u003e\u003cextra\u003e\u003c\u002fextra\u003e","legendgroup":"","marker":{"color":"#636efa","symbol":"circle"},"mode":"lines","name":"","showlegend":false,"x":[3.07,5.75,7.25,7.25,7.51,7.56,7.74,8.35,8.51,8.52,8.58,8.77,9.55,9.6,9.68,9.78,9.94,10.07,10.07,10.09,10.27,10.29,10.33,10.33,10.34,10.34,10.51,10.59,10.63,10.65,10.77,11.02,11.17,11.24,11.35,11.38,11.59,11.61,11.69,11.87,12.02,12.03,12.16,12.26,12.43,12.46,12.48,12.54,12.6,12.66,12.69,12.74,12.76,12.9,13.0,13.0,13.03,13.13,13.16,13.27,13.28,13.37,13.39,13.42,13.42,13.42,13.51,13.81,13.81,13.94,14.0,14.07,14.15,14.26,14.31,14.48,14.52,14.73,14.78,14.83,15.01,15.04,15.06,15.36,15.38,15.42,15.48,15.53,15.69,15.69,15.77,15.81,15.95,15.98,15.98,16.0,16.04,16.21,16.27,16.29,16.31,16.32,16.4,16.43,16.45,16.47,16.49,16.58,16.66,16.82,16.93,16.97,16.99,17.07,17.26,17.29,17.31,17.46,17.47,17.51,17.59,17.78,17.81,17.82,17.89,17.92,17.92,18.04,18.15,18.24,18.26,18.28,18.29,18.29,18.35,18.43,18.64,18.69,18.71,18.78,19.08,19.44,19.49,19.65,19.77,19.81,19.82,20.08,20.23,20.27,20.29,20.29,20.45,20.49,20.53,20.65,20.69,20.69,20.76,20.9,20.92,21.01,21.01,21.16,21.5,21.58,21.7,22.12,22.23,22.42,22.49,22.67,22.75,22.76,22.82,23.1,23.17,23.33,23.68,23.95,24.01,24.06,24.08,24.27,24.52,24.55,24.59,24.71,25.0,25.21,25.28,25.29,25.56,25.71,25.89,26.41,26.59,26.86,26.88,27.05,27.18,27.2,27.28,28.15,28.17,28.44,28.55,28.97,29.03,29.8,29.85,29.93,30.06,30.14,30.4,30.46,31.27,31.71,31.85,32.4,32.68,32.83,32.9,34.3,34.63,34.65,34.81,34.83,35.26,35.83,38.01,38.07,38.73,39.42,40.17,40.55,41.19,43.11,44.3,45.35,48.17,48.27,48.33,50.81],"xaxis":"x","y":[1.2426948819246395,1.5241605885147065,1.6816973645912365,1.6816973645912365,1.7090037391111685,1.7142549649803862,1.7331593781095698,1.7972243337140252,1.814028256495522,1.8150785016693654,1.8213799727124267,1.8413346310154537,1.9232537545752495,1.9285049804444672,1.9369069418352154,1.9474093935736507,1.9642133163551472,1.9778665036151133,1.9778665036151133,1.9799669939628002,1.9988714070919837,2.000971897439671,2.005172878135045,2.005172878135045,2.0062231233088887,2.0062231233088887,2.024077291264229,2.032479252654977,2.036680233350351,2.038780723698038,2.0513836657841606,2.0776397951302488,2.093393472737902,2.1007451889548068,2.1122978858670853,2.1154486213886163,2.1375037700393302,2.1396042603870176,2.1480062217777656,2.1669106349069494,2.182664312514602,2.183714557688446,2.1973677449484117,2.207870196686847,2.225724364642187,2.2288751001637177,2.230975590511405,2.237277061554466,2.2435785325975273,2.2498800036405884,2.253030739162119,2.258281965031337,2.2603824553790237,2.2750858878128333,2.2855883395512686,2.2855883395512686,2.288739075072799,2.2992415268112345,2.302392262332765,2.313944959245044,2.3149952044188877,2.3244474109834794,2.3265479013311667,2.329698636852697,2.329698636852697,2.329698636852697,2.339150843417289,2.370658198632595,2.370658198632595,2.384311385892561,2.390612856935622,2.3979645731525268,2.406366534543275,2.4179192314555538,2.4231704573247717,2.4410246252801118,2.4452256059754855,2.4672807546262,2.472531980495418,2.4777832063646352,2.496687619493819,2.4998383550153496,2.501938845363037,2.5334462005783425,2.53554669092603,2.539747671621404,2.546049142664465,2.5513003685336826,2.568104291315179,2.568104291315179,2.5765062527059275,2.5807072334013017,2.5954106658351113,2.598561401356642,2.598561401356642,2.6006618917043287,2.604862872399703,2.622717040355043,2.629018511398104,2.631119001745791,2.6332194920934784,2.634269737267322,2.64267169865807,2.6458224341796006,2.647922924527288,2.650023414874975,2.6521239052226617,2.6615761117872534,2.6699780731780023,2.6867819959594987,2.6983346928717773,2.7025356735671515,2.7046361639148384,2.713038125305587,2.7329927836086143,2.7361435191301444,2.7382440094778318,2.753997687085485,2.755047932259328,2.7592489129547024,2.767650874345451,2.787605532648478,2.7907562681700084,2.791806513343852,2.799158229560757,2.8023089650822874,2.8023089650822874,2.8149119071684097,2.8264646040806887,2.8359168106452803,2.8380173009929677,2.8401177913406546,2.841168036514498,2.841168036514498,2.8474695075575593,2.8558714689483073,2.8779266175990217,2.8831778434682396,2.8852783338159265,2.8926300500328312,2.9241374052481373,2.961946231506505,2.967197457375722,2.9840013801572187,2.996604322243341,3.000805302938715,3.001855548112559,3.0291619226324906,3.044915600240144,3.0491165809355176,3.051217071283205,3.051217071283205,3.0680209940647014,3.072221974760075,3.07642295545545,3.089025897541572,3.0932268782369463,3.0932268782369463,3.100578594453851,3.11528202688766,3.1173825172353475,3.1268347237999397,3.1268347237999397,3.1425884014075924,3.1782967373182727,3.1866986987090207,3.199301640795143,3.2434119380965716,3.2549646350088506,3.2749192933118776,3.2822710095287824,3.301175422657966,3.309577384048714,3.310627629222558,3.316929100265619,3.346335965133238,3.353687681350143,3.370491604131639,3.4072501852161627,3.435606804909938,3.4419082759529998,3.447159501822217,3.449259992169904,3.4692146504729315,3.4954707798190197,3.49862151534055,3.5028224960359244,3.515425438122047,3.5458825481635095,3.567937696814224,3.5752894130311286,3.576339658204972,3.6046962778987472,3.6204499555064005,3.639354368635584,3.693967117675448,3.712871530804631,3.7412281504984066,3.7433286408460935,3.761182808801434,3.7748359960613995,3.776936486409087,3.7853384477998353,3.8767097779242223,3.8788102682719097,3.907166887965685,3.918719584877964,3.9628298821793924,3.9691313532224535,4.050000231608406,4.055251457477623,4.0636534188683715,4.077306606128338,4.085708567519086,4.113014942039017,4.119316413082079,4.204386272163405,4.250597059812521,4.265300492246331,4.323063976807724,4.352470841675343,4.368224519282996,4.375576235499901,4.522610559837996,4.557268650574833,4.559369140922519,4.576173063704016,4.578273554051703,4.623434096526975,4.683298071436057,4.912251519333947,4.918552990377008,4.987869171850681,5.060336088845886,5.1391044768841505,5.1790137934902045,5.24622948461619,5.4478765579941495,5.572855733681529,5.683131476935101,5.979300615958977,5.989803067697413,5.9961045387404734,6.256565341853671],"yaxis":"y","type":"scatter","line":{"color":"red"}}],                        {"template":{"data":{"histogram2dcontour":[{"type":"histogram2dcontour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"choropleth":[{"type":"choropleth","colorbar":{"outlinewidth":0,"ticks":""}}],"histogram2d":[{"type":"histogram2d","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmap":[{"type":"heatmap","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmapgl":[{"type":"heatmapgl","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"contourcarpet":[{"type":"contourcarpet","colorbar":{"outlinewidth":0,"ticks":""}}],"contour":[{"type":"contour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"surface":[{"type":"surface","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"mesh3d":[{"type":"mesh3d","colorbar":{"outlinewidth":0,"ticks":""}}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"parcoords":[{"type":"parcoords","line":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolargl":[{"type":"scatterpolargl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"scattergeo":[{"type":"scattergeo","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolar":[{"type":"scatterpolar","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"scattergl":[{"type":"scattergl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatter3d":[{"type":"scatter3d","line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermapbox":[{"type":"scattermapbox","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterternary":[{"type":"scatterternary","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattercarpet":[{"type":"scattercarpet","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"pie":[{"automargin":true,"type":"pie"}]},"layout":{"autotypenumbers":"strict","colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"hovermode":"closest","hoverlabel":{"align":"left"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"bgcolor":"#E5ECF6","angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"ternary":{"bgcolor":"#E5ECF6","aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]]},"xaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"yaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"geo":{"bgcolor":"white","landcolor":"#E5ECF6","subunitcolor":"white","showland":true,"showlakes":true,"lakecolor":"white"},"title":{"x":0.05},"mapbox":{"style":"light"},"margin":{"b":0,"l":0,"r":0,"t":30}}},"xaxis":{"anchor":"y","domain":[0.0,1.0],"title":{"text":"total_bill"}},"yaxis":{"anchor":"x","domain":[0.0,1.0],"title":{"text":"tip"}},"legend":{"tracegroupgap":0},"height":250,"width":600},                        {"responsive": true}                    ).then(function(){
                            
var gd = document.getElementById('2743f3fa-a0e7-4b9a-9006-5ce693514382');
var x = new MutationObserver(function (mutations, observer) {{
        var display = window.getComputedStyle(gd).display;
        if (!display || display === 'none') {{
            console.log([gd, 'removed!']);
            Plotly.purge(gd);
            observer.disconnect();
        }}
}});

// Listen for the removal of the full notebook cells
var notebookContainer = gd.closest('#notebook-container');
if (notebookContainer) {{
    x.observe(notebookContainer, {childList: true});
}}

// Listen for the clearing of the current output cell
var outputEl = gd.closest('.output');
if (outputEl) {{
    x.observe(outputEl, {childList: true});
}}

                        })                };                });            </script>        </div>
</div>
</div>
<p>Using a separate chat like ChatGPT also works, but requires more copy-pasting, which breaks the flow.</p>
</section>
<section id="discussion" class="level2">
<h2 class="anchored" data-anchor-id="discussion">Discussion</h2>
<div class="grid">
<section id="pros" class="level3 g-col-6">
<h3 class="anchored" data-anchor-id="pros">Pros</h3>
<ul>
<li>Enhance understanding with code snippets, formulas and interactive visualizations</li>
<li>Collect the best learning resources in one place</li>
<li>Free, open-source software running locally without needing an internet connection</li>
<li>Text files are future-proof and can be read by any text editor</li>
<li>Possible to version control with Git</li>
<li>Easy to back up</li>
<li>Gets better over time as more notes are added and interlinked</li>
<li>Visualizes learning progress in a satisfying way</li>
</ul>
</section>
<section id="cons" class="level3 g-col-6">
<h3 class="anchored" data-anchor-id="cons">Cons</h3>
<ul>
<li>It doesn‚Äôt work well on mobile. You could find a way to read the notes, but editing is not practical</li>
<li>Over-engineering notes with interactivity can turn into pseudowork</li>
<li>Creating many shallow notes using an LLM can also be pseudowork</li>
<li>Learning curve if you‚Äôre not familiar with Markdown and a programming language supported by Quarto</li>
</ul>
</section>
</div>
<p>If you‚Äôre in machine learning, data engineering, or a similar technical field I highly recommend <a href="https://quarto.org">Quarto</a> for creating a personal wiki. If you don‚Äôt need code, formulas or interactive visualizations, <a href="https://obsidian.md">Obsidian</a> is an easier alternative that is based on Markdown and local-first. Finally, Apple Notes and Microsoft OneNote are OK too, if you don‚Äôt mind being locked into their ecosystems.</p>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further reading</h2>
<ul>
<li><a href="https://x.com/karpathy/status/1756380066580455557">The shortification of learning</a> by Andrej Karpathy</li>
<li><a href="https://www.scotthyoung.com/blog/2019/02/15/memory/">The Complete Guide to Memory</a> by Scott Young and Jakub J√≠lek</li>
</ul>


</section>

 ]]></description>
  <category>Productivity</category>
  <category>Machine Learning</category>
  <guid>https://simmering.dev/blog/quarto-wiki/</guid>
  <pubDate>Sat, 06 Jul 2024 22:00:00 GMT</pubDate>
  <media:content url="https://simmering.dev/blog/quarto-wiki/library.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Fast and good</title>
  <dc:creator>Paul Simmering</dc:creator>
  <link>https://simmering.dev/blog/fast-and-good/</link>
  <description><![CDATA[ 





<p>The adage goes: fast, good, cheap. Pick two. As a developer, you probably don‚Äôt want to be cheap labor, so I suggest that you strive for fast and good. Not just good, and not just fast‚Äîboth.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/fast-and-good/good_fast_cheap.png" class="img-fluid figure-img" style="width:65.0%"></p>
<figcaption>Good, fast, cheap</figcaption>
</figure>
</div>
<p>A developer writing bad code quickly creates troublesome ‚Äúspaghetti code‚Äù that may function for a demo but becomes a nightmare to maintain as the project scales. LLMs have made this even easier.</p>
<p>Conversely, a developer who writes good code at a glacial pace may see the project run out of money, be overtaken by competitors or get stuck in a cycle of endless refactoring.</p>
<p>Both outcomes are to be avoided.</p>
<p>But can‚Äôt you just write the first version quickly, get feedback, and then rewrite it properly?</p>
<p>You may not get the luxury of a full rewrite. Rewrites are <a href="https://swizec.com/blog/you-can-t-stop-the-business-or-why-rewrites-fail/">risky</a> and often <a href="https://www.joelonsoftware.com/2000/04/06/things-you-should-never-do-part-i/">ill-advised</a>. It‚Äôs hard to find the time for a rewrite on a project that is accelerating. It‚Äôs not impossible to do a successful rewrite, but rare. Projects like <a href="https://tailwindcss.com/blog/tailwindcss-v4-alpha">Tailwind CSS</a> and <a href="https://docs.pydantic.dev/2.0/blog/pydantic-v2-alpha/">Pydantic</a> have done successful rewrites in Rust. This happened after they achieved amazing adoption and had plenty of resources. For most projects, a rewrite is not a viable option. That means you need to get it right the first time.</p>
<p>The dual optimum of fast and good is achievable with a balanced approach.</p>
<p>Before diving into strategies, I‚Äôd like to clarify that fast doesn‚Äôt just mean typing quickly. <a href="https://en.wiktionary.org/wiki/slow_is_smooth,_smooth_is_fast">‚ÄúSlow is smooth, smooth is fast‚Äù</a>. The fastest way to write a feature can involve spending 2 hours sketching out the design first.</p>
<p>Now, here are some strategies that helped me, and might help you, get closer to the dual optimum:</p>
<section id="strategies-for-the-dual-optimum" class="level2">
<h2 class="anchored" data-anchor-id="strategies-for-the-dual-optimum">Strategies for the dual optimum</h2>
<section id="prioritize-and-plan" class="level3">
<h3 class="anchored" data-anchor-id="prioritize-and-plan">Prioritize and plan</h3>
<ul>
<li><strong>Don‚Äôt build unnecessary features</strong>: much easier said than done, but this belongs at the top of every list of productivity tips.</li>
<li><strong>Involve users early</strong>: work in sprints, get feedback and iterate.</li>
<li><strong>Sketch it first</strong>: write the names of functions and classes before writing the code, then fill in the details.</li>
<li><strong>Don‚Äôt over-engineer for scale you don‚Äôt have</strong>: Most companies have gigabytes to terrabytes of data, <a href="https://motherduck.com/blog/big-data-is-dead/">not petabytes</a>, and an outage once in a few months is acceptable. Don‚Äôt build for the scale of Google if you‚Äôre not Google.</li>
<li><strong>Don‚Äôt reinvent the wheel</strong>: For everything but your core differentiating features, use libraries and services. It can be worth adjusting your design to fit existing software.</li>
</ul>
</section>
<section id="minimize-waiting" class="level3">
<h3 class="anchored" data-anchor-id="minimize-waiting">Minimize waiting</h3>
<ul>
<li><strong>Minimize waiting for code</strong>: use a fast computer, fast internet connection, and run your code and tests locally if possible</li>
<li><strong>Minimize waiting for people</strong>: establish time limits for code reviews, schedule tasks in a way that minimizes dependencies on others.</li>
</ul>
</section>
<section id="create-an-environment-that-supports-flow" class="level3">
<h3 class="anchored" data-anchor-id="create-an-environment-that-supports-flow">Create an environment that supports flow</h3>
<ul>
<li><strong>Minimize interruptions</strong>: both external and <a href="https://ics.uci.edu/~gmark/Home_page/Publications_files/CHI%202011%20Self-interruption.pdf">self-interruptions</a>.</li>
<li><strong>Embrace bursts of productivity</strong>: use your best hours for coding, take breaks when you‚Äôre not productive, get on a <a href="https://www.paulgraham.com/makersschedule.html">maker‚Äôs schedule</a>, if possible.</li>
<li><strong>Learn to type fast</strong>: Not because typing speed itself is important, but because it reduces the friction between your thoughts and the code editor and the mental cost of rewriting a section of code.</li>
<li><strong>Learn your tools</strong>: keyboard shortcuts, IDE extensions, terminal commands.</li>
<li><strong>Use a <a href="https://github.com/features/copilot">Copilot</a></strong>: not because it writes better code than you, but because it lets you get it onto the page faster. This is especially useful for boilerplate code and for writing tests and documentation.</li>
</ul>
</section>
<section id="keep-a-clean-codebase" class="level3">
<h3 class="anchored" data-anchor-id="keep-a-clean-codebase">Keep a clean codebase</h3>
<ul>
<li><strong>Be willing to throw away code</strong>: if you realize you‚Äôve gone down the wrong path during a coding session, don‚Äôt be afraid to delete parts of the code and start over.</li>
<li><strong>Hop from good state to good state</strong>: When working on a big feature, break it down into smaller tasks that leave the code in a runnable state at the end of each task. This also makes for clean commits and easier code reviews.</li>
<li><strong>Putter, within reason</strong>: Reading and re-reading code, refactoring and tweaking it is necessary to make it good. But don‚Äôt overdo it.</li>
</ul>
</section>
<section id="test-and-automate" class="level3">
<h3 class="anchored" data-anchor-id="test-and-automate">Test and automate</h3>
<ul>
<li><strong>Reduce worry about breaking things</strong>: use version control, write tests, use a test environment rather than working on production data.</li>
<li><strong>Automate everything</strong>: use a linter, formatter, test runner, CI/CD, deployment scripts and infrastructure as code.</li>
<li><strong>Write tests as you go</strong>: tests will give you the confidence to refactor and add features quickly. It‚Äôs easiest to write tests when you‚Äôre writing the code.</li>
</ul>
<p>May you code swiftly and wisely.</p>
<p>The term dual optimum and finding strategies to achieve it came from the book <a href="https://www.goodreads.com/book/show/17730608-winning-without-losing">Winning without Losing</a> by Martin Bjergegaard and Jordan Milne.</p>


</section>
</section>

 ]]></description>
  <category>Productivity</category>
  <category>Advice</category>
  <guid>https://simmering.dev/blog/fast-and-good/</guid>
  <pubDate>Fri, 21 Jun 2024 22:00:00 GMT</pubDate>
  <media:content url="https://simmering.dev/blog/fast-and-good/good_fast_cheap.png" medium="image" type="image/png" height="132" width="144"/>
</item>
<item>
  <title>The best library for structured LLM output</title>
  <dc:creator>Paul Simmering</dc:creator>
  <link>https://simmering.dev/blog/structured_output/</link>
  <description><![CDATA[ 





<p>By default, Large Language Models (LLMs) output free-form text. But many use cases such as text classification, named entity recognition, relation extraction and information extraction require structured output. There are several Python libraries that help with this. In this article, I compare ten libraries in terms of efficiency, flexibility and ease of use.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/structured_output/image_wide.png" class="img-fluid figure-img"></p>
<figcaption>Image created with Playground v2.5</figcaption>
</figure>
</div>
<section id="python-libraries-for-structured-llm-output" class="level2">
<h2 class="anchored" data-anchor-id="python-libraries-for-structured-llm-output">10 Python libraries for structured LLM output</h2>
<p>Here are the most prominent solutions, sorted by the number of Github stars ‚≠ê:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Library</th>
<th style="text-align: right;">Stars</th>
<th>Method¬π</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><a href="https://python.langchain.com/docs/modules/model_io/output_parsers/types/pydantic/">langchain</a></td>
<td style="text-align: right;">84,100</td>
<td>Prompting &amp; function calling</td>
<td>Pydantic output parser as part of langchain</td>
</tr>
<tr class="even">
<td><a href="https://docs.llamaindex.ai/en/stable/module_guides/querying/structured_outputs/pydantic_program/">llama_index</a></td>
<td style="text-align: right;">31,500</td>
<td>Prompting &amp; function calling</td>
<td>Pydantic program as part of llama_index</td>
</tr>
<tr class="odd">
<td><a href="https://github.com/guidance-ai/guidance">guidance</a></td>
<td style="text-align: right;">17,500</td>
<td>Constrained token sampling</td>
<td>Programming paradigm for constrained generation</td>
</tr>
<tr class="even">
<td><a href="https://github.com/outlines-dev/outlines">outlines</a></td>
<td style="text-align: right;">5,800</td>
<td>Constrained token sampling</td>
<td>Constrained token sampling using CFGs¬≤</td>
</tr>
<tr class="odd">
<td><a href="https://github.com/jxnl/instructor">instructor</a></td>
<td style="text-align: right;">5,200</td>
<td>Function calling</td>
<td>Specify Pydantic models to define structure of LLM outputs</td>
</tr>
<tr class="even">
<td><a href="https://github.com/prefecthq/marvin">marvin</a></td>
<td style="text-align: right;">4,800</td>
<td>Function calling</td>
<td>Toolbox of task-specific OpenAI API wrappers</td>
</tr>
<tr class="odd">
<td><a href="https://github.com/explosion/spacy-llm">spacy-llm</a></td>
<td style="text-align: right;">948</td>
<td>Prompting</td>
<td>spaCy plugin to add LLM responses to a pipeline</td>
</tr>
<tr class="even">
<td><a href="https://github.com/bananaml/fructose">fructose</a></td>
<td style="text-align: right;">687</td>
<td>Function calling</td>
<td>LLM calls as strongly-typed functions</td>
</tr>
<tr class="odd">
<td><a href="https://github.com/Mirascope/mirascope">mirascope</a></td>
<td style="text-align: right;">204</td>
<td>Function calling</td>
<td>Prompting, chaining and structured information extraction</td>
</tr>
<tr class="even">
<td><a href="https://github.com/qagentur/texttunnel">texttunnel</a></td>
<td style="text-align: right;">11</td>
<td>Function calling</td>
<td>Efficient async OpenAI API function calling</td>
</tr>
</tbody>
</table>
<p>¬πThe method describes how the library generates structured output. See the following sections for more details.</p>
<p>¬≤Context-free grammars: a recursive way to define the structure of a natural language, programming language or other sequence of tokens. See <a href="https://en.wikipedia.org/wiki/Context-free_grammar">Wikipedia</a>.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
May 2024
</div>
</div>
<div class="callout-body-container callout-body">
<p>This article was written in May 2024 with the latest versions of the libraries and the number of Github stars at that time. The libraries are under active development and the features may have changed since then.</p>
</div>
</div>
<p>All libraries are released under the MIT or Apache 2.0 license, which are both permissive open-source licenses. Their code is available on Github and they can be installed via pip.</p>
<p>I‚Äôll compare the libraries based on three criteria: efficiency, ease of use and flexibility. Efficiency is about how tokens are generated, ease of use is about how easy it is to get started with the library and flexibility is about how much you can customize the output format.</p>
<p>I‚Äôll use a named entity recognition task as an example because it‚Äôs a common task that requires structured output. The task is to extract named entities from the following text:</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1">text <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"""BioNTech SE is set to acquire InstaDeep, </span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb1-2"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">a Tunis-born and U.K.-based artificial intelligence </span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb1-3"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">(AI) startup, for up to ¬£562 million</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb1-4"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"""</span></span></code></pre></div>
<p>In the following sections, I‚Äôll write a code snippet for each library. If possible, I‚Äôll use Pydantic classes to define the schema for the structured output. Depending on the library‚Äôs support I‚Äôll use OpenAI‚Äôs GPT-4-turbo or Meta‚Äôs Llama-3-8B-Instruct (<a href="https://huggingface.co/QuantFactory/Meta-Llama-3-8B-Instruct-GGUF">8-bit quantized and in GGUF format</a>) running on Ollama. I‚Äôll set the temperature to 0.0 to reduce randomness in the output. This is also a little test of how easy it is to customize the parameters.</p>
<p>The libraries will be ordered by their method of generating structured output: prompting (llama_index, spacy-llm), function calling (instructor, marvin, mirascope, langchain, texttunnel), and constrained token sampling (outlines and guidance). llama_index also supports function calling and langchain also supports prompting.</p>
<p>At the start of each section I‚Äôll give an overview of the generation method.</p>
</section>
<section id="prompting-for-structured-output" class="level2">
<h2 class="anchored" data-anchor-id="prompting-for-structured-output">Prompting for structured output</h2>
<p>This is the simplest approach. A prompt describes a desired output format and hopefully the LLM follows it.</p>
<p>Example prompt:</p>
<blockquote class="blockquote">
<p>Your task is to extract named entities from a text. Add no commentary, only extract the entities and their labels. Entities must have one of the following labels: PERSON, ORGANIZATION, LOCATION. Example text: ‚ÄúApple is a company started by Steve Jobs, Steve Wozniak and Ronald Wayne in Los Altos.‚Äù Entities: Apple (ORGANIZATION), Steve Jobs (PERSON), Steve Wozniak (PERSON), Ronald Wayne (PERSON), Los Altos (LOCATION)</p>
</blockquote>
<blockquote class="blockquote">
<p>Text: ‚ÄúBioNTech SE is set to acquire InstaDeep, a Tunis-born and U.K.-based artificial intelligence (AI) startup, for up to ¬£562 million‚Äù</p>
</blockquote>
<p>And answer from an LLM:</p>
<blockquote class="blockquote">
<p>BioNTech SE (ORGANIZATION), InstaDeep (ORGANIZATION), Tunis (LOCATION), U.K. (LOCATION)‚Äù</p>
</blockquote>
<p>‚úÖ Pros:</p>
<ul>
<li>Works with any LLM</li>
<li>Easy to get started with</li>
</ul>
<p>‚ùå Cons:</p>
<ul>
<li>LLM may deviate from the format, especially if not fine-tuned on the task</li>
<li>Parsing can be tricky if the LLM outputs additional commentary</li>
<li>Explanation of the format adds an overhead to the prompt, increasing cost and latency</li>
</ul>
<section id="llama_index" class="level3">
<h3 class="anchored" data-anchor-id="llama_index">llama_index</h3>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> typing <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> List, Literal</span>
<span id="cb2-2"></span>
<span id="cb2-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pydantic <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> BaseModel</span>
<span id="cb2-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> llama_index.core.program <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> LLMTextCompletionProgram</span>
<span id="cb2-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> llama_index.llms.openai <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> OpenAI</span>
<span id="cb2-6"></span>
<span id="cb2-7"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> Entity(BaseModel):</span>
<span id="cb2-8">    name: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span></span>
<span id="cb2-9">    label: Literal[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"PERSON"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ORGANIZATION"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"LOCATION"</span>]</span>
<span id="cb2-10"></span>
<span id="cb2-11"></span>
<span id="cb2-12"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> ExtractEntities(BaseModel):</span>
<span id="cb2-13">    entities: List[Entity]</span>
<span id="cb2-14"></span>
<span id="cb2-15"></span>
<span id="cb2-16">prompt_template_str <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"""</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb2-17"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Extract named entities from the following text: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{text}</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb2-18"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb2-19"></span>
<span id="cb2-20">llm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> OpenAI(model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"gpt-4-turbo"</span>, temperature<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span>)</span>
<span id="cb2-21"></span>
<span id="cb2-22">program <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> LLMTextCompletionProgram.from_defaults(</span>
<span id="cb2-23">    output_cls<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>ExtractEntities,</span>
<span id="cb2-24">    prompt_template_str<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>prompt_template_str,</span>
<span id="cb2-25">    llm<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>llm,</span>
<span id="cb2-26">)</span>
<span id="cb2-27"></span>
<span id="cb2-28">output <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> program(text<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>text)</span>
<span id="cb2-29"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(output)</span></code></pre></div>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">entities<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[Entity(name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'BioNTech SE'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ORGANIZATION'</span>), Entity(name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'InstaDeep'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ORGANIZATION'</span>), Entity(name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Tunis'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'LOCATION'</span>), Entity(name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'U.K.'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'LOCATION'</span>)]</span></code></pre></div>
<p>Note that llama_index also has a function calling mode. I‚Äôm showing the prompting mode here.</p>
<p>‚úÖ Pros:</p>
<ul>
<li>Works with prompting and function calling</li>
<li>Supports many <a href="https://docs.llamaindex.ai/en/stable/module_guides/models/llms/">LLMs</a> for Pydantic programs</li>
</ul>
<p>‚ùå Cons:</p>
<ul>
<li>Large library with many features, which can be overwhelming</li>
</ul>
<p>llama_index also has a guidance-based constrained generation mode, but it isn‚Äôt compatible with the latest version of guidance.</p>
<p>A common complaint about comprehensive libraries is that they have too many dependencies. This doesn‚Äôt apply to llama_index because it can be installed modularly. For example, you can install only the OpenAI module with <code>pip install llama-index-llms-openai</code>.</p>
</section>
<section id="spacy-llm" class="level3">
<h3 class="anchored" data-anchor-id="spacy-llm">spacy-llm</h3>
<p>spacy-llm uses the prompting approach in a sophisticated way. Prompts are built using a jinja-template based system to describe the task, give examples and implement chain-of-thought reasoning. See their <a href="https://github.com/explosion/spacy-llm/tree/main/spacy_llm/tasks/templates">templates</a> directory for examples.</p>
<p>To solve our named entity recognition task, we create a <code>config.cfg</code> file:</p>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode cfg code-with-copy"><code class="sourceCode ini"><span id="cb4-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">[nlp]</span></span>
<span id="cb4-2"><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">lang </span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;"> "en"</span></span>
<span id="cb4-3"><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">pipeline </span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;"> ["llm"]</span></span>
<span id="cb4-4"></span>
<span id="cb4-5"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">[components]</span></span>
<span id="cb4-6"></span>
<span id="cb4-7"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">[components.llm]</span></span>
<span id="cb4-8"><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">factory </span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;"> "llm"</span></span>
<span id="cb4-9"></span>
<span id="cb4-10"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">[components.llm.task]</span></span>
<span id="cb4-11"><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">@llm_tasks </span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;"> "spacy.NER.v3"</span></span>
<span id="cb4-12"><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">labels </span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;"> ["ORGANIZATION", "PERSON", "LOCATION"]</span></span>
<span id="cb4-13"></span>
<span id="cb4-14"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">[components.llm.model]</span></span>
<span id="cb4-15"><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">@llm_models </span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;"> "spacy.GPT-4.v3"</span></span>
<span id="cb4-16"><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">name </span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;"> "gpt-4"</span></span>
<span id="cb4-17"><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">config </span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;"> {"temperature": 0.0}</span></span></code></pre></div>
<p>Then run:</p>
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> spacy_llm.util <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> assemble</span>
<span id="cb5-2">nlp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> assemble(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"config.cfg"</span>)</span>
<span id="cb5-3">doc <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nlp(text)</span>
<span id="cb5-4"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>([(ent.text, ent.label_) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> ent <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> doc.ents])</span></code></pre></div>
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1">[(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'BioNTech SE'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ORGANIZATION'</span>), (<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'InstaDeep'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ORGANIZATION'</span>), (<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Tunis'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'LOCATION'</span>)]</span></code></pre></div>
<p>‚úÖ Pros:</p>
<ul>
<li>Seamless integration with spaCy and Prodigy (for labeling)</li>
<li>Compatible with many APIs and open source LLMs from Hugging Face</li>
<li>Recipes for many tasks available out of the box</li>
</ul>
<p>‚ùå Cons:</p>
<ul>
<li>Config system and jinja-based prompt templating has a learning curve, especially for those unfamiliar with spaCy</li>
<li>Prompt-based approach is inefficient with respect to token usage</li>
<li>Doesn‚Äôt support async/multi-threaded processing (see this <a href="https://github.com/explosion/spacy-llm/discussions/258">discussion</a>)</li>
</ul>
</section>
<section id="function-calling-for-structured-output" class="level3">
<h3 class="anchored" data-anchor-id="function-calling-for-structured-output">Function calling for structured output</h3>
<p>Some LLMs have a function calling mode, which allows passing a function signature to the model along with the prompt. The LLM generates the arguments for the function. The <a href="https://platform.openai.com/docs/guides/function-calling">OpenAI</a> docs explain this in detail.</p>
<p>Example <a href="https://json-schema.org">JSON schema</a> for the named entity recognition task:</p>
<div class="sourceCode" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode json code-with-copy"><code class="sourceCode json"><span id="cb7-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb7-2">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"name"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"extract_entities"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb7-3">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"parameters"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb7-4">        <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"type"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"object"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb7-5">        <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"properties"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb7-6">            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"entities"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb7-7">                <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"type"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"array"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb7-8">                <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"items"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb7-9">                    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"type"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"object"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb7-10">                    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"properties"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb7-11">                        <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"name"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"type"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"string"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">},</span></span>
<span id="cb7-12">                        <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"description"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Named entity extracted from the text"</span></span>
<span id="cb7-13">                        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"label"</span><span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">:</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb7-14">                            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"type"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"string"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb7-15">                            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"enum"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"PERSON"</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ORGANIZATION"</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"LOCATION"</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">]</span></span>
<span id="cb7-16">                        <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">},</span></span>
<span id="cb7-17">                    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">},</span></span>
<span id="cb7-18">                    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"required"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"name"</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"label"</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">]</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb7-19">                    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"additionalProperties"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">false</span></span>
<span id="cb7-20">                <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb7-21">            <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">},</span></span>
<span id="cb7-22">        <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">},</span></span>
<span id="cb7-23">        <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"required"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"answers"</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">]</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb7-24">        <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"additionalProperties"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">false</span></span>
<span id="cb7-25">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">},</span></span>
<span id="cb7-26"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span></code></pre></div>
<p>In OpenAI‚Äôs format, the API would respond with:</p>
<div class="sourceCode" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode json code-with-copy"><code class="sourceCode json"><span id="cb8-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb8-2">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"choices"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb8-3">        <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb8-4">            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"message"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb8-5">                <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"function_call"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb8-6">                    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"arguments"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb8-7">                        <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"entities"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb8-8">                            <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"name"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"BioNTech SE"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"label"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ORGANIZATION"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb8-9">                            <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"name"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"InstaDeep"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"label"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ORGANIZATION"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb8-10">                            <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"name"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Tunis"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"label"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"LOCATION"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb8-11">                            <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"name"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"U.K."</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"label"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"LOCATION"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb8-12">                        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">]</span></span>
<span id="cb8-13">                    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb8-14">                <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb8-15">            <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb8-16">        <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb8-17">    <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">]</span></span>
<span id="cb8-18"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span></code></pre></div>
<p>(Simplified for brevity)</p>
<p>‚úÖ Pros:</p>
<ul>
<li>Almost guaranteed valid output (LLMs are trained to generate valid function arguments)</li>
<li>Uses JSON as a standard interchange format</li>
<li>Easy to define constraints in JSON schema</li>
</ul>
<p>‚ùå Cons:</p>
<ul>
<li>Only a few LLMs support function calling</li>
<li>Adds overhead to the prompt</li>
</ul>
<p>instructor, mirascope, marvin, fructose, llama_index, langchain and texttunnel use this approach. As we‚Äôll see later, Pydantic is a popular wrapper for the JSON schema. It‚Äôs less verbose and also provides type checking.</p>
</section>
<section id="instructor" class="level3">
<h3 class="anchored" data-anchor-id="instructor">instructor</h3>
<p>instructor patches LLM clients to accept Pydantic models as input and output. Here‚Äôs an example with OpenAI:</p>
<div class="sourceCode" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> typing <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> List, Literal</span>
<span id="cb9-2"></span>
<span id="cb9-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> instructor</span>
<span id="cb9-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pydantic <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> BaseModel</span>
<span id="cb9-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> openai <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> OpenAI</span>
<span id="cb9-6"></span>
<span id="cb9-7"></span>
<span id="cb9-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define the schema for the function calling API</span></span>
<span id="cb9-9"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> Entity(BaseModel):</span>
<span id="cb9-10">    name: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span></span>
<span id="cb9-11">    label: Literal[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"PERSON"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ORGANIZATION"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"LOCATION"</span>]</span>
<span id="cb9-12"></span>
<span id="cb9-13"></span>
<span id="cb9-14"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> ExtractEntities(BaseModel):</span>
<span id="cb9-15">    entities: List[Entity]</span>
<span id="cb9-16"></span>
<span id="cb9-17"></span>
<span id="cb9-18"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Patch the OpenAI client</span></span>
<span id="cb9-19">client <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> instructor.from_openai(OpenAI())</span>
<span id="cb9-20"></span>
<span id="cb9-21"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Call the LLM</span></span>
<span id="cb9-22">entities <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> client.chat.completions.create(</span>
<span id="cb9-23">    model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"gpt-4-turbo"</span>,</span>
<span id="cb9-24">    temperature<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span>,</span>
<span id="cb9-25">    response_model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>ExtractEntities,</span>
<span id="cb9-26">    messages<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[{<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"role"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"user"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"content"</span>: text}],</span>
<span id="cb9-27">)</span>
<span id="cb9-28"></span>
<span id="cb9-29"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(entities)</span></code></pre></div>
<div class="sourceCode" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1">entities<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[Entity(name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'BioNTech SE'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ORGANIZATION'</span>), Entity(name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'InstaDeep'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ORGANIZATION'</span>), Entity(name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Tunis'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'LOCATION'</span>), Entity(name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'U.K.'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'LOCATION'</span>)]</span></code></pre></div>
<p>‚úÖ Pros:</p>
<ul>
<li>Easy to use due to its focused nature and plenty of examples</li>
<li>Patches OpenAI‚Äôs client instead of adding own abstractions, so it‚Äôs familiar to OpenAI users</li>
<li>Compatible with many APIs through direct support of OpenAI, Anthropic, Cohere, as well as LiteLLM which itself is compatible with <a href="https://docs.litellm.ai/docs/providers">more than 100 LLMs</a>, also support Ollama for local LLMs</li>
<li>Supports detailed Pydantic models with nested structures and validators, including re-tries with an adjusted prompt to show the LLM the formatting error of the previous response</li>
<li>Detailed docs with a cookbook</li>
</ul>
<p>‚ùå Cons:</p>
<ul>
<li>Does one job well, but doesn‚Äôt have many additional features</li>
<li>No complete solution for efficient batch processing, see <a href="docs">https://python.useinstructor.com/blog/2023/11/13/learn-async/?h=batch#practical-implications-of-batch-processing</a> (rate limiting not solved yet, though this is not found in many other libraries either)</li>
</ul>
</section>
<section id="mirascope" class="level3">
<h3 class="anchored" data-anchor-id="mirascope">mirascope</h3>
<div class="sourceCode" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> typing <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Literal, Type, List</span>
<span id="cb11-2"></span>
<span id="cb11-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> mirascope.openai <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> OpenAIExtractor</span>
<span id="cb11-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pydantic <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> BaseModel</span>
<span id="cb11-5"></span>
<span id="cb11-6"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> Entity(BaseModel):</span>
<span id="cb11-7">    name: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span></span>
<span id="cb11-8">    label: Literal[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"PERSON"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ORGANIZATION"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"LOCATION"</span>]</span>
<span id="cb11-9"></span>
<span id="cb11-10"></span>
<span id="cb11-11"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> Entities(BaseModel):</span>
<span id="cb11-12">    entities: List[Entity]</span>
<span id="cb11-13"></span>
<span id="cb11-14"></span>
<span id="cb11-15"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> EntityExtractor(OpenAIExtractor[Entities]):</span>
<span id="cb11-16">    extract_schema: Type[Entity] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Entities</span>
<span id="cb11-17">    prompt_template <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb11-18"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    Extract named entities from the following text:</span></span>
<span id="cb11-19"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{text}</span></span>
<span id="cb11-20"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb11-21"></span>
<span id="cb11-22">    text: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span></span>
<span id="cb11-23"></span>
<span id="cb11-24">entities <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> EntityExtractor(text<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>text).extract()</span>
<span id="cb11-25"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(entities)</span></code></pre></div>
<div class="sourceCode" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1">entities<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[Entity(name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'BioNTech SE'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ORGANIZATION'</span>), Entity(name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'InstaDeep'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ORGANIZATION'</span>), Entity(name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Tunis'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'LOCATION'</span>), Entity(name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'U.K.'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'LOCATION'</span>)]</span></code></pre></div>
<p>‚úÖ Pros:</p>
<ul>
<li>Uses function calling with Pydantic models</li>
<li>Compatible with many LLM <a href="https://github.com/Mirascope/mirascope/blob/dev/docs/concepts/supported_llm_providers.md">providers</a> including OpenAI, Anthropic, Cohere and Groq.</li>
<li>Built in code organization through their colocation principle: everything relevant to an LLM call is in one class</li>
</ul>
<p>‚ùå Cons:</p>
<ul>
<li>No support for ollama, litellm and Hugging Face yet</li>
<li>Not mature (cookbook missing, many features planned but not yet implemented, few contributors)</li>
</ul>
<p>mirascope is a new library with a lot of potential. For structured output, it has similar functionality to instructor, with a different approach: rather than patching the OpenAI client, it offers classes for each LLM provider. The roadmap has features for agents, RAG, metrics and a CLI. The question is whether there is room for another fully-featured library next to langchain and llama_index.</p>
</section>
<section id="marvin" class="level3">
<h3 class="anchored" data-anchor-id="marvin">marvin</h3>
<div class="sourceCode" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> typing <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Literal</span>
<span id="cb13-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pydantic <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> BaseModel</span>
<span id="cb13-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> marvin</span>
<span id="cb13-4"></span>
<span id="cb13-5">marvin.settings.openai.chat.completions.model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"gpt-4-turbo"</span></span>
<span id="cb13-6"></span>
<span id="cb13-7"></span>
<span id="cb13-8"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> Entity(BaseModel):</span>
<span id="cb13-9">    name: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span></span>
<span id="cb13-10">    label: Literal[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"PERSON"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ORGANIZATION"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"LOCATION"</span>]</span>
<span id="cb13-11"></span>
<span id="cb13-12"></span>
<span id="cb13-13">entities <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> marvin.extract(</span>
<span id="cb13-14">    text,</span>
<span id="cb13-15">    target<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>Entity,</span>
<span id="cb13-16">    model_kwargs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>{<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"temperature"</span>: <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span>},</span>
<span id="cb13-17">)</span>
<span id="cb13-18"></span>
<span id="cb13-19"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(entities)</span></code></pre></div>
<div class="sourceCode" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1">[Entity(name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'BioNTech SE'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ORGANIZATION'</span>), Entity(name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'InstaDeep'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ORGANIZATION'</span>), Entity(name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Tunis'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'LOCATION'</span>), Entity(name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'U.K.'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'LOCATION'</span>)]</span></code></pre></div>
<p>‚úÖ Pros:</p>
<ul>
<li>Easy to use due to its simple API and clear documentation</li>
<li>Many built-in tasks, including multi-modal ones like image classification and speech recognition</li>
</ul>
<p>‚ùå Cons:</p>
<ul>
<li>Only supports OpenAI models</li>
<li>Limited customization options and no access to underlying API response</li>
</ul>
<p>Marvin was the easiest to use in my test with instructor a close second. The developers describe marvin as a tool for developers who want to use rather than build AI. It‚Äôs a way to easily add many AI capabilities to your app. It‚Äôs not a tool for AI researchers.</p>
</section>
<section id="fructose" class="level3">
<h3 class="anchored" data-anchor-id="fructose">fructose</h3>
<div class="sourceCode" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> dataclasses <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> dataclass</span>
<span id="cb15-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> enum <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Enum</span>
<span id="cb15-3"></span>
<span id="cb15-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> fructose <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Fructose</span>
<span id="cb15-5"></span>
<span id="cb15-6">ai <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Fructose(model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"gpt-4-turbo"</span>)</span>
<span id="cb15-7"></span>
<span id="cb15-8"></span>
<span id="cb15-9"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> Label(Enum):</span>
<span id="cb15-10">    PERSON <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"PERSON"</span></span>
<span id="cb15-11">    ORGANIZATION <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ORGANIZATION"</span></span>
<span id="cb15-12">    LOCATION <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"LOCATION"</span></span>
<span id="cb15-13"></span>
<span id="cb15-14"></span>
<span id="cb15-15"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@dataclass</span></span>
<span id="cb15-16"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> Entity:</span>
<span id="cb15-17">    name: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span></span>
<span id="cb15-18">    label: Label</span>
<span id="cb15-19"></span>
<span id="cb15-20"></span>
<span id="cb15-21"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@ai</span></span>
<span id="cb15-22"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> extract_entities(text: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>[Entity]:</span>
<span id="cb15-23">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb15-24"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Given a text, extract the named entities with their labels.</span></span>
<span id="cb15-25"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb15-26">    ...</span>
<span id="cb15-27"></span>
<span id="cb15-28"></span>
<span id="cb15-29">entities <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> extract_entities(text)</span>
<span id="cb15-30"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(entities)</span></code></pre></div>
<div class="sourceCode" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1">[Entity(name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'BioNTech SE'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=&lt;</span>Label.ORGANIZATION: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ORGANIZATION'</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span>), Entity(name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'InstaDeep'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=&lt;</span>Label.ORGANIZATION: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ORGANIZATION'</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span>), Entity(name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Tunis'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=&lt;</span>Label.LOCATION: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'LOCATION'</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span>), Entity(name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'U.K.'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=&lt;</span>Label.LOCATION: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'LOCATION'</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span>)]</span></code></pre></div>
<p>‚úÖ Pros:</p>
<ul>
<li>Chainable functions with an elegant syntax</li>
<li>Built-in support for chain of thought prompting</li>
</ul>
<p>‚ùå Cons:</p>
<ul>
<li>Uses dataclasses instead of Pydantic models</li>
<li>Only OpenAI models are officially supported, though other models implementing OpenAI‚Äôs API format <a href="https://github.com/bananaml/fructose/issues/13">can work too</a></li>
<li>I didn‚Äôt find a way to set the temperature</li>
<li>No documentation website</li>
<li>Not actively developed</li>
</ul>
</section>
<section id="langchain" class="level3">
<h3 class="anchored" data-anchor-id="langchain">langchain</h3>
<div class="sourceCode" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> typing <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> List, Literal</span>
<span id="cb17-2"></span>
<span id="cb17-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langchain.output_parsers.openai_tools <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> PydanticToolsParser</span>
<span id="cb17-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langchain_core.prompts <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> PromptTemplate</span>
<span id="cb17-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langchain_core.pydantic_v1 <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> BaseModel, Field, validator</span>
<span id="cb17-6"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langchain_openai <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> ChatOpenAI</span>
<span id="cb17-7"></span>
<span id="cb17-8"></span>
<span id="cb17-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set up a Pydantic model for the structured output</span></span>
<span id="cb17-10"></span>
<span id="cb17-11"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> Entity(BaseModel):</span>
<span id="cb17-12">    name: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Field(description<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"name of the entity"</span>)</span>
<span id="cb17-13">    label: Literal[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"PERSON"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ORGANIZATION"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"LOCATION"</span>]</span>
<span id="cb17-14"></span>
<span id="cb17-15"></span>
<span id="cb17-16"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> ExtractEntities(BaseModel):</span>
<span id="cb17-17">    entities: List[Entity]</span>
<span id="cb17-18"></span>
<span id="cb17-19"></span>
<span id="cb17-20"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Choose a model</span></span>
<span id="cb17-21">llm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ChatOpenAI(model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"gpt-4-turbo"</span>, temperature<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span>)</span>
<span id="cb17-22"></span>
<span id="cb17-23"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Force the model to always use the ExtractEntities schema</span></span>
<span id="cb17-24">llm_with_tools <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> llm.bind_tools([ExtractEntities], tool_choice<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ExtractEntities"</span>)</span>
<span id="cb17-25"></span>
<span id="cb17-26"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Add a parser to convert the LLM output to a Pydantic object</span></span>
<span id="cb17-27">chain <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> llm_with_tools <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">|</span> PydanticToolsParser(tools<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[ExtractEntities])</span>
<span id="cb17-28"></span>
<span id="cb17-29">chain.invoke(text)[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span></code></pre></div>
<div class="sourceCode" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1">ExtractEntities(entities<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[Entity(name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'BioNTech SE'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ORGANIZATION'</span>), Entity(name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'InstaDeep'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ORGANIZATION'</span>), Entity(name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Tunis'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'LOCATION'</span>), Entity(name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'U.K.'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'LOCATION'</span>)])</span></code></pre></div>
<p>This is the function calling solution for langchain. It also supports <a href="https://python.langchain.com/v0.1/docs/modules/model_io/output_parsers/types/json/">prompting</a>.</p>
<p>‚úÖ Pros:</p>
<ul>
<li>Has both prompt-based and function calling solutions for structured output generation</li>
<li>Compatibly with many <a href="https://python.langchain.com/v0.1/docs/integrations/platforms/">APIs and LLMs</a></li>
</ul>
<p>‚ùå Cons:</p>
<p>Langchain is a huge library with many features, which can be overwhelming. There are multiple solutions to the same problem, which can be confusing for beginners. I‚Äôve often read the <a href="https://minimaxir.com/2023/07/langchain-problem/">argument</a> that langchain‚Äôs abstractions are adding complexity and figuring out the langchain way of doing things can be harder than working with the underlying libraries directly.</p>
<p>To be fair, in the test case above the solution was easy to find in the <a href="https://python.langchain.com/v0.1/docs/modules/model_io/chat/function_calling/">docs</a> and worked right away.</p>
<p>Like llama_index, langchain can be installed modularly.</p>
</section>
<section id="texttunnel" class="level3">
<h3 class="anchored" data-anchor-id="texttunnel">texttunnel</h3>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>I‚Äôm the developer of texttunnel, but I‚Äôll evaluate it as objectively as I can.</p>
</div>
</div>
<div class="sourceCode" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> texttunnel <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> chat, models, processor</span>
<span id="cb19-2"></span>
<span id="cb19-3">function <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb19-4">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"name"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"extract_entities"</span>,</span>
<span id="cb19-5">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"parameters"</span>: {</span>
<span id="cb19-6">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"type"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"object"</span>,</span>
<span id="cb19-7">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"properties"</span>: {</span>
<span id="cb19-8">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"entities"</span>: {</span>
<span id="cb19-9">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"type"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"array"</span>,</span>
<span id="cb19-10">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"items"</span>: {</span>
<span id="cb19-11">                    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"type"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"object"</span>,</span>
<span id="cb19-12">                    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"properties"</span>: {</span>
<span id="cb19-13">                        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"name"</span>: {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"type"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"string"</span>},</span>
<span id="cb19-14">                        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"label"</span>: {</span>
<span id="cb19-15">                            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"type"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"string"</span>,</span>
<span id="cb19-16">                            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"enum"</span>: [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"PERSON"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ORGANIZATION"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"LOCATION"</span>],</span>
<span id="cb19-17">                        },</span>
<span id="cb19-18">                    },</span>
<span id="cb19-19">                    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"required"</span>: [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"name"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"label"</span>],</span>
<span id="cb19-20">                    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"additionalProperties"</span>: <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>,</span>
<span id="cb19-21">                },</span>
<span id="cb19-22">            },</span>
<span id="cb19-23">        },</span>
<span id="cb19-24">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"required"</span>: [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"answers"</span>],</span>
<span id="cb19-25">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"additionalProperties"</span>: <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>,</span>
<span id="cb19-26">    },</span>
<span id="cb19-27">}</span>
<span id="cb19-28"></span>
<span id="cb19-29"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Build requests and process them</span></span>
<span id="cb19-30">requests <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> chat.build_requests(</span>
<span id="cb19-31">    texts<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[text],</span>
<span id="cb19-32">    function<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>function,</span>
<span id="cb19-33">    model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>models.GPT_4,</span>
<span id="cb19-34">    system_message<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"You are an NER model. Extract entities from the text."</span>,</span>
<span id="cb19-35">    params<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>models.Parameters(max_tokens<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">512</span>, temperature<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span>),</span>
<span id="cb19-36">)</span>
<span id="cb19-37"></span>
<span id="cb19-38">responses <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> processor.process_api_requests(requests)</span>
<span id="cb19-39"></span>
<span id="cb19-40">results <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [processor.parse_arguments(response<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>r) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> r <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> responses]</span>
<span id="cb19-41"></span>
<span id="cb19-42"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(results[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>])</span></code></pre></div>
<div class="sourceCode" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode json code-with-copy"><code class="sourceCode json"><span id="cb20-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span><span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">'entities'</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span><span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">'name'</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">'BioNTech</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">SE'</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">'label'</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">'ORGANIZATION'</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span><span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">'name'</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">'InstaDeep'</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">'label'</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">'ORGANIZATION'</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span><span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">'name'</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">'Tunis'</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">'label'</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">'LOCATION'</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span><span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">'name'</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">'U.K.'</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">'label'</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">'LOCATION'</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">]</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span></code></pre></div>
<p>texttunnel exposes the JSON schema directly, rather than wrapping it in a Pydantic model. It also returns the complete API response rather than only the extracted structured data. The unique selling point of texttunnel is its efficiency in calling the OpenAI API, as it uses asyncio to make multiple requests in parallel while respecting the individual rate limits of the user‚Äôs API key.</p>
<p>‚úÖ Pros:</p>
<ul>
<li>Exposes the JSON schema and API response directly</li>
<li>Efficient async function calling in a convenient wrapper</li>
</ul>
<p>‚ùå Cons:</p>
<ul>
<li>Only supports OpenAI models</li>
<li>Only supports function calling</li>
<li>JSON schema is verbose and less user-friendly than Pydantic models</li>
<li>Not actively developed</li>
</ul>
</section>
<section id="constrained-token-sampling-for-structured-output" class="level3">
<h3 class="anchored" data-anchor-id="constrained-token-sampling-for-structured-output">Constrained token sampling for structured output</h3>
<p>This approach hooks deeper into the LLM generation process. The user defines constraints as Pydantic models, regular expressions or other means that can be expressed as context-free grammars (<a href="https://en.wikipedia.org/wiki/Context-free_grammar">CFGs</a>). At inference time, the library‚Äôs token generator only considers tokens in the output layer that match the constraints.</p>
<p>This approach doesn‚Äôt add overhead to the prompt, guarantees valid output and is even more flexible than function calling. It‚Äôs also highly efficient because the generator can skip tokens that only have one possible value.</p>
<p>‚úÖ Pros:</p>
<ul>
<li>Guarantees valid output</li>
<li>Clear interchange format</li>
<li>Easy to define constraints</li>
<li>Efficient, skips unnecessary tokens</li>
</ul>
<p>‚ùå Cons:</p>
<ul>
<li>Requires endpoint integration, which API providers like OpenAI do not support</li>
</ul>
<p>outlines and guidance use this approach.</p>
</section>
<section id="outlines" class="level3">
<h3 class="anchored" data-anchor-id="outlines">outlines</h3>
<div class="sourceCode" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> typing <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> List, Literal</span>
<span id="cb21-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pydantic <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> BaseModel, Field</span>
<span id="cb21-3"></span>
<span id="cb21-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> outlines</span>
<span id="cb21-5"></span>
<span id="cb21-6">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> outlines.models.llamacpp(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"./models/Meta-Llama-3-8B-Instruct.Q8_0.gguf"</span>)</span>
<span id="cb21-7"></span>
<span id="cb21-8"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> Entity(BaseModel):</span>
<span id="cb21-9">    name: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Field(description<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"name of the entity"</span>)</span>
<span id="cb21-10">    label: Literal[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"PERSON"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ORGANIZATION"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"LOCATION"</span>]</span>
<span id="cb21-11"></span>
<span id="cb21-12"></span>
<span id="cb21-13"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> ExtractEntities(BaseModel):</span>
<span id="cb21-14">    entities: List[Entity]</span>
<span id="cb21-15"></span>
<span id="cb21-16"></span>
<span id="cb21-17">generator <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> outlines.generate.json(model, ExtractEntities)</span>
<span id="cb21-18"></span>
<span id="cb21-19">instruction <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Extract all named entities from the input using the labels: PERSON, ORGANIZATION, LOCATION. Input:"</span></span>
<span id="cb21-20">prompt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>instruction<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>text<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span></span>
<span id="cb21-21"></span>
<span id="cb21-22">entities <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> generator(prompt)</span>
<span id="cb21-23"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">repr</span>(entities))</span></code></pre></div>
<div class="sourceCode" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1">ExtractEntities(entities<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[Entity(name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'BioNTech SE'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ORGANIZATION'</span>), Entity(name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Instadeep'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ORGANIZATION'</span>), Entity(name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Tunis'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'LOCATION'</span>), Entity(name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'U.K.'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'LOCATION'</span>)])</span></code></pre></div>
<p>Under the hood outlines translates the Pydantic model to a CFG. It steps through the CFG token by token and generates the output.</p>
<p>‚úÖ Pros:</p>
<ul>
<li>Efficient token generation that adds no overhead and even speeds up inference (see <a href="http://blog.dottxt.co/coalescence.html">article</a>)</li>
<li>Translates Pydantic models, regular expressions, multiple choice questions and Jinja templates to CFGs</li>
<li>Compatible with transformers, llama.cpp and vLLM</li>
</ul>
<p>‚ùå Cons:</p>
<ul>
<li>Integration with OpenAI is limited, JSON schema is not supported</li>
<li>No support for Anthropic, Cohere or Groq</li>
<li>Cookbook is sparse relative to the wide set of supported workflows, though the available examples are well explained</li>
</ul>
</section>
<section id="guidance" class="level3">
<h3 class="anchored" data-anchor-id="guidance">guidance</h3>
<p>The guidance libary uses its own programming paradigm for constrained generation. Prompts are constructed from functions that define a CFG. Here is an example from the readme, with slight modifications:</p>
<div class="sourceCode" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> re</span>
<span id="cb23-2"></span>
<span id="cb23-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> guidance</span>
<span id="cb23-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> guidance <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> models, gen, select</span>
<span id="cb23-5"></span>
<span id="cb23-6">llm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> models.LlamaCpp(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"./models/Meta-Llama-3-8B-Instruct.Q8_0.gguf"</span>)</span>
<span id="cb23-7"></span>
<span id="cb23-8"></span>
<span id="cb23-9"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@guidance</span>(stateless<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb23-10"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> ner_instruction(lm, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">input</span>):</span>
<span id="cb23-11">    lm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"""</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb23-12"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">    Please tag each word in the input with PER, ORG, LOC, or nothing</span></span>
<span id="cb23-13"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">    ---</span></span>
<span id="cb23-14"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">    Input: John worked at Apple.</span></span>
<span id="cb23-15"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">    Output:</span></span>
<span id="cb23-16"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">    John: PER</span></span>
<span id="cb23-17"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">    worked: </span></span>
<span id="cb23-18"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">    at: </span></span>
<span id="cb23-19"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">    Apple: ORG</span></span>
<span id="cb23-20"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">    .: </span></span>
<span id="cb23-21"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">    ---</span></span>
<span id="cb23-22"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">    Input: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">input</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb23-23"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">    Output:</span></span>
<span id="cb23-24"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb23-25">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> lm</span>
<span id="cb23-26"></span>
<span id="cb23-27"></span>
<span id="cb23-28"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">input</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> text</span>
<span id="cb23-29"></span>
<span id="cb23-30"></span>
<span id="cb23-31"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@guidance</span>(stateless<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb23-32"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> constrained_ner(lm, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">input</span>):</span>
<span id="cb23-33">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Split into words</span></span>
<span id="cb23-34">    words <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [</span>
<span id="cb23-35">        x <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> x <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> re.split(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"([^a-zA-Z0-9])"</span>, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">input</span>) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> x <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">and</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> re.match(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"\s"</span>, x)</span>
<span id="cb23-36">    ]</span>
<span id="cb23-37">    ret <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span></span>
<span id="cb23-38">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> x <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> words:</span>
<span id="cb23-39">        ret <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">": "</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> select([<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"PER"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ORG"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"LOC"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span>]) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span></span>
<span id="cb23-40">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> lm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> ret</span>
<span id="cb23-41"></span>
<span id="cb23-42"></span>
<span id="cb23-43">llm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> ner_instruction(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">input</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> constrained_ner(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">input</span>)</span></code></pre></div>
<p>The <code>constrained_ner()</code> function looks like normal Python, but is actually a CFG that the LLM uses to generate the output. It tokenizes the text and assigns a label to each token that is either PERSON, ORGANIZATION, LOCATION or nothing.</p>
<p>The model returns:</p>
<pre><code>BioNTech: PER
SE: 
is: 
set: 
to: 
acquire: LOC
InstaDeep: ORG
,: 
a: 
Tunis: ORG
-: LOC
born: 
and: 
U: 
.: LOC
K: 
.: LOC
-: 
based: 
artificial: LOC
intelligence: 
(: LOC
AI: 
): LOC
startup: 
,: LOC
for: 
up: 
to: 
¬£: 
562: 
million: </code></pre>
<p>The simplified tokenization causes inaccurate labels, as terms like ‚ÄúU.K.‚Äù are split incorrectly. In addition, Llama-3 falsely labeled ‚Äúartificial‚Äù as a LOCATION.</p>
<p>To fix this, we could use a simplified approach that doesn‚Äôt require tokenization. The model could simply list the named entities, like in the other libraries.</p>
<div class="sourceCode" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> guidance</span>
<span id="cb25-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> guidance <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> models, gen, regex</span>
<span id="cb25-3"></span>
<span id="cb25-4">llm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> models.LlamaCpp(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"./models/Meta-Llama-3-8B-Instruct.Q8_0.gguf"</span>)</span>
<span id="cb25-5"></span>
<span id="cb25-6"></span>
<span id="cb25-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># stateless=True indicates this function does not depend on LLM generations</span></span>
<span id="cb25-8"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@guidance</span>(stateless<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb25-9"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> ner_instruction(lm, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">input</span>):</span>
<span id="cb25-10">    lm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"""</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb25-11"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">    Extract named entities from the input using the labels: PERSON, ORGANIZATION, LOCATION.</span></span>
<span id="cb25-12"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">    ---</span></span>
<span id="cb25-13"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">    Input: Jane and John live in San Francisco.</span></span>
<span id="cb25-14"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">    Output:</span></span>
<span id="cb25-15"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">    PERSON: Jane, John</span></span>
<span id="cb25-16"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">    ORGANIZATION:</span></span>
<span id="cb25-17"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">    LOCATION: San Francisco</span></span>
<span id="cb25-18"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">    ---</span></span>
<span id="cb25-19"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">    Input: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">input</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb25-20"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">    Output:</span></span>
<span id="cb25-21"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb25-22">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> lm</span>
<span id="cb25-23"></span>
<span id="cb25-24"></span>
<span id="cb25-25">pattern <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"PERSON:([\w, ]*)</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">ORGANIZATION:([\w, ]*)</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">LOCATION:([\w, ]*)"</span></span>
<span id="cb25-26"></span>
<span id="cb25-27">llm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> ner_instruction(text) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> regex(pattern) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> gen(stop<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"---"</span>)</span></code></pre></div>
<p>The regular expression guarantees that each line in the output begins with a label and a colon, in the order PERSON, ORGANIZATION, LOCATION, even if the input text doesn‚Äôt follow this order or doesn‚Äôt contain all three types of entities. <code>gen(stop="---")</code> stops the generation when the model outputs the <code>---</code> separator between the input and output.</p>
<p>The model returns:</p>
<pre><code>PERSON:relative
ORGANIZATION:UIButtonTypeCustom BioNTech SE, InstaDeep
LOCATION: Tunis, U.K.</code></pre>
<p>The output has the correct entities, but also contains garbage tokens like ‚Äúrelative‚Äù and ‚ÄúUIButtonTypeCustom‚Äù. Is this an issue with the model or the constraints? Let‚Äôs try pure generation without constraints:</p>
<div class="sourceCode" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1">llm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> ner_instruction(text) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> gen(stop<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"---"</span>)</span></code></pre></div>
<p>Output:</p>
<pre><code>PERSON:
ORGANIZATION: BioNTech SE, InstaDeep
LOCATION: Tunis, U.K.</code></pre>
<p>This works! I don‚Äôt know why the regular expression caused the model to output garbage tokens. I looked for a solution to specify the constraints using Pydantic. A Github <a href="https://github.com/guidance-ai/guidance/issues/462">issue</a> linked to a module in LlamaIndex called <a href="https://docs.llamaindex.ai/en/stable/examples/output_parsing/guidance_pydantic_program/">Guidance Pydantic Program</a> which has this feature, however, it doesn‚Äôt work with the latest version of guidance.</p>
<p>‚úÖ Pros:</p>
<ul>
<li>Efficient token generation through constrained generation</li>
<li>Flexible prompting system with CFGs which support complex constraints and recursive structures</li>
</ul>
<p>‚ùå Cons:</p>
<ul>
<li>NER didn‚Äôt work as expected with tokenization or regular expressions</li>
<li>No built-in support for Pydantic models</li>
<li>Writing CFGs via regular expressions has a steep learning curve</li>
<li>Most powerful features are not compatible with OpenAI</li>
</ul>
</section>
</section>
<section id="recommendations" class="level2">
<h2 class="anchored" data-anchor-id="recommendations">Recommendations</h2>
<p>In general, constrained generation is superior in terms of efficiency and guaranteed valid output. Function calling is the second best option and has higher compatibility with APIs. Prompting is the least efficient method but compatible with any LLM, local or via API.</p>
<p>The best library for your structured LLM task depends on your surrounding software stack. If you are already using‚Ä¶.</p>
<ul>
<li>transformers, llama.cpp or vLLM, meaning you control the token generation process, constrained generation with <a href="https://github.com/outlines-dev/outlines">outlines</a> is the most efficient way to generate structured output. outlines is easier to use than <a href="https://github.com/guidance-ai/guidance">guidance</a>, because it supports Pydantic models.</li>
<li>an API that supports function calling, such as OpenAI‚Äôs API, use one of the libraries that support function calling with Pydantic models. Their functionality is quite similar. <a href="https://github.com/prefecthq/marvin">marvin</a> has the simplest syntax and many built-in tasks, though limited customization and it only supports OpenAI. <a href="https://github.com/jxnl/instructor">instructor</a> is focused on structured output and stays as close to the OpenAI Python client as possible. <a href="https://github.com/Mirascope/mirascope">mirascope</a> has a wider scope, adding chaining and other prompt engineering techniques.</li>
<li><a href="https://python.langchain.com/docs/modules/model_io/output_parsers/types/pydantic/">langchain</a> or <a href="https://docs.llamaindex.ai/en/stable/module_guides/querying/structured_outputs/pydantic_program/">llama_index</a>, you can use their Pydantic output parsers for structured output from function calling or prompting too. Either is a decent choice if you prefer a comprehensive library over a specialized one. In my test, llama_index was easier to use.</li>
<li>spaCy, choose <a href="https://github.com/explosion/spacy-llm">spacy-llm</a> because it integrates seamlessly.</li>
</ul>
<p><a href="https://github.com/bananaml/fructose">fructose</a> and <a href="https://github.com/qagentur/texttunnel">texttunnel</a> are not actively developed, so I don‚Äôt recommend them for new projects.</p>
<section id="further-reading" class="level3">
<h3 class="anchored" data-anchor-id="further-reading">Further reading</h3>
<ul>
<li><a href="https://huggingface.co/blog/evaluation-structured-outputs">Improving Prompt Consistency with Structured Generations</a> by Will Kurt, Remi Louf and Cl√©mentine Fourrier at Hugging Face.</li>
<li><a href="http://blog.dottxt.co/performance-gsm8k.html">Structured Generation Improves LLM performance: GSM8K Benchmark</a> by the .txt team.</li>
<li><a href="https://pydantic.dev/articles/llm-intro">Steering Large Language Models with Pydantic</a> by Jason Liu, developer of instructor.</li>
<li><a href="https://towardsdatascience.com/the-definitive-guide-to-structured-data-parsing-with-openai-gpt3-5-0e5ea0e52637">The Definitive Guide to Structured Data Parsing with OpenAI GPT 3.5</a> (paywalled) by Marie Stephen Leo. A systematic comparison and benchmark of langchain, instructor, fructose and mirascope.</li>
</ul>


</section>
</section>

 ]]></description>
  <category>Machine Learning</category>
  <category>Python</category>
  <guid>https://simmering.dev/blog/structured_output/</guid>
  <pubDate>Fri, 10 May 2024 22:00:00 GMT</pubDate>
  <media:content url="https://simmering.dev/blog/structured_output/image.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Evaluating an LLM for your use case</title>
  <dc:creator>Paul Simmering</dc:creator>
  <link>https://simmering.dev/blog/llm-eval/</link>
  <description><![CDATA[ 





<p>In the last two months we‚Äôve seen releases of flagship LLMs like <a href="https://llama.meta.com/llama3/">Llama 3</a>, <a href="https://mistral.ai/news/mixtral-8x22b/">Mixtral 8x22B</a>, and <a href="https://www.anthropic.com/news/claude-3-family">Claude 3</a>. The title of Mistral‚Äôs announcement summarizes the dynamic well: <em>Cheaper, Better, Faster, Stronger</em>. It‚Äôs like neverending Christmas for AI developers! But how do you evaluate these models for your use case? This article is a deep dive into evaluations, covering accuracy, speed, cost, customization, context window, safety, and licensing.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/llm-eval/llm_eval_cropped.png" class="img-fluid figure-img"></p>
<figcaption>Image created with GPT-4</figcaption>
</figure>
</div>
<section id="general-language-understanding-benchmarks" class="level2">
<h2 class="anchored" data-anchor-id="general-language-understanding-benchmarks">General language understanding benchmarks</h2>
<p>General benchmarks are good for ranking models by their general language understanding and reasoning capabilities. The <a href="https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard">Hugging Face Open LLM leaderboard</a> scores models on 6 benchmarks.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/llm-eval/huggingface_open_llm_leaderboard.png" class="img-fluid figure-img"></p>
<figcaption>Hugging Face Open LLM leaderboard</figcaption>
</figure>
</div>
<table class="caption-top table">
<colgroup>
<col style="width: 34%">
<col style="width: 40%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th>Benchmark</th>
<th>Description</th>
<th>Author</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>AI2 Reasoning Challenge</td>
<td>Grade school science multiple choice questions</td>
<td><span class="citation" data-cites="clark2018think">Clark et al. (2018)</span></td>
</tr>
<tr class="even">
<td>HellaSwag</td>
<td>Sentence completion task about everyday situations, using examples that are easy for humans but hard for machines</td>
<td><span class="citation" data-cites="zellers2019hellaswag">Zellers et al. (2019)</span></td>
</tr>
<tr class="odd">
<td>Multi-task language understanding (MMLU)</td>
<td>Multiple choice questions across 57 subjects</td>
<td><span class="citation" data-cites="hendrycks2020measuring">Hendrycks et al. (2020)</span></td>
</tr>
<tr class="even">
<td>TruthfulQA</td>
<td>Multiple choice questions across 38 categories that some humans would answer falsely due to common misconceptions</td>
<td><span class="citation" data-cites="lin2021truthfulqa">Lin, Hilton, and Evans (2021)</span></td>
</tr>
<tr class="odd">
<td>Winogrande</td>
<td>Grammar challenge on pronoun disambiguation using contextual knowledge</td>
<td><span class="citation" data-cites="sakaguchi2021winogrande">Sakaguchi et al. (2021)</span></td>
</tr>
<tr class="even">
<td>GSM8K</td>
<td>Grade school math word problems</td>
<td><span class="citation" data-cites="cobbe2021training">Cobbe et al. (2021)</span></td>
</tr>
</tbody>
</table>
<p>Each benchmark probes a different aspect of language understanding and reasoning. Although no single benchmark perfectly measures a model‚Äôs capabilities, together they provide a comprehensive overview of the model‚Äôs <em>general</em> abilities. Note that all of them are posed in English by default, though there are translated versions of some benchmarks.</p>
<p>If you intend to use the model for <a href="https://platform.openai.com/docs/guides/function-calling">function calling</a>, the <a href="https://gorilla.cs.berkeley.edu/leaderboard.html">Berkeley Function-Calling Leaderboard</a> is a good benchmark. It consists of 2000 question-function-answer triples across multiple programming languages and REST APIs, including cases where the model needs to select which function to call.</p>
<p>Note that the way a benchmark is administered can affect the results. There are two main levers:</p>
<ol type="1">
<li>Additional prompt engineering, e.g.&nbsp;chain-of-thought prompts. This boosts reasoning ability at the cost of speed.</li>
<li>Few-shot sampling. Rather than asking the model just once, the model generates multiple completions and the most common answer is selected. This boosts robustness at the cost of speed. For example Google Gemini <span class="citation" data-cites="team2023gemini">(Anil et al. 2023)</span> only beats GPT-4 on the 32-shot setting, not in the 5-shot setting.</li>
</ol>
<p>A downside of public benchmarks is that cheating is possible by training a model on the test set. An alternative that can‚Äôt be gamed in this way is the <a href="https://chat.lmsys.org/?leaderboard">LLM Arena</a>. It‚Äôs a chat-based benchmark where visitors prompt two models at once and vote on the better answer. The relevant metric is an <a href="https://en.wikipedia.org/wiki/Elo_rating_system">Elo rating</a>, like in chess.</p>
<p>However, picking the model with the highest MMLU or Elo rating isn‚Äôt always the best choice. The benchmarks are general and may not reflect the specific requirements of your use case and domain. It may not have seen examples of your data and task during training. So general benchmarks are a good starting point, but not the end of the evaluation process.</p>
</section>
<section id="manual-evaluations" class="level2">
<h2 class="anchored" data-anchor-id="manual-evaluations">Manual evaluations</h2>
<p>The easiest way to evaluate a model is to try it out yourself in a chat window. For an unbiased evaluation, you should use the same prompts for all models you‚Äôre comparing. At a minimum, I suggest writing down three example prompts and perfect answers to them. This approach has three benefits:</p>
<ol type="1">
<li>you may find issues with the task definition</li>
<li>you can clarify your quality criteria</li>
<li>you can objectively compare model answers to your gold standard answers</li>
</ol>
<p>This is easier for tasks with strictly defined answers, such as text classification tasks. With more generative tasks like summarization, it‚Äôs necessary to define more fuzzy quality criteria, such as completeness and the absence of irrelevant information.</p>
<p>The <a href="https://chat.lmsys.org/?leaderboard">LLM Arena</a> has a side by side comparison feature to compare models on your own prompts.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/llm-eval/llm_arena.png" class="img-fluid figure-img"></p>
<figcaption>LLM Arena with the prompt: I have 4 apples today. I ate 3 apples yesterday. How many apples do I have today?</figcaption>
</figure>
</div>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p>LLM Arena saves all prompts and responses and may redistribute them. Don‚Äôt put in sensitive information.</p>
</div>
</div>
</section>
<section id="programmatic-evaluations" class="level2">
<h2 class="anchored" data-anchor-id="programmatic-evaluations">Programmatic evaluations</h2>
<p>The downside of manual evaluations is that they are limited to a small number of test cases. More examples are needed to get robust estimates of accuracy. The number depends on the complexity of the task and the desired confidence level. A binary classification task might require 200 examples, while an entity linking task might require 1000 or more examples. I recently published a <a href="../../blog/gold-data/">guide</a> to collecting gold-standard evaluation data.</p>
<p>To administer the test, a script that formats the examples as prompts, receives the model‚Äôs responses and compares them to the gold standard is needed. A custom script is the most flexible and lightweight solution, but there are also libraries that can help, such as <a href="https://github.com/openai/evals/tree/main">OpenAI Evals</a>, <a href="https://github.com/confident-ai/deepeval">promptflow</a>, <a href="https://github.com/parea-ai/parea-sdk-py">parea</a>, <a href="https://ragas.io">ragas</a> and <a href="https://github.com/confident-ai/deepeval">deepeval</a>.</p>
<p>In the following section I‚Äôll provide a brief overview of model evaluation metrics. A more comprehensive guide is provided by <span class="citation" data-cites="huang2024">Huang, Li, and Yehdego (2024)</span>.</p>
<p>There are two main types of evaluation: structured and unstructured responses.</p>
</section>
<section id="evaluation-of-structured-responses" class="level2">
<h2 class="anchored" data-anchor-id="evaluation-of-structured-responses">Evaluation of structured responses</h2>
<p>Structured responses consist of a fixed set of possible answers. Examples are multiple choice questions, text classification tasks, and function calling. If a text-to-text model is used, there‚Äôs an additional step of verifying that the LLM‚Äôs response conforms to the expected structure. Getting the LLM to always follow the format is best done through function calling (e.g.&nbsp;via the <a href="https://github.com/jxnl/instructor">instructor</a> library) or fine-tuning.</p>
<p>Once everything‚Äôs in the right format, <a href="https://scikit-learn.org/stable/modules/model_evaluation.html">sklearn-metrics</a> is the standard library to calculate the metrics. The most common metrics are accuracy, precision, recall and F1 score.</p>
</section>
<section id="evaluation-of-free-form-responses" class="level2">
<h2 class="anchored" data-anchor-id="evaluation-of-free-form-responses">Evaluation of free form responses</h2>
<p>A free form response text is harder to evaluate. Examples are summarization, translation and chatbots. Comparing such answers with a gold answer word-by-word is too strict, as the model may use synonyms or rephrase the answer.</p>
<p>In the pre-LLM era, n-gram overlap metrics were used to evaluate free form responses. The most common are:</p>
<ul>
<li>Bilingual Evaluation Understudy (<a href="https://en.wikipedia.org/wiki/BLEU">BLEU</a>) for translation</li>
<li>Recall-Oriented Understudy for Gisting Evaluation (<a href="https://en.wikipedia.org/wiki/BLEU">ROUGE</a>) for summarization</li>
</ul>
<p>They are cheap to compute, but they have well-known limitations: they are sensitive to word order, don‚Äôt account for synonyms and don‚Äôt measure the writing quality of the generated text.</p>
<p>Recently, LLMs themselves have been used to evaluate LLMs on unstructured tasks. The idea is to ask a second LLM to rate the quality of the first LLM‚Äôs response using a pre-defined criterion. In its simplest form, the second LLM is asked to classify the first LLM‚Äôs response as good or bad.</p>
<p>Let‚Äôs try this out with a simple example of a bot that generates jokes, using Claude 3 Opus as the joke generator and GPT-4 as the joke evaluator.</p>
<ul>
<li><strong>Prompt for Opus</strong>: ‚ÄúTell me a joke about AI‚Äù</li>
<li><strong>Opus</strong>: ‚ÄúWhy did the AI cross the road? ü§ñüõ£Ô∏è To get to the other dataset! üìäüòÑ‚Äù</li>
<li><strong>Prompt for GPT-4</strong>: ‚ÄúYou are a comedian. I asked a model to tell me a joke about AI. This is the joke it told me:‚ÄùWhy did the AI cross the road? ü§ñüõ£Ô∏è To get to the other dataset! üìäüòÑ‚Äú. Rate this joke on a scale of 1 to 5. Give a short reason and end your answer with a single number.‚Äù</li>
<li><strong>GPT-4</strong>: ‚ÄúThis joke plays on the classic‚ÄùWhy did the chicken cross the road?‚Äù setup, using a pun related to AI‚Äôs data-driven nature. It‚Äôs straightforward and mildly amusing but lacks surprise or complexity. Rating: 3‚Äù</li>
</ul>
<p>The prompt to GPT-4 uses three prompt engineering techniques: role play, asking for a reason to get better answers and ending the answer with a single number to make it easier to parse. To measure the humor of Opus, one could substitute the subject ‚ÄúAI‚Äù with others like ‚Äúchickens‚Äù, ‚Äúdoctors‚Äù or ‚Äúpoliticians‚Äù and aggregate the GPT-4 ratings.</p>
<p>This is a simple example, but can be extended to more complex tasks. More complex criteria such as fluency, relevance, informativeness and coherence offer a more nuanced evaluation. One of the most common use cases where free form responses occur is retrieval-augmented generation. The <a href="https:ragas.io">ragas</a> library offers a comprehensive set of <a href="(https://docs.ragas.io/en/latest/concepts/metrics/index.html)">metrics</a> for LLM-to-LLM evaluation, including optimized prompts for the second LLM.</p>
<p>The downside of LLM-to-LLM evaluation is that the second LLM may not have the ability to judge the quality of the first LLM‚Äôs response or have a bias towards certain types of responses.</p>
<p>Practical considerations around deploying the model also come into play: inference speed, cost, customization, safety and licensing. These factors can be more important than the model‚Äôs accuracy. The following sections provide an overview of these factors using graphs from <a href="https://artificialanalysis.ai/">artificialanalysis.ai</a>, a site that benchmarks LLMs.</p>
</section>
<section id="inference-speed" class="level2">
<h2 class="anchored" data-anchor-id="inference-speed">Inference speed</h2>
<p>How fast can the model generate responses? This matters most for real-time applications like chatbots. A slow response makes for a poor user experience.</p>
<p>Inference speed is determined by the model, meaning the number and precision of weights. It‚Äôs also determined by the hardware used, with higher-end GPUs offering more speed. The efficiency of inference code is also crucial, with libraries like <a href="https://github.com/vllm-project/vllm">vLLM</a> offering a 2x or greater speedup over the baseline implementation. <a href="https://pages.run.ai/hubfs/PDFs/Serving-Large-Language-Models-Run-ai-Benchmarking-Study.pdf">run.ai</a> has an in-depth analysis of throughput across serving engines and models.</p>
<p>Artificialanalysis.ai benchmarks throughput for a variety of models and providers and visualizes it by model and by provider.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/llm-eval/throughput_by_model.png" class="img-fluid figure-img"></p>
<figcaption>Throughput by model, across providers supporting the model</figcaption>
</figure>
</div>
<p>Smaller models, measured by the number of parameters, are faster. Mixture-of-experts models like Mixtral 8x7B have a clever approach to inference: each request only uses a subset of the model, reducing the number of matrix multiplications needed.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/llm-eval/throughput_by_provider.png" class="img-fluid figure-img"></p>
<figcaption>Throughput for llama-3 70B instruct, by provider</figcaption>
</figure>
</div>
<p>The second graph shows throughput for the same model across different providers. The fastest provider offers nearly 10x the throughput of the slowest provider.</p>
</section>
<section id="cost" class="level2">
<h2 class="anchored" data-anchor-id="cost">Cost</h2>
<p>There are two common pricing modes: per-token or per GPU-hour.</p>
<section id="per-token-pricing" class="level4">
<h4 class="anchored" data-anchor-id="per-token-pricing">Per token pricing</h4>
<p>This is typical for models served by an API. The longer the prompt and the response, the greater the cost. Cost for output tokens is typically 2 to 5 times higher than input tokens. Let‚Äôs look at an example, using GPT-4 Turbo‚Äôs pricing of $10/1M input tokens and $30/1M output tokens.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 21%">
<col style="width: 32%">
<col style="width: 28%">
<col style="width: 17%">
</colgroup>
<thead>
<tr class="header">
<th>Role</th>
<th>Message</th>
<th>Tokens</th>
<th>Cost</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>User</td>
<td>Translate the following text to German: How are you?</td>
<td>11</td>
<td>$0.00011</td>
</tr>
<tr class="even">
<td>Assistant</td>
<td>Wie geht es dir?</td>
<td>5</td>
<td>$0.00015</td>
</tr>
</tbody>
</table>
<p>Note that the cost is per token, not per word. A token is a word or a subword. For simple calculations, multiplying the number of words by 1.33 works. You can try OpenAI‚Äôs free <a href="tokenizer">https://platform.openai.com/tokenizer</a> or the <a href="https://github.com/openai/tiktoken">tiktoken</a> library to get the exact token count for a text. Note that models with a different tokenizer will have different token counts for the same prompt.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/llm-eval/tokenizer.png" class="img-fluid figure-img" style="width:65.0%"></p>
<figcaption>OpenAI‚Äôs tokenizer</figcaption>
</figure>
</div>
<p>You can save money by using shorter prompts. Fine-tuning can ‚Äúbake‚Äù instructions into a model, foregoing the need to explain the task in each request. However, token prices for fine-tuned models are typically higher than for the base model.</p>
<p>OpenAI recently announced <a href="https://help.openai.com/en/articles/9197833-batch-api-faq">batch inference</a> with 24h turnaround time at 50% off the token price.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/llm-eval/pricing.png" class="img-fluid figure-img"></p>
<figcaption>Input and output token cost by model, median across providers</figcaption>
</figure>
</div>
<p>Per-token costs vary widely across providers and models. Larger models are more expensive, and major cloud providers charge higher prices than smaller providers. There‚Äôs a downward trend in pricing over time, given a fixed model size.</p>
</section>
<section id="gpu-hour-pricing" class="level4">
<h4 class="anchored" data-anchor-id="gpu-hour-pricing">GPU hour pricing</h4>
<p>The second case is that you self-host the model. Here, pricing depends on <a href="https://fullstackdeeplearning.com/cloud-gpus/">GPU rent</a> (or depreciation of your own GPU). My currently favored GPU provider is <a href="https://modal.com/pricing">Modal</a>. They offer a generous free tier, pricing is competitive, only actually used GPU time is billed and it‚Äôs easy to use.</p>
<p>To figure out the actual cost of your workload it‚Äôs normally necessary to run your own cost benchmark. There are too many moving pieces, and each can change the cost by a factor of 2 or more: GPU configuration (model, number of GPUs), the LLM, quantization, inference library, timing of inference (batch or live, long term reservation or on demand) and the geographic region.</p>
</section>
</section>
<section id="customization" class="level2">
<h2 class="anchored" data-anchor-id="customization">Customization</h2>
<p>Open models running on your own infrastructure offer deeper customization than models served from APIs.</p>
<p>There are three main types of customization:</p>
<ol type="1">
<li>Finetuning via SFT, RLHF, DPO or ORPO</li>
<li>Quantization, meaning reducing the precision of the weights to 16-bit or 8-bit</li>
<li>Token sampling settings, such as temperature, top-k, nucleus sampling and beam search. For a full overview, check the Hugging Face <a href="https://huggingface.co/docs/transformers/main_classes/text_generation">GenerationConfig</a> documentation</li>
</ol>
<p>API providers offer only a subset of these options and only for certain models. More knobs to twist is only meaningful if you have the time to actually use them. If your main focus is elsewhere, good presets can be more productive than maximum control. It‚Äôs the same reason why many devs choose macOS over Arch Linux.</p>
</section>
<section id="context-window" class="level2">
<h2 class="anchored" data-anchor-id="context-window">Context window</h2>
<p>The context window is the number of input tokens the model can handle in one go. Higher is better, as it allows the model to reason over more information. For reference, an A4 page of text is about 500 words, which is about 665 tokens. The smallest context size found in current models is 4096 tokens, which corresponds to about 6 pages of text.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/llm-eval/context_window.png" class="img-fluid figure-img"></p>
<figcaption>Context window sizes by model</figcaption>
</figure>
</div>
<p>This comes with some caveats:</p>
<ul>
<li>output token limits are significantly lower than input token limits</li>
<li>processing a large number of input tokens is expensive</li>
<li>the model may not be able to actually use the full context, this is referred to the ‚Äúlost in the middle‚Äù problem <span class="citation" data-cites="liu2023lost">(Liu et al. 2023)</span></li>
</ul>
</section>
<section id="safety-and-fairness" class="level2">
<h2 class="anchored" data-anchor-id="safety-and-fairness">Safety and fairness</h2>
<p>Others have written extensively on safety and fairness evaluation of LLMs. <a href="https://www.anthropic.com/news/training-a-helpful-and-harmless-assistant-with-reinforcement-learning-from-human-feedback">Anthropic‚Äôs principle</a> ‚ÄúHelpful, Honest and Harmless AI‚Äù is industry-leading in this regard. They provide an evaluation <a href="https://huggingface.co/datasets/Anthropic/hh-rlhf">dataset</a> on Hugging Face.</p>
<p>Key questions to ask about a foundation model are:</p>
<ul>
<li>Does the model exhibit biases around gender, race, religion or other protected classes?</li>
<li>Does the model refuse requests to do dangerous or illegal activities?</li>
<li>Can it be goaded into violating its own principles?</li>
</ul>
<p>The documentation by the model providers a good place to start. The abscence of consideration of these factors in a foundation model is a red flag.</p>
<p>The actual risk of a model depends on the task. High-risk tasks such as medical diagnosis, legal advice or loan approval require more scrutiny than tasks such as sentiment analysis or summarization. Situations in which models have free-form interaction with users, such as chatbots carry greater potential for harm and also surface area for prompt injection attacks.</p>
</section>
<section id="licensing" class="level2">
<h2 class="anchored" data-anchor-id="licensing">Licensing</h2>
<p>Broadly, models can be categorized as open source or proprietary. Generally, the more open the better because you can inspect the model, customize it and deploy it on your own infrastructure. In addition, open source models give you ownership of the model, rather than being at the mercy of the provider‚Äôs pricing and availability.</p>
<p>The term open source has become muddled in the context of LLMs. The minimum requirement is that the model‚Äôs weights are available for download. However, full open source also includes the training data, training code, inference code and documentation. Further, there are a variety of open licenses that can be applied. The <a href="https://opensource.org/license/mit">MIT license</a> and <a href="https://opensource.org/license/apache-2-0">Apache 2.0</a> are the most permissive and place the fewest restrictions and duties on the user. Finally, there are custom licenses. Notably, Meta has released the Llama 3 model under a <a href="https://llama.meta.com/llama3/license/">custom license</a> that requires attribution and requires that organzations with more than 700 million monthly active users (effectively only the largest tech companies) to request a commercial license.</p>
</section>
<section id="llm-evaluation-checklist" class="level2">
<h2 class="anchored" data-anchor-id="llm-evaluation-checklist">LLM Evaluation Checklist</h2>
<p>Evaluating LLMs is a multi-faceted challenge. While benchmarks and case studies are valuable, there‚Äôs no substitute for hands-on testing in one‚Äôs particular domain. To summarize, here‚Äôs a checklist for evaluating an LLM:</p>
<ol type="1">
<li>‚úÖ <strong>Licensing</strong>: Check that the model‚Äôs license is compatible with your use case.</li>
<li>‚úÖ <strong>Customization</strong>: Consider the model‚Äôs customization options based on the license and your needs.</li>
<li>‚úÖ <strong>Context window</strong>: Check if the model‚Äôs context window is large enough to fit your inputs.</li>
<li>‚úÖ <strong>Quality</strong>: Start with general benchmarks, then move to manual and programmatic evaluations. Consider structured and unstructured responses.</li>
<li>‚úÖ <strong>Safety and fairness</strong>: Assess the model‚Äôs safety and fairness, especially for use cases involving individual judgments or open-ended interaction.</li>
<li>‚úÖ <strong>Cost</strong>: Analyze the cost per token or GPU hour for your usage patterns.</li>
<li>‚úÖ <strong>Speed</strong>: Benchmark the model‚Äôs throughput in your setup, whether self-hosted or served from an API. There is often significant optimization potential here.</li>
</ol>
<p>Being clear about the task and success criteria at every step is key. Writing down arguments and results lets you repeat the analysis for new models and justify your choice in architecture and budget reviews. Sharing benchmark results builds trust by users of your model. Without quantitative tests, their opinion of the model hinges on their first interaction alone.</p>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0">
<div id="ref-team2023gemini" class="csl-entry">
Anil, Rohan, Sebastian Borgeaud, Yonghui Wu, Jean-Baptiste Alayrac, Jiahui Yu, Radu Soricut, Johan Schalkwyk, Andrew M Dai, Anja Hauth, et al. 2023. <span>‚ÄúGemini: A Family of Highly Capable Multimodal Models.‚Äù</span> <em>arXiv Preprint arXiv:2312.11805</em>. <a href="https://arxiv.org/abs/2312.11805">https://arxiv.org/abs/2312.11805</a>.
</div>
<div id="ref-clark2018think" class="csl-entry">
Clark, Peter, Isaac Cowhey, Oren Etzioni, Tushar Khot, Ashish Sabharwal, Carissa Schoenick, and Oyvind Tafjord. 2018. <span>‚ÄúThink You Have Solved Question Answering? Try Arc, the Ai2 Reasoning Challenge.‚Äù</span> <em>arXiv Preprint arXiv:1803.05457</em>. <a href="https://arxiv.org/abs/1803.05457">https://arxiv.org/abs/1803.05457</a>.
</div>
<div id="ref-cobbe2021training" class="csl-entry">
Cobbe, Karl, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, et al. 2021. <span>‚ÄúTraining Verifiers to Solve Math Word Problems.‚Äù</span> <em>arXiv Preprint arXiv:2110.14168</em>. <a href="https://arxiv.org/abs/2110.14168">https://arxiv.org/abs/2110.14168</a>.
</div>
<div id="ref-hendrycks2020measuring" class="csl-entry">
Hendrycks, Dan, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt. 2020. <span>‚ÄúMeasuring Massive Multitask Language Understanding.‚Äù</span> <em>arXiv Preprint arXiv:2009.03300</em>. <a href="https://arxiv.org/abs/2009.03300">https://arxiv.org/abs/2009.03300</a>.
</div>
<div id="ref-huang2024" class="csl-entry">
Huang, Jane, Kirk Li, and Daniel Yehdego. 2024. <span>‚ÄúEvaluating Large Language Model (LLM) Systems: Metrics, Challenges, and Best Practices.‚Äù</span> Data Science at Microsoft. 2024. <a href="https://medium.com/data-science-at-microsoft/evaluating-llm-systems-metrics-challenges-and-best-practices-664ac25be7e5">https://medium.com/data-science-at-microsoft/evaluating-llm-systems-metrics-challenges-and-best-practices-664ac25be7e5</a>.
</div>
<div id="ref-lin2021truthfulqa" class="csl-entry">
Lin, Stephanie, Jacob Hilton, and Owain Evans. 2021. <span>‚ÄúTruthfulqa: Measuring How Models Mimic Human Falsehoods.‚Äù</span> <em>arXiv Preprint arXiv:2109.07958</em>. <a href="https://arxiv.org/abs/2109.07958">https://arxiv.org/abs/2109.07958</a>.
</div>
<div id="ref-liu2023lost" class="csl-entry">
Liu, Nelson F., Kevin Lin, John Hewitt, Ashwin Paranjape, Michele Bevilacqua, Fabio Petroni, and Percy Liang. 2023. <span>‚ÄúLost in the Middle: How Language Models Use Long Contexts.‚Äù</span> <a href="https://arxiv.org/abs/2307.03172">https://arxiv.org/abs/2307.03172</a>.
</div>
<div id="ref-sakaguchi2021winogrande" class="csl-entry">
Sakaguchi, Keisuke, Ronan Le Bras, Chandra Bhagavatula, and Yejin Choi. 2021. <span>‚ÄúWinogrande: An Adversarial Winograd Schema Challenge at Scale.‚Äù</span> <em>Communications of the ACM</em> 64 (9): 99‚Äì106. <a href="https://arxiv.org/abs/1907.10641">https://arxiv.org/abs/1907.10641</a>.
</div>
<div id="ref-zellers2019hellaswag" class="csl-entry">
Zellers, Rowan, Ari Holtzman, Yonatan Bisk, Ali Farhadi, and Yejin Choi. 2019. <span>‚ÄúHellaswag: Can a Machine Really Finish Your Sentence?‚Äù</span> <em>arXiv Preprint arXiv:1905.07830</em>. <a href="https://arxiv.org/abs/1905.07830">https://arxiv.org/abs/1905.07830</a>.
</div>
</div></section></div> ]]></description>
  <category>Machine Learning</category>
  <guid>https://simmering.dev/blog/llm-eval/</guid>
  <pubDate>Sat, 27 Apr 2024 22:00:00 GMT</pubDate>
  <media:content url="https://simmering.dev/blog/llm-eval/llm_eval.webp" medium="image" type="image/webp"/>
</item>
<item>
  <title>How to get gold standard data for NLP</title>
  <dc:creator>Paul Simmering</dc:creator>
  <link>https://simmering.dev/blog/gold-data/</link>
  <description><![CDATA[ 





<p>With the attention on new LLM releases, it‚Äôs easy to forget that correctly labeled examples are still a critical factor for accuracy in most NLP tasks. I think they‚Äôre the best source of competitive advantage for most teams. Labeled examples will be useful in conjunction with any model that comes out.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/gold-data/vault_cropped.png" class="img-fluid figure-img"></p>
<figcaption>Gold-standard data, image generated with Midjourney</figcaption>
</figure>
</div>
<p>High quality, human-labeled examples are aptly called ‚Äúgold standard‚Äù. This guide will help you accumulate and refine this treasure. It‚Äôs based on my five years of experience collecting and refining labeled data for NLP projects, plus a review of the literature.</p>
<section id="fine-tuned-models-outperform-few-shot-and-zero-shot-approaches" class="level2">
<h2 class="anchored" data-anchor-id="fine-tuned-models-outperform-few-shot-and-zero-shot-approaches">Fine-tuned models outperform few-shot and zero-shot approaches</h2>
<p>Zero-shot and few-shot prediction with LLMs promises to let you skip the labeling and training. Just give the model a few examples and it‚Äôll figure out the rest. This is great for a proof of concept, but how do you know that the labels it gives are correct? Checking individual examples by hand is helpful, but not enough proof. Even if the model doesn‚Äôt need finetuning, you‚Äôll need at least a test set to evaluate on.</p>
<p>For classic NLP tasks like text classification, named entity recognition and sentiment analysis, fine-tuned models are still by far the most accurate. This is shown in the benchmarks below. Fine-tuned models perform best across all tasks, followed by few-shot instructed models. Zero-shot performance is the least accurate.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/gold-data/benchmarks.png" class="img-fluid figure-img"></p>
<figcaption>Finetuning vs.&nbsp;few-shot vs.&nbsp;zero-shot benchmark results</figcaption>
</figure>
</div>
<p>Benchmarks were done by <span class="citation" data-cites="ziems2023can">Ziems et al. (2023)</span>, <span class="citation" data-cites="qin2023chatgpt">Qin et al. (2023)</span>, <span class="citation" data-cites="wang2023gpt">Wang et al. (2023)</span> and <span class="citation" data-cites="simmering2023large">Simmering and Huoviala (2023)</span>.</p>
</section>
<section id="ways-to-get-training-data" class="level2">
<h2 class="anchored" data-anchor-id="ways-to-get-training-data">Ways to get training data</h2>
<p>I hope that I convinced you that training data is still relevant. So how to acquire it?</p>
<section id="public-sources" class="level3">
<h3 class="anchored" data-anchor-id="public-sources">Public sources</h3>
<p>First, check if there‚Äôs a public dataset that fits your needs. Here are some places to look:</p>
<ul>
<li><a href="https://huggingface.co/datasets">Huggingface Hub</a> features more than 100,000 free datasets.</li>
<li><a href="https://www.kaggle.com/datasets">Kaggle</a> has more than 50,000 free datasets.</li>
<li><a href="https://paperswithcode.com/datasets">Papers with Code</a> has more than 2,000 text datasets, covering all popular NLP benchmarks.</li>
<li><a href="https://data.world/datasets/nlp">data.world</a> has 72 free NLP datasets.</li>
<li><a href="https://github.com/niderhoff/nlp-datasets">nlp-datasets Github repository</a> has a curated list of free NLP datasets.</li>
</ul>
<p>If the dataset is popular you may also find pre-trained models for it on Huggingface. They can give you an idea of the accuracy you can expect to reach and the difficulty of the examples. That‚Äôs useful information even if you train your own model.</p>
<p>The majority of public NLP datasets are in English. It may be possible to translate a dataset to your language. DeepL and other translation APIs are affordable. Try it with some examples and see if the translations are good enough.</p>
</section>
<section id="using-natural-labels" class="level3">
<h3 class="anchored" data-anchor-id="using-natural-labels">Using natural labels</h3>
<p>Natural labels are signals that are already present in the data. They can be used to train a model without any human labeling. Here are some examples:</p>
<ul>
<li>Star ratings for reviews are a signal for sentiment analysis.</li>
<li>Positive / negative feedback for support answers is a signal for customer satisfaction.</li>
<li>The number of upvotes, likes and shares for social media posts is a signal for popularity.</li>
<li>The upvotes for question answers on Stack Overflow is a signal for correctness.</li>
<li>Open rate of emails is a signal for interest of the subject line.</li>
</ul>
<p>Perhaps there is a dataset in your organization that has natural labels for the task you want to solve.</p>
</section>
<section id="labeling-by-hand" class="level3">
<h3 class="anchored" data-anchor-id="labeling-by-hand">Labeling by hand</h3>
<p>If you‚Äôre not lucky enough to find a public dataset or natural labels, creating your own dataset is the way to go. To go beyond a few thousand examples, a team of labelers is necessary. In any case, I suggest you start by labeling a few examples yourself. This will give you a good understanding of the task.</p>
<p>Here are some points to consider when creating a labeled dataset, whether in a team or alone:</p>
<ul>
<li><strong>Annotation guide</strong>: Write a detailed annotation guide with examples. This is a living document that gets updated with details and examples throughout the project.</li>
<li><strong>Iterate on the rules</strong>: Figuring out clear rules is the number one priority at the start. Discuss unclear examples with the team and refine the annotation guide. It can be necessary to change a rule and re-label the examples done until then. The cost increases as the project progresses.</li>
<li><strong>Skip the weirdest examples</strong>: User generated internet content can be wild in terms of content and grammar. It can be better better to skip the weirdest examples than to try to label them. They‚Äôre more likely to confuse your model than help it learn and it‚Äôs unlikely that they‚Äôll be encountered in practice.</li>
<li><strong>Quality control</strong>: Double annotation and analysis of inter-annotator reliability is a key technique for correct annotation from a team.</li>
<li><strong>Labeling tool</strong>: Good labeling UI and workflow makes a big difference in productivity and quality. It‚Äôs worth investing the time to find the right tool and configure it optimally. The tool should also make it easy look at the examples that were already annotated and fix errors.</li>
<li><strong>Simplify the task</strong>: Have reasonable expectations for what a labeler can do. For example, correctly using 20 different labels in a text classification task is not realistic. It‚Äôs too easy to forget one of them. Binary labeling is easier and it can be worth it to split a task into subtasks that use fewer labels.</li>
<li><strong>Onboarding</strong>: When a new labeler starts, have a one-to-one onboarding session in which you label some examples together. This is often much more effective than reading the guide. It‚Äôs also an opportunity to teach efficient use of the labeling tool.</li>
<li><strong>Quality over quantity</strong>: A small, high quality dataset is preferable to a large, low quality dataset. Falsely labeled examples are misleading for the model and for evaluation. Plus, they increase the time and cost for training.</li>
<li><strong>Diminishing rates of return</strong>: Check the difference that adding more examples to the training set makes on model performance. You can do this by training your model on varying amounts of your labeled data, e.g.&nbsp;with 80%, 90% and 100%. If the last 10% of labeled data make a clear difference, keep annotating more data.</li>
<li><strong>You get what you pay for</strong>: When choosing a contractor or full labeling service, ask for inter-annotator reliability and how labelers are instructed and whether they‚Äôre native speakers for the language of the task.</li>
</ul>
<section id="gpt-4-is-more-accurate-than-low-quality-labeling-services" class="level4">
<h4 class="anchored" data-anchor-id="gpt-4-is-more-accurate-than-low-quality-labeling-services">GPT-4 is more accurate than low-quality labeling services</h4>
<p><span class="citation" data-cites="tornberg2023chatgpt">T√∂rnberg (2023)</span> and <span class="citation" data-cites="gilardi2023chatgpt">Gilardi, Alizadeh, and Kubli (2023)</span> compared labeling accuracy of GPT-4 with labels created by Amazon Mechanical Turk workers. They found that GPT-4 with a zero-shot instruction was more accurate on tweet text classification tasks. As a buyer of labeling services, a low-quality service may be a worse deal than using an LLM to label the examples (see next section). Hence, it‚Äôs only worth using a labeling service if it‚Äôs high quality. The ideal solution is a team of experienced labelers that communicate well, refine the annotation guide and use a highly efficient labeling tool.</p>
</section>
</section>
<section id="synthetic-data-labels" class="level3">
<h3 class="anchored" data-anchor-id="synthetic-data-labels">Synthetic data / labels</h3>
<p>The most capable LLMs like GPT-4 can solve many NLP problems with decent accuracy with a few-shot example prompt. You can kickstart a project by letting it label examples and then training your smaller, more efficient model on them. <span class="citation" data-cites="laurer2024synthetic">Laurer (2024)</span> provides a great deep dive into this approach and its efficiency benefits.</p>
<p>Experiment with the prompt and the examples to get the best performance. An annotation guide with examples as described in the previous section is a great starting point for an effective prompt.</p>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">graph LR
    A[Raw data] --&gt; B[Few-shot prompt]
    C[4 to 10 examples] --&gt; B
    B --&gt;|Instruct| D[LLM]
    D --&gt;|Predict| E[Labels]
    E --&gt;|Manual check| F[Corrected labels]
    F --&gt;|Train| G[Efficient model]
    
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<p>If the model‚Äôs few-shot accuracy isn‚Äôt good enough, check the examples and correct the labels by hand. The human-in-the-loop step is required to get proper ‚Äúgold standard‚Äù data. It‚Äôs still faster than labeling from scratch.</p>
<section id="active-learning" class="level4">
<h4 class="anchored" data-anchor-id="active-learning">Active learning</h4>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">graph LR
    A[Model] --&gt;|Predict| B[Label]
    B --&gt;|Prioritize low confidence predictions| C[Human check]
    C --&gt;|Train| A
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<p>With active learning, the model is trained incrementally as new examples are labeled. A human labeler is presented with the examples that the model is most uncertain about and labels them. This maximizes labeling productivity and also gives insight into the model‚Äôs weaknesses. The tool <a href="https://prodi.gy">Prodigy</a> by Explosion AI was a pioneer in this area and is still a popular choice.</p>
</section>
</section>
</section>
<section id="improving-your-labeled-data" class="level2">
<h2 class="anchored" data-anchor-id="improving-your-labeled-data">Improving your labeled data</h2>
<blockquote class="blockquote">
<p>‚ÄúThe biggest alpha in AI is actually looking at your data‚Äù - Mark Tenenholtz on <a href="https://twitter.com/marktenenholtz/status/1762179463033278963">X</a></p>
</blockquote>
<p>Better training data makes everything easier, without adding complexity to the model, your code or your infrastructure. There‚Äôs no substitute for high quality data. Here are some ways to improve your labeled data:</p>
<section id="stare-at-the-data" class="level3">
<h3 class="anchored" data-anchor-id="stare-at-the-data">Stare at the data</h3>
<p>Ultra simple, but effective. Look at the examples and labels, check that they conform to the annotation guide. Think about what the model will learn from them. This is a high-value activity, worthy of a senior engineer‚Äôs time. It doesn‚Äôt scale, but it‚Äôs worth doing every now and then.</p>
</section>
<section id="perform-all-standard-checks" class="level3">
<h3 class="anchored" data-anchor-id="perform-all-standard-checks">Perform all standard checks</h3>
<p>Here are some standard questions that are always worth asking about your data:</p>
<ol type="1">
<li>Is your training data as diverse as the data you‚Äôll encounter in practice? For example, if you‚Äôre doing fake news detection, do you have examples from all political sides?</li>
<li>Are the predicted classes balanced, and if not, does your training and evaluation handle imbalance properly? For example, star ratings for reviews are often biased towards 5 stars.</li>
<li>Do you version your data along with the trained machine learning models? This is critical for reproducibility and debugging.</li>
<li>Do the labels have clear and non-overlapping definitions?</li>
<li>Does the dataset contain outliers or unrealistic values? For example, a review with more than 5 stars.</li>
<li>Are there any duplicates in the data?</li>
<li>Is there overlap between the training and evaluation data?</li>
</ol>
</section>
<section id="fix-errors-in-training-data-by-analyzing-wrong-predictions" class="level3">
<h3 class="anchored" data-anchor-id="fix-errors-in-training-data-by-analyzing-wrong-predictions">Fix errors in training data by analyzing wrong predictions</h3>
<p>Mistaken labels are poison for your model. It learns wrong rules or gets falsely penalized for correct predictions. How do you find and fix them? The model can help with that! One way to find training examples that may be wrong is to train a model on the examples and then run inference on them. If the model gets the label wrong even after having seen it during training, the example may be wrong. The model learned the rule from the other examples, but this example doesn‚Äôt follow it. Check those examples and fix the label where necessary.</p>
</section>
<section id="add-high-signal-examples" class="level3">
<h3 class="anchored" data-anchor-id="add-high-signal-examples">Add high-signal examples</h3>
<p>Labels for difficult examples are a stronger signal than labels for easy examples. Once the model has figured out the basic labeling rules from general examples, it doesn‚Äôt have as much to learn from them anymore. You can identify difficult examples by checking the model‚Äôs confidence when predicting their answers. Classification models typically return a probability distribution over labels, and LLMs can provide next-token probabilities. Label the examples that have a more uniform distribution, meaning low confidence in the chosen solution. These examples will also help you find edge cases for the annotation guide.</p>
</section>
<section id="data-augmentation" class="level3">
<h3 class="anchored" data-anchor-id="data-augmentation">Data augmentation</h3>
<p>You can turn one example into many by slightly changing the wording while keeping the label. <span class="citation" data-cites="chaudhary2020visual">Chaudhary (2020)</span> offers a visual overview of techniques, including:</p>
<ol type="1">
<li>Lexical substitution: Replace words with synonyms.</li>
<li>Back translation: Translate the text to another language and back.</li>
<li>Text surface transformation: Contract expressions e.g.&nbsp;‚ÄúI am‚Äù -&gt; ‚ÄúI‚Äôm‚Äù.</li>
<li>Random noise injection: Adding spelling mistakes, shuffling sentences, randomly removing words.</li>
<li>Generative methods: Use a generative model to create new examples similar to the original.</li>
</ol>
<p>These variations of the same example can improve robustness and generalization of the model. They can also help to balance the classes. However, they are less valuable than real examples. Only use them for the training set, not for the test set and run experiments to see if they actually improve performance or just slow down training.</p>
</section>
</section>
<section id="models-come-and-go-data-is-forever" class="level2">
<h2 class="anchored" data-anchor-id="models-come-and-go-data-is-forever">Models come and go, data is forever</h2>
<p>New models are released every week and we seem to have a revolution in model architecture about every 3 years. It can be exhausting to keep up, especially if your goal is to serve a customer need rather than conduct research. If you find yourself in this position, prioritizing training and evaluation data over modeling is a good strategy. Your labeled data will likely be compatible with any model that will come out. Even if the model doesn‚Äôt need to be trained, it‚Äôll still be good to have an accurate evaluation dataset. By keeping your code as model-agnostic as possible you can ride the waves of new models coming out, reaping the performance improvements, with little model customization on your part. Just plug in the new model and combine it with your real treasure, the labeled data.</p>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0">
<div id="ref-chaudhary2020visual" class="csl-entry">
Chaudhary, Amit. 2020. <span>‚ÄúA Visual Survey of Data Augmentation in NLP.‚Äù</span> <a href="https://amitness.com/2020/05/data-augmentation-for-nlp/">https://amitness.com/2020/05/data-augmentation-for-nlp/</a>.
</div>
<div id="ref-gilardi2023chatgpt" class="csl-entry">
Gilardi, Fabrizio, Meysam Alizadeh, and Ma√´l Kubli. 2023. <span>‚ÄúChatGPT Outperforms Crowd Workers for Text-Annotation Tasks.‚Äù</span> <em>Proceedings of the National Academy of Sciences</em> 120 (30): e2305016120.
</div>
<div id="ref-laurer2024synthetic" class="csl-entry">
Laurer, Moritz. 2024. <span>‚ÄúSynthetic Data: Save Money, Time and Carbon with Open Source.‚Äù</span> <a href="https://huggingface.co/blog/synthetic-data-save-costs">https://huggingface.co/blog/synthetic-data-save-costs</a>.
</div>
<div id="ref-qin2023chatgpt" class="csl-entry">
Qin, Chengwei, Aston Zhang, Zhuosheng Zhang, Jiaao Chen, Michihiro Yasunaga, and Diyi Yang. 2023. <span>‚ÄúIs ChatGPT a General-Purpose Natural Language Processing Task Solver?‚Äù</span> <em>arXiv Preprint arXiv:2302.06476</em>.
</div>
<div id="ref-simmering2023large" class="csl-entry">
Simmering, Paul F, and Paavo Huoviala. 2023. <span>‚ÄúLarge Language Models for Aspect-Based Sentiment Analysis.‚Äù</span> <em>arXiv Preprint arXiv:2310.18025</em>.
</div>
<div id="ref-tornberg2023chatgpt" class="csl-entry">
T√∂rnberg, Petter. 2023. <span>‚ÄúChatgpt-4 Outperforms Experts and Crowd Workers in Annotating Political Twitter Messages with Zero-Shot Learning.‚Äù</span> <em>arXiv Preprint arXiv:2304.06588</em>.
</div>
<div id="ref-wang2023gpt" class="csl-entry">
Wang, Shuhe, Xiaofei Sun, Xiaoya Li, Rongbin Ouyang, Fei Wu, Tianwei Zhang, Jiwei Li, and Guoyin Wang. 2023. <span>‚ÄúGpt-Ner: Named Entity Recognition via Large Language Models.‚Äù</span> <em>arXiv Preprint arXiv:2304.10428</em>.
</div>
<div id="ref-ziems2023can" class="csl-entry">
Ziems, Caleb, Omar Shaikh, Zhehao Zhang, William Held, Jiaao Chen, and Diyi Yang. 2023. <span>‚ÄúCan Large Language Models Transform Computational Social Science?‚Äù</span> <em>Computational Linguistics</em>, 1‚Äì53.
</div>
</div></section></div> ]]></description>
  <category>Machine Learning</category>
  <guid>https://simmering.dev/blog/gold-data/</guid>
  <pubDate>Sat, 09 Mar 2024 23:00:00 GMT</pubDate>
  <media:content url="https://simmering.dev/blog/gold-data/vault.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>LLM Price Comparison</title>
  <dc:creator>Paul Simmering</dc:creator>
  <link>https://simmering.dev/blog/llm-price-performance/</link>
  <description><![CDATA[ 





<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>This article is about prices as of January 11, 2024. For current prices and more comprehensive analysis, check <a href="https://artificialanalysis.ai">artificialanalysis.ai</a> (not affiliated with me).</p>
</div>
</div>
<p>This is an overview of pricing for large language models from different developers and API providers. The dataset is available on <a href="https://github.com/psimm/website/blob/master/blog/llm-price-performance/data.csv">GitHub</a>. Prices are expressed in USD per 1 million tokens. To learn more about tokens, see the <a href="https://platform.openai.com/tokenizer">Tokenizer</a> by OpenAI.</p>
<section id="price-comparison" class="level2">
<h2 class="anchored" data-anchor-id="price-comparison">Price comparison</h2>
<div id="a490e678" class="cell" data-execution_count="2">
<div class="cell-output cell-output-display">
<div>                            <div id="778847f3-16db-44a6-b236-1ec64c8da3e1" class="plotly-graph-div" style="height:525px; width:100%;"></div>            <script type="text/javascript">                require(["plotly"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById("778847f3-16db-44a6-b236-1ec64c8da3e1")) {                    Plotly.newPlot(                        "778847f3-16db-44a6-b236-1ec64c8da3e1",                        [{"alignmentgroup":"True","customdata":[["mistral-7b-openorca","Anyscale","32k",0.15,0.15],["mistral-7b-instruct","Anyscale","32k",0.15,0.15],["llama-guard-7b","Anyscale","4k",0.15,0.15],["llama-2-7b-chat-hf","Anyscale","4k",0.15,0.15],["llama-2-13b-chat-hf","Anyscale","4k",0.25,0.25],["mixtral-8x7b-instruct","Anyscale","32k",0.5,0.5],["llama2-70b-chat-hf","Anyscale","4k",1.0,1.0]],"hovertemplate":"Model: %{customdata[0]}\u003cbr\u003eProvider: %{customdata[1]}\u003cbr\u003eContext Size: %{customdata[2]}\u003cbr\u003eInput Token $\u002f1M: %{customdata[3]}\u003cbr\u003eOutput Token $\u002f1M: %{customdata[4]}\u003cbr\u003eAvg Price $\u002f1M: %{x}","legendgroup":"Anyscale","marker":{"color":"#636efa","pattern":{"shape":""}},"name":"Anyscale","offsetgroup":"Anyscale","orientation":"h","showlegend":true,"textposition":"auto","x":[0.15,0.15,0.15,0.15,0.25,0.5,1.0],"xaxis":"x","y":["Anyscale-mistral-7b-openorca","Anyscale-mistral-7b-instruct","Anyscale-llama-guard-7b","Anyscale-llama-2-7b-chat-hf","Anyscale-llama-2-13b-chat-hf","Anyscale-mixtral-8x7b-instruct","Anyscale-llama2-70b-chat-hf"],"yaxis":"y","type":"bar"},{"alignmentgroup":"True","customdata":[["mistral-7b-instruct","Mistral","32k",0.14,0.42],["mixtral-8x7b-instruct","Mistral","32k",0.6,1.8],["mistral-medium","Mistral","32k",2.5,7.5]],"hovertemplate":"Model: %{customdata[0]}\u003cbr\u003eProvider: %{customdata[1]}\u003cbr\u003eContext Size: %{customdata[2]}\u003cbr\u003eInput Token $\u002f1M: %{customdata[3]}\u003cbr\u003eOutput Token $\u002f1M: %{customdata[4]}\u003cbr\u003eAvg Price $\u002f1M: %{x}","legendgroup":"Mistral","marker":{"color":"#EF553B","pattern":{"shape":""}},"name":"Mistral","offsetgroup":"Mistral","orientation":"h","showlegend":true,"textposition":"auto","x":[0.28,1.2,5.0],"xaxis":"x","y":["Mistral-mistral-7b-instruct","Mistral-mixtral-8x7b-instruct","Mistral-mistral-medium"],"yaxis":"y","type":"bar"},{"alignmentgroup":"True","customdata":[["cohere-light","AWS","4k",0.3,0.6],["llama-2-chat-13b","AWS","4k",0.75,1.0],["claude-instant","AWS","100k",0.8,2.4],["claude","AWS","100k",0.8,2.4],["titan-text-express","AWS","8k",1.2,2.3],["cohere-command","AWS","4k",1.5,2.0],["llama-2-chat-70b","AWS","4k",1.95,2.56],["jurassic-2-mid","AWS","8k",12.5,12.5],["jurassic-2-ultra","AWS","8k",18.8,18.8]],"hovertemplate":"Model: %{customdata[0]}\u003cbr\u003eProvider: %{customdata[1]}\u003cbr\u003eContext Size: %{customdata[2]}\u003cbr\u003eInput Token $\u002f1M: %{customdata[3]}\u003cbr\u003eOutput Token $\u002f1M: %{customdata[4]}\u003cbr\u003eAvg Price $\u002f1M: %{x}","legendgroup":"AWS","marker":{"color":"#00cc96","pattern":{"shape":""}},"name":"AWS","offsetgroup":"AWS","orientation":"h","showlegend":true,"textposition":"auto","x":[0.45,0.88,1.6,1.6,1.75,1.75,2.26,12.5,18.8],"xaxis":"x","y":["AWS-cohere-light","AWS-llama-2-chat-13b","AWS-claude-instant","AWS-claude","AWS-titan-text-express","AWS-cohere-command","AWS-llama-2-chat-70b","AWS-jurassic-2-mid","AWS-jurassic-2-ultra"],"yaxis":"y","type":"bar"},{"alignmentgroup":"True","customdata":[["gpt-3.5-turbo-1106","OpenAI","16k",1.0,2.0],["gpt-3.5-turbo-turbo-instruct","OpenAI","16k",1.5,2.0],["gpt-4-1106-preview","OpenAI","128k",10.0,30.0],["gpt-4-1106-vision-preview","OpenAI","128k",10.0,30.0],["gpt-4","OpenAI","8k",30.0,60.0],["gpt-4-32k","OpenAI","32k",60.0,120.0]],"hovertemplate":"Model: %{customdata[0]}\u003cbr\u003eProvider: %{customdata[1]}\u003cbr\u003eContext Size: %{customdata[2]}\u003cbr\u003eInput Token $\u002f1M: %{customdata[3]}\u003cbr\u003eOutput Token $\u002f1M: %{customdata[4]}\u003cbr\u003eAvg Price $\u002f1M: %{x}","legendgroup":"OpenAI","marker":{"color":"#ab63fa","pattern":{"shape":""}},"name":"OpenAI","offsetgroup":"OpenAI","orientation":"h","showlegend":true,"textposition":"auto","x":[1.5,1.75,20.0,20.0,45.0,90.0],"xaxis":"x","y":["OpenAI-gpt-3.5-turbo-1106","OpenAI-gpt-3.5-turbo-turbo-instruct","OpenAI-gpt-4-1106-preview","OpenAI-gpt-4-1106-vision-preview","OpenAI-gpt-4","OpenAI-gpt-4-32k"],"yaxis":"y","type":"bar"},{"alignmentgroup":"True","customdata":[["gemini-pro","GCP","32k",1.0,2.0],["palm2","GCP","8k",2.0,2.0]],"hovertemplate":"Model: %{customdata[0]}\u003cbr\u003eProvider: %{customdata[1]}\u003cbr\u003eContext Size: %{customdata[2]}\u003cbr\u003eInput Token $\u002f1M: %{customdata[3]}\u003cbr\u003eOutput Token $\u002f1M: %{customdata[4]}\u003cbr\u003eAvg Price $\u002f1M: %{x}","legendgroup":"GCP","marker":{"color":"#FFA15A","pattern":{"shape":""}},"name":"GCP","offsetgroup":"GCP","orientation":"h","showlegend":true,"textposition":"auto","x":[1.5,2.0],"xaxis":"x","y":["GCP-gemini-pro","GCP-palm2"],"yaxis":"y","type":"bar"},{"alignmentgroup":"True","customdata":[["gpt-3.5-turbo-4k","Azure","4k",1.5,2.0],["gpt-3.5-turbo-16k","Azure","16k",3.0,4.0],["gpt-4-8k","Azure","8k",30.0,60.0],["gpt-4-32k","Azure","32k",60.0,120.0]],"hovertemplate":"Model: %{customdata[0]}\u003cbr\u003eProvider: %{customdata[1]}\u003cbr\u003eContext Size: %{customdata[2]}\u003cbr\u003eInput Token $\u002f1M: %{customdata[3]}\u003cbr\u003eOutput Token $\u002f1M: %{customdata[4]}\u003cbr\u003eAvg Price $\u002f1M: %{x}","legendgroup":"Azure","marker":{"color":"#19d3f3","pattern":{"shape":""}},"name":"Azure","offsetgroup":"Azure","orientation":"h","showlegend":true,"textposition":"auto","x":[1.75,3.5,45.0,90.0],"xaxis":"x","y":["Azure-gpt-3.5-turbo-4k","Azure-gpt-3.5-turbo-16k","Azure-gpt-4-8k","Azure-gpt-4-32k"],"yaxis":"y","type":"bar"}],                        {"template":{"data":{"histogram2dcontour":[{"type":"histogram2dcontour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"choropleth":[{"type":"choropleth","colorbar":{"outlinewidth":0,"ticks":""}}],"histogram2d":[{"type":"histogram2d","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmap":[{"type":"heatmap","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmapgl":[{"type":"heatmapgl","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"contourcarpet":[{"type":"contourcarpet","colorbar":{"outlinewidth":0,"ticks":""}}],"contour":[{"type":"contour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"surface":[{"type":"surface","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"mesh3d":[{"type":"mesh3d","colorbar":{"outlinewidth":0,"ticks":""}}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"parcoords":[{"type":"parcoords","line":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolargl":[{"type":"scatterpolargl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"scattergeo":[{"type":"scattergeo","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolar":[{"type":"scatterpolar","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"scattergl":[{"type":"scattergl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatter3d":[{"type":"scatter3d","line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermapbox":[{"type":"scattermapbox","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterternary":[{"type":"scatterternary","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattercarpet":[{"type":"scattercarpet","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"pie":[{"automargin":true,"type":"pie"}]},"layout":{"autotypenumbers":"strict","colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"hovermode":"closest","hoverlabel":{"align":"left"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"bgcolor":"#E5ECF6","angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"ternary":{"bgcolor":"#E5ECF6","aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]]},"xaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"yaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"geo":{"bgcolor":"white","landcolor":"#E5ECF6","subunitcolor":"white","showland":true,"showlakes":true,"lakecolor":"white"},"title":{"x":0.05},"mapbox":{"style":"light"},"margin":{"b":0,"l":0,"r":0,"t":30}}},"xaxis":{"anchor":"y","domain":[0.0,1.0],"title":{"text":"$\u002f1M tokens"}},"yaxis":{"anchor":"x","domain":[0.0,1.0],"title":{}},"legend":{"title":{"text":"Provider"},"tracegroupgap":0,"traceorder":"reversed"},"barmode":"relative"},                        {"responsive": true}                    ).then(function(){
                            
var gd = document.getElementById('778847f3-16db-44a6-b236-1ec64c8da3e1');
var x = new MutationObserver(function (mutations, observer) {{
        var display = window.getComputedStyle(gd).display;
        if (!display || display === 'none') {{
            console.log([gd, 'removed!']);
            Plotly.purge(gd);
            observer.disconnect();
        }}
}});

// Listen for the removal of the full notebook cells
var notebookContainer = gd.closest('#notebook-container');
if (notebookContainer) {{
    x.observe(notebookContainer, {childList: true});
}}

// Listen for the clearing of the current output cell
var outputEl = gd.closest('.output');
if (outputEl) {{
    x.observe(outputEl, {childList: true});
}}

                        })                };                });            </script>        </div>
</div>
</div>
<p>Hover over bars to see extra information (also available in table below). The prices for input and output tokens were averaged. For AWS, the region us-east-1 was used.</p>
<ul>
<li>Price differences are huge, with a 600x difference between the cheapest and most expensive models ($0.15 vs $90)</li>
<li>GPT-4 is the most expensive model, followed by GPT-3.5 and PaLM2</li>
<li>Prices on Azure and OpenAI are identical</li>
<li>Anyscale is the cheapest provider for large models, serving Mistral‚Äôs models at lower prices than Mistral itself</li>
<li>Prices roughly reflect the number of parameters in the models, which again roughly map to their capability</li>
</ul>
<p><a href="https://paperswithcode.com/sota/multi-task-language-understanding-on-mmlu">Papers with Code</a> has a leaderboard for the MMLU (Massive Multitask Language Understanding) benchmark. The <a href="https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard">HuggingFace OpenLLM Leaderboard</a> offers a more detailed ranking of open source models across different benchmarks. These leaderboards don‚Äôt have benchmarks for every model listed here.</p>
</section>
<section id="model-table" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="model-table">Model table</h2>
<p>Click on column headers to sort. On mobile, scroll right to see all columns.</p>
<div id="ea6ee759" class="cell page-columns page-full" data-execution_count="3">
<div class="cell-output cell-output-display column-screen">
<style>.itables table td {
    text-overflow: ellipsis;
    overflow: hidden;
}

.itables table th {
    text-overflow: ellipsis;
    overflow: hidden;
}

.itables thead input {
    width: 100%;
    padding: 3px;
    box-sizing: border-box;
}

.itables tfoot input {
    width: 100%;
    padding: 3px;
    box-sizing: border-box;
}
</style>
<div class="itables">

<table id="4434095c-1c67-4c0b-89c5-b77fe8a9c71c" class="display nowrap compact caption-top table table-sm table-striped small" data-quarto-postprocess="true">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th">Model</th>
<th data-quarto-table-cell-role="th">Provider</th>
<th data-quarto-table-cell-role="th">Developer</th>
<th data-quarto-table-cell-role="th">Context size</th>
<th data-quarto-table-cell-role="th">Input $/1M</th>
<th data-quarto-table-cell-role="th">Output $/1M</th>
<th data-quarto-table-cell-role="th">Avg. $/1M</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Loading... (need <a href="https://mwouts.github.io/itables/troubleshooting.html">help</a>?)</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>

<link rel="stylesheet" type="text/css" href="https://cdn.datatables.net/1.13.1/css/jquery.dataTables.min.css">
<script type="module">
    // Import jquery and DataTable
    import 'https://code.jquery.com/jquery-3.6.0.min.js';
    import dt from 'https://cdn.datatables.net/1.12.1/js/jquery.dataTables.mjs';
    dt($);

    // Define the table data
    const data = [["mistral-7b-openorca", "Anyscale", "Mistral", "32k", 0.15, 0.15, 0.15], ["mistral-7b-instruct", "Anyscale", "Mistral", "32k", 0.15, 0.15, 0.15], ["llama-guard-7b", "Anyscale", "Meta", "4k", 0.15, 0.15, 0.15], ["llama-2-7b-chat-hf", "Anyscale", "Meta", "4k", 0.15, 0.15, 0.15], ["llama-2-13b-chat-hf", "Anyscale", "Meta", "4k", 0.25, 0.25, 0.25], ["mistral-7b-instruct", "Mistral", "Mistral", "32k", 0.14, 0.42, 0.28], ["cohere-light", "AWS", "Cohere", "4k", 0.3, 0.6, 0.45], ["mixtral-8x7b-instruct", "Anyscale", "Mistral", "32k", 0.5, 0.5, 0.5], ["llama-2-chat-13b", "AWS", "Meta", "4k", 0.75, 1.0, 0.88], ["llama2-70b-chat-hf", "Anyscale", "Meta", "4k", 1.0, 1.0, 1.0], ["mixtral-8x7b-instruct", "Mistral", "Mistral", "32k", 0.6, 1.8, 1.2], ["gpt-3.5-turbo-1106", "OpenAI", "OpenAI", "16k", 1.0, 2.0, 1.5], ["gemini-pro", "GCP", "Google", "32k", 1.0, 2.0, 1.5], ["claude-instant", "AWS", "Anthropic", "100k", 0.8, 2.4, 1.6], ["claude", "AWS", "Anthropic", "100k", 0.8, 2.4, 1.6], ["gpt-3.5-turbo-turbo-instruct", "OpenAI", "OpenAI", "16k", 1.5, 2.0, 1.75], ["titan-text-express", "AWS", "AWS", "8k", 1.2, 2.3, 1.75], ["cohere-command", "AWS", "Cohere", "4k", 1.5, 2.0, 1.75], ["gpt-3.5-turbo-4k", "Azure", "OpenAI", "4k", 1.5, 2.0, 1.75], ["palm2", "GCP", "Google", "8k", 2.0, 2.0, 2.0], ["llama-2-chat-70b", "AWS", "Meta", "4k", 1.95, 2.56, 2.26], ["gpt-3.5-turbo-16k", "Azure", "OpenAI", "16k", 3.0, 4.0, 3.5], ["mistral-medium", "Mistral", "Mistral", "32k", 2.5, 7.5, 5.0], ["jurassic-2-mid", "AWS", "AI21 Labs", "8k", 12.5, 12.5, 12.5], ["jurassic-2-ultra", "AWS", "AI21 Labs", "8k", 18.8, 18.8, 18.8], ["gpt-4-1106-preview", "OpenAI", "OpenAI", "128k", 10.0, 30.0, 20.0], ["gpt-4-1106-vision-preview", "OpenAI", "OpenAI", "128k", 10.0, 30.0, 20.0], ["gpt-4", "OpenAI", "OpenAI", "8k", 30.0, 60.0, 45.0], ["gpt-4-8k", "Azure", "OpenAI", "8k", 30.0, 60.0, 45.0], ["gpt-4-32k", "OpenAI", "OpenAI", "32k", 60.0, 120.0, 90.0], ["gpt-4-32k", "Azure", "OpenAI", "32k", 60.0, 120.0, 90.0]];

    // Define the dt_args
    let dt_args = {"columnDefs": [{"targets": [3, 4, 5, 6], "className": "dt-right"}, {"targets": [4, 5, 6], "render": $.fn.dataTable.render.number(',', '.', 2)}], "order": [[6, "desc"]], "paging": false, "dom": "tpr"};
    dt_args["data"] = data;

    $(document).ready(function () {
        
        $('#4434095c-1c67-4c0b-89c5-b77fe8a9c71c').DataTable(dt_args);
    });
</script>
</div>
</div>
</div>
</section>
<section id="sources" class="level2">
<h2 class="anchored" data-anchor-id="sources">Sources</h2>
<section id="pricing-pages" class="level3">
<h3 class="anchored" data-anchor-id="pricing-pages">Pricing pages</h3>
<ul>
<li><a href="https://openai.com/pricing">OpenAI Pricing</a></li>
<li><a href="https://docs.mistral.ai/platform/pricing/">Mistral AI Pricing</a></li>
<li><a href="https://docs.endpoints.anyscale.com/pricing/">AnyScale Pricing</a></li>
<li><a href="https://aws.amazon.com/bedrock/pricing/">AWS Bedrock Pricing</a></li>
<li><a href="https://azure.microsoft.com/de-de/pricing/details/cognitive-services/openai-service/">Azure Cognitive Services - OpenAI Service Pricing</a></li>
</ul>
</section>
<section id="context-size-information" class="level3">
<h3 class="anchored" data-anchor-id="context-size-information">Context size information</h3>
<ul>
<li><a href="https://docs.mistral.ai/platform/endpoints/">Mistral AI Endpoints</a></li>
<li><a href="https://www.anthropic.com/index/100k-context-windows">Anthropic 100k Context Windows</a></li>
<li><a href="https://huggingface.co/HuggingFaceH4/zephyr-7b-beta/discussions/13">Zephyr-7B Beta Discussion on HuggingFace</a></li>
<li><a href="https://www.maginative.com/article/mistral-ai-launches-platform-services#:~:text=Mistral%2Dtiny%3A%20The%20most%20cost,where%20cost%20efficiency%20is%20paramount">Mistral AI Launches Platform Services</a></li>
<li><a href="https://aws.amazon.com/bedrock/cohere-command-embed/">AWS Bedrock Cohere Command Embed</a></li>
<li><a href="https://aws.amazon.com/marketplace/pp/prodview-ivk4wjg6gbr26#:~:text=Pre%2Dtrained%20language%20model%20trained,be%20at%20most%208192%20tokens">AWS Marketplace ‚Äì Pretrained Language Model</a></li>
<li><a href="https://aws.amazon.com/marketplace/ppprodview-irdbpdk5v5p5g#:~:text=This%20model%20has%20a%208192,among%20the%20top%20LLM%20models">AWS Marketplace ‚Äì Top LLM models</a></li>
<li><a href="https://aws.amazon.com/machine-learning/responsible-machine-learning/titan-text/">AWS Responsible Machine Learning -Titan Text</a></li>
</ul>


</section>
</section>

 ]]></description>
  <category>Machine Learning</category>
  <category>Cloud</category>
  <category>Economics</category>
  <guid>https://simmering.dev/blog/llm-price-performance/</guid>
  <pubDate>Wed, 10 Jan 2024 23:00:00 GMT</pubDate>
  <media:content url="https://simmering.dev/blog/llm-price-performance/image.png" medium="image" type="image/png" height="106" width="144"/>
</item>
<item>
  <title>The Grug Brained Data Scientist</title>
  <dc:creator>Paul Simmering</dc:creator>
  <link>https://simmering.dev/blog/data-grug/</link>
  <description><![CDATA[ 





<p><a href="https://grugbrain.dev">The Grug Brained Developer</a> is a funny essay on advice for software developers. The lessons resonated with me. This is my own version, geared towards data professionals.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/data-grug/grug.png" class="img-fluid figure-img"></p>
<figcaption>grug and the demons - made with DALL-E</figcaption>
</figure>
</div>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>this collection of data science thoughts. good for young grugs that liked The Grug Brained Developer and now want more into data</p>
<p>grug data scientist not understand all but try many thing and fail and learn and do better over time and share what not awful</p>
</section>
<section id="complexity-bad-in-data-science-too" class="level2">
<h2 class="anchored" data-anchor-id="complexity-bad-in-data-science-too">Complexity bad in data science too</h2>
<p>data science much complex. many thing go wrong, invisible to grug</p>
<p>complexity bad, make grug‚Äôs brain hurt and cause mistakes that bite grug later</p>
<p>some complexity necessary to solve business problem. that is grug‚Äôs job. but grug must not add complexity that not needed</p>
</section>
<section id="data-quality" class="level2">
<h2 class="anchored" data-anchor-id="data-quality">Data quality</h2>
<p>data quality most important. if data bad, model bad. if model bad, prediction bad. if prediction bad, business bad, so no shiny rocks for grug</p>
<p>bad data is demon of data sciencing. is sneaky demon that hides in data and makes grug look bad, or worse, give bad info to business shamans. many shiny rocks lost to bad data</p>
<p>grug likes being close to data. but big brain data tools hide data and make it hard for grug to look at tables. grug like to look at tables. grug finds problems in data by looking at tables</p>
<p>grug work in data warehouse for years and when grug smells a stink, grug look at tables and find problem. when grug ignores stink and not look at tables, grug always regret</p>
<p>but projects have many tables and grug busy. so grug must automate look at tables. data quality framework check if data is missing, is in wrong format, or is out of range and if foreign keys are valid</p>
<p>best guarantee comes from enforced constraints in database. constraints always on guard and never sleep</p>
<p>but analytics databases are too lazy to enforce constraints. so grug must use data quality framework to check data. grug not like this but best grug can do</p>
</section>
<section id="data-problem-needs-data-solution" class="level2">
<h2 class="anchored" data-anchor-id="data-problem-needs-data-solution">Data problem needs data solution</h2>
<p>grugs tempted to use complex methods to fix problem of missing data and other stink. but better to fix at source</p>
<p>if data is bad, fix data</p>
<p>say again: <em>if data is bad, fix data</em></p>
<p>to fix data, grugs need talk other grugs and business shamans. much wait. but must endure and fix data. tempting, use code to fix. very bad idea</p>
</section>
<section id="counting-things" class="level2">
<h2 class="anchored" data-anchor-id="counting-things">Counting things</h2>
<p>grug like to count things. when data quality nice, counting things already good enough to make business shamans happy. grug can count anything: users, orders, clicks, shiny rocks collected and more. grug can also separate counting by time, location, and other things</p>
<p>counting easy to do and fit into brain</p>
</section>
<section id="visualization" class="level2">
<h2 class="anchored" data-anchor-id="visualization">Visualization</h2>
<p>bar chart is grug‚Äôs best friend forever. grug can make bar chart of anything. easy for business shamans and grug to understand</p>
<p>complex chart like network graph or tree map or radar chart too hard to understand. message get lost in complexity</p>
<p>pie chart and word cloud look easy but cause misunderstanding. almost always better to use bar chart. sometimes business shamans ask for pie chart, and when pie has few slices, is ok. when pie has many slices, grug must say no</p>
</section>
<section id="machine-learning" class="level2">
<h2 class="anchored" data-anchor-id="machine-learning">Machine learning</h2>
<p>machine learning is powerful tool and unlocker of many shiny rocks. grug understands is not magic and not always best tool for job</p>
<p>big brains use complex machine learning models to solve problem that can be solved with simple model. like to show off big brain</p>
<p>this very bad because big model cost many shiny rocks for train and run. grug can‚Äôt look into big model to see what is doing and grug can‚Äôt explain big model to business shamans</p>
<p>some hard problem can only be solved with big model. then grug must use big model</p>
<p>grug likes reproducible model training and evaluation. grug and colleagues need to retrain models and compare. easy to forget settings and which data was used. brain limited. better to have tool that logs everything</p>
<p>last few years many big model change grug‚Äôs life. grug can now do things that grug could not before. big brains work very fast to make big model better and better. grug very happy about this and grug hope big brains keep doing this</p>
<p>grug prepares for new big model to change. grug knows: model come and go. model is not forever. new model will come and make old model look bad</p>
</section>
<section id="performance-and-productivity" class="level2">
<h2 class="anchored" data-anchor-id="performance-and-productivity">Performance and productivity</h2>
<p>when grug has to wait for model to train or database to query, grug gets bored and grug‚Äôs brain wanders. bad for grug‚Äôs productivity. make business shamans impatient too</p>
<p>data exploration and model experimentation is more fun when machine goes brrrr rather than when machine goes zzzzz. so when slow, grug uses performance profiling tools to find bottleneck</p>
<p>caching grug‚Äôs #2 best friend. grug ask for same thing many times. indexing also good friend</p>
<p>cloud development twisted concept. cloud scales in production - nice! but bad for developer experience. write code on laptop, package, upload, and wait for cloud to run. very slow and tiny bug that grug could fix in 1 minute takes long time. grug look for ways to develop locally or with quick feedback loop. setup can be headache but worth it!</p>
</section>
<section id="expanding-the-grug-brain" class="level2">
<h2 class="anchored" data-anchor-id="expanding-the-grug-brain">Expanding the grug brain</h2>
<p>grug‚Äôs brain too small and grug too busy to keep up with all new shiny toys. grug must choose which shiny toys to learn</p>
<p>popular data shamans have new toys every day and promise that new toys will solve all problems. grug not always believe this. but some tools are actually good. so grug must choose wisely</p>
<p>learn evergreen skills - always good idea. grug loves SQL because SQL was good for shiny rock collection for decades and will be good for long time more. many new toys use SQL so grug can use SQL with new toys</p>
<p>grug wants to have brain shaped like letter T. grug wants to know basics of many things and aspires to big brain in one thing</p>
<p>always need data quality and visualization and model evaluation. these are basic demon defense skills that every grug must have. cloud also good</p>
<p>to get more shiny rocks, grug must be extra good at one more thing, like model deepthink or huge data organization or business shaman rituals</p>
<p>some grugs identify by their tools. grug is wary of this. grug is grug, not Spark grug or Snowflake grug or AWS grug. when grug join new shiny rock mine, grug will use tool that other grugs use</p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>good data better than complex pipeline</p>


</section>

 ]]></description>
  <category>Advice</category>
  <guid>https://simmering.dev/blog/data-grug/</guid>
  <pubDate>Fri, 08 Dec 2023 23:00:00 GMT</pubDate>
  <media:content url="https://simmering.dev/blog/data-grug/grug.png" medium="image" type="image/png" height="82" width="144"/>
</item>
</channel>
</rss>
