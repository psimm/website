<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Paul Simmering&#39;s Blog</title>
<link>https://simmering.dev/blog.html</link>
<atom:link href="https://simmering.dev/blog.xml" rel="self" type="application/rss+xml"/>
<description>Data science, machine learning and developer productivity.</description>
<language>en</language>
<generator>quarto-1.8.26</generator>
<lastBuildDate>Sat, 14 Feb 2026 23:00:00 GMT</lastBuildDate>
<item>
  <title>From Vibe Coding to Agentic Engineering</title>
  <dc:creator>Paul Simmering</dc:creator>
  <link>https://simmering.dev/blog/agentic-engineering/</link>
  <description><![CDATA[ 






<p>The term <em>vibe coding</em> just turned one. Andrej Karpathy, who <a href="https://x.com/karpathy/status/1886192184808149383?lang=de">coined</a> it in February 2025 and long preferred autocomplete over agents, flipped to 80% agentic coding in <a href="(https://x.com/karpathy/status/2015883857489522876)">January 2026</a>. Agentic coding has leveled up massively: Claude 4.5 Opus reached 80.9% on <a href="https://www.swebench.com">SWE-bench Verified</a>, better harnesses enable longer runs and multi-agent collaboration, and we have new apps such as Codex for controlling them.</p>
<p>In 2023, I reported on my first experiences with AI assistance and the <a href="https://simmering.dev/blog/ai-assistants/">post</a> is now a window into a quaint past. The problems I noticed then were fixed by better tools. Now developers need to catch up on how to use them. New practices under the banner of <em>agentic engineering</em> are emerging. This article is a framework for using coding agents professionally: five coding styles with different tradeoffs between speed, control and learning, followed by practical techniques for context engineering and harness design. It also confronts an uncomfortable finding from recent research: AI boosts output but erodes understanding, creating <em>cognitive debt</em>.</p>
<section id="five-coding-styles" class="level2">
<h2 class="anchored" data-anchor-id="five-coding-styles">Five coding styles</h2>
<p>The improvements in AI assistance and automation tools have enabled new styles of coding. I’m classifying them into distinct styles, which I’ve rated in terms of speed, control and learning, the main tradeoffs I see in choosing a style.</p>
<ul>
<li><strong>Speed</strong>: How fast you complete the code. I mean the time taken for a single change, not development velocity over the long run.</li>
<li><strong>Control</strong>: How many of the decisions involved you make rather than delegate to an AI. This involves the architecture level and the micro level of individual lines of code or chunks like functions and classes. Reviewing code doesn’t give the same control as creating it from scratch, as it anchors on the AI’s choices.</li>
<li><strong>Learning</strong>: How much you advance your own coding skills and knowledge of the project. Experiments from <a href="https://www.anthropic.com/research/AI-assistance-coding-skills">Anthropic</a>, <a href="https://www.media.mit.edu/publications/your-brain-on-chatgpt/">MIT</a> and <a href="https://www.nature.com/articles/s41598-025-98385-2">Zhejiang University</a> found that knowledge workers using AI have enhanced results, but that the gain doesn’t carry over when working alone afterward. Further, they don’t retain as much information and report lower sense of ownership. The MIT study coins this condition <em>cognitive debt</em>. <a href="https://margaretstorey.com/blog/2026/02/09/cognitive-debt/">Margaret-Anne Storey</a> from the University of Victoria relates it back to coding as a new type of debt that projects accumulate when developer’s understanding doesn’t keep up with growing complexity.</li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Style</th>
<th>Speed</th>
<th>Control</th>
<th>Learning</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>No AI</td>
<td>●○○○○</td>
<td>●●●●●</td>
<td>●●●●●</td>
</tr>
<tr class="even">
<td>Autocomplete</td>
<td>●●○○○</td>
<td>●●●●○</td>
<td>●●●●○</td>
</tr>
<tr class="odd">
<td>Single agent</td>
<td>●●●○○</td>
<td>●●●○○</td>
<td>●●○○○</td>
</tr>
<tr class="even">
<td>Multi agent for parallel features</td>
<td>●●●●●</td>
<td>●○○○○</td>
<td>●○○○○</td>
</tr>
<tr class="odd">
<td>Multi agent for exploration</td>
<td>●●○○○</td>
<td>●●●○○</td>
<td>●●●●○</td>
</tr>
</tbody>
</table>
<p>The ratings are my subjective view and outcomes depend on how exactly a style is performed. For instance, asking the agent questions about its implementation can boost learning again. Ownership could be a fourth aspect, but its ratings would highly correlate with control and learning. I don’t list copy-pasting into a chatbot as a viable style, because it’s so inefficient in comparison to the others.</p>
<section id="no-ai" class="level3">
<h3 class="anchored" data-anchor-id="no-ai">No AI</h3>
<p>Manual coding speed is highly dependent on how well a developer has memorized the programming language they’re using. Writing code manually repeats the basics such as loops, conditions and indexing over and over. You solve small logic problems all the time and become fluent in a programming language. After writing a piece of code, you know the ins and outs of it.</p>
<p><strong>Strengths:</strong> learning on micro and macro level, drilling the basics, control, ownership</p>
<p><strong>Weaknesses:</strong> slow, limited to familiar programming languages, high cognitive load</p>
</section>
<section id="autocomplete" class="level3">
<h3 class="anchored" data-anchor-id="autocomplete">Autocomplete</h3>
<p>Using the autocomplete with a coding extension for an IDE or a VSCode fork provides a very nice speed boost. You can skip over the common small logic problems. Knowing the language is still important. Autocomplete also doesn’t do architecture, it focuses on the micro. As the generated code comes in small chunks, developers naturally check it as they go.</p>
<p>The speed of the coding model is critical for this style; if you have to wait, the flow state is broken. The recent <a href="https://openai.com/index/introducing-gpt-5-3-codex-spark/">GPT-5.3-Codex-Spark</a> is promising near-instant answers with decent intelligence.</p>
<p>Early on, I used to write comments specifically to trigger the autocomplete to write the implementation. With agents that take direct prompts as an instruction, I wouldn’t recommend this specific technique anymore. Overall I see autocomplete as a nicely balanced style.</p>
<p><strong>Strengths:</strong> speed up over manual coding, good control</p>
<p><strong>Weaknesses:</strong> not as fast as agents, less learning on micro level</p>
</section>
<section id="single-agent" class="level3">
<h3 class="anchored" data-anchor-id="single-agent">Single agent</h3>
<p>Write a prompt, perhaps use planning mode and let a CLI agent or an agent embedded in an IDE go off reading docs, writing code and running tests until it reports back with a result. I’ll share productivity tips in a section below.</p>
<p><strong>Strengths:</strong> fast, work in unfamiliar languages</p>
<p><strong>Weaknesses:</strong> loss of ownership, control and learning, wait for agent to complete</p>
</section>
<section id="multi-agent-for-parallel-features" class="level3">
<h3 class="anchored" data-anchor-id="multi-agent-for-parallel-features">Multi agent for parallel features</h3>
<p>Kick off multiple agents, each working on a different task. This is a style favored by Peter Steinberger, developer of OpenClaw, famously programming from his smartphone. I tried it with OpenAI’s Codex app for a React + NextJS side project and found that I could run the app in a browser, write instructions to Codex and see the update in real time. It completely moved my focus to the app’s functionality and UX, rather than the code. This generated an ungodly amout of changes that I dreaded to review, so I kept vibing instead.</p>
<p>This is fantastic for hackathons, demos and experiments. Personally, I don’t feel confident doing this for a serious project, where I am responsible for each line of code. I’d also run out of token budget before the end of the month.</p>
<p><strong>Strengths:</strong> absurdly fast</p>
<p><strong>Weaknesses:</strong> extreme loss of ownership, control and learning, token usage</p>
</section>
<section id="multi-agent-for-exploration" class="level3">
<h3 class="anchored" data-anchor-id="multi-agent-for-exploration">Multi agent for exploration</h3>
<p>Kick off multiple agents to do the same task independently, then review their solutions and pick the best one. This makes sense for complex tasks with many possible solutions that have advantages and drawbacks that only become clear during implementation.</p>
<p>Cursor implements this explicitly by letting you compare the results of different models.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/agentic-engineering/cursor.webp" class="img-fluid figure-img"></p>
<figcaption>Cursor’s multi agent interface</figcaption>
</figure>
</div>
<p>This is a rare, but promising style that I haven’t built much experience with yet.</p>
<p><strong>Strengths:</strong> can improve quality of architecture, learning on the macro level</p>
<p><strong>Weaknesses:</strong> time consuming to review, loss of learning on micro level, token usage</p>
</section>
</section>
<section id="optimizing-agent-productivity" class="level2">
<h2 class="anchored" data-anchor-id="optimizing-agent-productivity">Optimizing agent productivity</h2>
<p>Let’s look at how exactly we can get maximum productivity from agentic engineering and the best ways to stay in control of the macro while delegating the micro.</p>
<section id="plan-mode" class="level3">
<h3 class="anchored" data-anchor-id="plan-mode">Plan mode</h3>
<p>Everything you don’t specify has to be guessed by the LLM. That’s similar to a stakeholder formulating a business requirement and a developer having to fill in all the technical details. For complex changes, I’m a fan of <em>plan mode</em>, where the agent answers with a to do list, rather than jumping into action. It’s a forcing function for clarity and a dedicated place for the developer to review architecture. If the plan doesn’t match what you meant, you catch it in 30 seconds instead of 10 minutes reviewing generated code. That’s also token-efficient.</p>
<p>Simple changes don’t need plan mode, but if I already know how I want something implemented, I’ll mention it in the prompt, e.g.&nbsp;“implement this with an env var” or “upsert the entry to the database”. For UI, pasting screenshots of your own app or inspirations works surprisingly well.</p>
<p>Keep in mind that LLMs are still optimized to please. Current leaders aren’t quite as sycophantic as the notorious GPT-4o, but they’re still not pushing back on bad ideas like a real senior engineer would. If you ask an LLM to find a bug, it will try really hard to constitute a bug, whether there is one or not. If you ask whether something could be simpler, it will try to simplify that bit, perhaps at the expense of complexity elsewhere.</p>
</section>
<section id="context-engineering-by-example" class="level3">
<h3 class="anchored" data-anchor-id="context-engineering-by-example">Context engineering by example</h3>
<p>Context engineering is the art of managing the LLM’s context window and seeding it with all relevant information at the start of an interaction. The best context engineering doesn’t happen in the prompt, but in the code base:</p>
<ul>
<li>Making the project <em>agent legible</em> helps, i.e.&nbsp;using a monorepo, paying attention to consistent variable names and co-locating related information such as content and style using Tailwind CSS.</li>
<li>Existing code serves as examples of how to write. Agents are great at picking up patterns and repeating them. For example, if existing code has full test coverage, an agent will likely write a test for new code as well.</li>
<li>Readmes and other notes explain the purpose of the project, conventions and instructions to run it. Anything that helps a new hire also helps an agent. Rule files like <code>copilot-instructions.md</code> or <code>AGENTS.md</code> are more specifically aimed at agents. Effort invested here is leveraged by every agent run. Less is more: a few well maintained rules beat an overstuffed and rotting tome. Turning <code>AGENTS.md</code> into a table of contents linking to other notes worked well for a large AI engineering project by <a href="https://openai.com/index/harness-engineering/">OpenAI</a>. They took it further with custom linters by the principle: “Human taste is captured once, then enforced continuously on every line of code”. The emphasis is on <em>human taste</em>: Using an LLM to generate the instructions defeats the point. An <a href="https://arxiv.org/pdf/2602.11988">benchmark study</a> about solving Python Github issues found that LLM-generated <code>AGENTS.md</code> actually marginal decreased agent performance while increasing token usage by 20%.</li>
</ul>
<p>These help with the intial context loading. Later, as the chat fills with prompts and responses, it’s important to be mindful of context window size and purity. Wrong information and failed attempts mislead LLMs. Claude’s phrase “You’re absolutely right” has become a meme because of this. When you see it, your context is rotten, and it’s time to start a new thread. One way to wrap up a thread is manual compaction: asking the LLM to summarize the problem, what it has tried and learned. The answer can be both educational and useful as a starting point for a new attempt. Anthropic has a full <a href="https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents">guide</a> on context engineering for agents.</p>
</section>
<section id="harness-engineering" class="level3">
<h3 class="anchored" data-anchor-id="harness-engineering">Harness engineering</h3>
<p>Beyond context, you’re designing the agent’s development environment: the information it gets, the tools to unblock itself, and the guidance that keeps it aligned with your plans. Models are trained to hill-climb via RLHF and don’t give up easily, but they need instruments and feedback. Watch for situations where the LLM is blind to a problem and add the tools it needs to resolve problems without human intervention.</p>
<p>Among tooling, type checking deserves special mention: it lets agents easily catch errors statically. <a href="https://www.youtube.com/watch?v=iV1EcfZSdCM&amp;pp=0gcJCZEKAYcqIYzv">Theo Browne</a> makes a strong case for TypeScript as an optimal language for agentic coding, as it guarantees type safety in frontend, backend and on their interfaces. <a href="https://honnibal.dev/blog/llm-style-tips">Matt Honnibal</a> gives practical Python advice focused on type safety and testability through pure functions. Linters, unit tests and tools to let agents look at the app’s UI are also important.</p>
<p>The most ambitious projects take multi-agent setups and long runs that span multiple context windows with compaction steps. Anthropic’s <a href="https://www.anthropic.com/engineering/effective-harnesses-for-long-running-agents">guide on effective harnesses</a> covers failure modes and fixes, <a href="https://openai.com/index/harness-engineering">OpenAI’s case study</a> is another good read. This is the forefront of agentic engineering.</p>
</section>
</section>
<section id="staying-in-control" class="level2">
<h2 class="anchored" data-anchor-id="staying-in-control">Staying in control</h2>
<section id="resisting-fragmentation" class="level3">
<h3 class="anchored" data-anchor-id="resisting-fragmentation">Resisting fragmentation</h3>
<p>While an AI chat window formally places the user in control, the dynamic can flip in practice: agents going off making unwanted changes, notifications interrupting the user’s work and the user becoming the agent’s QA help. It’s also easy to get lazy and let the agent do all the thinking.</p>
<p>Developers reporting on their experience emphasize controlling the dynamic:</p>
<blockquote class="blockquote">
<p>Try to avoid workflow loops where you go off and do things, paste the error back into the LLM, and then go do whatever it tells you. I’ve seen this anti-pattern called a “reverse centaur”: you want to be the head of the human/horse hybrid, not the ass. – Matt Honnibal</p>
</blockquote>
<blockquote class="blockquote">
<p>“I found that it was my job as a human to be in control of when I interrupt the agent, not the other way around.” – Mitchell Hashimoto</p>
</blockquote>
<p>Keeping agents running in the background while you’re working on something else is efficient, but can also be exhausting context switching. A <a href="https://hbr.org/2026/02/ai-doesnt-reduce-work-it-intensifies-it">study</a> tracking AI use at a tech company found that AI use increased multitasking, such as manually coding while orchestrating agents working on other tasks. Workers reported increased cognitive fatigue as they took on extra tasks outside of their core competence and filled natural breaks with AI usage.</p>
</section>
<section id="taking-responsibility" class="level3">
<h3 class="anchored" data-anchor-id="taking-responsibility">Taking responsibility</h3>
<p>Opening a pull request is saying: I believe this code is good enough to be merged and is worthy of the reviewer’s time. But popular open source projects are facing an onslaught of low quality vibe coded pull request. As a consequence, <a href="https://github.com/ghostty-org/ghostty/pull/10412">new norms</a> about AI-generated code are forming. Maintainers are rightfully angry when someone expects them to review an AI-generated mess. Reviewing is harder than generating.</p>
<p>The solution is to increase the burden of proof in regards to relevance and correctness. Simon Willison <a href="https://simonwillison.net/2025/Dec/18/code-proven-to-work/">wrote</a>: “Your job is to deliver code you have proven to work” and suggests more comprehensive tests, screenshots or even a video attached to the PR. I’d add that it’s also a developer’s job to understand the code and be able to answer questions about it during review.</p>
<p>Part of packaging code up for review is using Git. I find that staging changes for a commit is a natural point for human control to review generated code. Conceding git control to agents would remove this valuable loop.</p>
</section>
</section>
<section id="theres-no-going-back" class="level2">
<h2 class="anchored" data-anchor-id="theres-no-going-back">There’s no going back</h2>
<p>Some are <a href="https://world.hey.com/dhh/promoting-ai-agents-3ee04945">exhilarated</a> with new possiblities, others are <a href="https://nolanlawson.com/2026/02/07/we-mourn-our-craft/">mourning</a> the loss of their craft, still others are <a href="https://ezhik.jp/ai-slop-terrifies-me/">concerned</a> that we’re about to enter a new era of slop. What they agree on is that software engineering is changed forever. Even if LLMs never become better than today, which is unlikely, just better tooling will keep getting us better coding agents.</p>
<p>Based on Anthropic’s <a href="https://www.anthropic.com/research/estimating-productivity-gains">estimates</a>, the programmers cited in this article and my own experience, agentic engineering is a 2x or greater speed-up for experienced developers. It’s also an enabler for beginners. But as the studies discussed above have shown, they’re also a trap for cognitive debt and loss of craftsmanship. It’s a challenge for both individual developers and organizations to find work patterns and shared expectations that get the best of both worlds, classic and agentic software engineering.</p>


</section>

 ]]></description>
  <category>Productivity</category>
  <category>Agents</category>
  <guid>https://simmering.dev/blog/agentic-engineering/</guid>
  <pubDate>Sat, 14 Feb 2026 23:00:00 GMT</pubDate>
  <media:content url="https://simmering.dev/blog/agentic-engineering/image.webp" medium="image" type="image/webp"/>
</item>
<item>
  <title>The Reliability Gap: Agent Benchmarks for Enterprise</title>
  <dc:creator>Paul Simmering</dc:creator>
  <link>https://simmering.dev/blog/agent-benchmarks/</link>
  <description><![CDATA[ 






<section id="unrealized-potential-due-to-lacking-reliability" class="level2">
<h2 class="anchored" data-anchor-id="unrealized-potential-due-to-lacking-reliability">Unrealized potential due to lacking reliability</h2>
<p>A 2025 survey by <span class="citation" data-cites="panMeasuringAgentsProduction2025">Pan et al. (2025)</span> among 306 AI agent practitioners found that reliability issues are the biggest barrier to adoption of AI agents in enterprise. To achieve the reliability required, practitioners are foregoing open-ended and long-running tasks in favor of workflows involving fewer steps. They control potential damage by building internal facing agents whose work is reviewed by internal employees, rather than customer facing or machine-to-machine interfaces. These limited agents are economically useful, but don’t realize the full potential.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/agent-benchmarks/reliability_gap.webp" class="img-fluid figure-img"></p>
<figcaption>Image created with GPT Image 1.5</figcaption>
</figure>
</div>
<p>To quantify how large the reliability gap towards the full potential is, I’ll review public benchmarks for agentic AI. In October 2025, <span class="citation" data-cites="schmidAIAgentBenchmarkCompendium2025">Schmid (2025)</span> listed over 50 benchmarks. That’s too many to pay attention to, so in this article I’ll prioritize them from the perspective of an enterprise looking to automate common business tasks.</p>
<section id="benchmark-selection-criteria" class="level3">
<h3 class="anchored" data-anchor-id="benchmark-selection-criteria">Benchmark selection criteria</h3>
<ol type="1">
<li><strong>Relevance</strong>. Tests abilities relevant for business use cases, ideally the exact task that the enterprise is looking to automate.</li>
<li><strong>Agentic</strong>. Measures agentic abilities with multiple turns and tool use, not just single turn reasoning.</li>
<li><strong>Best in class</strong>. The benchmark is not overshadowed by a more comprehensive benchmark measuring the same or closely related ability or a newer version of the same benchmark.</li>
<li><strong>Leaderboard</strong>. A benchmark needs a public leaderboard with up-to-date models listed. This disqualifies the majority of benchmarks. Most are published as a paper with a few model scores, which are quickly outdated.</li>
</ol>
<div class="callout callout-style-default callout-note callout-titled" title="Interpreting agentic benchmarks">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Interpreting agentic benchmarks
</div>
</div>
<div class="callout-body-container callout-body">
<p>Benchmark results are sensitive to the language model, the agentic loop code, tools available to the agent including their documentation, the benchmark harness (the environment in which the agent is evaluated), the evaluation method and random variations. Each score reflects a snapshot of all of these variables.</p>
<p>In addition to regular percentages of correctly completed tasks, benchmarks sometimes use two other metrics:</p>
<ul>
<li><strong>pass@k</strong> (pronounced “pass at k”): the probability of passing at least one of k runs. In other words, whether the agent is capable of succeeding at all if you let it try many times.</li>
<li><strong>pass^k</strong> (pronounced “pass wedge k”): the probability of passing on all k runs of the same task. In other words, how many times you can expect the agent to succeed if you run it k times. Measured empirically by running each task k times and counting what fraction pass all attempts. Steeper decline indicates less consistent performance across runs.</li>
</ul>
<p>From the lens of business automation, pass^k is more relevant. Unfortunately, most benchmarks only report pass^1, not higher pass^k metrics. Other important metrics that are not always reported are the time required to complete the task and the cost incurred in terms of input and output tokens. BFCL is an example of a benchmark that reports these metrics.</p>
<p>Benchmarks often have problems on release and are improved over time. For example, the original SWE-bench (2024) had ~68% of tasks that were unsolvable due to underspecified problems or unfair tests, leading to SWE-bench Verified’s human validation process.</p>
<p><span class="citation" data-cites="shankarUnderstandingAIBenchmarks2025">Shankar (2025)</span> goes into more detail on benchmark interpretation.</p>
</div>
</div>
</section>
</section>
<section id="key-benchmarks-for-evaluating-agents-for-enterprise-use" class="level2">
<h2 class="anchored" data-anchor-id="key-benchmarks-for-evaluating-agents-for-enterprise-use">Key benchmarks for evaluating agents for enterprise use</h2>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Benchmark</th>
<th>Task</th>
<th>Best pass^1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>GAIA</td>
<td>Answer questions using tools and web</td>
<td>90% (SU Zero agent)</td>
</tr>
<tr class="even">
<td>BFCL V3</td>
<td>Call functions correctly</td>
<td>77% (Claude Opus 4.5)</td>
</tr>
<tr class="odd">
<td>τ²-bench</td>
<td>Serve customers with policy compliance</td>
<td>85% (Gemini 3 Pro)</td>
</tr>
<tr class="even">
<td>Vending-Bench 2</td>
<td>Run a business over many turns</td>
<td>$5,478 (Gemini 3 Pro)</td>
</tr>
</tbody>
</table>
<p>I have selected these featured benchmarks based on the criteria listed above. Click on the benchmark name to learn more about each of the featured benchmarks. The scores here are pass^1. Only τ²-bench systematically reports pass^k metrics, though not for all entries. See its section for a detailed breakdown.</p>
<section id="specialty-benchmarks-with-narrower-focus" class="level3">
<h3 class="anchored" data-anchor-id="specialty-benchmarks-with-narrower-focus">Specialty benchmarks with narrower focus</h3>
<ul>
<li><strong>Coding</strong>: <a href="https://www.swebench.com/">SWE-bench verified</a>. Fix real GitHub issues from Python repositories. While highly relevant for evaluating coding capabilities, most enterprises will adopt existing AI coding tools (Claude Code, GitHub Copilot, Cursor) rather than develop custom coding agents. Leading score: 74.4% (Claude Opus 4.5, end of 2025).</li>
<li><strong>Web automation</strong>: <a href="https://webarena.dev/">WebArena</a>, <a href="https://osu-nlp-group.github.io/Mind2Web/">Mind2Web</a>. Navigate and complete tasks on real websites. Web browsing is partially covered in GAIA.</li>
<li><strong>GUI automation</strong>: <a href="https://os-world.github.io/">OSWorld</a>, <a href="https://github.com/zlwang-cs/OfficeBench">OfficeBench</a>, <a href="https://github.com/google-research/android_world">AndroidWorld</a>. Control Windows/Mac/Linux/Android via a graphical user interface. Only relevant if the agent must use a GUI instead of APIs. GUIs add a failure mode.</li>
<li><strong>Safety</strong>: <a href="https://scale.com/leaderboard/fortress">FORTRESS</a>. Tests safeguard robustness vs over-refusal. Important for production deployments but not the focus of this article.</li>
</ul>
</section>
<section id="which-types-of-agents-are-ready-for-enterprise-use" class="level3">
<h3 class="anchored" data-anchor-id="which-types-of-agents-are-ready-for-enterprise-use">Which types of agents are ready for enterprise use?</h3>
<p>Let’s consider a business that wants to automate a task. According to the survey of <span class="citation" data-cites="panMeasuringAgentsProduction2025">Pan et al. (2025)</span>, increasing productivity is the most common motivation. The baseline for accuracy is a human worker doing the task, who can also make mistakes. Unlike standard software, the expectation shouldn’t be 100% accuracy, but an acceptable trade-off for the benefits of automation. GAIA provides a human baseline of 92%, which is just 2 percentage points ahead of the best models.</p>
<p>I propose three stages of readiness:</p>
<ol type="1">
<li><strong>Internal tools</strong> reporting to humans, such as deep research, data analysis, information extraction, documentation and coding agents are ready now. The current highest scores for GAIA, BFCL and SWE-bench at the end of 2025 are 90%, 77.5% and 74.4%, respectively. Agents provide a profitable trade-off between accuracy and productivity. The time that humans spend checking results must be less than the time savings from automation.</li>
<li><strong>Customer facing tools</strong>, such as customer service agents. The challenge here is consistency, not capability. τ-bench shows models hitting 80% pass^1 but dropping significantly on pass^8, meaning the agent might handle a request perfectly one day and fail the next. Tight monitoring and a swift escalation path to a human is necessary.</li>
<li><strong>Long running autonomous work</strong>, such as inventory and portfolio management, scheduling, management of other agents over multiple tasks is not ready yet. Vending-Bench shows that even the best models show massive variance across runs, and there’s a risk of hitting meltdowns where they spiral into bizarre behavior.</li>
</ol>
</section>
</section>
<section id="featured-benchmarks-in-detail" class="level2">
<h2 class="anchored" data-anchor-id="featured-benchmarks-in-detail">Featured benchmarks in detail</h2>
<section id="gaia" class="level3">
<h3 class="anchored" data-anchor-id="gaia">GAIA: General AI Assistant</h3>
<p><a href="https://huggingface.co/spaces/gaia-benchmark/leaderboard">GAIA</a> <span class="citation" data-cites="mialonGAIABenchmarkGeneral2023">(Mialon et al. 2023)</span> is the most important general benchmark. It consists of 466 high quality questions at three difficulty levels, annotated by humans. The authors value quality over quantity and it took them about 2 hours to make each question. The questions have unambiguous verifiable answers and require multi-step reasoning.</p>
<p>As a test, I asked Raycast AI to answer the level 3 difficulty example question from the paper.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/agent-benchmarks/raycast_gaia.png" class="img-fluid figure-img"></p>
<figcaption>GAIA benchmark example question with Claude 4.5 Sonnet in Raycast AI</figcaption>
</figure>
</div>
<p>It ended up doing 9 web searches and 1 call to a calculator tool. It got the answer wrong due to a false assumption.</p>
<p>Most tasks take 1 to 3 tools and 3 to 12 steps to solve. Questions can be solved by looking up information or by having it memorized. Answering the questions requires the following tools:</p>
<ul>
<li>Web search. It relies on information from trusted websites that are unlikely to disappear, such as arXiv and Wikipedia.</li>
<li>Reading different file types: PDF, Excel, PowerPoint, CSV, image, audio and even video.</li>
<li>Handling multimodal data, OCR (optical character recognition) and using Google Street View.</li>
<li>Coding.</li>
</ul>
<p>In contrast to other benchmarks, GAIA challengers are whole agentic systems that package one or more LLMs, the tools and an agentic loop. The current leader is SU Zero by Suzhou AI Lab. This enables measuring more innovation on the agentic loop and tools, but also means the scores can’t be used directly when choosing an off-the-shelf LLM.</p>
<p>GAIA is the most general benchmark and worth paying attention to, though at risk of saturation as the highscore already reached 90%. Like other benchmarks, GAIA questions and the majority of source materials are in English. Expect a drop in performance on other languages.</p>
</section>
<section id="bfcl" class="level3">
<h3 class="anchored" data-anchor-id="bfcl">Berkeley Function-Calling Leaderboard (BFCL) V3</h3>
<p>The <a href="https://gorilla.cs.berkeley.edu/leaderboard.html">Berkeley Function-Calling Leaderboard</a> <span class="citation" data-cites="patilBerkeleyFunctionCalling2025">(Patil et al. 2025)</span> measures LLMs’ ability to invoke functions/tools accurately across multiple programming languages and agentic scenarios. Function calling is the foundation of agentic AI: every API call to update a CRM, check inventory, process a payment, or query a database relies on accurate function calling.</p>
<p>The benchmark consists of 4441 question-function-answer triplets across Python, Java, JavaScript, SQL and REST API calls. They vary in complexity from simple function calls to multi-turn interactions. The augmented multi-turn questions added in V3 are especially challenging, as they require models to recognize situations in which additional information has to be requested from the user, or there isn’t a function that does the job.</p>
<p>Here’s one of the simplest questions: “Can you fetch me the weather data for the coordinates 37.8651 N, 119.5383 W, including the hourly forecast for temperature, wind speed, and precipitation for the next 10 days?” The correct answer is <code>requests.get(url="https://api.open-meteo.com/v1/forecast", params={"latitude": "37.8651", "longitude": "-119.5383", "forecast_days": 10})</code>.</p>
<p>The current leader is Claude Opus 4.5 at 77.5% overall accuracy (pass^1, end of 2025). It scores particularly well on the web search subscore at 84.5%. The leaderboard also reports cost, which ranges from less than $1 with small open weights models to $355 with Grok-4.</p>
</section>
<section id="tau2-bench" class="level3">
<h3 class="anchored" data-anchor-id="tau2-bench">τ²-bench: Tool-Agent-User Interaction</h3>
<p><a href="https://taubench.com/#leaderboard">τ²-bench</a> <span class="citation" data-cites="yaoTauBenchBenchmarkToolAgentUser2024">(Yao et al. 2024)</span> is a multi-turn support bot benchmark. It measures agents’ ability to interact with simulated users and follow domain-specific policies while using tools in multi-turn conversations. The original τ-bench (2024) introduced the retail and airline domains. τ²-bench (2025) added a telecom domain where both user and agent have access to different tools and must coordinate, better simulating expert-novice gaps in technical support scenarios.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/agent-benchmarks/tau2_chat.png" class="img-fluid figure-img"></p>
<figcaption>τ²-bench example chat in the telecom domain. Image from the paper</figcaption>
</figure>
</div>
<p>The chat above is an example conversation that shows how user and agent exchange information and coordinate tool calls. An ablation study in which the support agent had access to all tools showed a significantly higher success rate, indicating that user-agent communication is a common failure mode. The full chat histories of the benchmark runs are available on the <a href="https://taubench.com/#trajectory-visualizer">website</a>.</p>
<p>The leading overall score is 85% (Gemini 3 Pro) for pass^1. Its domain subscores are 85% for retail, 73% for airline and 98% for telecom. The telecom score surprised me, as it’s so far above the best score reported in the paper introducing the domain, which listed Claude 3.7 Sonnet at 49% pass^1. However, other models also listed with scores in the high 90s for the telecom domain.</p>
</section>
<section id="quantified-reliability-with-passk" class="level3">
<h3 class="anchored" data-anchor-id="quantified-reliability-with-passk">Quantified reliability with pass^k</h3>
<p>The τ²-bench leaderboard reports pass^k metrics for most entries. The graph below shows the dropoff pattern from pass^1 to pass^4 for the current top models that report pass^k metrics and pooled across all domains.</p>
<div id="3edf2304" class="cell" data-execution_count="1">
<div class="cell-output cell-output-display">
<div>            <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG"></script><script type="text/javascript">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: "STIX-Web"}});}</script>                <script type="text/javascript">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>
        <script charset="utf-8" src="https://cdn.plot.ly/plotly-3.3.0.min.js" integrity="sha256-bO3dS6yCpk9aK4gUpNELtCiDeSYvGYnK7jFI58NQnHI=" crossorigin="anonymous"></script>                <div id="516cfe22-fc6c-4e83-aee5-999249e3bde4" class="plotly-graph-div" style="height:500px; width:100%;"></div>            <script type="text/javascript">                window.PLOTLYENV=window.PLOTLYENV || {};                                if (document.getElementById("516cfe22-fc6c-4e83-aee5-999249e3bde4")) {                    Plotly.newPlot(                        "516cfe22-fc6c-4e83-aee5-999249e3bde4",                        [{"hovertemplate":"%{fullData.name}: %{y:.1f}%\u003cextra\u003e\u003c\u002fextra\u003e","line":{"width":2},"marker":{"size":8},"mode":"lines+markers","name":"Qwen3-Max-Thinking-Preview","x":{"dtype":"i4","bdata":"AQAAAAIAAAADAAAABAAAAA=="},"y":{"dtype":"f8","bdata":"MzMzMzMzVEAAAAAAAKBSQDMzMzMzk1FAMzMzMzOzUEA="},"type":"scatter"},{"hovertemplate":"%{fullData.name}: %{y:.1f}%\u003cextra\u003e\u003c\u002fextra\u003e","line":{"width":2},"marker":{"size":8},"mode":"lines+markers","name":"GPT-5","x":{"dtype":"i4","bdata":"AQAAAAIAAAADAAAABAAAAA=="},"y":{"dtype":"f8","bdata":"AAAAAAAAVEAAAAAAAEBSQAAAAAAAAFFAAAAAAAAAUEA="},"type":"scatter"},{"hovertemplate":"%{fullData.name}: %{y:.1f}%\u003cextra\u003e\u003c\u002fextra\u003e","line":{"width":2},"marker":{"size":8},"mode":"lines+markers","name":"Claude-3.7-Sonnet","x":{"dtype":"i4","bdata":"AQAAAAIAAAADAAAABAAAAA=="},"y":{"dtype":"f8","bdata":"ZmZmZmbmTkAAAAAAAEBMQDMzMzMzc0pAmpmZmZnZSEA="},"type":"scatter"},{"hovertemplate":"%{fullData.name}: %{y:.1f}%\u003cextra\u003e\u003c\u002fextra\u003e","line":{"width":2},"marker":{"size":8},"mode":"lines+markers","name":"o4-mini","x":{"dtype":"i4","bdata":"AQAAAAIAAAADAAAABAAAAA=="},"y":{"dtype":"f8","bdata":"MzMzMzNzTEBmZmZmZiZIQM3MzMzMTEVAAAAAAAAAQ0A="},"type":"scatter"},{"hovertemplate":"%{fullData.name}: %{y:.1f}%\u003cextra\u003e\u003c\u002fextra\u003e","line":{"width":2},"marker":{"size":8},"mode":"lines+markers","name":"GPT-4.1","x":{"dtype":"i4","bdata":"AQAAAAIAAAADAAAABAAAAA=="},"y":{"dtype":"f8","bdata":"mpmZmZlZS0AAAAAAAEBHQDMzMzMzs0RAMzMzMzNzQkA="},"type":"scatter"},{"hovertemplate":"%{fullData.name}: %{y:.1f}%\u003cextra\u003e\u003c\u002fextra\u003e","line":{"width":2},"marker":{"size":8},"mode":"lines+markers","name":"GPT-4.1-mini","x":{"dtype":"i4","bdata":"AQAAAAIAAAADAAAABAAAAA=="},"y":{"dtype":"f8","bdata":"AAAAAACASkAAAAAAAEBFQJqZmZmZmUFAzczMzMxMPkA="},"type":"scatter"}],                        {"template":{"data":{"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"contour"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"heatmap"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"histogram2dcontour"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"histogram2d"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scattermap":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermap"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"margin":{"b":0,"l":0,"r":0,"t":30},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"xaxis":{"title":{"text":"pass^k (k)"},"tickmode":"array","tickvals":[1,2,3,4],"ticktext":["pass^1","pass^2","pass^3","pass^4"],"fixedrange":true,"hoverformat":"\u003cb\u003epass^%{x}\u003c\u002fb\u003e"},"yaxis":{"title":{"text":"Score (%)"},"range":[0,100],"fixedrange":true},"legend":{"yanchor":"bottom","y":0.01,"xanchor":"left","x":0.01},"hoverlabel":{"font":{"size":12,"family":"sans-serif"},"bgcolor":"white"},"height":500,"hovermode":"x unified"},                        {"displayModeBar": false, "scrollZoom": false, "doubleClick": false, "staticPlot": false, "responsive": true}                    ).then(function(){
                            
var gd = document.getElementById('516cfe22-fc6c-4e83-aee5-999249e3bde4');
var x = new MutationObserver(function (mutations, observer) {{
        var display = window.getComputedStyle(gd).display;
        if (!display || display === 'none') {{
            console.log([gd, 'removed!']);
            Plotly.purge(gd);
            observer.disconnect();
        }}
}});

// Listen for the removal of the full notebook cells
var notebookContainer = gd.closest('#notebook-container');
if (notebookContainer) {{
    x.observe(notebookContainer, {childList: true});
}}

// Listen for the clearing of the current output cell
var outputEl = gd.closest('.output');
if (outputEl) {{
    x.observe(outputEl, {childList: true});
}}

                        })                };            </script>        </div>
</div>
</div>
</section>
<section id="vending-bench" class="level3">
<h3 class="anchored" data-anchor-id="vending-bench">Vending-Bench 2</h3>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/agent-benchmarks/vending_bench_2_cover.png" class="img-fluid figure-img"></p>
<figcaption>Vending bench cover image from the website</figcaption>
</figure>
</div>
<p><a href="https://andonlabs.com/evals/vending-bench">Vending-Bench</a> <span class="citation" data-cites="backlundVendingBenchBenchmarkLongTerm2025">(Backlund and Petersson 2025)</span> measures LLM agents’ ability to maintain coherent decision-making over extended time horizons by managing a simulated vending machine business.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/agent-benchmarks/vending_bench_2_tools.png" class="img-fluid figure-img"></p>
<figcaption>Tools available to the agent in Vending-Bench. Image from the website</figcaption>
</figure>
</div>
<p>The agent needs to use the internet with Perplexity to find hypothetical suppliers, order from them via email exchanges with simulated suppliers, stock the vending machine, set prices and collect earnings. It has access to a scratchpad, key-value database and vector database to help it remember information.</p>
</section>
<section id="evaluation-and-alternative-settings" class="level3">
<h3 class="anchored" data-anchor-id="evaluation-and-alternative-settings">Evaluation and alternative settings</h3>
<p>Since version 2, models are solely scored by their cash at the end of the simulation. The leading score is $5,478 (Gemini 3 Pro). The score doesn’t have a clear ceiling. Recent models made massive improvements over their predecessors, such as GPT-5.1 ($1,473) to GPT-5.2 ($3,591) and Gemini 2.5 Pro ($574) to Gemini 3 Pro ($5,478). According to an analysis of Andon Labs, a good player should be able to make at least $63k by finding the best suppliers and negotiating low prices.</p>
<p>In addition to the standard mode, there are two alternative settings:</p>
<ul>
<li><strong>Arena mode</strong>, where multiple agents compete against each other in a multi-agent environment. They can exchange emails and act cooperatively or competitively. They display sophisticated behavior, such as negotiating payments for sharing information, joining their supplier orders for bulk discounts and even consignment deals.</li>
<li><a href="https://www.anthropic.com/research/project-vend-1"><strong>Project Vend</strong></a>, where a Claude agent managed a physical vending machine. It ended up with a huge loss after players persuaded it to give away items for free and stocking unusual items, such as tungsten cubes.</li>
</ul>
</section>
<section id="loss-of-coherence" class="level3">
<h3 class="anchored" data-anchor-id="loss-of-coherence">Loss of coherence</h3>
<p>In the original paper <span class="citation" data-cites="backlundVendingBenchBenchmarkLongTerm2025">(Backlund and Petersson 2025)</span>, all models had runs that derailed completely. Even Claude 3.5 Sonnet, the best performer, only increased net worth in three of five runs. In its worst run, it sold zero items. Failure means the agent stops doing basic tasks: restocking the machine, ordering from suppliers, or collecting earnings. These are individually trivial actions, but over hundreds of days, agents lose track of what they’re supposed to be doing.</p>
<p>When this happens, agents don’t degrade gradually. They melt down. Once an agent misinterprets its situation, it tends to spiral rather than self-correct. In one example, Claude 3.5 Haiku escalated a supplier dispute into increasingly unhinged emails demanding “QUANTUM NUCLEAR LEGAL INTERVENTION.” In another, Claude reported the $2 daily fee to the FBI as “ONGOING CYBER FINANCIAL CRIME.”</p>
<p>The original paper found no correlation between failures and context window limits (r = 0.167). Models failed well after their memory became full, suggesting breakdowns stem from something other than forgetting. Despite having access to scratchpads, key-value stores and vector databases, agents still lose coherence over time. Vending-Bench 2 added better planning tools including note-taking and reminder systems, yet coherence failures persist across all tested models.</p>
</section>
<section id="takeaways-for-enterprise-agents" class="level3">
<h3 class="anchored" data-anchor-id="takeaways-for-enterprise-agents">Takeaways for enterprise agents</h3>
<p>These findings generalize beyond vending machines to any long-running autonomous agent. Enterprise deployments need circuit breakers that detect anomalous behavior patterns and escalate to human review before meltdowns compound. External state management and periodic human checkpoints remain necessary even when agents have memory tools. Agents interfacing with external parties need skepticism built in, since those that over-trust their environment get exploited. For enterprise reliability, the relevant question isn’t “can it succeed?” but “how often does it fail catastrophically?” Even top models show high variance across runs.</p>
</section>
</section>
<section id="references" class="level2">




</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0">
<div id="ref-backlundVendingBenchBenchmarkLongTerm2025" class="csl-entry">
Backlund, Axel, and Lukas Petersson. 2025. <span>“Vending-Bench: <span>A Benchmark</span> for <span>Long-Term Coherence</span> of <span>Autonomous Agents</span>.”</span> arXiv. <a href="https://doi.org/10.48550/arXiv.2502.15840">https://doi.org/10.48550/arXiv.2502.15840</a>.
</div>
<div id="ref-mialonGAIABenchmarkGeneral2023" class="csl-entry">
Mialon, Grégoire, Clémentine Fourrier, Craig Swift, Thomas Wolf, Yann LeCun, and Thomas Scialom. 2023. <span>“<span>GAIA</span>: A Benchmark for <span>General AI Assistants</span>.”</span> arXiv. <a href="https://doi.org/10.48550/arXiv.2311.12983">https://doi.org/10.48550/arXiv.2311.12983</a>.
</div>
<div id="ref-panMeasuringAgentsProduction2025" class="csl-entry">
Pan, Melissa Z., Negar Arabzadeh, Riccardo Cogo, Yuxuan Zhu, Alexander Xiong, Lakshya A. Agrawal, Huanzhi Mao, et al. 2025. <span>“Measuring <span>Agents</span> in <span>Production</span>.”</span> arXiv. <a href="https://doi.org/10.48550/arXiv.2512.04123">https://doi.org/10.48550/arXiv.2512.04123</a>.
</div>
<div id="ref-patilBerkeleyFunctionCalling2025" class="csl-entry">
Patil, Shishir G, Huanzhi Mao, Fanjia Yan, Charlie Cheng-Jie Ji, Vishnu Suresh, Ion Stoica, and Joseph E. Gonzalez. 2025. <span>“The <span>Berkeley Function Calling Leaderboard</span> (<span>BFCL</span>): <span>From Tool Use</span> to <span>Agentic Evaluation</span> of <span>Large Language Models</span>.”</span> In <em>Forty-Second International Conference on Machine Learning</em>. ICML. <a href="https://openreview.net/forum?id=2GmDdhBdDk">https://openreview.net/forum?id=2GmDdhBdDk</a>.
</div>
<div id="ref-schmidAIAgentBenchmarkCompendium2025" class="csl-entry">
Schmid, Philipp. 2025. <span>“<span>AI Agent Benchmark Compendium</span>.”</span> October 2025. <a href="https://www.philschmid.de/benchmark-compedium">https://www.philschmid.de/benchmark-compedium</a>.
</div>
<div id="ref-shankarUnderstandingAIBenchmarks2025" class="csl-entry">
Shankar, Shrivu. 2025. <span>“Understanding <span>AI Benchmarks</span>.”</span> December 2025. <a href="https://blog.sshh.io/p/understanding-ai-benchmarks">https://blog.sshh.io/p/understanding-ai-benchmarks</a>.
</div>
<div id="ref-yaoTauBenchBenchmarkToolAgentUser2024" class="csl-entry">
Yao, Shunyu, Noah Shinn, Pedram Razavi, and Karthik Narasimhan. 2024. <span>“<img src="https://latex.codecogs.com/png.latex?%5Ctau">-Bench: <span>A Benchmark</span> for <span>Tool-Agent-User Interaction</span> in <span>Real-World Domains</span>.”</span> arXiv. <a href="https://doi.org/10.48550/arXiv.2406.12045">https://doi.org/10.48550/arXiv.2406.12045</a>.
</div>
</div></section></div> ]]></description>
  <category>Agents</category>
  <guid>https://simmering.dev/blog/agent-benchmarks/</guid>
  <pubDate>Sat, 03 Jan 2026 23:00:00 GMT</pubDate>
  <media:content url="https://simmering.dev/blog/agent-benchmarks/reliability_gap.webp" medium="image" type="image/webp"/>
</item>
<item>
  <title>Pivoting to a Career in AI and Data</title>
  <dc:creator>Paul Simmering</dc:creator>
  <link>https://simmering.dev/blog/pivoting-to-ai-data/</link>
  <description><![CDATA[ 






<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/pivoting-to-ai-data/image_wide.webp" class="img-fluid figure-img"></p>
<figcaption>Climbing the tech wall. Image generated with GPT Image 1.5</figcaption>
</figure>
</div>
<p>In 2018, I graduated with a degree in economics and promptly pivoted to a career in data science. I effectively discarded the majority of the knowledge I had just acquired. My main motivation was my late discovery of a passion for programming. It took years of extra effort on nights and weekends to catch up to the capabilities of someone who had studied computer science instead. I was lucky to work in a company that was willing to invest in me and take chances with experiments in data science.</p>
<p>If you’re also considering a pivot to AI and data, this article is for you. I’ll share a strategy for smart specialization and leverage of your existing domain knowledge.</p>
<p>The explosion of the AI trend since the release of large language models has made such a pivot both easier and harder. Easier, because AI unlocked many new opportunities and can serve as a tutor. Harder, because companies replace entry level technical jobs with AI, making the competition for the remaining ones fierce.</p>
<section id="pick-a-role-and-go-depth-first" class="level2">
<h2 class="anchored" data-anchor-id="pick-a-role-and-go-depth-first">Pick a role and go depth first</h2>
<p>Data and AI are enormous fields with different archetypical job roles. Each of them is deep and constantly evolving. Pick only one and acquire its foundational skillset.</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Role</th>
<th>Deliverable</th>
<th>Code</th>
<th>Math/Stats</th>
<th>Communication</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Data Engineer</td>
<td>Pipeline</td>
<td>Heavy</td>
<td>Light</td>
<td>Low</td>
</tr>
<tr class="even">
<td>ML Engineer</td>
<td>Model serving infra.</td>
<td>Heavy</td>
<td>Moderate</td>
<td>Low</td>
</tr>
<tr class="odd">
<td>AI Engineer</td>
<td>AI-powered app</td>
<td>Heavy</td>
<td>Moderate</td>
<td>Medium</td>
</tr>
<tr class="even">
<td>Data Scientist</td>
<td>Prediction model</td>
<td>Heavy</td>
<td>Heavy</td>
<td>Medium</td>
</tr>
<tr class="odd">
<td>Research Scientist</td>
<td>Paper</td>
<td>Heavy</td>
<td>Heavy</td>
<td>Medium</td>
</tr>
<tr class="even">
<td>Data Analyst</td>
<td>Report, dashboard</td>
<td>Light</td>
<td>Light</td>
<td>High</td>
</tr>
<tr class="odd">
<td>AI Consultant</td>
<td>Management pitch</td>
<td>Light</td>
<td>Light</td>
<td>High</td>
</tr>
<tr class="even">
<td>AI Champion</td>
<td>AI adoption</td>
<td>None</td>
<td>Light</td>
<td>High</td>
</tr>
</tbody>
</table>
<p>Disambiguations:</p>
<ul>
<li>Data Engineer vs.&nbsp;Data Analyst: Data Engineers build pipelines and infrastructure that get the data into a usable state. Data Analysts query the data to answer business questions.</li>
<li>ML vs.&nbsp;AI Engineer: ML Engineers focus on model serving, monitoring, and infrastructure. AI Engineers build and tune the applications on top of it.</li>
<li>Research Scientist vs.&nbsp;Data Scientist: Research Scientists focus on creating new models and papers, currently in particular on LLMs. Data Scientists apply models in a business context and frequently work with classic machine learning models over LLMs.</li>
<li>AI Consultant vs AI Champion: AI Consultants analyze a business problem and propose an AI solution. They are typically external to the business unit. AI Champions are domain experts in the business unit who work on requirements with developers and third party suppliers, compare solutions and promote use by the business unit.</li>
</ul>
<p>The names and scopes differ between organizations. The larger the organization, the more specialized the roles tend to be. Look for job postings for the roles you are interested in to get a sense of the scope and requirements. Also read experiences that people share online regarding what the roles actually involve. In practice, almost every job in this area involves a significant amount of finding, cleaning and transforming data, whether your job title contains “data” or not.</p>
</section>
<section id="use-your-domain-knowledge" class="level2">
<h2 class="anchored" data-anchor-id="use-your-domain-knowledge">Use your domain knowledge</h2>
<p>In less technical fields, it is relatively easy to become better at data and AI than 95% of your colleagues. My example: I worked in market research, where many have some skills in statistical analysis but few had the chops to write an automated data pipeline. Skills that are trivial for programmers are outstanding among market researchers. This gap also let me become a speaker at market research conferences early in my career.</p>
<p>One way to get there is to volunteer to automate something painful for the team. Some examples:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 18%">
<col style="width: 22%">
<col style="width: 59%">
</colgroup>
<thead>
<tr class="header">
<th>Domain</th>
<th>AI Pivot</th>
<th>Project</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Customer Support</td>
<td>AI-Assisted Reply Drafting</td>
<td>Set up prompts that draft replies from your help docs, agents edit and send instead of typing from scratch</td>
</tr>
<tr class="even">
<td>Finance</td>
<td>Reporting Automation</td>
<td>Automate the monthly report everyone dreads—pull from different tools, format, deliver without the copy-paste ritual</td>
</tr>
<tr class="odd">
<td>Content Marketing</td>
<td>Content Repurposing</td>
<td>Turn one long-form piece into social posts, email snippets, and summaries using prompts tuned to your voice</td>
</tr>
<tr class="even">
<td>Non-profit Fundraising</td>
<td>Donor Dashboard</td>
<td>Unify donor data from events, email, and payment tools into one view, automatically group by giving behavior</td>
</tr>
<tr class="odd">
<td>Journalism</td>
<td>Public Records Structuring</td>
<td>Turn messy PDFs and spreadsheets from government disclosures into searchable data you can actually analyze</td>
</tr>
</tbody>
</table>
<p>Lots of opportunities for automation with AI and data engineering have not been realized, because programmers lack the necessary domain knowledge. You can be the domain expert who picks up programming and realize these opportunities.</p>
<p>Such roles are not typically advertised, they are created within organizations and may later be formalized with a job title. The cleanest pivot may not be quitting your job to study, then applying cold. It’s creating an AI/data role where you already are.</p>
</section>
<section id="learn-one-set-of-tools" class="level2">
<h2 class="anchored" data-anchor-id="learn-one-set-of-tools">Learn one set of tools</h2>
<p>Pick one programming language, one cloud provider, one LLM API, one database and so on. If you know one, picking up another as necessary will be much easier. Learning multiple alternatives upfront slows you down.</p>
<p>You can go harder on the specialization on one ecosystem by pursuing certifications in it. For example, you could aim to get the relevant Azure certifications for your chosen role. This route can give you a speed boost, because you quickly get to specialized knowledge that employers on that stack need. However, it also locks you into an ecosystem. Research your choice well, for example by checking the number of job openings mentioning it.</p>
<p>If you prefer to stay more open, prioritize learning open source software and common standards. For example, instead of learning AWS Cloud Formation, their infrastructure as code framework, learn Terraform which handles multiple cloud providers.</p>
</section>
<section id="learn-the-essentials-of-software-engineering-alongside-your-first-programming-language" class="level2">
<h2 class="anchored" data-anchor-id="learn-the-essentials-of-software-engineering-alongside-your-first-programming-language">Learn the essentials of software engineering alongside your first programming language</h2>
<p>While many techniques are coming and going, there are some essential skills that every professional who codes has to know, regardless of the programming language they use. These are:</p>
<ul>
<li>Using a code editor, such as VSCode</li>
<li>Command line basics</li>
<li>Version management with Git and a code repository like Github</li>
<li>Calling an API</li>
<li>Querying a database with SQL</li>
</ul>
<p>The actual list of useful and expected skills is much longer, these are just the absolute essentials.</p>
<p>Learn them alongside your first programming language. There are great YouTube videos teaching them and you can try them right away on your computer. MIT’s “The Missing Semester” course is an advanced version. The 2020 lectures are on <a href="https://www.youtube.com/playlist?list=PLyzOVJj3bHQuloKGG59rS43e29ro7I57J">YouTube</a>.</p>
</section>
<section id="leapfrog" class="level2">
<h2 class="anchored" data-anchor-id="leapfrog">Leapfrog</h2>
<p>AI technology is evolving rapidly. This is an opportunity for newcomers. You can pick up the latest techniques and be competitive on them right away. You don’t have to study the whole tech tree. Skip the obsolete technologies. If the newer technique replaced rather than built upon the old one, you can skip the old; if it’s foundational, learn it.</p>
<p>For example, when you get into natural language processing today, start with large language models, skip learning recurrent neural networks, as they were superseded by transformers.</p>
<p>This shortens the time to your first role and you can always come back to fill in the gaps.</p>
<p>Data engineering also evolves, but at a slower pace. Database migrations are expensive and risky, so companies tend to stick with them for longer.</p>
</section>
<section id="understanding-over-speed" class="level2">
<h2 class="anchored" data-anchor-id="understanding-over-speed">Understanding over speed</h2>
<p>Grokking a concept gives you the power to apply it yourself. Just nodding along doesn’t. Done doesn’t mean that the code is running: it means that you could explain the concept clearly to someone else.</p>
<p>When programming with an AI assistant, it’s tempting to go hands off and gloss over the code. But that doesn’t teach you much. On learning projects, turn off AI autocompletion and ask AI to review your code, rather than write it for you. Ask it for advice when you get badly stuck, not as the default.</p>
</section>
<section id="create-proof-of-work" class="level2">
<h2 class="anchored" data-anchor-id="create-proof-of-work">Create proof of work</h2>
<p>Without a CS degree, you need other evidence of capability. Create it as you go:</p>
<ol type="1">
<li>Job experience, which you may be able to build up with side projects in your current job or after a lateral move inside your company.</li>
<li>Published work, such as GitHub repositories, websites, apps, videos, or articles. Creating an original project is more impressive than a solution to a common tutorial. Your first project doesn’t have to be groundbreaking, but make sure it’s polished and easy to grasp in the few moments someone spends reviewing it. The readme may be the most important file.</li>
<li>Certifications, but choose carefully. A LinkedIn badge signals nothing. Advanced platform-specific certifications, such as the AWS Data Engineer Associate, are a signal for jobs focused on that platform. Don’t collect certificates for the sake of it; one serious one beats five easy ones.</li>
</ol>
</section>
<section id="milestone-move-it-into-your-core-hours" class="level2">
<h2 class="anchored" data-anchor-id="milestone-move-it-into-your-core-hours">Milestone: Move it into your core hours</h2>
<p>The pivot is a marathon, not a sprint. It gets easier once you’re in a position where you’re working in AI / data during your core working hours. Spending nights and weekends is often necessary, but you won’t be at your best learning ability and for many people it’s not sustainable.</p>
<p>Getting there might mean adjusting your current job, taking a hybrid job between domain and technology, or taking time off to study. Once you have an in, keep steering towards your goal position or prepare to take the leap to a full AI / data job.</p>
<hr>
<p>The path isn’t linear. You’ll work on projects that don’t pan out and learn tools that become obsolete. That’s normal. A good check is to look at your work from a few months ago: if you shake your head and would do it much better now, you’re learning. Focus on depth in one role and leverage what you already know. Whether you end up switching careers or add a technical side to you current job, learning AI and data skills will put you in the driver’s seat as AI reshapes all knowledge work.</p>


</section>

 ]]></description>
  <category>Career</category>
  <guid>https://simmering.dev/blog/pivoting-to-ai-data/</guid>
  <pubDate>Tue, 16 Dec 2025 23:00:00 GMT</pubDate>
  <media:content url="https://simmering.dev/blog/pivoting-to-ai-data/image.webp" medium="image" type="image/webp"/>
</item>
<item>
  <title>A Philosophy of AI Coding</title>
  <dc:creator>Paul Simmering</dc:creator>
  <link>https://simmering.dev/blog/a-philosophy-of-ai-coding/</link>
  <description><![CDATA[ 






<div class="grid">
<div class="g-col-8">
<p>This is an analysis of the acclaimed book <a href="https://www.goodreads.com/book/show/39996759-philosophy-of-software-design">A Philosophy of Software Design (2nd Edition)</a> by John Ousterhout in the context of AI coding. Building on it, I propose a theory of a reinforcing loop for development: design of software using the book’s principles enhances AI coding, and AI coding enhances the design process. Finally, I will share prompts to put it into practice.</p>
<p>As the cover illustrates, the book is about replacing complex spaghetti code with neat, modular code. Work on software projects typically slows down as the project grows and ages. This is doubly true for AI coding, which works impressively on demos and greenfield projects, but is often unusable in mature projects. The book teaches principles of task decomposition that enable packaging complexity in such a way that a project can grow without the slowdown.</p>
</div>
<div class="g-col-4">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/a-philosophy-of-ai-coding/bookcover.jpg" class="img-fluid figure-img"></p>
<figcaption>Book cover</figcaption>
</figure>
</div>
</div>
</div>
<p>Distilled to a maximum, the principles of the book are:</p>
<ol type="1">
<li>Unmanaged complexity burdens a project with high cognitive load for developers, slow development, and leads to bugs and performance problems.</li>
<li>Complexity can be handled by deep modules. A deep module handles a sizeable task, solves it fully and presents a simple interface that hides information irrelevant to the caller.</li>
<li>Approach software development with an investment mindset, because extra time spent on design, documentation, consistency and clear naming quickly turns into productivity gains.</li>
<li>Design systems twice before implementing them.</li>
</ol>
<p>The book was enlightening, as it taught me new concepts and also put concepts I discovered myself through practice into words. The book’s examples are on object-oriented application programming, but the lessons also apply to my areas of machine learning, data engineering and cloud infrastructure.</p>
<section id="reinforcing-loop-of-principled-development-with-ai" class="level2">
<h2 class="anchored" data-anchor-id="reinforcing-loop-of-principled-development-with-ai">Reinforcing loop of principled development with AI</h2>
<p>John Ousterhout was a recent guest of Gergely Orosz on the <a href="https://www.youtube.com/watch?v=lz451zUlF-k">Pragmatic Engineer podcast</a> where he commented that software design becomes even more important with AI coding. Let’s dive deeper into this.</p>
<p>It happens in two ways: (1) implementation work can, at least in part, be completed by AI, which means a larger fraction of the remaining work is design; (2) neatly designed software is easier for AI to extend.</p>
<p>In the following, I describe how this becomes a reinforcing loop that strengthens both design and implementation.</p>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">graph LR
    A[Good design] --&gt;|enables| B[Reliable AI coding]
    B --&gt;|reinforces| A
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<section id="reinforcing-loop-part-i-taming-the-tornado" class="level3">
<h3 class="anchored" data-anchor-id="reinforcing-loop-part-i-taming-the-tornado">Reinforcing loop, part I: Taming the tornado</h3>
<p>Ousterhout coined the term <em>tactical tornado</em>, which describes a programmer that adds features quickly, but at the expense of code quality. Most AI coding assistants are tactical tornados. Given too long a lead, they turn a codebase into spaghetti. This is understandable. The AI is thrust into an unfamiliar project, and it has been trained to please its user, which often means achieving whatever is asked. That leads to tacking on the requested feature wherever it fits, rather than stepping back to suggest a redesign that would accommodate the feature more elegantly.</p>
<p>I find it useful to relate to coding agents as a smart, eager new intern. It works best when the project’s architecture is already set up by a senior engineer, and it’s given a well scoped task and all relevant context. Let’s break these requirements down further. Part I focuses on setting conditions where AI can operate safely and effectively.</p>
<section id="ai-amplifies-the-design" class="level4">
<h4 class="anchored" data-anchor-id="ai-amplifies-the-design">AI amplifies the design</h4>
<p>In chapter 22, the conclusion, Ousterhout writes:</p>
<blockquote class="blockquote">
<p>The reward for being a good designer is that you get to spend a larger fraction of your time in the design phase, which is fun. Poor designers spend most of their time chasing bugs in complicated and brittle code.</p>
</blockquote>
<p>With AI coding, this could be extended to: The reward for being a good designer is that you can automate more of the coding. Everything that makes working on a project easy or hard for a human developer affects an AI assistant too.</p>
<p>When a coding agent edits a chaotic project it’s likely to add to the chaos. When it edits a neat project that has an obvious place for the new feature, it will maintain that neatness.</p>
</section>
<section id="design-improves-context-engineering" class="level4">
<h4 class="anchored" data-anchor-id="design-improves-context-engineering">Design improves context engineering</h4>
<p>Context engineering is an evolution of prompt engineering around the insight:</p>
<blockquote class="blockquote">
<p>The real skill isn’t crafting perfect prompts but providing the right context. Think of it as building up a relevant knowledge window for the AI rather than perfecting magical instructions. Most models are good enough now that even imperfect prompts work if the context is right.</p>
</blockquote>
<p>Jason Liu on <a href="https://x.com/jxnlco/status/1960043508917539244">X</a></p>
<p>For a coding agent, the context needs to show the files to edit, and also communicate the overall design. The design is naturally communicated through the code, with names of files and the comments immediately surrounding them, such as docstrings. In addition, a design document, such as a markdown file, could be included in every request.</p>
<p>The principles laid out in the book reduce the required context to execute a task. A deep, well documented module offers a packaged solution to a problem. It’s not necessary to read the code to use it. So unless the AI is specifically tasked with changing that code, it’s enough to load the function’s name and docstring into the context window.</p>
</section>
<section id="comments-first-workflow" class="level4">
<h4 class="anchored" data-anchor-id="comments-first-workflow">Comments first workflow</h4>
<p>According to Ousterhout, comments should be the first thing to be written, followed by code and then tests. For an AI-centric workflow, I would modify the order:</p>
<ol type="1">
<li>Human: Write comments (including docstrings). This is the most fluid stage of the code, where changing one’s mind is almost free. Class and function names and their signatures become the documentation for other developers calling them, and a scaffold for implementation.</li>
<li>AI + human review: Write unit tests.</li>
<li>AI + human review: Let a coding agent hill-climb by iterating until the tests pass.</li>
</ol>
<p>Ousterhout is not a proponent of test-driven development (tests before code), because writing tests first leads to tactical programming. However, if code generation is cheaper, it’s emotionally easier to redo the implementation if it turns out to have a design problem. The synergy of the tireless effort of a coding agent and a unit test to hill-climb against is great. As with any workflow, it has to be adapted to reality and remixed on the fly.</p>
</section>
<section id="senior-engineer-in-the-loop" class="level4">
<h4 class="anchored" data-anchor-id="senior-engineer-in-the-loop">Senior engineer in the loop</h4>
<p>Who benefits most from AI coding? It could be nonprogrammers or beginner programmers, who can perilously skip learning to code. But arguably it is senior engineers who get to scale their design skills and taste.</p>
<blockquote class="blockquote">
<p>These tools are most valuable for your most senior engineers, not juniors. Your staff engineers understand the system best but have limited time - AI tools let them implement exploratory features, load testing, and complex integrations they’d otherwise deprioritize.</p>
</blockquote>
<p>Jason Liu on <a href="https://x.com/jxnlco/status/1960043508917539244">X</a></p>
<p>Despite the marketing, even supposed PhD-level intelligence models make frustrating mistakes all the time. This is where vibe coding hits the wall.</p>
<blockquote class="blockquote">
<p>AI demonstrates the sunk-cost fallacy perfectly: Just one more “this doesn’t work!” prompt, you think, and it’ll fix it!! But often it won’t, and now you’ve wasted 30 minutes begging that you could have spent learning how to actually fucking do it yourself.</p>
</blockquote>
<p>DHH on <a href="https://x.com/dhh/status/1958505914341654675">X</a></p>
<p>That’s also why I’m skeptical of one-shot, hands-off tools like Jules and Devin (<a href="https://www.answer.ai/posts/2025-01-08-devin.html">January 2025 review</a> by Answer.AI). I prefer IDEs and extensions that enable a fast feedback loop between developer and AI.</p>
<p>A developer in the loop can be the bulwark against slop creeping in. Rather than writing the perfect incantation, the developer can stay in the lead and aggressively delegate all rote work.</p>
<blockquote class="blockquote">
<p>[…] I find that instead of narrowing in on a perfect one thing my usage is increasingly diversifying across a few workflows […] Personally the bread &amp; butter (~75%?) of my LLM assistance continues to be just (Cursor) tab complete. This is because I find that writing concrete chunks of code/comments myself and in the right part of the code is a high bandwidth way of communicating “task specification” to the LLM, i.e.&nbsp;it’s primarily about task specification bits - it takes too many bits and too much latency to communicate what I want in text, and it’s faster to just demonstrate it in the code and in the right place.</p>
</blockquote>
<p>Andrej Karpathy on <a href="https://x.com/karpathy/status/1959703967694545296">X</a></p>
</section>
</section>
<section id="reinforcing-loop-part-ii-reinforcing-design-through-consistent-practice" class="level3">
<h3 class="anchored" data-anchor-id="reinforcing-loop-part-ii-reinforcing-design-through-consistent-practice">Reinforcing loop, part II: Reinforcing design through consistent practice</h3>
<p>So far we’ve seen how good design enables better AI output. But the loop works in reverse too - AI makes it cheaper to maintain good design practices.</p>
<p>On the question of how much to plan in advance (the waterfall approach) versus how much to start and then adjust as you go (agile), Ousterhout opined that a middle way is best. With AI available, I suggest moving more towards agile than before, because writing code has become cheaper.</p>
<p>Ousterhout also advocates an investment mindset, meaning to spend a little more time upfront on design and comments which repays soon in added productivity. AI improves the economics of this:</p>
<ul>
<li>The investment has become cheaper and also more valuable, since it benefits AI in addition to human developers. - - Tasks that feel like drudgery, such as updating comments or adding unit tests, can be delegated. Everyone now has infinite interns to pawn off tasks to.</li>
</ul>
<section id="better-adherence-to-best-practices" class="level4">
<h4 class="anchored" data-anchor-id="better-adherence-to-best-practices">Better adherence to best practices</h4>
<p>AI can help with:</p>
<ul>
<li><strong>Diagrams</strong>. It can generate and evolve diagrams as code with tools like Mermaid and D2, which improves understanding of architecture and can increase creativity. See my article: <a href="../../blog/diagrams/index.html">Diagrams as Code: Supercharged by AI Assistants</a>.</li>
<li><strong>Naming</strong>. It can flag unclear names and suggesting improvements, which makes interfaces easier to use.</li>
<li><strong>Documentation</strong>. It can keep documentation consistent by drafting updates and spotting drift. Together these capabilities tighten the loop between design and implementation.</li>
<li><strong>Refactoring</strong>. It can enable bolder refactoring by freeing developer time, surfacing code smells, suggesting structural improvements, and doing the mechanical edits while tests protect behavior.</li>
</ul>
</section>
<section id="from-design-it-twice-to-build-it-twice" class="level4">
<h4 class="anchored" data-anchor-id="from-design-it-twice-to-build-it-twice">From “Design it twice” to “Build it twice”</h4>
<p>So far, I’ve treated design as the holy task that only humans can do. That’s not quite true.</p>
<p>Ousterhout advises to “design it twice” before building software, meaning to come up with two separate plans and reason through their pros and cons. But what teaches a developer more than designing something twice? Comparing two actual implementations. With AI, it’s possible to draft a whole implementation quickly. If we view the development of a large system as a minefield of potential roadblocks, we can now probe for little money instead of playing Minesweeper in our heads to detect them in advance. In addition, AI can of course come up with plans of its own and write pro/con lists of different approaches.</p>
<p>However, I still see the design as the foremost responsibility of the human developer.</p>
</section>
</section>
</section>
<section id="wrap-up" class="level2">
<h2 class="anchored" data-anchor-id="wrap-up">Wrap up</h2>
<section id="takeaways" class="level3">
<h3 class="anchored" data-anchor-id="takeaways">Takeaways</h3>
<ul>
<li>Better design improves AI output; AI then accelerates development and enables bolder changes.</li>
<li>Design first: Deep modules, simple interfaces, and clear names make AI effective.</li>
<li>Comments-first workflow: Write comments, let AI draft tests, then implement.</li>
<li>Senior engineer in the loop: Boost human developers rather than attempting to replace them.</li>
</ul>
<p>Finally, don’t let AI sap the joy out of programming! Keep your coding skills sharp. Turn off tab completion from time to time, especially when you’re working with something new. “A Philosophy of Software Design” does a great job of making principles explicit, but a lot of tacit knowledge and taste remains that needs to be honed by actively coding.</p>
</section>
<section id="book-to-prompt" class="level3">
<h3 class="anchored" data-anchor-id="book-to-prompt">Book to prompt</h3>
<p>The book provides handy summaries on the last pages: a list of principles (how to design well) and a list of red flags (to detect bad design and trigger rethinking). I suggest reviewing them, perhaps adding items related to your specific project, and then adding the list into a <code>.cursorrules</code> if you’re using Cursor or the equivalent for other assistants.</p>


</section>
</section>

 ]]></description>
  <category>Productivity</category>
  <guid>https://simmering.dev/blog/a-philosophy-of-ai-coding/</guid>
  <pubDate>Tue, 26 Aug 2025 22:00:00 GMT</pubDate>
  <media:content url="https://simmering.dev/blog/a-philosophy-of-ai-coding/image.webp" medium="image" type="image/webp"/>
</item>
<item>
  <title>When (Not) to Use Agentic AI</title>
  <dc:creator>Paul Simmering</dc:creator>
  <link>https://simmering.dev/blog/agentic-ai/</link>
  <description><![CDATA[ 






<p>2025 could be the year of agentic AI. The first agentic AI demos came out in early 2023 and the technology has gained momentum through better tools, smarter models, and the first successful commercial products. The interest in agentic AI is also reflected in the number of GitHub stars for frameworks:</p>
<div id="dc072b77" class="cell" data-execution_count="2">
<div class="cell-output cell-output-display">
<div>            <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG"></script><script type="text/javascript">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: "STIX-Web"}});}</script>                <script type="text/javascript">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>
        <script charset="utf-8" src="https://cdn.plot.ly/plotly-3.3.0.min.js" integrity="sha256-bO3dS6yCpk9aK4gUpNELtCiDeSYvGYnK7jFI58NQnHI=" crossorigin="anonymous"></script>                <div id="57497c1a-5a86-48ae-acaa-9dc67b1bc4c0" class="plotly-graph-div" style="height:525px; width:100%;"></div>            <script type="text/javascript">                window.PLOTLYENV=window.PLOTLYENV || {};                                if (document.getElementById("57497c1a-5a86-48ae-acaa-9dc67b1bc4c0")) {                    Plotly.newPlot(                        "57497c1a-5a86-48ae-acaa-9dc67b1bc4c0",                        [{"hovertemplate":"Repository=microsoft\u002fautogen\u003cbr\u003eDate=%{x}\u003cbr\u003eStars=%{y}\u003cextra\u003e\u003c\u002fextra\u003e","legendgroup":"microsoft\u002fautogen","line":{"color":"#636efa","dash":"solid"},"marker":{"symbol":"circle"},"mode":"lines+markers","name":"microsoft\u002fautogen","orientation":"v","showlegend":true,"x":["2023-08-29T00:00:00.000","2023-10-05T00:00:00.000","2023-10-12T00:00:00.000","2023-10-17T00:00:00.000","2023-10-25T00:00:00.000","2023-11-19T00:00:00.000","2024-01-03T00:00:00.000","2024-02-14T00:00:00.000","2024-04-13T00:00:00.000","2024-06-10T00:00:00.000","2024-08-16T00:00:00.000","2024-10-24T00:00:00.000","2024-11-27T00:00:00.000","2025-01-15T00:00:00.000","2025-02-23T00:00:00.000","2025-02-28T00:00:00.000"],"xaxis":"x","y":{"dtype":"i4","bdata":"AAAAAKAUAAAOHwAAfCkAAOozAABYPgAAxkgAABZTAACEXQAA8mcAAGByAADOfAAAPIcAAKqRAAAYnAAA650AAA=="},"yaxis":"y","type":"scatter"},{"hovertemplate":"Repository=crewAIInc\u002fcrewAI\u003cbr\u003eDate=%{x}\u003cbr\u003eStars=%{y}\u003cextra\u003e\u003c\u002fextra\u003e","legendgroup":"crewAIInc\u002fcrewAI","line":{"color":"#EF553B","dash":"solid"},"marker":{"symbol":"circle"},"mode":"lines+markers","name":"crewAIInc\u002fcrewAI","orientation":"v","showlegend":true,"x":["2023-11-14T00:00:00.000","2024-01-10T00:00:00.000","2024-01-23T00:00:00.000","2024-02-15T00:00:00.000","2024-03-11T00:00:00.000","2024-04-04T00:00:00.000","2024-04-28T00:00:00.000","2024-05-28T00:00:00.000","2024-07-01T00:00:00.000","2024-08-23T00:00:00.000","2024-10-22T00:00:00.000","2024-12-05T00:00:00.000","2025-01-04T00:00:00.000","2025-01-31T00:00:00.000","2025-02-28T00:00:00.000","2025-02-28T00:00:00.000"],"xaxis":"x","y":{"dtype":"i2","bdata":"AAAQDjYVXByCI6gqzjESOThAXkeETqpV0Fz2YxxrQ2s="},"yaxis":"y","type":"scatter"},{"hovertemplate":"Repository=openai\u002fswarm\u003cbr\u003eDate=%{x}\u003cbr\u003eStars=%{y}\u003cextra\u003e\u003c\u002fextra\u003e","legendgroup":"openai\u002fswarm","line":{"color":"#00cc96","dash":"solid"},"marker":{"symbol":"circle"},"mode":"lines+markers","name":"openai\u002fswarm","orientation":"v","showlegend":true,"x":["2024-05-29T00:00:00.000","2024-10-12T00:00:00.000","2024-10-12T00:00:00.000","2024-10-13T00:00:00.000","2024-10-14T00:00:00.000","2024-10-14T00:00:00.000","2024-10-15T00:00:00.000","2024-10-15T00:00:00.000","2024-10-16T00:00:00.000","2024-10-17T00:00:00.000","2024-10-21T00:00:00.000","2024-11-01T00:00:00.000","2024-12-03T00:00:00.000","2025-01-16T00:00:00.000","2025-02-27T00:00:00.000","2025-03-01T00:00:00.000"],"xaxis":"x","y":{"dtype":"i2","bdata":"AACcCYgOkhN+GGodViJCJy4sGjEGNhA7\u002fD\u002foRNRJ+kk="},"yaxis":"y","type":"scatter"},{"hovertemplate":"Repository=huggingface\u002fsmolagents\u003cbr\u003eDate=%{x}\u003cbr\u003eStars=%{y}\u003cextra\u003e\u003c\u002fextra\u003e","legendgroup":"huggingface\u002fsmolagents","line":{"color":"#ab63fa","dash":"solid"},"marker":{"symbol":"circle"},"mode":"lines+markers","name":"huggingface\u002fsmolagents","orientation":"v","showlegend":true,"x":["2024-12-10T00:00:00.000","2025-01-02T00:00:00.000","2025-01-04T00:00:00.000","2025-01-06T00:00:00.000","2025-01-09T00:00:00.000","2025-01-15T00:00:00.000","2025-01-28T00:00:00.000","2025-02-05T00:00:00.000","2025-02-06T00:00:00.000","2025-02-07T00:00:00.000","2025-02-08T00:00:00.000","2025-02-13T00:00:00.000","2025-02-18T00:00:00.000","2025-02-26T00:00:00.000","2025-02-28T00:00:00.000","2025-02-28T00:00:00.000"],"xaxis":"x","y":{"dtype":"i2","bdata":"AAByBtgJIA2GEM4TNBd8GuIdKiGQJNgnPiuGLuwxJjI="},"yaxis":"y","type":"scatter"},{"hovertemplate":"Repository=langchain-ai\u002flanggraph\u003cbr\u003eDate=%{x}\u003cbr\u003eStars=%{y}\u003cextra\u003e\u003c\u002fextra\u003e","legendgroup":"langchain-ai\u002flanggraph","line":{"color":"#FFA15A","dash":"solid"},"marker":{"symbol":"circle"},"mode":"lines+markers","name":"langchain-ai\u002flanggraph","orientation":"v","showlegend":true,"x":["2023-08-11T00:00:00.000","2024-02-15T00:00:00.000","2024-03-20T00:00:00.000","2024-04-22T00:00:00.000","2024-05-25T00:00:00.000","2024-06-20T00:00:00.000","2024-07-19T00:00:00.000","2024-08-16T00:00:00.000","2024-09-20T00:00:00.000","2024-10-29T00:00:00.000","2024-12-04T00:00:00.000","2024-12-31T00:00:00.000","2025-01-21T00:00:00.000","2025-02-12T00:00:00.000","2025-02-28T00:00:00.000","2025-02-28T00:00:00.000"],"xaxis":"x","y":{"dtype":"i2","bdata":"AADOBEQHugkwDMQOOhGwEyYWuhgwG6YdHCCwIiYlSCU="},"yaxis":"y","type":"scatter"},{"hovertemplate":"Repository=pydantic\u002fpydantic-ai\u003cbr\u003eDate=%{x}\u003cbr\u003eStars=%{y}\u003cextra\u003e\u003c\u002fextra\u003e","legendgroup":"pydantic\u002fpydantic-ai","line":{"color":"#19d3f3","dash":"solid"},"marker":{"symbol":"circle"},"mode":"lines+markers","name":"pydantic\u002fpydantic-ai","orientation":"v","showlegend":true,"x":["2024-06-21T00:00:00.000","2024-12-03T00:00:00.000","2024-12-04T00:00:00.000","2024-12-05T00:00:00.000","2024-12-05T00:00:00.000","2024-12-06T00:00:00.000","2024-12-08T00:00:00.000","2024-12-11T00:00:00.000","2024-12-17T00:00:00.000","2024-12-28T00:00:00.000","2025-01-06T00:00:00.000","2025-01-16T00:00:00.000","2025-01-26T00:00:00.000","2025-02-10T00:00:00.000","2025-02-26T00:00:00.000","2025-02-28T00:00:00.000"],"xaxis":"x","y":{"dtype":"i2","bdata":"AABIAwoFzAaOCFAKEgy2DXgPOhH8Er4UgBZCGAQaOBo="},"yaxis":"y","type":"scatter"}],                        {"template":{"data":{"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"contour"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"heatmap"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"histogram2dcontour"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"histogram2d"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scattermap":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermap"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"margin":{"b":0,"l":0,"r":0,"t":30},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"xaxis":{"anchor":"y","domain":[0.0,1.0],"title":{"text":"Date"},"fixedrange":true},"yaxis":{"anchor":"x","domain":[0.0,1.0],"title":{"text":"GitHub Stars"},"fixedrange":true},"legend":{"title":{"text":""},"tracegroupgap":0},"modebar":{"remove":["zoom","pan","select","lasso","zoomIn","zoomOut","autoScale","resetScale","toImage","sendDataToCloud","toggleSpikelines","hoverClosestCartesian","hoverCompareCartesian","plotly"]}},                        {"displaylogo": false, "responsive": true}                    ).then(function(){
                            
var gd = document.getElementById('57497c1a-5a86-48ae-acaa-9dc67b1bc4c0');
var x = new MutationObserver(function (mutations, observer) {{
        var display = window.getComputedStyle(gd).display;
        if (!display || display === 'none') {{
            console.log([gd, 'removed!']);
            Plotly.purge(gd);
            observer.disconnect();
        }}
}});

// Listen for the removal of the full notebook cells
var notebookContainer = gd.closest('#notebook-container');
if (notebookContainer) {{
    x.observe(notebookContainer, {childList: true});
}}

// Listen for the clearing of the current output cell
var outputEl = gd.closest('.output');
if (outputEl) {{
    x.observe(outputEl, {childList: true});
}}

                        })                };            </script>        </div>
<p>Star history of agentic AI frameworks, data retrieved on 2025-02-28 from star-history.com.</p>
</div>
</div>
<p>Interest is also high among business leaders. Deloitte’s Jul/Sep 2024 <a href="https://www2.deloitte.com/content/dam/Deloitte/us/Documents/consulting/us-state-of-gen-ai-q4.pdf">State of Generative AI in the Enterprise Survey</a> showed that agentic AI garners the highest attention of all GenA-related developments, with 52% of C-suite-level respondents indicating interest in it (page 27).</p>
<p>But not every app needs agentic AI and not everyone believes in the hype. As MLOps Tech Lead Maria Vechtomova puts it in a <a href="https://www.linkedin.com/feed/update/urn:li:activity:7298117212064657408">LinkedIn post</a>:</p>
<blockquote class="blockquote">
<p>I’m so tired of the #AI hype… How many more millions will companies waste trying to adopt AI agents for any possible use case before the bubble bursts?</p>
</blockquote>
<p>and LLM consultant Hamel Husain <a href="https://www.linkedin.com/posts/hamelhusain_dont-repeat-this-mistake-you-have-been-activity-7273119135293710336-SnEj?utm_source=share">posted</a> this meme:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/agentic-ai/agents_iq_meme.png" class="img-fluid figure-img" style="width:70.0%"></p>
<figcaption>IQ meme: Are agents the overthinker’s choice? Cropped from Hamel’s LinkedIn post</figcaption>
</figure>
</div>
<p>Is agentic AI a hype or the key to the next generation of AI apps? This article provides a balanced look at it, written to help you decide whether agentic AI is right for your use case. It won’t go into the details of any specific agentic AI frameworks, but rather focus on the principles and tradeoffs.</p>
<section id="four-levels-of-agency" class="level3">
<h3 class="anchored" data-anchor-id="four-levels-of-agency">Four levels of agency</h3>
<p>To start, let’s establish a definition of what an agent is. The simplest definition I found is from Eugene Yan on <a href="https://www.linkedin.com/posts/eugeneyan_agent-model-tools-within-a-for-loop-ugcPost-7300335307558658048-ST_a?utm_source=share&amp;utm_medium=member_desktop&amp;rcm=ACoAABYvtdwBLdBW43CUqePc_yFkM0OKTe6yH00">LinkedIn</a>:</p>
<blockquote class="blockquote">
<p>agent ≈ model + tools, within a for-loop + environment</p>
</blockquote>
<p>Let’s break this down:</p>
<ul>
<li><strong>Model</strong>: an LLM receiving inputs tokens and outputting response tokens</li>
<li><strong>Tools</strong>: function definitions provided to the model, e.g.&nbsp;<code>search_web(query: str) -&gt; str</code> that it can provide arguments to in its response</li>
<li><strong>For-loop</strong>: the model is called multiple times, with the output of one call being the input to a tool or another call</li>
<li><strong>Environment</strong>: the runtime calling the model, providing it with access to tools, data, and tracking the state of the workflow</li>
</ul>
<p>This definition is a great starting point and cuts through the overthinking and hype. It needs one more element to be complete:</p>
<p><strong>Degree of agency</strong>: The agent is in charge of the workflow. It decides on what to do next to pursue a given goal. This can be categorized into 4 levels:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/agentic-ai/levels.svg" class="img-fluid figure-img"></p>
<figcaption>4 Levels of agency</figcaption>
</figure>
</div>
<ol type="1">
<li><strong>Single call, single tool</strong>: the model is called once with a single tool provided</li>
<li><strong>Single call, multiple tools</strong>: the model is called once with multiple tools provided and the model decides which ones to use</li>
<li><strong>Fixed workflow</strong>: the model is called multiple times with a predetermined sequence of prompts, feeding the output of one call into the next</li>
<li><strong>Open-ended workflow / true agentic AI</strong>: the model is called multiple times with a flexible sequence of prompts, feeding the output of one call into the next, and choosing the end of the loop independently</li>
</ol>
<p>The order of levels 2 and 3 is debatable. Level 2 adds the tool decision, level 3 adds having multiple steps. Level 4 has both, is open ended and is the only true agentic one.</p>
<p>The main question of this article is to provide a framework to decide whether the jump from level 3 to level 4 is worth it for a given use case. We will look at the new use cases unlocked and the tradeoffs involved.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>The LLM in a for-loop definition used here is the simplest possible. If you’re looking for a more sophisticated definition, check out <a href="https://weaviate.io/blog/ai-agents">Weaviate’s article (Feb 2025)</a> that offers a history of the methodology, <a href="https://www.anthropic.com/research/building-effective-agents">Anthropic’s article (Dec 2024)</a> describing common workflow patterns including parallel operations, and <a href="https://huyenchip.com/2025/01/07/agents">Chip Huyen’s article (Jan 2025)</a> that goes into detail on the planning phase of agentic workflows. Acharya and Kuppan provide a <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10849561">formal ontology (Jan 2025)</a> of agents.</p>
</div>
</div>
</section>
<section id="real-world-use" class="level3">
<h3 class="anchored" data-anchor-id="real-world-use">Real world use</h3>
<p><a href="https://aiagentindex.mit.edu">The AI Agent Index</a> by Casper et al.&nbsp;from MIT tracks the number of agentic AI systems deployed by large organizations. The number of agents deployed is growing every month. Their requirements for inclusion are strict and likely undercount the actual number of agents deployed.</p>
<div id="690b0684" class="cell" data-execution_count="3">
<div class="cell-output cell-output-display">
<div>            <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG"></script><script type="text/javascript">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: "STIX-Web"}});}</script>                <script type="text/javascript">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>
        <script charset="utf-8" src="https://cdn.plot.ly/plotly-3.3.0.min.js" integrity="sha256-bO3dS6yCpk9aK4gUpNELtCiDeSYvGYnK7jFI58NQnHI=" crossorigin="anonymous"></script>                <div id="e968c5df-f7f2-48b6-831d-b1f8813ef87b" class="plotly-graph-div" style="height:300px; width:100%;"></div>            <script type="text/javascript">                window.PLOTLYENV=window.PLOTLYENV || {};                                if (document.getElementById("e968c5df-f7f2-48b6-831d-b1f8813ef87b")) {                    Plotly.newPlot(                        "e968c5df-f7f2-48b6-831d-b1f8813ef87b",                        [{"hovertemplate":"date=%{x}\u003cbr\u003ecount=%{y}\u003cextra\u003e\u003c\u002fextra\u003e","legendgroup":"","marker":{"color":"#636efa","pattern":{"shape":""}},"name":"","orientation":"v","showlegend":false,"textposition":"auto","x":["2023-03-01T00:00:00.000000000","2023-05-01T00:00:00.000000000","2023-07-01T00:00:00.000000000","2023-09-01T00:00:00.000000000","2023-11-01T00:00:00.000000000","2024-01-01T00:00:00.000000000","2024-03-01T00:00:00.000000000","2024-05-01T00:00:00.000000000","2024-07-01T00:00:00.000000000","2024-09-01T00:00:00.000000000","2024-11-01T00:00:00.000000000"],"xaxis":"x","y":{"dtype":"i1","bdata":"AgIBBAMDBwUGChA="},"yaxis":"y","type":"bar"}],                        {"template":{"data":{"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"contour"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"heatmap"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"histogram2dcontour"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"histogram2d"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scattermap":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermap"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"margin":{"b":0,"l":0,"r":0,"t":30},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"xaxis":{"anchor":"y","domain":[0.0,1.0],"title":{"text":"Release Date"},"tickmode":"array","tickvals":["2023-03-01T00:00:00.000000000","2023-05-01T00:00:00.000000000","2023-07-01T00:00:00.000000000","2023-09-01T00:00:00.000000000","2023-11-01T00:00:00.000000000","2024-01-01T00:00:00.000000000","2024-03-01T00:00:00.000000000","2024-05-01T00:00:00.000000000","2024-07-01T00:00:00.000000000","2024-09-01T00:00:00.000000000","2024-11-01T00:00:00.000000000"],"ticktext":["2023-03","2023-05","2023-07","2023-09","2023-11","2024-01","2024-03","2024-05","2024-07","2024-09","2024-11"],"fixedrange":true},"yaxis":{"anchor":"x","domain":[0.0,1.0],"title":{"text":"Number of Agents"},"fixedrange":true},"legend":{"tracegroupgap":0},"title":{"text":"Agentic AI Deployments at Large Organizations"},"barmode":"relative","height":300,"modebar":{"remove":["zoom","pan","select","lasso","zoomIn","zoomOut","autoScale","resetScale","toImage","sendDataToCloud","toggleSpikelines","hoverClosestCartesian","hoverCompareCartesian","plotly"]},"showlegend":false},                        {"displaylogo": false, "responsive": true}                    ).then(function(){
                            
var gd = document.getElementById('e968c5df-f7f2-48b6-831d-b1f8813ef87b');
var x = new MutationObserver(function (mutations, observer) {{
        var display = window.getComputedStyle(gd).display;
        if (!display || display === 'none') {{
            console.log([gd, 'removed!']);
            Plotly.purge(gd);
            observer.disconnect();
        }}
}});

// Listen for the removal of the full notebook cells
var notebookContainer = gd.closest('#notebook-container');
if (notebookContainer) {{
    x.observe(notebookContainer, {childList: true});
}}

// Listen for the clearing of the current output cell
var outputEl = gd.closest('.output');
if (outputEl) {{
    x.observe(outputEl, {childList: true});
}}

                        })                };            </script>        </div>
</div>
</div>
<p>Let’s take a look at the most promising use cases. Click on the use cases to expand them.</p>
<div class="callout callout-style-simple callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Deep research
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>An agent that accepts a search query, asks clarifying questions, searches the web systematically for 5 to 30 minutesand writes a detailed report, akin to a literature review.</p>
<p>Examples, all released in February 2025:</p>
<ul>
<li><a href="https://openai.com/research/deep-research">OpenAI’s Deep Research</a>: Performs multi-step web searches, synthesizes information from multiple sources, and generates cited reports.</li>
<li><a href="https://www.perplexity.ai/blog/introducing-deep-research">Perplexity’s Deep Research</a>: Searches the web, writes code to analyze data, and compiles findings with source citations.</li>
<li><a href="https://research.google/blog/ai-co-scientist">Google’s AI Co-scientist</a>: Analyzes scientific literature, suggests hypotheses, and outlines potential experimental approaches.</li>
<li><a href="https://x.ai/blog/grok-3">X’s Grok DeepSearch</a>: Searches the internet and X platform, uses specialized reasoning modes for complex problem-solving.</li>
</ul>
<p>There is no default benchmark for this use case yet. The difficulty is that the agent needs to search the web live, and the content of the web changes constantly.</p>
<p>I read reviews of OpenAI’s Deep Research by <a href="https://www.oneusefulthing.org/i/156359450/deep-research">Ethan Mollick</a>, <a href="https://marginalrevolution.com/marginalrevolution/2025/02/deep-research.html">Tyler Cowen</a>, <a href="https://leonfurze.com/2025/02/15/hands-on-with-deep-research/">Leon Furze</a>, <a href="https://generativehistory.substack.com/p/is-this-the-last-generation-of-historians">Mark Humphries</a>, and <a href="https://www.science.org/content/blog-post/evaluation-deep-research-performance">Derek Lowe</a>. Each reviewer asked it to perform a literature review or similar in their field of expertise, ranging from economics to toxicology. The common themes were:</p>
<ul>
<li>Impressed by the volume and polish of the output</li>
<li>Massive time saver, Tyler Cowen reports that it’s like having a PhD-level research assistant that does a week’s work in five minutes.</li>
<li>The agent can’t access paywalled content, e.g.&nbsp;journal papers, which limits its usefulness in fields that are behind on open access.</li>
<li>Can be too surface-level, lacking in synthesis.</li>
<li>Can get details wrong, misleading non-experts. Derek Lowe puts it well: “you have to know the material already to realize when your foot has gone through what was earlier solid flooring”</li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Computer use
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>An agent that can help with a wide variety of computer tasks going from simple (setting a reminder, creating a note, sending an email) to more complex (finding leads on LinkedIn, scheduling a meeting with many people and across timezones, finding the best flight for a trip).</p>
<p>Examples:</p>
<ul>
<li><a href="https://www.anthropic.com/news/3-5-models-and-computer-use">Anthropic’s Claude with Computer Use</a>: Controls desktop applications, navigates interfaces, manipulates files, and interacts with web browsers through API-based screen access.</li>
<li><a href="https://openai.com/index/introducing-operator/">OpenAI’s Operator</a>: Navigates websites, completes forms, books reservations, makes purchases, and performs multi-step tasks with browser automation.</li>
<li><a href="https://www.aboutamazon.com/news/devices/new-alexa-generative-artificial-intelligence">Amazon’s Alexa Plus</a>: Maintains conversational context, controls smart home devices, answers complex questions, and performs multi-step tasks through voice commands.</li>
<li><a href="https://www.raycast.com/core-features/ai">Raycast’s AI extensions</a>: Integrates with desktop applications, executes system commands, manages files, and provides contextual assistance through a keyboard-driven launcher.</li>
</ul>
<p>The <a href="https://github.com/web-arena-x/webarena?tab=readme-ov-file">webarena benchmark</a> gives an idea of how well computer use agents work on a range of browser-based tasks. As of February 2025, the best performing agent was IBM CUGA with a success rate of 61.7%, followed by OpenAI’s Operator at 58.1%. Clearly, there’s room for improvement.</p>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Coding
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>An agent that can write code, review changes, and debug.</p>
<p>Examples:</p>
<ul>
<li><a href="https://docs.cursor.com/agent">Cursor Agent</a>: Indexes codebases, performs web searches for up-to-date information, executes multi-step coding tasks, and generates tests through an AI-powered code editor.</li>
<li><a href="https://codeium.com/cascade">Windsurf Cascade</a>: Processes code across multiple files, understands project structure, accepts image inputs, maintains memory of previous interactions, and implements code changes.</li>
<li><a href="https://docs.anthropic.com/en/docs/agents-and-tools/claude-code/overview">Claude Code</a>: Operates in the terminal, understands entire codebases, executes shell commands, and implements code changes through natural language instructions.</li>
<li><a href="https://devin.ai">Devin</a>: Collaborates via Slack, accesses repositories, writes and debugs code, learns from projects, and adapts to team workflows over time.</li>
<li><a href="https://pub.sakana.ai/static/paper.pdf">Sakana AI’s CUDA kernel optimization agent</a>: Translates PyTorch code to optimized CUDA kernels, utilizes specialized hardware features, and improves model performance on GPUs.</li>
</ul>
<p>Benchmarks and reviews:</p>
<ul>
<li><a href="https://www.swebench.com/#verified">SWE-Bench Verified</a>: solving real GitHub issues focusing on code generation and bug fixing. Current best agent reaches 64.6%.</li>
<li>The folks at Answer.ai <a href="https://www.answer.ai/posts/2025-01-08-devin.html">evaluated Devin</a> across 20 tasks and saw 14 failures, 3 inconclusive results and just 3 successes. Further, they weren’t able to predict which tasks Devin would succeed at. Ultimately, they concluded that the closer feedback loop of an AI acting inside an IDE is more effective.</li>
<li>Sakana’s CUDA kernel optimization agent <a href="https://x.com/SakanaAILabs/status/1892992938013270019">proved</a> too smart for its own good and wrote code that exploited a bug in the evaluation code to “cheat” and get higher scores. Still, the concept of specialized coding agents is promising.</li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Customer support
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>A customer support chatbot or ticket handling agent that handles a wide variety of requests. It can either enhance or replace a human agent.</p>
<p>Examples:</p>
<ul>
<li><a href="https://www.intercom.com/fin">Intercom’s Fin AI</a>: Answers questions using knowledge bases, processes transactions, and maintains conversation context throughout customer interactions.</li>
<li><a href="https://www.klarna.com/international/press/klarna-ai-assistant-handles-two-thirds-of-customer-service-chats-in-its-first-month/">Klarna’s AI assistant</a>: Processes refunds, manages returns, handles payment issues, and provides shopping recommendations in multiple languages. A case study on LangChain’s <a href="https://blog.langchain.dev/customers-klarna/">website</a> gives more recent technical insight.</li>
<li><a href="https://www.salesforce.com/news/press-releases/2024/09/12/agentforce-announcement/">Salesforce AgentForce</a>: Resolves customer cases using company data, integrates with CRM systems, and automates support workflows.</li>
</ul>
<p>Benchmarks and reviews:</p>
<ul>
<li>Intercom claims to have handled more than 15 million customer queries using Fin with a 54% resolution rate, steadily increasing over time as the agent is improved.</li>
<li>In February 2024, Klarna reported that its AI assistant handled two thirds of customer service chats in its first month, doing the equivalent work of 700 full-time employees. Klarna maintains a 4.1 rating on <a href="https://www.trustpilot.com/review/klarna.com">Trustpilot</a>, higher than most financial service providers, suggesting that the agentic approach is effective.</li>
<li>Salesforce cites their customer Wiley, claiming a 40% increase in case resolution over a previous chatbot. However, they don’t give an actual resolution rate.</li>
</ul>
</div>
</div>
</div>
<p>These are just the four most common and promising use cases, based on my research. <a href="https://cloud.google.com/transform/101-real-world-generative-ai-use-cases-from-industry-leaders?hl=en">Google Cloud</a> lists a whopping 321 gen AI use cases, and <a href="https://blogs.microsoft.com/blog/2025/02/05/https-blogs-microsoft-com-blog-2024-11-12-how-real-world-businesses-are-transforming-with-ai/">Microsoft</a> also lists more than 300. Only a minority of them are truely agentic though, the majority are on levels 1 to 3. In addition to these publicly available examples, companies are developing internal tools to solve all kinds of problems, ranging from report generation to automated pricing updates.</p>
<p>Looking over the benchmarks and reviews cited in the use cases above, success rates range from 10% to 65%. Clearly, agentic AI is not ready for unsupervised high stakes jobs. It needs oversight by a human expert.</p>
</section>
<section id="compounding-error-problem" class="level3">
<h3 class="anchored" data-anchor-id="compounding-error-problem">Compounding error problem</h3>
<p>Each step in an agentic workflow has a chance of introducing an error. Let’s model this in a simplified way where each step has the same error rate and there is no error recovery. The graph below shows the chance of the workflow being correct as a function of the number of steps, for different error rates.</p>
<div id="6798f56d" class="cell" data-execution_count="4">
<div class="cell-output cell-output-display">
<div>            <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG"></script><script type="text/javascript">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: "STIX-Web"}});}</script>                <script type="text/javascript">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>
        <script charset="utf-8" src="https://cdn.plot.ly/plotly-3.3.0.min.js" integrity="sha256-bO3dS6yCpk9aK4gUpNELtCiDeSYvGYnK7jFI58NQnHI=" crossorigin="anonymous"></script>                <div id="9e8fdaca-b215-44c9-8a9b-28b9aca2991f" class="plotly-graph-div" style="height:350px; width:100%;"></div>            <script type="text/javascript">                window.PLOTLYENV=window.PLOTLYENV || {};                                if (document.getElementById("9e8fdaca-b215-44c9-8a9b-28b9aca2991f")) {                    Plotly.newPlot(                        "9e8fdaca-b215-44c9-8a9b-28b9aca2991f",                        [{"hovertemplate":"Error Rate=1% error rate\u003cbr\u003eNumber of steps=%{x}\u003cbr\u003eProbability of no error=%{y}\u003cextra\u003e\u003c\u002fextra\u003e","legendgroup":"1% error rate","line":{"color":"#636efa","dash":"solid"},"marker":{"symbol":"circle"},"mode":"lines+markers","name":"1% error rate","orientation":"v","showlegend":true,"x":{"dtype":"i1","bdata":"AQIDBAUGBwgJCg=="},"xaxis":"x","y":{"dtype":"f8","bdata":"rkfhehSu7z8+6Nms+lzvP5rtCn2wDO8\u002fYsfz1zO97j+CimSvgm7uP+1VcPqaIO4\u002fL9pftXrT7T+GA6ThH4ftPwzGyIWIO+0\u002fvwtorbLw7D8="},"yaxis":"y","type":"scatter"},{"hovertemplate":"Error Rate=2% error rate\u003cbr\u003eNumber of steps=%{x}\u003cbr\u003eProbability of no error=%{y}\u003cextra\u003e\u003c\u002fextra\u003e","legendgroup":"2% error rate","line":{"color":"#EF553B","dash":"solid"},"marker":{"symbol":"circle"},"mode":"lines+markers","name":"2% error rate","orientation":"v","showlegend":true,"x":{"dtype":"i1","bdata":"AQIDBAUGBwgJCg=="},"xaxis":"x","y":{"dtype":"f8","bdata":"XI\u002fC9Shc7z9AguLHmLvuP\u002fc3aK8+Hu4\u002fU0tCOwqE7T+zxI1O6+zsP84X5x7SWOw\u002fSsDDMq\u002fH6z\u002fsUNRfcznrPy\u002fKbskPruo\u002f0Q0B33Ul6j8="},"yaxis":"y","type":"scatter"},{"hovertemplate":"Error Rate=5% error rate\u003cbr\u003eNumber of steps=%{x}\u003cbr\u003eProbability of no error=%{y}\u003cextra\u003e\u003c\u002fextra\u003e","legendgroup":"5% error rate","line":{"color":"#00cc96","dash":"solid"},"marker":{"symbol":"circle"},"mode":"lines+markers","name":"5% error rate","orientation":"v","showlegend":true,"x":{"dtype":"i1","bdata":"AQIDBAUGBwgJCg=="},"xaxis":"x","y":{"dtype":"f8","bdata":"ZmZmZmZm7j\u002fhehSuR+HsP1UOLbKdb+s\u002fN2dEaW8Q6j9AlZo90MLoP\u002f1AuW3fhec\u002fVpcJdcdY5j\u002fFT\u002fx7vTrlP2HlYs8AK+Q\u002fg\u002fOdXtoo4z8="},"yaxis":"y","type":"scatter"},{"hovertemplate":"Error Rate=10% error rate\u003cbr\u003eNumber of steps=%{x}\u003cbr\u003eProbability of no error=%{y}\u003cextra\u003e\u003c\u002fextra\u003e","legendgroup":"10% error rate","line":{"color":"#ab63fa","dash":"solid"},"marker":{"symbol":"circle"},"mode":"lines+markers","name":"10% error rate","orientation":"v","showlegend":true,"x":{"dtype":"i1","bdata":"AQIDBAUGBwgJCg=="},"xaxis":"x","y":{"dtype":"f8","bdata":"zczMzMzM7D\u002fsUbgehevpP4gW2c73U+c\u002frfpcbcX+5D9prtNIS+XiP\u002fgcWI6QAeE\u002fv83RmWqc3j\u002fG0jxXxozbP3+Kg05\u002fy9g\u002f2S9DYL9Q1j8="},"yaxis":"y","type":"scatter"}],                        {"template":{"data":{"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"contour"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"heatmap"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"histogram2dcontour"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"histogram2d"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scattermap":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermap"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"margin":{"b":0,"l":0,"r":0,"t":30},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"xaxis":{"anchor":"y","domain":[0.0,1.0],"title":{"text":"Number of steps"},"dtick":1,"fixedrange":true},"yaxis":{"anchor":"x","domain":[0.0,1.0],"title":{"text":"Probability of no error"},"tickmode":"array","tickvals":{"dtype":"f8","bdata":"AAAAAAAAAACamZmZmZm5P5qZmZmZmck\u002fNDMzMzMz0z+amZmZmZnZPwAAAAAAAOA\u002fNDMzMzMz4z9nZmZmZmbmP5qZmZmZmek\u002fzczMzMzM7D8AAAAAAADwPw=="},"ticktext":["0%","10%","20%","30%","40%","50%","60%","70%","80%","90%","100%"],"fixedrange":true},"legend":{"title":{"text":"Error Rate"},"tracegroupgap":0},"modebar":{"remove":["zoom","pan","select","lasso","zoomIn","zoomOut","autoScale","resetScale","toImage","sendDataToCloud","toggleSpikelines","hoverClosestCartesian","hoverCompareCartesian","plotly"]},"height":350},                        {"displaylogo": false, "responsive": true}                    ).then(function(){
                            
var gd = document.getElementById('9e8fdaca-b215-44c9-8a9b-28b9aca2991f');
var x = new MutationObserver(function (mutations, observer) {{
        var display = window.getComputedStyle(gd).display;
        if (!display || display === 'none') {{
            console.log([gd, 'removed!']);
            Plotly.purge(gd);
            observer.disconnect();
        }}
}});

// Listen for the removal of the full notebook cells
var notebookContainer = gd.closest('#notebook-container');
if (notebookContainer) {{
    x.observe(notebookContainer, {childList: true});
}}

// Listen for the clearing of the current output cell
var outputEl = gd.closest('.output');
if (outputEl) {{
    x.observe(outputEl, {childList: true});
}}

                        })                };            </script>        </div>
</div>
</div>
<p>Clearly, higher error rates and more steps make the workflow less likely to succeed. A developer that values correctness has to obsess over error rates and keep the number of steps low.</p>
<p>Error tolerance in business is dependent on culture, familiarity with AI, expectation management and what’s at stake. Let’s consider examples of different errors:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 16%">
<col style="width: 50%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th>Error</th>
<th>Example</th>
<th>Mitigation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Planning failure</strong></td>
<td>Agent misunderstands the goal, the constraints or the tools that it has available and plans a path that spins in circles, crashes or returns an incorrect answer.</td>
<td>Clear goal specification, user confirmation steps</td>
</tr>
<tr class="even">
<td><strong>Tool failure</strong></td>
<td>A tool fails to return a correct answer, such as a search that returns an irrelevant or outdated result, or a web scraper that gets blocked by a CAPTCHA. Some errors are loud (e.g.&nbsp;the CAPTCHA), whereas others are silent and poison the output.</td>
<td>Tests for each tool, monitoring of tool calls, try-catch blocks</td>
</tr>
<tr class="odd">
<td><strong>Type errors</strong></td>
<td>The agent doesn’t provide correctly formatted arguments to a tool, or the tool returns an unexpected format.</td>
<td>Validating types statically and at runtime</td>
</tr>
<tr class="even">
<td><strong>Latency</strong></td>
<td>The workflow becomes too long due to too many steps taken or slow tool calls. Users get bored and abandon the agent.</td>
<td>Parallelization, caching, limiting the number of steps</td>
</tr>
</tbody>
</table>
</section>
<section id="agents-causing-harm" class="level3">
<h3 class="anchored" data-anchor-id="agents-causing-harm">Agents causing harm</h3>
<p>In the previous section, we considered failure modes that cause inconvenience. However, agents can also cause harm in the form of data loss, financial damage, legal liability or cyber security incidents.</p>
<ol type="1">
<li><strong>User error</strong>. For example, giving unclear instructions that lead to a wrong file being overwritten or a message sent to the wrong person. Ask the user for confirmation and give them a way to undo the action, where possible.</li>
<li><strong>Model error</strong>. A tool could misunderstand the user’s intent or the way a tool works.</li>
<li><strong>Prompt injection</strong>. LLMs are susceptible to prompt injection, meaning someone hijacking the workflow by overriding the original instructions with a clever prompt. Malicious prompts can be found on websites, received via emails or be hidden in the user’s files.</li>
</ol>
<p>The potential damage primarily depends on the tools that the agent has access to. Consider what the worst thing is that the agent could do with a tool. If that is unacceptable, limit the agent’s access. For example, an agent that can access a database could only be allowed to read, not write, or to only write to a specific append-only table. Payments, deleting data, and other dangerous actions should require user confirmation.</p>
</section>
<section id="not-every-workflow-needs-agentic-ai" class="level2">
<h2 class="anchored" data-anchor-id="not-every-workflow-needs-agentic-ai">Not every workflow needs agentic AI</h2>
<p>Based on the previous case studies and analysis of error rates, here’s a list of reasons to use agentic AI and reasons to avoid it:</p>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Reasons to use agentic AI ✅</strong></p>
<ul>
<li>The problem space is too large to enumerate every path</li>
<li>Every interaction is truly different</li>
<li>The problems are hard enough that only a flexible multi-hop system can solve them</li>
<li>High payoff for successful resolution (e.g.&nbsp;saving a human a lot of work)</li>
<li>Low cost of exploration and occasional missteps</li>
<li>You have the necessary time to evaluate the agentic workflow, install safeguards</li>
<li>You value the ease of adding new tools to an agentic workflow</li>
<li>The tools the agent would use already work independently, so it’s just a matter of coordinating them</li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>Reasons to avoid agentic AI ❌</strong></p>
<ul>
<li>The task can be described as a fixed workflow of steps</li>
<li>Low latency is required</li>
<li>Low error tolerance, e.g.&nbsp;for legal, organizational or social reasons</li>
<li>Need to keep token usage low</li>
<li>Need predictable workflows</li>
<li>Need high explainability</li>
<li>Need to prove that every step of the workflow is correct</li>
<li>Agentic AI frameworks are not mature yet</li>
<li>Cybersecurity concerns from prompt injection and other attacks</li>
</ul>
</div>
</div>
<p>Agents aren’t all or nothing - there are many shades of agentic AI. Each level of agent autonomy increases the surface area for errors. Therefore, it can be wiser to use a hybrid approach that is level 2 or 3 on the agency scale above, with fixedsteps and tool selection, and limited decision making by the agent. Ask: Is the task really so complex and open-ended that it can’t be described as a fixed series of steps and decision points?</p>
<section id="converting-agentic-workflows-to-fixed-workflows" class="level3">
<h3 class="anchored" data-anchor-id="converting-agentic-workflows-to-fixed-workflows">Converting agentic workflows to fixed workflows</h3>
<p>In city planning, there’s the concept of a “desire path”. Rather than walking the long, intended path, people take a shortcut. There’s an urban legend that when Dwight D. Eisenhower was in charge of an extension of Columbia University, he let students walk on grass until natural paths had formed, and then had them paved.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/agentic-ai/desire_path.png" class="img-fluid figure-img"></p>
<figcaption>Desire path being paved. Image created with FLUX.1-pro</figcaption>
</figure>
</div>
<p>This concept could be applied to agentic workflows. Start by giving an agent the freedom to choose tools and order of execution. Observe which paths are taken and which result in success. Then pave those paths by making them fixed workflows, enabling greater reliability.</p>
</section>
</section>
<section id="so-you-want-to-build-an-agentic-workflow" class="level2">
<h2 class="anchored" data-anchor-id="so-you-want-to-build-an-agentic-workflow">So you want to build an agentic workflow?</h2>
<p>It’s alluringly easy to build a system that looks like it’s working and has impressive sounding capabilities. Just copy-paste from the documentation of a popular agent tool. Copy a tool for web search, a code interpreter and a memory layer and you have an agent with impressive <em>theoretical</em> capabilities.</p>
<p>The hard part is to make the agentic workflow work reliably in production, without close supervision. And that’s where the business value is – a demo doesn’t repay an investment.</p>
<p>The following sections are suggestions for how to make agentic workflows succeed reliably in production.</p>
<section id="start-with-solid-software-engineering" class="level3">
<h3 class="anchored" data-anchor-id="start-with-solid-software-engineering">Start with solid software engineering</h3>
<p>The building blocks of agentic workflows are not new: loops, strings being passed between tools, arrays of floats for embeddings, HTTP requests, JSON. So the established concepts of writing clean code, enforcing type safety, having a test environment and running automated tests apply. A good agentic app starts with a good app.</p>
</section>
<section id="agent-frameworks-are-optional" class="level3">
<h3 class="anchored" data-anchor-id="agent-frameworks-are-optional">Agent frameworks are optional</h3>
<p>Going back to Eugene Yan’s definition of agents as “model + tools, within a for-loop + environment”, it’s clear that agents can be implemented in any programming language that can make HTTP requests. In <a href="https://www.anthropic.com/research/building-effective-agents">Building Effective Agents</a>, Anthropic notes:</p>
<blockquote class="blockquote">
<p>Consistently, the most successful implementations weren’t using complex frameworks or specialized libraries. Instead, they were building with simple, composable patterns.</p>
</blockquote>
<p>So should you use an agent framework or not? Let’s examine the tradeoffs:</p>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Reasons to use frameworks ✅</strong></p>
<ul>
<li>Boost early development speed with pre-packaged patterns and integrations</li>
<li>Provide mental models for workflow structure (e.g.&nbsp;CrewAI’s role-playing metaphor)</li>
<li>Easier onboarding for new colleagues familiar with the framework</li>
<li>Express complex workflows concisely</li>
<li>Tap into pre-built tool integrations for data input, monitoring, etc.</li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>Reasons to avoid frameworks ❌</strong></p>
<ul>
<li>Often immature with frequent bugs and unclear documentation</li>
<li>Breaking API changes</li>
<li>Many dependencies</li>
<li>Force programming in “framework way”</li>
<li>Many have a monolithic design, instead of composable unix philosophy</li>
<li>Tendency to reinvent the wheel in a less production grade way</li>
<li>Steep learning curve, depending on the framework</li>
</ul>
</div>
</div>
<p>As a case study, the AI test automation company Octomind wrote an <a href="https://www.octomind.dev/blog/why-we-no-longer-use-langchain-for-building-our-ai-agents">article</a> comparing LangChain to vanilla Python, explaining why they moved away from frameworks altogether.</p>
</section>
<section id="trace-every-step" class="level3">
<h3 class="anchored" data-anchor-id="trace-every-step">Trace every step</h3>
<p>Regardless of whether you use an agent framework or not, effective monitoring is a must. The first thing to put into place is a system that logs every step of the workflow: user inputs, transformed inputs, tool choices, tool calls, tool call results, reasoning tokens, output, latency, token usage, etc. The best and easiest time to set this up is right at the start of the project. As the project grows, set up a dashboard and alerts for critical metrics.</p>
</section>
<section id="theres-no-substitute-for-manual-inspection" class="level3">
<h3 class="anchored" data-anchor-id="theres-no-substitute-for-manual-inspection">There’s no substitute for manual inspection</h3>
<blockquote class="blockquote">
<p>Manual inspection of data has probably the highest value-to-prestige ratio of any activity in machine learning.</p>
</blockquote>
<p><a href="https://x.com/gdb/status/1622683988736479232">Greg Brockman</a>, President and co-founder of OpenAI</p>
<p>Before going to automatic tests, LLM as judge etc., inspect some workflows manually using the monitoring system. Check the input, the tool calls, the intermittent reasoning tokens, and the output. Many problems can be diagnosed this way. In addition, it peels away some of the “magic” that agentic frameworks by showing the prompts and tool calls. Hamel Husain put it well in an <a href="https://hamel.dev/blog/posts/prompt/">article</a>, asking “Show me the prompt” of every LLM library. Manual inspection keeps yielding insights, even after automatic evals are in place.</p>
</section>
</section>
<section id="conclusion-build-as-agentic-as-needed-not-as-agentic-as-possible" class="level2">
<h2 class="anchored" data-anchor-id="conclusion-build-as-agentic-as-needed-not-as-agentic-as-possible">Conclusion: Build as agentic as needed, not as agentic as possible</h2>
<p>As shown by benchmark scores and user reviews, agentic AI is currently a “65% solution”. There are impressive demos, but the real world is messy. The gap needs to be bridged by careful safeguards, domain-specific heuristics, smart task framing, and human oversight. Much like operating a self-driving car, users need to stay alert and be ready to take control at any moment. However, consider that human workers also make mistakes - perfection is not a realistic benchmark.</p>
<p>From a business perspective, there is still an enormous amount of value to be realized by simpler uses of generative AI. Going all-in on agentic AI may not be necessary. Consider the pros and cons listed above and locate the task at hand on the four-level agency scale.</p>


</section>

 ]]></description>
  <category>Machine Learning</category>
  <category>Agents</category>
  <guid>https://simmering.dev/blog/agentic-ai/</guid>
  <pubDate>Fri, 28 Feb 2025 23:00:00 GMT</pubDate>
  <media:content url="https://simmering.dev/blog/agentic-ai/image.webp" medium="image" type="image/webp"/>
</item>
<item>
  <title>ModernBERT vs LLMs for Detecting Adverse Drug Reactions</title>
  <dc:creator>Paul Simmering</dc:creator>
  <link>https://simmering.dev/blog/modernbert-vs-llm/</link>
  <description><![CDATA[ 






<p>HuggingFace recently released ModernBERT <span class="citation" data-cites="warner2024smarterbetterfasterlonger">(Warner et al. 2024)</span>, an updated version of the BERT language model <span class="citation" data-cites="devlin2018bert">(Devlin 2018)</span> which backports many improvements from LLM research back to the classic 2018 model. In contrast to LLMs, ModernBERT is an encoder-only model that is fitted with a task-specific head outputting probabilities for structured NLP tasks, rather than tokens.</p>
<p>While LLMs with their decoder-only architecture were originally designed for text generation, they have also been used for structured NLP tasks like text classification. They are imbued with a large amount of general knowledge and excel at zero-shot and few-shot learning. Through the proliferation of the LLM ecosystem they are also widely available via APIs and familiar to many developers.</p>
<p>Here, I will compare ModernBERT to Meta’s Llama 3.2-3B by <span class="citation" data-cites="grattafiori2024llama3herdmodels">Grattafiori et al. (2024)</span> on a text classification task using the dimensions accuracy, speed, cost and ease of use. Text classification is a simple task, yet very common and important in NLP pipelines. It may also be coupled with text generation in a chat bot, such as for intent classification or as a guardrail to prevent undesirable responses.</p>
<section id="task-adverse-event-classification" class="level2">
<h2 class="anchored" data-anchor-id="task-adverse-event-classification">Task: Adverse event classification</h2>
<p>During my work in market research for pharmaceutical companies, I frequently have to monitor data for <strong>adverse events</strong>. An adverse event is any undesirable medical event that occurs during or after treatment with a drug. Examples include side effects, lack of efficacy, and overdoses. It is of utmost importance to identify adverse events and report them to the producing pharmaceutical company. This task is labor intensive, so naturally I’m interested in automating it. I’ll use the ADE-Benchmark Corpus <span class="citation" data-cites="gurulingappa_development_2012">Gurulingappa et al. (2012)</span> as an example dataset. It contains 23,500 English medical text sentences describing effects of drugs. Each sentence is classified as 1: adverse drug reaction or 0: no adverse drug reaction. This represents a subtask of the broader task of adverse event monitoring.</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Resource</th>
<th>Link</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>💻 Python code &amp; readme</td>
<td><a href="https://github.com/psimm/website/blob/master/blog/modernbert-vs-llm/">GitHub</a></td>
</tr>
<tr class="even">
<td>📊 Experiment results</td>
<td><a href="https://wandb.ai/psimm/modernbert-vs-llm?nw=0uja1rkfaqe">Weights &amp; Biases project</a></td>
</tr>
<tr class="odd">
<td>📝 Dataset: ADE-Benchmark Corpus</td>
<td><a href="https://huggingface.co/datasets/ade-benchmark-corpus/ade_corpus_v2">Hugging Face Hub</a></td>
</tr>
</tbody>
</table>
<p>All training and inference is done on a single A10G GPU hosted on <a href="https://modal.com">Modal</a>. It costs $1.10/h. A Modal account is required to run the code. The free tier ($30 of free credits per month) is sufficient for this experiment.</p>
</section>
<section id="experiment-setup" class="level2">
<h2 class="anchored" data-anchor-id="experiment-setup">Experiment setup</h2>
<p>The diagram below illustrates three experiment setups: fine-tuning ModernBERT, few-shot learning with Llama 3.2-3B, and fine-tuning Llama 3.2-3B.</p>
<p><img src="https://simmering.dev/blog/modernbert-vs-llm/experiment.svg" class="img-fluid"></p>
<section id="dataset-preparation" class="level3">
<h3 class="anchored" data-anchor-id="dataset-preparation">Dataset preparation</h3>
<p>The dataset on HuggingFace consists of 23,516 sentences. After removing duplicate sentences, 20,896 unique examples are left. The distribution of classes is uneven, with more examples of texts without an adverse events. To balance the classes, I’m subsampling the negative examples down to 4,271 cases. Balanced classes prevent the models from overfitting to the majority class and let us compare the models using a simple accuracy metric.</p>
<p>Then, the dataset is split into 60% training, 20% validation and 20% test sets. The validation set is used to tune hyperparameters and implement early stopping. Splits are stratified by class to ensure a 50:50 split between positive and negative examples in each split. The final example count is:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Split</th>
<th>Class</th>
<th style="text-align: right;">Examples</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Training</td>
<td>Adverse Event</td>
<td style="text-align: right;">2,562</td>
</tr>
<tr class="even">
<td>Training</td>
<td>No Adverse Event</td>
<td style="text-align: right;">2,562</td>
</tr>
<tr class="odd">
<td>Validation</td>
<td>Adverse Event</td>
<td style="text-align: right;">855</td>
</tr>
<tr class="even">
<td>Validation</td>
<td>No Adverse Event</td>
<td style="text-align: right;">855</td>
</tr>
<tr class="odd">
<td>Test</td>
<td>Adverse Event</td>
<td style="text-align: right;">854</td>
</tr>
<tr class="even">
<td>Test</td>
<td>No Adverse Event</td>
<td style="text-align: right;">854</td>
</tr>
</tbody>
</table>
</section>
<section id="model-selection" class="level3">
<h3 class="anchored" data-anchor-id="model-selection">Model selection</h3>
<p>I’m comparing ModernBERT-base and ModernBERT-large as the structured language models with Llama 3.2-3B-instruct as the LLM.</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Model</th>
<th>Architecture</th>
<th>Parameters</th>
<th>Size at FP32</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><a href="https://huggingface.co/answerdotai/ModernBERT-base">ModernBERT-base</a></td>
<td>Encoder-only: outputs a probability distribution over classes</td>
<td>149M</td>
<td>~0.6GB</td>
</tr>
<tr class="even">
<td><a href="https://huggingface.co/answerdotai/ModernBERT-large">ModernBERT-large</a></td>
<td>Encoder-only: outputs a probability distribution over classes</td>
<td>395M</td>
<td>~1.6GB</td>
</tr>
<tr class="odd">
<td><a href="https://huggingface.co/meta-llama/Llama-3.2-3B">Llama 3.2-3B</a></td>
<td>Decoder-only: outputs text</td>
<td>3B</td>
<td>~12GB</td>
</tr>
</tbody>
</table>
<p>For inference, about 1.5 to 2x the model size is required to store the attention cache, calculate layer activations and other intermediate results. The A10G GPU used for this experiment has 24GB memory, so both models fit. The memory footprint can be reduced by half by using FP16 or INT8 precision, which is common for inference.</p>
</section>
<section id="setup-1-fine-tuning-modernbert" class="level3">
<h3 class="anchored" data-anchor-id="setup-1-fine-tuning-modernbert">Setup 1: Fine-tuning ModernBERT</h3>
<p>I’m using the transformers library to fine-tune ModernBERT base and large on the training set. <span class="citation" data-cites="schmid_fine_tune_2024">Schmid (2024)</span> from Hugging Face wrote a helpful guide which I adapted for use on Modal. The models are optimized on binary cross-entropy loss for 5 epochs. Training took about 2 minutes for ModernBERT-base and 3.5 minutes for ModernBERT-large.</p>
</section>
<section id="setup-2-few-shot-learning-with-llama-3.2-3b-and-dspy" class="level3">
<h3 class="anchored" data-anchor-id="setup-2-few-shot-learning-with-llama-3.2-3b-and-dspy">Setup 2: Few-shot learning with Llama 3.2-3B and DSPy</h3>
<p>I’m using DSPy <span class="citation" data-cites="khattab2023dspycompilingdeclarativelanguage">(Khattab et al. 2023)</span> to automatically select an optimal set of examples for few-shot learning. That’s a more objective approach than manual prompting and usually results in equally good or better accuracy. In my first trials, DSPy didn’t manage to write a suitable system prompt as it didn’t understand the adverse drug reaction task from examples alone. So I added the prompt: “Determine if the following sentence is about adverse drug reactions:” to the examples. This increased the accuracy by about 15 percentage points.</p>
<p>DSPy settings:</p>
<ul>
<li>20 few-shot examples plus 5 bootstrapped (AI generated) examples</li>
<li>Optimized for accuracy using MIPROv2 (minibatch size 50, minibatch full eval steps 10, num trials 3)</li>
<li>25 threads for calls to the LLM, which is hosted using FastAPI and vLLM on Modal</li>
</ul>
<p>The optimized predictor is available as a JSON file in the <a href="https://wandb.ai/psimm/modernbert-vs-llm?nw=0uja1rkfaqe">Weights &amp; Biases project</a>.</p>
</section>
<section id="setup-3-fine-tuning-llama-3.2-3b" class="level3">
<h3 class="anchored" data-anchor-id="setup-3-fine-tuning-llama-3.2-3b">Setup 3: Fine-tuning Llama 3.2-3B</h3>
<p>I’m using the torchtune library and a fine-tuning configuration to train a LoRA adapter on the training set. It targets the attention and feed-forward layers of the model. The adapter is a smaller set of weights that are added to the model at inference time. LoRA training incurs less training cost than full fine-tuning of all weights, but may result in worse accuracy. The LoRA settings used for training are available in the W&amp;B project and the training config file for torchtune. Training took about 8 minutes on the A10G.</p>
</section>
</section>
<section id="results" class="level2">
<h2 class="anchored" data-anchor-id="results">Results</h2>
<section id="accuracy-and-speed" class="level3">
<h3 class="anchored" data-anchor-id="accuracy-and-speed">Accuracy and speed</h3>
<div id="8f4e753b" class="cell" data-execution_count="2">
<div class="cell-output cell-output-display" data-execution_count="4">
<div id="wlsxcaorkl" style="padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>
#wlsxcaorkl table {
          font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;
          -webkit-font-smoothing: antialiased;
          -moz-osx-font-smoothing: grayscale;
        }

#wlsxcaorkl thead, tbody, tfoot, tr, td, th { border-style: none; }
 tr { background-color: transparent; }
#wlsxcaorkl p { margin: 0; padding: 0; }
 #wlsxcaorkl .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #004D80; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #004D80; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; }
 #wlsxcaorkl .gt_caption { padding-top: 4px; padding-bottom: 4px; }
 #wlsxcaorkl .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; }
 #wlsxcaorkl .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; }
 #wlsxcaorkl .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; }
 #wlsxcaorkl .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #0076BA; }
 #wlsxcaorkl .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #0076BA; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #0076BA; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; }
 #wlsxcaorkl .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; }
 #wlsxcaorkl .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; }
 #wlsxcaorkl .gt_column_spanner_outer:first-child { padding-left: 0; }
 #wlsxcaorkl .gt_column_spanner_outer:last-child { padding-right: 0; }
 #wlsxcaorkl .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #0076BA; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; }
 #wlsxcaorkl .gt_spanner_row { border-bottom-style: hidden; }
 #wlsxcaorkl .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #0076BA; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #0076BA; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; }
 #wlsxcaorkl .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #0076BA; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #0076BA; vertical-align: middle; }
 #wlsxcaorkl .gt_from_md> :first-child { margin-top: 0; }
 #wlsxcaorkl .gt_from_md> :last-child { margin-bottom: 0; }
 #wlsxcaorkl .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: none; border-top-width: 1px; border-top-color: #89D3FE; border-left-style: none; border-left-width: 1px; border-left-color: #89D3FE; border-right-style: none; border-right-width: 1px; border-right-color: #89D3FE; vertical-align: middle; overflow-x: hidden; }
 #wlsxcaorkl .gt_stub { color: #FFFFFF; background-color: #0076BA; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #0076BA; padding-left: 5px; padding-right: 5px; }
 #wlsxcaorkl .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; }
 #wlsxcaorkl .gt_row_group_first td { border-top-width: 2px; }
 #wlsxcaorkl .gt_row_group_first th { border-top-width: 2px; }
 #wlsxcaorkl .gt_striped { background-color: #F4F4F4; }
 #wlsxcaorkl .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #0076BA; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #0076BA; }
 #wlsxcaorkl .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; }
 #wlsxcaorkl .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; text-align: left; }
 #wlsxcaorkl .gt_left { text-align: left; }
 #wlsxcaorkl .gt_center { text-align: center; }
 #wlsxcaorkl .gt_right { text-align: right; font-variant-numeric: tabular-nums; }
 #wlsxcaorkl .gt_font_normal { font-weight: normal; }
 #wlsxcaorkl .gt_font_bold { font-weight: bold; }
 #wlsxcaorkl .gt_font_italic { font-style: italic; }
 #wlsxcaorkl .gt_super { font-size: 65%; }
 #wlsxcaorkl .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; }
 #wlsxcaorkl .gt_asterisk { font-size: 100%; vertical-align: 0; }
 
</style>

<table class="gt_table caption-top table table-sm table-striped small" data-quarto-bootstrap="false">
<thead>
<tr class="gt_heading header">
<td colspan="6" class="gt_heading gt_title gt_font_normal">Model Performance Comparison</td>
</tr>
<tr class="gt_col_headings even">
<th id="Setup" class="gt_col_heading gt_columns_bottom_border gt_left" data-quarto-table-cell-role="th" scope="col">Setup</th>
<th id="F1 Score (%)" class="gt_col_heading gt_columns_bottom_border gt_right" data-quarto-table-cell-role="th" scope="col">F1 Score (%)</th>
<th id="Recall (%)" class="gt_col_heading gt_columns_bottom_border gt_right" data-quarto-table-cell-role="th" scope="col">Recall (%)</th>
<th id="Precision (%)" class="gt_col_heading gt_columns_bottom_border gt_right" data-quarto-table-cell-role="th" scope="col">Precision (%)</th>
<th id="Examples/sec" class="gt_col_heading gt_columns_bottom_border gt_right" data-quarto-table-cell-role="th" scope="col">Examples/sec</th>
<th id="Configuration" class="gt_col_heading gt_columns_bottom_border gt_left" data-quarto-table-cell-role="th" scope="col">Configuration</th>
</tr>
</thead>
<tbody class="gt_table_body">
<tr class="odd">
<td class="gt_row gt_left">1a-modernbert-base</td>
<td class="gt_row gt_right">86.0</td>
<td class="gt_row gt_right">90.3</td>
<td class="gt_row gt_right">82.2</td>
<td class="gt_row gt_right">118</td>
<td class="gt_row gt_left">transformers pipeline, batch size 128</td>
</tr>
<tr class="even">
<td class="gt_row gt_left gt_striped">1b-modernbert-large</td>
<td class="gt_row gt_right gt_striped">89.2</td>
<td class="gt_row gt_right gt_striped">91.8</td>
<td class="gt_row gt_right gt_striped">86.8</td>
<td class="gt_row gt_right gt_striped">87</td>
<td class="gt_row gt_left gt_striped">transformers pipeline, batch size 128</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">2-DSPy-25-threads-Llama-3.2-3B-Instruct</td>
<td class="gt_row gt_right">80.7</td>
<td class="gt_row gt_right">87.9</td>
<td class="gt_row gt_right">74.6</td>
<td class="gt_row gt_right">4</td>
<td class="gt_row gt_left">DSPy, 25 threads, vLLM OpenAI server with default settings</td>
</tr>
<tr class="even">
<td class="gt_row gt_left gt_striped">3-Llama-3.2-3B-Instruct-LoRA</td>
<td class="gt_row gt_right gt_striped">93.1</td>
<td class="gt_row gt_right gt_striped">92.0</td>
<td class="gt_row gt_right gt_striped">94.2</td>
<td class="gt_row gt_right gt_striped">152</td>
<td class="gt_row gt_left gt_striped">vLLM, default settings</td>
</tr>
</tbody><tfoot class="gt_sourcenotes">
<tr class="odd">
<td colspan="6" class="gt_sourcenote">*Speed of setup 2 is limited by DSPy. Speeds similar to setup 3 can be achieved with efficient batching.</td>
</tr>
</tfoot>

</table>


</div>
</div>
</div>
<p>ModernBERT-base and ModernBERT-large performed similarly. Large has a 3.2 percentage point advantage in F1 score but at the cost of 27% slower inference. The few-shot approach doesn’t need nearly as much training data, but also results in a less accurate model. It also ran slowly, and this didn’t change when I increased the number of threads used by DSPy to communicate with the vLLM server. I suspect it’s due to inefficient batch inference code in DSPy. Higher speeds could be achieved with a more efficient batching approach.</p>
<p>The clear winner of the experiment is the LoRA fine-tuned Llama 3.2-3B. It’s the most accurate and the fastest. This is down to vLLM being extremely well optimized and using CUDA graph capturing ahead of inference time. If that preparation time of 30 seconds is added, it’s examples per second go down to 42.</p>
</section>
<section id="cost-and-effort" class="level3">
<h3 class="anchored" data-anchor-id="cost-and-effort">Cost and effort</h3>
<p>All setups can be trained for under one dollar and in less than 15 minutes. The differences are negligible. What matters more is the time spent setting up training and inference. The transformers library and the tutorial made it very easy to fine-tune ModernBERT and run inference. A major plus is that due to its low size, it can run on CPU at good speed too. DSPy was more involved because it required setting up a vLLM server too. This step is easier when using a managed service like Fireworks AI. Fine-tuning Llama 3.2-3B was the most involved step, as it required formatting the data in a chat format and going through the detailed configuration of the torchtune library and vLLM. Still, it only took a few hours. This step is also easier with a managed service.</p>
</section>
</section>
<section id="discussion" class="level2">
<h2 class="anchored" data-anchor-id="discussion">Discussion</h2>
<section id="implications-for-nlp" class="level3">
<h3 class="anchored" data-anchor-id="implications-for-nlp">Implications for NLP</h3>
<section id="fine-tuning-vs-prompt-based-approaches" class="level4">
<h4 class="anchored" data-anchor-id="fine-tuning-vs-prompt-based-approaches">Fine-tuning vs prompt-based approaches</h4>
<p>Fine-tuning continues to outperform purely prompt-based approaches, even when those are optimized using automated prompt engineering. If you have enough examples to fine-tune on, it’s a good idea to do so. Still the recall achieved by the few-shot approach is impressive and can serve as a strong baseline and starting point in the development of text classification systems.</p>
</section>
<section id="model-size-and-architecture" class="level4">
<h4 class="anchored" data-anchor-id="model-size-and-architecture">Model size and architecture</h4>
<p>In fine-tuning, the size of the model is a key factor. Here, ModernBERT did well and is a strong choice for text classification and other structured NLP tasks. ModernBERT-large offers a modest accuracy improvement in exchange for slower inference. However, Llama 3.2-3B with a fine-tuned LoRA adapter outperformed it in accuracy in this experiment. Its architecture as a decoder-only model is, in theory, less suited for structured tasks. Did it win by sheer size? It would be interesting to see what a ModernBERT-3B or -8B model would achieve. In a related task of sentiment analysis <span class="citation" data-cites="zhou_comprehensive_2024">(Zhou et al. 2024)</span>, the scaling limit was found to be at 8 billion parameters with a decoder-only model.</p>
</section>
<section id="processing-speed" class="level4">
<h4 class="anchored" data-anchor-id="processing-speed">Processing speed</h4>
<p>Processing speed is highly sensitive to the hardware and inference setup. Thanks to vLLM’s CUDA graph capturing and other optimizations, the Llama 3.2-3B LoRA adapter ran faster than the ModernBERT models in this experiment, despite its size. Perhaps the efficiency optimizations made in LLM research could be backported to encoder-only models too, just like ModernBERT backported training techniques from LLMs back to the classic 2018 model. Note that this speed comparison was not comprehensive and is dependent on the GPU, the inference library and the exact settings used, such as batch size.</p>
</section>
</section>
<section id="implications-for-adverse-event-monitoring" class="level3">
<h3 class="anchored" data-anchor-id="implications-for-adverse-event-monitoring">Implications for adverse event monitoring</h3>
<section id="greater-sensitivity-with-larger-models" class="level4">
<h4 class="anchored" data-anchor-id="greater-sensitivity-with-larger-models">Greater sensitivity with larger models</h4>
<p>The primary metric for adverse event monitoring is sensitivity, as missing a true adverse event is much more costly than flagging a false positive. The results show a sensitivity of 92% in detection of adverse drug reactions in medical texts using a Llama 3.2-3B. It outperforms previous approaches that used a convolutional neural network <span class="citation" data-cites="huynh_adverse_2016">(Huynh et al. 2016, 89%)</span> and a BERT sentence embeddings model <span class="citation" data-cites="haq_mining_2022">(Haq, Kocaman, and Talby 2022, 85%)</span>. This advance is a step towards an automated adverse event monitoring system. With larger models and more training data, the sensitivity can be improved further.</p>
</section>
<section id="towards-a-production-system" class="level4">
<h4 class="anchored" data-anchor-id="towards-a-production-system">Towards a production system</h4>
<p>A production system for automated adverse event monitoring would need a more comprehensive approach:</p>
<ul>
<li>Adjustable threshold for flagging adverse events</li>
<li>Flagging of complex cases for human review</li>
<li>Tests and training data for other languages, other text types such as case reports, social media and interview transcripts</li>
<li>Tests and training data for other adverse types, such as overdose, lack of efficacy, and use during pregnancy or breastfeeding</li>
</ul>
<p>None of these require new breakthroughs in AI - they are doable with current technology.</p>
<hr>
<p>Preview image generated with FLUX.1-schnell and DiffusionBee.</p>



</section>
</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0">
<div id="ref-devlin2018bert" class="csl-entry">
Devlin, Jacob. 2018. <span>“Bert: Pre-Training of Deep Bidirectional Transformers for Language Understanding.”</span> <em>arXiv Preprint arXiv:1810.04805</em>.
</div>
<div id="ref-grattafiori2024llama3herdmodels" class="csl-entry">
Grattafiori, Aaron, Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Zef Rosnbrick, et al. 2024. <span>“The Llama 3 Herd of Models.”</span> <a href="https://arxiv.org/abs/2407.21783">https://arxiv.org/abs/2407.21783</a>.
</div>
<div id="ref-gurulingappa_development_2012" class="csl-entry">
Gurulingappa, Harsha, Abdul Mateen Rajput, Angus Roberts, Juliane Fluck, Martin Hofmann-Apitius, and Luca Toldo. 2012. <span>“Development of a Benchmark Corpus to Support the Automatic Extraction of Drug-Related Adverse Effects from Medical Case Reports.”</span> <em>Journal of Biomedical Informatics</em>, Text <span>Mining</span> and <span>Natural</span> <span>Language</span> <span>Processing</span> in <span>Pharmacogenomics</span>, 45 (5): 885–92. <a href="https://doi.org/10.1016/j.jbi.2012.04.008">https://doi.org/10.1016/j.jbi.2012.04.008</a>.
</div>
<div id="ref-haq_mining_2022" class="csl-entry">
Haq, Hasham Ul, Veysel Kocaman, and David Talby. 2022. <span>“Mining <span>Adverse</span> <span>Drug</span> <span>Reactions</span> from <span>Unstructured</span> <span>Mediums</span> at <span>Scale</span>.”</span> arXiv. <a href="https://doi.org/10.48550/arXiv.2201.01405">https://doi.org/10.48550/arXiv.2201.01405</a>.
</div>
<div id="ref-huynh_adverse_2016" class="csl-entry">
Huynh, Trung, Yulan He, Alistair Willis, and Stefan Rüger. 2016. <span>“Adverse <span>Drug</span> <span>Reaction</span> <span>Classification</span> <span>With</span> <span>Deep</span> <span>Neural</span> <span>Networks</span>.”</span> In, 877–87. Osaka: COLING. <a href="http://coling2016.anlp.jp/doc/main.pdf">http://coling2016.anlp.jp/doc/main.pdf</a>.
</div>
<div id="ref-khattab2023dspycompilingdeclarativelanguage" class="csl-entry">
Khattab, Omar, Arnav Singhvi, Paridhi Maheshwari, Zhiyuan Zhang, Keshav Santhanam, Sri Vardhamanan, Saiful Haq, et al. 2023. <span>“DSPy: Compiling Declarative Language Model Calls into Self-Improving Pipelines.”</span> <a href="https://arxiv.org/abs/2310.03714">https://arxiv.org/abs/2310.03714</a>.
</div>
<div id="ref-schmid_fine_tune_2024" class="csl-entry">
Schmid, Philipp. 2024. <span>“Fine-Tune Classifier with <span>ModernBERT</span> in 2025.”</span> <a href="https://www.philschmid.de/fine-tune-modern-bert-in-2025">https://www.philschmid.de/fine-tune-modern-bert-in-2025</a>.
</div>
<div id="ref-warner2024smarterbetterfasterlonger" class="csl-entry">
Warner, Benjamin, Antoine Chaffin, Benjamin Clavié, Orion Weller, Oskar Hallström, Said Taghadouini, Alexis Gallagher, et al. 2024. <span>“Smarter, Better, Faster, Longer: A Modern Bidirectional Encoder for Fast, Memory Efficient, and Long Context Finetuning and Inference.”</span> <a href="https://arxiv.org/abs/2412.13663">https://arxiv.org/abs/2412.13663</a>.
</div>
<div id="ref-zhou_comprehensive_2024" class="csl-entry">
Zhou, Changzhi, Dandan Song, Yuhang Tian, Zhijing Wu, Hao Wang, Xinyu Zhang, Jun Yang, Ziyi Yang, and Shuhao Zhang. 2024. <span>“A <span>Comprehensive</span> <span>Evaluation</span> of <span>Large</span> <span>Language</span> <span>Models</span> on <span>Aspect</span>-<span>Based</span> <span>Sentiment</span> <span>Analysis</span>.”</span> arXiv. <a href="https://doi.org/10.48550/arXiv.2412.02279">https://doi.org/10.48550/arXiv.2412.02279</a>.
</div>
</div></section></div> ]]></description>
  <category>Machine Learning</category>
  <guid>https://simmering.dev/blog/modernbert-vs-llm/</guid>
  <pubDate>Sat, 11 Jan 2025 23:00:00 GMT</pubDate>
  <media:content url="https://simmering.dev/blog/modernbert-vs-llm/image.webp" medium="image" type="image/webp"/>
</item>
<item>
  <title>Diagrams as Code: Supercharged by AI Assistants</title>
  <dc:creator>Paul Simmering</dc:creator>
  <link>https://simmering.dev/blog/diagrams/</link>
  <description><![CDATA[ 






<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/diagrams/diagrams_wide.webp" class="img-fluid figure-img"></p>
<figcaption>D2 code and rendered diagram of a Kafka cluster for a web shop</figcaption>
</figure>
</div>
<p>Diagrams as code are an efficient way to communicate complex ideas and document software architecture. In this post I’ll explain how an AI assistant makes them even better.</p>
<section id="what-is-diagrams-as-code" class="level2">
<h2 class="anchored" data-anchor-id="what-is-diagrams-as-code">What is diagrams as code?</h2>
<p>It’s a diagram that is generated from markdown-like text. Rather than clicking and dragging, you write the text and the diagram is generated. Elements are automatically positioned and connected using a layout engine. This lets you focus on the content, rather than the look, at the expense of some flexibility. Since the diagrams are text-based, they can be version controlled with Git.</p>
<p>Here’s a quick example of a diagram as code in <a href="https://d2lang.com/">D2</a>:</p>
<pre><code>shape: sequence_diagram
User -&gt; LLM: How many R's are in the word "strawberry"?
LLM -&gt; User: The word "strawberry" contains 2 instances of the letter "r".</code></pre>
<p>This generates the following diagram:</p>
<p><img src="https://simmering.dev/blog/diagrams/data:image/svg+xml;base64,<?xml version="1.0" encoding="utf-8"?><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" d2Version="0.6.8" preserveAspectRatio="xMinYMin meet" viewBox="0 0 569 328"><svg id="d2-svg" class="d2-2754761364" width="569" height="328" viewBox="1 41 569 328"><rect x="1.000000" y="41.000000" width="569.000000" height="328.000000" rx="0.000000" fill="transparent" stroke-width="0" /><style type="text/css"><![CDATA[
.d2-2754761364 .text {
	font-family: "d2-2754761364-font-regular";
}
@font-face {
	font-family: d2-2754761364-font-regular;
	src: url("data:application/font-woff;base64,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");
}
.d2-2754761364 .text-italic {
	font-family: "d2-2754761364-font-italic";
}
@font-face {
	font-family: d2-2754761364-font-italic;
	src: url("data:application/font-woff;base64,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");
}]]></style><style type="text/css"><![CDATA[.shape {
  shape-rendering: geometricPrecision;
  stroke-linejoin: round;
}
.connection {
  stroke-linecap: round;
  stroke-linejoin: round;
}
.blend {
  mix-blend-mode: multiply;
  opacity: 0.5;
}

		.d2-2754761364 .fill-N1{fill:#0A0F25;}
		.d2-2754761364 .fill-N2{fill:#676C7E;}
		.d2-2754761364 .fill-N3{fill:#9499AB;}
		.d2-2754761364 .fill-N4{fill:#CFD2DD;}
		.d2-2754761364 .fill-N5{fill:#DEE1EB;}
		.d2-2754761364 .fill-N6{fill:#EEF1F8;}
		.d2-2754761364 .fill-N7{fill:#FFFFFF;}
		.d2-2754761364 .fill-B1{fill:#0D32B2;}
		.d2-2754761364 .fill-B2{fill:#0D32B2;}
		.d2-2754761364 .fill-B3{fill:#E3E9FD;}
		.d2-2754761364 .fill-B4{fill:#E3E9FD;}
		.d2-2754761364 .fill-B5{fill:#EDF0FD;}
		.d2-2754761364 .fill-B6{fill:#F7F8FE;}
		.d2-2754761364 .fill-AA2{fill:#4A6FF3;}
		.d2-2754761364 .fill-AA4{fill:#EDF0FD;}
		.d2-2754761364 .fill-AA5{fill:#F7F8FE;}
		.d2-2754761364 .fill-AB4{fill:#EDF0FD;}
		.d2-2754761364 .fill-AB5{fill:#F7F8FE;}
		.d2-2754761364 .stroke-N1{stroke:#0A0F25;}
		.d2-2754761364 .stroke-N2{stroke:#676C7E;}
		.d2-2754761364 .stroke-N3{stroke:#9499AB;}
		.d2-2754761364 .stroke-N4{stroke:#CFD2DD;}
		.d2-2754761364 .stroke-N5{stroke:#DEE1EB;}
		.d2-2754761364 .stroke-N6{stroke:#EEF1F8;}
		.d2-2754761364 .stroke-N7{stroke:#FFFFFF;}
		.d2-2754761364 .stroke-B1{stroke:#0D32B2;}
		.d2-2754761364 .stroke-B2{stroke:#0D32B2;}
		.d2-2754761364 .stroke-B3{stroke:#E3E9FD;}
		.d2-2754761364 .stroke-B4{stroke:#E3E9FD;}
		.d2-2754761364 .stroke-B5{stroke:#EDF0FD;}
		.d2-2754761364 .stroke-B6{stroke:#F7F8FE;}
		.d2-2754761364 .stroke-AA2{stroke:#4A6FF3;}
		.d2-2754761364 .stroke-AA4{stroke:#EDF0FD;}
		.d2-2754761364 .stroke-AA5{stroke:#F7F8FE;}
		.d2-2754761364 .stroke-AB4{stroke:#EDF0FD;}
		.d2-2754761364 .stroke-AB5{stroke:#F7F8FE;}
		.d2-2754761364 .background-color-N1{background-color:#0A0F25;}
		.d2-2754761364 .background-color-N2{background-color:#676C7E;}
		.d2-2754761364 .background-color-N3{background-color:#9499AB;}
		.d2-2754761364 .background-color-N4{background-color:#CFD2DD;}
		.d2-2754761364 .background-color-N5{background-color:#DEE1EB;}
		.d2-2754761364 .background-color-N6{background-color:#EEF1F8;}
		.d2-2754761364 .background-color-N7{background-color:#FFFFFF;}
		.d2-2754761364 .background-color-B1{background-color:#0D32B2;}
		.d2-2754761364 .background-color-B2{background-color:#0D32B2;}
		.d2-2754761364 .background-color-B3{background-color:#E3E9FD;}
		.d2-2754761364 .background-color-B4{background-color:#E3E9FD;}
		.d2-2754761364 .background-color-B5{background-color:#EDF0FD;}
		.d2-2754761364 .background-color-B6{background-color:#F7F8FE;}
		.d2-2754761364 .background-color-AA2{background-color:#4A6FF3;}
		.d2-2754761364 .background-color-AA4{background-color:#EDF0FD;}
		.d2-2754761364 .background-color-AA5{background-color:#F7F8FE;}
		.d2-2754761364 .background-color-AB4{background-color:#EDF0FD;}
		.d2-2754761364 .background-color-AB5{background-color:#F7F8FE;}
		.d2-2754761364 .color-N1{color:#0A0F25;}
		.d2-2754761364 .color-N2{color:#676C7E;}
		.d2-2754761364 .color-N3{color:#9499AB;}
		.d2-2754761364 .color-N4{color:#CFD2DD;}
		.d2-2754761364 .color-N5{color:#DEE1EB;}
		.d2-2754761364 .color-N6{color:#EEF1F8;}
		.d2-2754761364 .color-N7{color:#FFFFFF;}
		.d2-2754761364 .color-B1{color:#0D32B2;}
		.d2-2754761364 .color-B2{color:#0D32B2;}
		.d2-2754761364 .color-B3{color:#E3E9FD;}
		.d2-2754761364 .color-B4{color:#E3E9FD;}
		.d2-2754761364 .color-B5{color:#EDF0FD;}
		.d2-2754761364 .color-B6{color:#F7F8FE;}
		.d2-2754761364 .color-AA2{color:#4A6FF3;}
		.d2-2754761364 .color-AA4{color:#EDF0FD;}
		.d2-2754761364 .color-AA5{color:#F7F8FE;}
		.d2-2754761364 .color-AB4{color:#EDF0FD;}
		.d2-2754761364 .color-AB5{color:#F7F8FE;}.appendix text.text{fill:#0A0F25}.md{--color-fg-default:#0A0F25;--color-fg-muted:#676C7E;--color-fg-subtle:#9499AB;--color-canvas-default:#FFFFFF;--color-canvas-subtle:#EEF1F8;--color-border-default:#0D32B2;--color-border-muted:#0D32B2;--color-neutral-muted:#EEF1F8;--color-accent-fg:#0D32B2;--color-accent-emphasis:#0D32B2;--color-attention-subtle:#676C7E;--color-danger-fg:red;}.sketch-overlay-B1{fill:url(#streaks-darker);mix-blend-mode:lighten}.sketch-overlay-B2{fill:url(#streaks-darker);mix-blend-mode:lighten}.sketch-overlay-B3{fill:url(#streaks-bright);mix-blend-mode:darken}.sketch-overlay-B4{fill:url(#streaks-bright);mix-blend-mode:darken}.sketch-overlay-B5{fill:url(#streaks-bright);mix-blend-mode:darken}.sketch-overlay-B6{fill:url(#streaks-bright);mix-blend-mode:darken}.sketch-overlay-AA2{fill:url(#streaks-dark);mix-blend-mode:overlay}.sketch-overlay-AA4{fill:url(#streaks-bright);mix-blend-mode:darken}.sketch-overlay-AA5{fill:url(#streaks-bright);mix-blend-mode:darken}.sketch-overlay-AB4{fill:url(#streaks-bright);mix-blend-mode:darken}.sketch-overlay-AB5{fill:url(#streaks-bright);mix-blend-mode:darken}.sketch-overlay-N1{fill:url(#streaks-darker);mix-blend-mode:lighten}.sketch-overlay-N2{fill:url(#streaks-dark);mix-blend-mode:overlay}.sketch-overlay-N3{fill:url(#streaks-normal);mix-blend-mode:color-burn}.sketch-overlay-N4{fill:url(#streaks-normal);mix-blend-mode:color-burn}.sketch-overlay-N5{fill:url(#streaks-bright);mix-blend-mode:darken}.sketch-overlay-N6{fill:url(#streaks-bright);mix-blend-mode:darken}.sketch-overlay-N7{fill:url(#streaks-bright);mix-blend-mode:darken}.light-code{display: block}.dark-code{display: none}]]></style><g id="User"><g class="shape" ><rect x="12.000000" y="52.000000" width="100.000000" height="66.000000" stroke="#0D32B2" fill="#EDF0FD" class=" stroke-B1 fill-B5" style="stroke-width:2;" /></g><text x="62.000000" y="90.500000" fill="#0A0F25" class="text fill-N1" style="text-anchor:middle;font-size:16px">User</text></g><g id="LLM"><g class="shape" ><rect x="459.000000" y="52.000000" width="100.000000" height="66.000000" stroke="#0D32B2" fill="#EDF0FD" class=" stroke-B1 fill-B5" style="stroke-width:2;" /></g><text x="509.000000" y="90.500000" fill="#0A0F25" class="text fill-N1" style="text-anchor:middle;font-size:16px">LLM</text></g><g id="(User -- )[0]"><path d="M 62.000000 120.000000 L 62.000000 357.000000" stroke="#0D32B2" fill="none" class="connection stroke-B2" style="stroke-width:2;stroke-dasharray:12.000000,11.838767;" mask="url(#d2-2754761364)" /></g><g id="(LLM -- )[0]"><path d="M 509.000000 120.000000 L 509.000000 357.000000" stroke="#0D32B2" fill="none" class="connection stroke-B2" style="stroke-width:2;stroke-dasharray:12.000000,11.838767;" mask="url(#d2-2754761364)" /></g><g id="(User -&gt; LLM)[0]"><marker id="mk-3488378134" markerWidth="10.000000" markerHeight="12.000000" refX="7.000000" refY="6.000000" viewBox="0.000000 0.000000 10.000000 12.000000" orient="auto" markerUnits="userSpaceOnUse"> <polygon points="0.000000,0.000000 10.000000,6.000000 0.000000,12.000000" fill="#0D32B2" class="connection fill-B1" stroke-width="2" /> </marker><path d="M 64.000000 198.000000 L 505.000000 198.000000" stroke="#0D32B2" fill="none" class="connection stroke-B1" style="stroke-width:2;" marker-end="url(#mk-3488378134)" mask="url(#d2-2754761364)" /><text x="285.500000" y="204.000000" fill="#676C7E" class="text-italic fill-N2" style="text-anchor:middle;font-size:16px">How many R&#39;s are in the word &#34;strawberry&#34;?</text></g><g id="(LLM -&gt; User)[0]"><path d="M 507.000000 288.000000 L 66.000000 288.000000" stroke="#0D32B2" fill="none" class="connection stroke-B1" style="stroke-width:2;" marker-end="url(#mk-3488378134)" mask="url(#d2-2754761364)" /><text x="285.500000" y="294.000000" fill="#676C7E" class="text-italic fill-N2" style="text-anchor:middle;font-size:16px">The word &#34;strawberry&#34; contains 2 instances of the letter &#34;r&#34;.</text></g><mask id="d2-2754761364" maskUnits="userSpaceOnUse" x="1" y="41" width="569" height="328">
<rect x="1" y="41" width="569" height="328" fill="white"></rect>
<rect x="47.000000" y="74.500000" width="30" height="21" fill="rgba(0,0,0,0.75)"></rect>
<rect x="496.000000" y="74.500000" width="26" height="21" fill="rgba(0,0,0,0.75)"></rect>
<rect x="141.000000" y="188.000000" width="289" height="21" fill="black"></rect>
<rect x="92.000000" y="278.000000" width="387" height="21" fill="black"></rect>
</mask></svg></svg>
" class="img-fluid" style="width:75.0%"></p>
<p>Diagrams as code are not new, with the <a href="https://en.wikipedia.org/wiki/DOT_language">DOT language</a> being used for <a href="https://graphviz.org/">GraphViz</a> since 1991. They were great all along, but they’ve become even better with the rise of AI assistants.</p>
</section>
<section id="assistants-make-diagrams-effortless" class="level2">
<h2 class="anchored" data-anchor-id="assistants-make-diagrams-effortless">Assistants make diagrams effortless</h2>
<p>Commonly used LLMs like GPT-4o, Claude and Gemini are familiar with text-based diagram syntax. They can turn a quick prompt into diagram code. They can also take the diagram as input and write code to implement it. Diagrams as code are an intermediate step between natural language and code. As assistants take on more coding tasks, this level of abstraction becomes more important for developers.</p>
<p>An AI can assist throughout the diagram lifecycle - from generating initial diagrams from natural language prompts to updating them based on code changes. It can validate diagrams against existing code, convert between different diagram formats, and even suggest structural improvements. For developers new to diagrams as code, the assistant serves as a helpful guide, explaining syntax and best practices. The time savings also make it more convenient to keep diagrams in sync with code, which is a common problem.</p>
<p>The stakes for diagrams are relatively low, so it’s not necessary to review every generated line. When an assistant makes a mistake, syntax errors will be caught during rendering and content errors are easily spotted during visual review.</p>
</section>
<section id="diagrams-as-code-systems" class="level2">
<h2 class="anchored" data-anchor-id="diagrams-as-code-systems">Diagrams as code systems</h2>
<p>Let’s take a look at some of the most popular implementations:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Name</th>
<th>Description</th>
<th>Best for</th>
<th>Release</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><a href="https://graphviz.org/">GraphViz</a></td>
<td>Foundational graph visualization technology powering many modern tools. Its DOT language and layout algorithms are widely used as a backend for other visualization software. Provides programmatic generation of structured layouts.</td>
<td>Network topology, dependency trees, and hierarchical data visualization where automated layout is crucial. Often used as an engine rather than directly.</td>
<td>1991</td>
</tr>
<tr class="even">
<td><a href="https://plantuml.com/">PlantUML</a></td>
<td>Supports UML diagrams (class, sequence, use case, activity, etc.), network diagrams, wireframes, Gantt charts, and more. Widely integrated into IDEs, wikis, and documentation tools.</td>
<td>Technical documentation requiring standardized diagrams, especially UML.</td>
<td>2009</td>
</tr>
<tr class="odd">
<td><a href="https://www.drawio.com/">Draw.io</a></td>
<td>Browser-based diagramming tool (also known as diagrams.net) with desktop versions available. Features extensive shape libraries, custom templates, and automatic layouts. Supports offline use, multiple storage backends (Google Drive, OneDrive, GitHub), and collaborative editing.</td>
<td>General-purpose diagramming suitable for both technical and business users.</td>
<td>2012</td>
</tr>
<tr class="even">
<td><a href="https://mermaid.js.org/">Mermaid</a></td>
<td>JavaScript-based diagramming library that renders text definitions into SVG diagrams. Supports flowcharts, sequence diagrams, class diagrams, state diagrams, user journeys, Gantt charts, and pie charts. Widely adopted in documentation platforms and Markdown tools.</td>
<td>Diagrams in documentation, especially in Markdown environments like GitHub and documentation sites.</td>
<td>2014</td>
</tr>
<tr class="odd">
<td><a href="https://d2lang.com/">D2</a></td>
<td>Modern diagram scripting language focusing on developer experience. Features concise syntax, multiple layout engines, and scripting capabilities. Emphasizes version control friendly text-based diagram definitions.</td>
<td>Software architecture and system documentation. Sophisticated custom diagrams.</td>
<td>2022</td>
</tr>
</tbody>
</table>
<p>All of them are free to use and have an extension for VSCode. The website <a href="https://text-to-diagram.com/">text-to-diagram.com</a> has a fantastic comparison of D2, Mermaid, PlantUML and GraphViz.</p>
<p>My favorite is <strong>D2</strong>, as it creates the most aesthetic and readable diagrams using the <a href="https://d2lang.com/tour/elk">ELK layout engine</a>. It also supports many export formats, including SVG, PNG, PDF, and even PowerPoint.</p>
<p>Mermaid is another strong choice, as it offers a wider range of diagram types and can be used as a code blocks in markdown environments like GitHub.</p>
<p>If you’re using Quarto, like I do for this blog, Mermaid and GraphViz support is <a href="https://quarto.org/docs/authoring/diagrams.html">built-in</a> and D2 support can be added with a <a href="https://github.com/data-intuitive/quarto-d2">plugin</a>. Alternatively, create a separate <code>.d2</code> file and render it to SVG.</p>
</section>
<section id="level-up-your-diagrams" class="level2">
<h2 class="anchored" data-anchor-id="level-up-your-diagrams">Level up your diagrams</h2>
<p>With an assistant, it’s faster than ever to generate a giant hairball of boxes and arrows. But that’s not the goal - it’s about communicating ideas. Let’s go over some principles that help increase the clarity and usefulness of diagrams. If you agree with them, you may want to copy them into a prompt.</p>
<section id="content-and-layout" class="level3">
<h3 class="anchored" data-anchor-id="content-and-layout">Content and layout</h3>
<ol type="1">
<li><p>Use the appropriate diagram type. Flowcharts are the most common, but there are many others such as <a href="https://d2lang.com/tour/sequence-diagrams/">sequence diagrams</a>, <a href="https://d2lang.com/tour/uml-classes">class diagrams</a>, and <a href="https://mermaid.js.org/syntax/userJourney.html">user journey diagrams</a>.</p></li>
<li><p>Model the key components, rather than every possible detail. Keep the diagram at a single level of abstraction. Use multiple diagrams if needed.</p></li>
</ol>
<blockquote class="blockquote">
<p>My rule of thumb is that you need to be able to print the diagram on a single A4 sheet while keeping things readable. – <a href="https://bellekens.com/2012/02/21/uml-best-practice-5-rules-for-better-uml-diagrams/">Geert Bellekens, enterprise architect</a></p>
</blockquote>
<ol start="3" type="1">
<li>Avoid crossing lines. Layout engines do a good job of this. If they fail to find a layout that avoids overlaps, it’s a sign that the diagram is too complex. Also prefer vertical and horizontal lines over diagonal ones, as they give the diagram a more professional look.</li>
</ol>
</section>
<section id="styling" class="level3">
<h3 class="anchored" data-anchor-id="styling">Styling</h3>
<ol type="1">
<li>Label all components and arrows. A relationship may be obvious to you, but not to others. Use one or two word labels in a sans-serif font at a size readable for aging eyes.</li>
<li>Use consistent shapes, arrows and colors. This helps readers scan the diagram quicker. Use stylistic elements like thicker lines for primary flows and thinner for secondary flows, dotted or dashed lines for optional or future relationships, and different shapes for different types of components.</li>
<li>Use color sparingly and meaningfully, e.g., to highlight critical paths. Don’t rely on color as the only way information is conveyed. Use labels and shapes to ensure the diagram works in black and white too. 1 in 12 men are <a href="https://www.nei.nih.gov/learn-about-eye-health/eye-conditions-and-diseases/color-blindness">colorblind</a>.</li>
<li>Consider using a <a href="https://d2lang.com/blog/hand-drawn-diagrams">hand-drawn style</a> in early stages of a design. It conveys that the diagram is a draft and not a final product.</li>
</ol>
<p><img src="https://simmering.dev/blog/diagrams/data:image/svg+xml;base64,<?xml version="1.0" encoding="utf-8"?><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" d2Version="0.6.8" preserveAspectRatio="xMinYMin meet" viewBox="0 0 1140 174"><svg id="d2-svg" class="d2-1355680374" width="1140" height="174" viewBox="1 1 1140 174"><rect x="1.000000" y="1.000000" width="1140.000000" height="174.000000" rx="0.000000" fill="transparent" stroke-width="0" /><style type="text/css"><![CDATA[
.d2-1355680374 .text-bold {
	font-family: "d2-1355680374-font-bold";
}
@font-face {
	font-family: d2-1355680374-font-bold;
	src: url("data:application/font-woff;base64,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");
}]]></style><style type="text/css"><![CDATA[.shape {
  shape-rendering: geometricPrecision;
  stroke-linejoin: round;
}
.connection {
  stroke-linecap: round;
  stroke-linejoin: round;
}
.blend {
  mix-blend-mode: multiply;
  opacity: 0.5;
}

		.d2-1355680374 .fill-N1{fill:#0A0F25;}
		.d2-1355680374 .fill-N2{fill:#676C7E;}
		.d2-1355680374 .fill-N3{fill:#9499AB;}
		.d2-1355680374 .fill-N4{fill:#CFD2DD;}
		.d2-1355680374 .fill-N5{fill:#DEE1EB;}
		.d2-1355680374 .fill-N6{fill:#EEF1F8;}
		.d2-1355680374 .fill-N7{fill:#FFFFFF;}
		.d2-1355680374 .fill-B1{fill:#0D32B2;}
		.d2-1355680374 .fill-B2{fill:#0D32B2;}
		.d2-1355680374 .fill-B3{fill:#E3E9FD;}
		.d2-1355680374 .fill-B4{fill:#E3E9FD;}
		.d2-1355680374 .fill-B5{fill:#EDF0FD;}
		.d2-1355680374 .fill-B6{fill:#F7F8FE;}
		.d2-1355680374 .fill-AA2{fill:#4A6FF3;}
		.d2-1355680374 .fill-AA4{fill:#EDF0FD;}
		.d2-1355680374 .fill-AA5{fill:#F7F8FE;}
		.d2-1355680374 .fill-AB4{fill:#EDF0FD;}
		.d2-1355680374 .fill-AB5{fill:#F7F8FE;}
		.d2-1355680374 .stroke-N1{stroke:#0A0F25;}
		.d2-1355680374 .stroke-N2{stroke:#676C7E;}
		.d2-1355680374 .stroke-N3{stroke:#9499AB;}
		.d2-1355680374 .stroke-N4{stroke:#CFD2DD;}
		.d2-1355680374 .stroke-N5{stroke:#DEE1EB;}
		.d2-1355680374 .stroke-N6{stroke:#EEF1F8;}
		.d2-1355680374 .stroke-N7{stroke:#FFFFFF;}
		.d2-1355680374 .stroke-B1{stroke:#0D32B2;}
		.d2-1355680374 .stroke-B2{stroke:#0D32B2;}
		.d2-1355680374 .stroke-B3{stroke:#E3E9FD;}
		.d2-1355680374 .stroke-B4{stroke:#E3E9FD;}
		.d2-1355680374 .stroke-B5{stroke:#EDF0FD;}
		.d2-1355680374 .stroke-B6{stroke:#F7F8FE;}
		.d2-1355680374 .stroke-AA2{stroke:#4A6FF3;}
		.d2-1355680374 .stroke-AA4{stroke:#EDF0FD;}
		.d2-1355680374 .stroke-AA5{stroke:#F7F8FE;}
		.d2-1355680374 .stroke-AB4{stroke:#EDF0FD;}
		.d2-1355680374 .stroke-AB5{stroke:#F7F8FE;}
		.d2-1355680374 .background-color-N1{background-color:#0A0F25;}
		.d2-1355680374 .background-color-N2{background-color:#676C7E;}
		.d2-1355680374 .background-color-N3{background-color:#9499AB;}
		.d2-1355680374 .background-color-N4{background-color:#CFD2DD;}
		.d2-1355680374 .background-color-N5{background-color:#DEE1EB;}
		.d2-1355680374 .background-color-N6{background-color:#EEF1F8;}
		.d2-1355680374 .background-color-N7{background-color:#FFFFFF;}
		.d2-1355680374 .background-color-B1{background-color:#0D32B2;}
		.d2-1355680374 .background-color-B2{background-color:#0D32B2;}
		.d2-1355680374 .background-color-B3{background-color:#E3E9FD;}
		.d2-1355680374 .background-color-B4{background-color:#E3E9FD;}
		.d2-1355680374 .background-color-B5{background-color:#EDF0FD;}
		.d2-1355680374 .background-color-B6{background-color:#F7F8FE;}
		.d2-1355680374 .background-color-AA2{background-color:#4A6FF3;}
		.d2-1355680374 .background-color-AA4{background-color:#EDF0FD;}
		.d2-1355680374 .background-color-AA5{background-color:#F7F8FE;}
		.d2-1355680374 .background-color-AB4{background-color:#EDF0FD;}
		.d2-1355680374 .background-color-AB5{background-color:#F7F8FE;}
		.d2-1355680374 .color-N1{color:#0A0F25;}
		.d2-1355680374 .color-N2{color:#676C7E;}
		.d2-1355680374 .color-N3{color:#9499AB;}
		.d2-1355680374 .color-N4{color:#CFD2DD;}
		.d2-1355680374 .color-N5{color:#DEE1EB;}
		.d2-1355680374 .color-N6{color:#EEF1F8;}
		.d2-1355680374 .color-N7{color:#FFFFFF;}
		.d2-1355680374 .color-B1{color:#0D32B2;}
		.d2-1355680374 .color-B2{color:#0D32B2;}
		.d2-1355680374 .color-B3{color:#E3E9FD;}
		.d2-1355680374 .color-B4{color:#E3E9FD;}
		.d2-1355680374 .color-B5{color:#EDF0FD;}
		.d2-1355680374 .color-B6{color:#F7F8FE;}
		.d2-1355680374 .color-AA2{color:#4A6FF3;}
		.d2-1355680374 .color-AA4{color:#EDF0FD;}
		.d2-1355680374 .color-AA5{color:#F7F8FE;}
		.d2-1355680374 .color-AB4{color:#EDF0FD;}
		.d2-1355680374 .color-AB5{color:#F7F8FE;}.appendix text.text{fill:#0A0F25}.md{--color-fg-default:#0A0F25;--color-fg-muted:#676C7E;--color-fg-subtle:#9499AB;--color-canvas-default:#FFFFFF;--color-canvas-subtle:#EEF1F8;--color-border-default:#0D32B2;--color-border-muted:#0D32B2;--color-neutral-muted:#EEF1F8;--color-accent-fg:#0D32B2;--color-accent-emphasis:#0D32B2;--color-attention-subtle:#676C7E;--color-danger-fg:red;}.sketch-overlay-B1{fill:url(#streaks-darker);mix-blend-mode:lighten}.sketch-overlay-B2{fill:url(#streaks-darker);mix-blend-mode:lighten}.sketch-overlay-B3{fill:url(#streaks-bright);mix-blend-mode:darken}.sketch-overlay-B4{fill:url(#streaks-bright);mix-blend-mode:darken}.sketch-overlay-B5{fill:url(#streaks-bright);mix-blend-mode:darken}.sketch-overlay-B6{fill:url(#streaks-bright);mix-blend-mode:darken}.sketch-overlay-AA2{fill:url(#streaks-dark);mix-blend-mode:overlay}.sketch-overlay-AA4{fill:url(#streaks-bright);mix-blend-mode:darken}.sketch-overlay-AA5{fill:url(#streaks-bright);mix-blend-mode:darken}.sketch-overlay-AB4{fill:url(#streaks-bright);mix-blend-mode:darken}.sketch-overlay-AB5{fill:url(#streaks-bright);mix-blend-mode:darken}.sketch-overlay-N1{fill:url(#streaks-darker);mix-blend-mode:lighten}.sketch-overlay-N2{fill:url(#streaks-dark);mix-blend-mode:overlay}.sketch-overlay-N3{fill:url(#streaks-normal);mix-blend-mode:color-burn}.sketch-overlay-N4{fill:url(#streaks-normal);mix-blend-mode:color-burn}.sketch-overlay-N5{fill:url(#streaks-bright);mix-blend-mode:darken}.sketch-overlay-N6{fill:url(#streaks-bright);mix-blend-mode:darken}.sketch-overlay-N7{fill:url(#streaks-bright);mix-blend-mode:darken}.light-code{display: block}.dark-code{display: none}]]></style><defs><pattern id="streaks-bright" x="0" y="0" width="100" height="100" patternUnits="userSpaceOnUse">
    <path fill="rgba(0, 0, 0, 0.1)" fill-rule="evenodd" clip-rule="evenodd" d="M58.1193 0H58.1703L55.4939 2.67644L58.1193 0ZM45.7725 0H45.811L41.2851 4.61498L42.7191 3.29325L37.0824 8.92997L35.0554 10.9569L32.0719 13.9404L29.6229 16.5017L27.1738 19.0631L25.8089 20.2034L23.2195 22.6244L18.181 27.6068L23.8178 21.97L27.0615 18.9508L33.8666 11.9773L33.1562 12.5194L37.0262 8.87383L40.784 5.11602L38.0299 7.64561L45.7725 0ZM23.1079 0H23.108L21.5814 1.66688L20.3126 2.79534L23.1079 0ZM7.53869 0H7.54254L7.50005 0.035944L7.53869 0ZM2.49995 0H2.52362L0.900245 1.59971L2.49995 0ZM0 3.64398V3.60744L0.278386 3.36559L0 3.64398ZM0 18.6564V18.5398L0.67985 17.8416L3.4459 15.0755L1.15701 17.1333L2.78713 15.6022L6.01437 12.507L8.5168 9.87253L5.15803 13.2313L11.0357 7.25453L10.4926 7.89678L13.6868 4.7686L8.54982 9.90555L7.05177 11.5687L4.68087 13.9396L0.729379 17.8911L3.01827 15.8333L0 18.6564ZM0 69.2431V69.178L1.64651 67.4763L1.46347 67.7796L5.84063 63.4025L4.42167 64.9016L0 69.4007V69.3408L0.247596 68.9955L0 69.2431ZM2.51594 100H2.49238L5.19989 97.2925L7.70071 95.0162L12.8713 89.6772L12.3094 90.0707L15.288 87.3167L18.1542 84.4504L16.0269 86.3532L22.8752 79.6172L18.5364 84.0683L19.6435 83.0734L15.3441 87.3728L13.798 88.9189L11.5224 91.1945L9.66768 93.1615L7.81297 95.1285L6.74529 95.9716L4.75024 97.7983L2.51594 100ZM7.54255 100H7.5387L9.81396 97.884L8.46606 99.2189L7.54255 100ZM45.8189 100H45.7807L46.9912 98.8047L45.8189 100ZM58.1784 100H58.1272L62.2952 95.7511L66.1408 91.9055L63.0037 94.8115L65.2507 92.6635L69.7117 88.3346L73.2165 84.6977L68.5469 89.3673L76.7379 81.0773L75.9634 81.9509L80.3913 77.5889L73.2496 84.7307L71.1346 87.0107L67.8384 90.3069L62.3447 95.8006L65.4818 92.8947L61.2625 96.9159L58.1784 100ZM75.4277 100H75.229L82.1834 92.9039L81.3403 93.5787L86.0063 89.1371L90.5601 84.5833L87.2464 87.6725L98.0937 76.9375L91.1673 83.9761L92.8932 82.3625L86.0625 89.1933L83.6062 91.6496L79.9907 95.265L77.011 98.357L75.4277 100ZM100 18.5398V18.6563L99.9556 18.6979L95.8065 22.847L100 18.5398ZM100 3.60743V3.64398L99.6791 3.9649L99.2094 4.29428L100 3.60743ZM75.4201 0L74.0312 1.4412L72.401 2.84687L69.281 5.79854L63.1812 11.8422L70.0119 5.01151L73.919 1.32893L75.2214 0H75.4201ZM100 69.1858V69.2509L98.059 71.1919L100 69.1858ZM100 69.3486V69.4085L99.8414 69.5698L100 69.3486ZM41.9398 28.8254L53.6223 16.993L52.5215 18.2437L54.7428 16.0575L54.6875 16.0759L54.8008 16.0004L58.842 12.0231L54.9925 15.8726L55.1085 15.7953L54.898 16.0058L54.84 16.0251L48.6523 22.2128L45.6419 25.473L40.9389 30.1759L33.1007 38.0142L37.5866 33.878L31.558 39.6068L23.3278 47.837L33.0257 37.9393L38.5125 32.4525L34.0266 36.5887L37.2369 33.5283L43.6074 27.3576L48.6023 22.1628L41.9398 28.8254ZM41.0977 17.0531L39.718 18.2925L40.312 17.8388L41.0977 17.0531ZM36.875 20.3106L48.1601 7.88137L42.3438 13.7478L36.875 20.3106ZM35.7125 25.8109L34.3328 27.0503L34.9268 26.5966L35.7125 25.8109ZM17.7022 39.7534L19.0819 38.514L18.8092 38.7867L36.7575 21.8045L23.1569 35.3051L13.5771 43.7372L18.1448 39.4154L17.7022 39.7534ZM3.48102 28.9281L1.53562 30.8735L1.22228 31.0465L0.0765686 32.3326L1.60579 30.9437L2.57849 29.971L3.48102 28.9281ZM0.953463 26.2027L19.5702 7.58594L9.31575 18.6078L0.953463 26.2027ZM23.7175 12.11L17.9339 18.0875L21.4622 14.5592L20.8074 15.4725L28.1915 7.95918L30.4791 5.54232L23.4224 12.599L23.7175 12.11ZM43.4641 43.1538L40.7872 46.1552L42.4907 44.4517L42.3285 45.0465L45.8166 41.3421L46.8441 40.0983L43.4371 43.5053L43.4641 43.1538ZM1.32715 48.3271L8.0918 41.5625L4.3657 45.5674L1.32715 48.3271ZM11.1479 31.2556L11.5689 30.975L11.3584 31.1855L11.1479 31.2556ZM11.9898 27.4667L12.2003 27.2562L11.7793 27.5369L11.9898 27.4667ZM11.3585 34.5531L11.148 34.7636L10.9375 34.8338L11.3585 34.5531ZM72.929 28.5457L82.2965 19.0792L81.4043 20.0705L86.4597 15.0811L78.2983 23.2425L75.8697 25.8362L72.1029 29.603L65.8249 35.881L69.3934 32.5437L64.5858 37.1531L57.994 43.745L65.7754 35.8314L70.17 31.4369L66.6015 34.7742L69.1623 32.3125L74.2507 27.3562L78.2653 23.2095L72.929 28.5457ZM82.6674 1.83549L84.3245 0.31872L83.3724 1.27088L82.6674 1.83549ZM64.5872 16.1312L62.9301 17.648L63.6351 17.0834L64.5872 16.1312ZM70.868 9.85044L80.0048 1.1214L74.6221 6.47142L70.868 9.85044ZM90.2409 41.9448L70.7578 61.4279L79.5093 53.4795L90.2409 41.9448ZM91.8088 42.5434L95.3963 38.8357L95.2132 39.139L99.5904 34.7618L98.1714 36.261L93.5912 40.9214L93.9973 40.3549L91.8088 42.5434ZM94.331 12.8233L89.9853 17.1691L89.2853 17.5555L86.7259 20.4284L90.142 17.3258L92.3149 15.1529L94.331 12.8233ZM44.7972 62.3259L76.9824 30.1406L59.2542 49.1955L44.7972 62.3259ZM77.1482 40.321L70.1709 47.5323L70 47.6463L70.0895 47.6164L68.1916 49.5779L70.185 47.5846L70.2105 47.5761L70.421 47.3656L70.37 47.3996L73.6557 44.1139L72.6416 45.5283L84.0768 33.893L87.6194 30.1502L76.6913 41.0783L77.1482 40.321ZM50.5355 34.3137L72.6617 12.1875L60.4955 25.3084L50.5355 34.3137ZM70.2104 44.0681L70.6314 43.7875L70.4209 43.998L70.2104 44.0681ZM71.263 40.0687L70.842 40.3494L71.0525 40.2792L71.263 40.0687ZM55.1084 12.4355L55.3189 12.225L54.8979 12.5056L55.1084 12.4355ZM48.8718 15.5785L60.2075 4.70496L49.4056 15.4006L48.8718 15.5785ZM23.7636 57.4491L29.9099 51.5854L26.1656 55.6123L27.2361 54.8244L23.435 58.6255L22.0681 59.9924L20.0562 62.0042L18.5082 63.8349L16.9601 65.6656L15.8328 66.2277L13.9315 67.7051L10.4821 71.0132L14.2832 67.2121L16.6775 65.383L21.1113 60.5253L20.477 60.7357L23.2937 58.4842L25.8277 55.9502L23.7636 57.4491ZM48.3825 74.1824L44.8832 77.8523L46.9145 75.8211L45.4748 77.4881L43.4493 79.2862L42.4082 80.1568L43.9215 79.0414L42.2487 80.7143L39.3752 83.8151L41.8844 81.3059L43.8473 79.6842L42.334 80.7995L44.7237 78.4098L46.1576 76.976L46.9713 75.8779L50.078 72.7713L48.1093 74.6262L48.3825 74.1824ZM29.2877 62.9906L29.0772 63.2011L28.8667 63.2713L29.2877 62.9906ZM29.7088 59.4823L29.9193 59.2719L29.4983 59.5525L29.7088 59.4823ZM29.0772 66.5687L28.8667 66.7792L28.6562 66.8494L29.0772 66.5687ZM22.9729 68.748L23.1834 68.5375L22.7624 68.8181L22.9729 68.748ZM3.8147e-05 91.7593L13.2499 79.1355L6.5001 86.2595L3.8147e-05 91.7593ZM16.0685 87.9974L17.1375 87.0687L16.5382 87.668L16.0685 87.9974ZM21.7869 79.3344L20.7179 80.263L21.1876 79.9337L21.7869 79.3344ZM12.3607 95.0755L13.4298 94.1469L12.8304 94.7462L12.3607 95.0755ZM42.7176 59.3801L43.2789 58.8187L43.0684 59.1696L42.7877 59.4502L42.2966 59.801L42.5772 59.3801H42.7176ZM26.3124 49.3152L24.3599 51.2676L23.996 51.3918L22.8956 52.732L24.4798 51.3875L25.456 50.4113L26.3124 49.3152ZM39.0689 63.3097L38.5777 63.6606L39.56 62.6782L39.0689 63.3097ZM20.3574 55.8032L19.3751 56.7856L19.8662 56.4347L20.3574 55.8032ZM39.9297 64.195L41.5504 62.3779L41.534 62.5907L43.5967 60.528L42.9746 61.2811L40.8628 63.5238L40.961 63.1637L39.9297 64.195ZM22.3921 55.457L21.3998 56.5696L22.0313 55.9381L21.9711 56.1587L23.2642 54.7854L23.6451 54.3243L22.3821 55.5873L22.3921 55.457ZM40.6473 92.4498L45.0485 88.0485L43.0066 90.4079L40.806 92.6085L37.3463 95.7507L39.9384 92.8412L40.6473 92.4498ZM18.5042 48.7973L11.5457 55.7558L10.4249 56.3746L6.32684 60.9746L11.7967 56.0067L15.2759 52.5275L18.5042 48.7973ZM32.7113 78.139L31.1131 79.7372L30.8432 79.8668L29.9145 80.9358L31.1833 79.8074L31.9823 79.0083L32.7113 78.139ZM21.7577 93.9525L31.2855 84.0344L30.8324 84.8777L42.4999 73.2102L38.7408 77.2295L26.5552 89.6753L27.5914 88.1187L21.7577 93.9525ZM98.5132 90.0591L89.9224 97.9224L93.5769 94.9953L98.5132 90.0591ZM97.8456 80.2105L99.5027 78.6937L98.5506 79.6459L97.8456 80.2105ZM88.5656 56.4599L78.9205 65.7009L82.1262 63.3036L78.1413 67.2885L73.7522 70.8692L74.7195 70.5082L67.717 78.117L63.992 81.0336L58.0146 87.011L63.4289 81.7988L66.3887 79.4454L68.1212 78.5213L70.5757 75.6625L73.0302 72.8038L76.194 69.64L78.3434 67.4906L84.3208 61.5132L82.6575 62.7723L88.5656 56.4599ZM85.1893 67.0375L83.7304 68.356L84.3561 67.8707L85.1893 67.0375ZM90.7969 58.2022L99.2725 50.5418L94.4317 55.3826L90.7969 58.2022ZM79.377 76.2172L77.9182 77.5357L78.5438 77.0504L79.377 76.2172ZM59.4922 91.7253L56.4011 94.1231L60.0049 90.8659L63.6087 87.6087L59.4922 91.7253ZM63.8833 75.4153L46 92.3896L49.6884 89.1193L53.3767 85.8491L63.8833 75.4153ZM71.6063 55.0765L69.6609 57.0219L69.3475 57.1949L68.2018 58.481L69.731 57.0921L70.7037 56.1194L71.6063 55.0765ZM55.1405 71.6857L61.4131 65.4131L57.958 69.1267L55.1405 71.6857ZM65.8396 69.4497L61.7138 73.7138L64.2308 71.1968L63.7637 71.8484L69.0313 66.4886L70.6632 64.7645L65.6292 69.7985L65.8396 69.4497ZM53.0034 65.4955L58.2258 59.8914L58.0558 60.4431L64.5517 53.9472L62.5136 56.2398L55.7841 63.2238L56.2513 62.2475L53.0034 65.4955ZM97.0997 71.2032L79.6514 88.6515L86.7697 80.814L97.0997 71.2032ZM35.1848 56.2513L31.93 59.9006L34.0012 57.8294L33.804 58.5527L38.0451 54.0485L39.2945 52.5361L35.1519 56.6787L35.1848 56.2513ZM66.8712 26.2471L78.1907 14.3099L77.7244 15.394L91.6784 1.4399L87.233 6.29715L72.7096 21.2323L73.8482 19.2701L66.8712 26.2471ZM28.0473 68.2068L20.4355 76.375L25.1695 71.641L24.4884 73.0639L34.297 62.8844L37.2675 59.5429L27.7995 69.0109L28.0473 68.2068ZM8.94067 39.5658L14.1631 33.9617L13.993 34.5134L20.4889 28.0175L18.4509 30.3101L11.7213 37.2941L12.1886 36.3178L8.94067 39.5658ZM99.7403 26L88 37.7404L93.2735 32.9508L99.7403 26ZM1.93388 8.08743L4.77765 5.04974L4.67856 5.34275L8.20743 1.81388L7.09578 3.05481L3.4355 6.84437L3.69832 6.32299L1.93388 8.08743ZM54.4485 44.211L48.5985 50.061L47.6563 50.5813L44.211 54.4485L48.8095 50.272L51.7345 47.347L54.4485 44.211Z" />
</pattern><pattern id="streaks-normal" x="0" y="0" width="100" height="100" patternUnits="userSpaceOnUse">
    <path fill="rgba(0, 0, 0, 0.16)" fill-rule="evenodd" clip-rule="evenodd" d="M58.1193 0H58.1703L55.4939 2.67644L58.1193 0ZM45.7725 0H45.811L41.2851 4.61498L42.7191 3.29325L37.0824 8.92997L35.0554 10.9569L32.0719 13.9404L29.6229 16.5017L27.1738 19.0631L25.8089 20.2034L23.2195 22.6244L18.181 27.6068L23.8178 21.97L27.0615 18.9508L33.8666 11.9773L33.1562 12.5194L37.0262 8.87383L40.784 5.11602L38.0299 7.64561L45.7725 0ZM23.1079 0H23.108L21.5814 1.66688L20.3126 2.79534L23.1079 0ZM7.53869 0H7.54254L7.50005 0.035944L7.53869 0ZM2.49995 0H2.52362L0.900245 1.59971L2.49995 0ZM0 3.64398V3.60744L0.278386 3.36559L0 3.64398ZM0 18.6564V18.5398L0.67985 17.8416L3.4459 15.0755L1.15701 17.1333L2.78713 15.6022L6.01437 12.507L8.5168 9.87253L5.15803 13.2313L11.0357 7.25453L10.4926 7.89678L13.6868 4.7686L8.54982 9.90555L7.05177 11.5687L4.68087 13.9396L0.729379 17.8911L3.01827 15.8333L0 18.6564ZM0 69.2431V69.178L1.64651 67.4763L1.46347 67.7796L5.84063 63.4025L4.42167 64.9016L0 69.4007V69.3408L0.247596 68.9955L0 69.2431ZM2.51594 100H2.49238L5.19989 97.2925L7.70071 95.0162L12.8713 89.6772L12.3094 90.0707L15.288 87.3167L18.1542 84.4504L16.0269 86.3532L22.8752 79.6172L18.5364 84.0683L19.6435 83.0734L15.3441 87.3728L13.798 88.9189L11.5224 91.1945L9.66768 93.1615L7.81297 95.1285L6.74529 95.9716L4.75024 97.7983L2.51594 100ZM7.54255 100H7.5387L9.81396 97.884L8.46606 99.2189L7.54255 100ZM45.8189 100H45.7807L46.9912 98.8047L45.8189 100ZM58.1784 100H58.1272L62.2952 95.7511L66.1408 91.9055L63.0037 94.8115L65.2507 92.6635L69.7117 88.3346L73.2165 84.6977L68.5469 89.3673L76.7379 81.0773L75.9634 81.9509L80.3913 77.5889L73.2496 84.7307L71.1346 87.0107L67.8384 90.3069L62.3447 95.8006L65.4818 92.8947L61.2625 96.9159L58.1784 100ZM75.4277 100H75.229L82.1834 92.9039L81.3403 93.5787L86.0063 89.1371L90.5601 84.5833L87.2464 87.6725L98.0937 76.9375L91.1673 83.9761L92.8932 82.3625L86.0625 89.1933L83.6062 91.6496L79.9907 95.265L77.011 98.357L75.4277 100ZM100 18.5398V18.6563L99.9556 18.6979L95.8065 22.847L100 18.5398ZM100 3.60743V3.64398L99.6791 3.9649L99.2094 4.29428L100 3.60743ZM75.4201 0L74.0312 1.4412L72.401 2.84687L69.281 5.79854L63.1812 11.8422L70.0119 5.01151L73.919 1.32893L75.2214 0H75.4201ZM100 69.1858V69.2509L98.059 71.1919L100 69.1858ZM100 69.3486V69.4085L99.8414 69.5698L100 69.3486ZM41.9398 28.8254L53.6223 16.993L52.5215 18.2437L54.7428 16.0575L54.6875 16.0759L54.8008 16.0004L58.842 12.0231L54.9925 15.8726L55.1085 15.7953L54.898 16.0058L54.84 16.0251L48.6523 22.2128L45.6419 25.473L40.9389 30.1759L33.1007 38.0142L37.5866 33.878L31.558 39.6068L23.3278 47.837L33.0257 37.9393L38.5125 32.4525L34.0266 36.5887L37.2369 33.5283L43.6074 27.3576L48.6023 22.1628L41.9398 28.8254ZM41.0977 17.0531L39.718 18.2925L40.312 17.8388L41.0977 17.0531ZM36.875 20.3106L48.1601 7.88137L42.3438 13.7478L36.875 20.3106ZM35.7125 25.8109L34.3328 27.0503L34.9268 26.5966L35.7125 25.8109ZM17.7022 39.7534L19.0819 38.514L18.8092 38.7867L36.7575 21.8045L23.1569 35.3051L13.5771 43.7372L18.1448 39.4154L17.7022 39.7534ZM3.48102 28.9281L1.53562 30.8735L1.22228 31.0465L0.0765686 32.3326L1.60579 30.9437L2.57849 29.971L3.48102 28.9281ZM0.953463 26.2027L19.5702 7.58594L9.31575 18.6078L0.953463 26.2027ZM23.7175 12.11L17.9339 18.0875L21.4622 14.5592L20.8074 15.4725L28.1915 7.95918L30.4791 5.54232L23.4224 12.599L23.7175 12.11ZM43.4641 43.1538L40.7872 46.1552L42.4907 44.4517L42.3285 45.0465L45.8166 41.3421L46.8441 40.0983L43.4371 43.5053L43.4641 43.1538ZM1.32715 48.3271L8.0918 41.5625L4.3657 45.5674L1.32715 48.3271ZM11.1479 31.2556L11.5689 30.975L11.3584 31.1855L11.1479 31.2556ZM11.9898 27.4667L12.2003 27.2562L11.7793 27.5369L11.9898 27.4667ZM11.3585 34.5531L11.148 34.7636L10.9375 34.8338L11.3585 34.5531ZM72.929 28.5457L82.2965 19.0792L81.4043 20.0705L86.4597 15.0811L78.2983 23.2425L75.8697 25.8362L72.1029 29.603L65.8249 35.881L69.3934 32.5437L64.5858 37.1531L57.994 43.745L65.7754 35.8314L70.17 31.4369L66.6015 34.7742L69.1623 32.3125L74.2507 27.3562L78.2653 23.2095L72.929 28.5457ZM82.6674 1.83549L84.3245 0.31872L83.3724 1.27088L82.6674 1.83549ZM64.5872 16.1312L62.9301 17.648L63.6351 17.0834L64.5872 16.1312ZM70.868 9.85044L80.0048 1.1214L74.6221 6.47142L70.868 9.85044ZM90.2409 41.9448L70.7578 61.4279L79.5093 53.4795L90.2409 41.9448ZM91.8088 42.5434L95.3963 38.8357L95.2132 39.139L99.5904 34.7618L98.1714 36.261L93.5912 40.9214L93.9973 40.3549L91.8088 42.5434ZM94.331 12.8233L89.9853 17.1691L89.2853 17.5555L86.7259 20.4284L90.142 17.3258L92.3149 15.1529L94.331 12.8233ZM44.7972 62.3259L76.9824 30.1406L59.2542 49.1955L44.7972 62.3259ZM77.1482 40.321L70.1709 47.5323L70 47.6463L70.0895 47.6164L68.1916 49.5779L70.185 47.5846L70.2105 47.5761L70.421 47.3656L70.37 47.3996L73.6557 44.1139L72.6416 45.5283L84.0768 33.893L87.6194 30.1502L76.6913 41.0783L77.1482 40.321ZM50.5355 34.3137L72.6617 12.1875L60.4955 25.3084L50.5355 34.3137ZM70.2104 44.0681L70.6314 43.7875L70.4209 43.998L70.2104 44.0681ZM71.263 40.0687L70.842 40.3494L71.0525 40.2792L71.263 40.0687ZM55.1084 12.4355L55.3189 12.225L54.8979 12.5056L55.1084 12.4355ZM48.8718 15.5785L60.2075 4.70496L49.4056 15.4006L48.8718 15.5785ZM23.7636 57.4491L29.9099 51.5854L26.1656 55.6123L27.2361 54.8244L23.435 58.6255L22.0681 59.9924L20.0562 62.0042L18.5082 63.8349L16.9601 65.6656L15.8328 66.2277L13.9315 67.7051L10.4821 71.0132L14.2832 67.2121L16.6775 65.383L21.1113 60.5253L20.477 60.7357L23.2937 58.4842L25.8277 55.9502L23.7636 57.4491ZM48.3825 74.1824L44.8832 77.8523L46.9145 75.8211L45.4748 77.4881L43.4493 79.2862L42.4082 80.1568L43.9215 79.0414L42.2487 80.7143L39.3752 83.8151L41.8844 81.3059L43.8473 79.6842L42.334 80.7995L44.7237 78.4098L46.1576 76.976L46.9713 75.8779L50.078 72.7713L48.1093 74.6262L48.3825 74.1824ZM29.2877 62.9906L29.0772 63.2011L28.8667 63.2713L29.2877 62.9906ZM29.7088 59.4823L29.9193 59.2719L29.4983 59.5525L29.7088 59.4823ZM29.0772 66.5687L28.8667 66.7792L28.6562 66.8494L29.0772 66.5687ZM22.9729 68.748L23.1834 68.5375L22.7624 68.8181L22.9729 68.748ZM3.8147e-05 91.7593L13.2499 79.1355L6.5001 86.2595L3.8147e-05 91.7593ZM16.0685 87.9974L17.1375 87.0687L16.5382 87.668L16.0685 87.9974ZM21.7869 79.3344L20.7179 80.263L21.1876 79.9337L21.7869 79.3344ZM12.3607 95.0755L13.4298 94.1469L12.8304 94.7462L12.3607 95.0755ZM42.7176 59.3801L43.2789 58.8187L43.0684 59.1696L42.7877 59.4502L42.2966 59.801L42.5772 59.3801H42.7176ZM26.3124 49.3152L24.3599 51.2676L23.996 51.3918L22.8956 52.732L24.4798 51.3875L25.456 50.4113L26.3124 49.3152ZM39.0689 63.3097L38.5777 63.6606L39.56 62.6782L39.0689 63.3097ZM20.3574 55.8032L19.3751 56.7856L19.8662 56.4347L20.3574 55.8032ZM39.9297 64.195L41.5504 62.3779L41.534 62.5907L43.5967 60.528L42.9746 61.2811L40.8628 63.5238L40.961 63.1637L39.9297 64.195ZM22.3921 55.457L21.3998 56.5696L22.0313 55.9381L21.9711 56.1587L23.2642 54.7854L23.6451 54.3243L22.3821 55.5873L22.3921 55.457ZM40.6473 92.4498L45.0485 88.0485L43.0066 90.4079L40.806 92.6085L37.3463 95.7507L39.9384 92.8412L40.6473 92.4498ZM18.5042 48.7973L11.5457 55.7558L10.4249 56.3746L6.32684 60.9746L11.7967 56.0067L15.2759 52.5275L18.5042 48.7973ZM32.7113 78.139L31.1131 79.7372L30.8432 79.8668L29.9145 80.9358L31.1833 79.8074L31.9823 79.0083L32.7113 78.139ZM21.7577 93.9525L31.2855 84.0344L30.8324 84.8777L42.4999 73.2102L38.7408 77.2295L26.5552 89.6753L27.5914 88.1187L21.7577 93.9525ZM98.5132 90.0591L89.9224 97.9224L93.5769 94.9953L98.5132 90.0591ZM97.8456 80.2105L99.5027 78.6937L98.5506 79.6459L97.8456 80.2105ZM88.5656 56.4599L78.9205 65.7009L82.1262 63.3036L78.1413 67.2885L73.7522 70.8692L74.7195 70.5082L67.717 78.117L63.992 81.0336L58.0146 87.011L63.4289 81.7988L66.3887 79.4454L68.1212 78.5213L70.5757 75.6625L73.0302 72.8038L76.194 69.64L78.3434 67.4906L84.3208 61.5132L82.6575 62.7723L88.5656 56.4599ZM85.1893 67.0375L83.7304 68.356L84.3561 67.8707L85.1893 67.0375ZM90.7969 58.2022L99.2725 50.5418L94.4317 55.3826L90.7969 58.2022ZM79.377 76.2172L77.9182 77.5357L78.5438 77.0504L79.377 76.2172ZM59.4922 91.7253L56.4011 94.1231L60.0049 90.8659L63.6087 87.6087L59.4922 91.7253ZM63.8833 75.4153L46 92.3896L49.6884 89.1193L53.3767 85.8491L63.8833 75.4153ZM71.6063 55.0765L69.6609 57.0219L69.3475 57.1949L68.2018 58.481L69.731 57.0921L70.7037 56.1194L71.6063 55.0765ZM55.1405 71.6857L61.4131 65.4131L57.958 69.1267L55.1405 71.6857ZM65.8396 69.4497L61.7138 73.7138L64.2308 71.1968L63.7637 71.8484L69.0313 66.4886L70.6632 64.7645L65.6292 69.7985L65.8396 69.4497ZM53.0034 65.4955L58.2258 59.8914L58.0558 60.4431L64.5517 53.9472L62.5136 56.2398L55.7841 63.2238L56.2513 62.2475L53.0034 65.4955ZM97.0997 71.2032L79.6514 88.6515L86.7697 80.814L97.0997 71.2032ZM35.1848 56.2513L31.93 59.9006L34.0012 57.8294L33.804 58.5527L38.0451 54.0485L39.2945 52.5361L35.1519 56.6787L35.1848 56.2513ZM66.8712 26.2471L78.1907 14.3099L77.7244 15.394L91.6784 1.4399L87.233 6.29715L72.7096 21.2323L73.8482 19.2701L66.8712 26.2471ZM28.0473 68.2068L20.4355 76.375L25.1695 71.641L24.4884 73.0639L34.297 62.8844L37.2675 59.5429L27.7995 69.0109L28.0473 68.2068ZM8.94067 39.5658L14.1631 33.9617L13.993 34.5134L20.4889 28.0175L18.4509 30.3101L11.7213 37.2941L12.1886 36.3178L8.94067 39.5658ZM99.7403 26L88 37.7404L93.2735 32.9508L99.7403 26ZM1.93388 8.08743L4.77765 5.04974L4.67856 5.34275L8.20743 1.81388L7.09578 3.05481L3.4355 6.84437L3.69832 6.32299L1.93388 8.08743ZM54.4485 44.211L48.5985 50.061L47.6563 50.5813L44.211 54.4485L48.8095 50.272L51.7345 47.347L54.4485 44.211Z" />
</pattern><pattern id="streaks-dark" x="0" y="0" width="100" height="100" patternUnits="userSpaceOnUse">
    <path fill="rgba(0, 0, 0, 0.32)" fill-rule="evenodd" clip-rule="evenodd" d="M58.1193 0H58.1703L55.4939 2.67644L58.1193 0ZM45.7725 0H45.811L41.2851 4.61498L42.7191 3.29325L37.0824 8.92997L35.0554 10.9569L32.0719 13.9404L29.6229 16.5017L27.1738 19.0631L25.8089 20.2034L23.2195 22.6244L18.181 27.6068L23.8178 21.97L27.0615 18.9508L33.8666 11.9773L33.1562 12.5194L37.0262 8.87383L40.784 5.11602L38.0299 7.64561L45.7725 0ZM23.1079 0H23.108L21.5814 1.66688L20.3126 2.79534L23.1079 0ZM7.53869 0H7.54254L7.50005 0.035944L7.53869 0ZM2.49995 0H2.52362L0.900245 1.59971L2.49995 0ZM0 3.64398V3.60744L0.278386 3.36559L0 3.64398ZM0 18.6564V18.5398L0.67985 17.8416L3.4459 15.0755L1.15701 17.1333L2.78713 15.6022L6.01437 12.507L8.5168 9.87253L5.15803 13.2313L11.0357 7.25453L10.4926 7.89678L13.6868 4.7686L8.54982 9.90555L7.05177 11.5687L4.68087 13.9396L0.729379 17.8911L3.01827 15.8333L0 18.6564ZM0 69.2431V69.178L1.64651 67.4763L1.46347 67.7796L5.84063 63.4025L4.42167 64.9016L0 69.4007V69.3408L0.247596 68.9955L0 69.2431ZM2.51594 100H2.49238L5.19989 97.2925L7.70071 95.0162L12.8713 89.6772L12.3094 90.0707L15.288 87.3167L18.1542 84.4504L16.0269 86.3532L22.8752 79.6172L18.5364 84.0683L19.6435 83.0734L15.3441 87.3728L13.798 88.9189L11.5224 91.1945L9.66768 93.1615L7.81297 95.1285L6.74529 95.9716L4.75024 97.7983L2.51594 100ZM7.54255 100H7.5387L9.81396 97.884L8.46606 99.2189L7.54255 100ZM45.8189 100H45.7807L46.9912 98.8047L45.8189 100ZM58.1784 100H58.1272L62.2952 95.7511L66.1408 91.9055L63.0037 94.8115L65.2507 92.6635L69.7117 88.3346L73.2165 84.6977L68.5469 89.3673L76.7379 81.0773L75.9634 81.9509L80.3913 77.5889L73.2496 84.7307L71.1346 87.0107L67.8384 90.3069L62.3447 95.8006L65.4818 92.8947L61.2625 96.9159L58.1784 100ZM75.4277 100H75.229L82.1834 92.9039L81.3403 93.5787L86.0063 89.1371L90.5601 84.5833L87.2464 87.6725L98.0937 76.9375L91.1673 83.9761L92.8932 82.3625L86.0625 89.1933L83.6062 91.6496L79.9907 95.265L77.011 98.357L75.4277 100ZM100 18.5398V18.6563L99.9556 18.6979L95.8065 22.847L100 18.5398ZM100 3.60743V3.64398L99.6791 3.9649L99.2094 4.29428L100 3.60743ZM75.4201 0L74.0312 1.4412L72.401 2.84687L69.281 5.79854L63.1812 11.8422L70.0119 5.01151L73.919 1.32893L75.2214 0H75.4201ZM100 69.1858V69.2509L98.059 71.1919L100 69.1858ZM100 69.3486V69.4085L99.8414 69.5698L100 69.3486ZM41.9398 28.8254L53.6223 16.993L52.5215 18.2437L54.7428 16.0575L54.6875 16.0759L54.8008 16.0004L58.842 12.0231L54.9925 15.8726L55.1085 15.7953L54.898 16.0058L54.84 16.0251L48.6523 22.2128L45.6419 25.473L40.9389 30.1759L33.1007 38.0142L37.5866 33.878L31.558 39.6068L23.3278 47.837L33.0257 37.9393L38.5125 32.4525L34.0266 36.5887L37.2369 33.5283L43.6074 27.3576L48.6023 22.1628L41.9398 28.8254ZM41.0977 17.0531L39.718 18.2925L40.312 17.8388L41.0977 17.0531ZM36.875 20.3106L48.1601 7.88137L42.3438 13.7478L36.875 20.3106ZM35.7125 25.8109L34.3328 27.0503L34.9268 26.5966L35.7125 25.8109ZM17.7022 39.7534L19.0819 38.514L18.8092 38.7867L36.7575 21.8045L23.1569 35.3051L13.5771 43.7372L18.1448 39.4154L17.7022 39.7534ZM3.48102 28.9281L1.53562 30.8735L1.22228 31.0465L0.0765686 32.3326L1.60579 30.9437L2.57849 29.971L3.48102 28.9281ZM0.953463 26.2027L19.5702 7.58594L9.31575 18.6078L0.953463 26.2027ZM23.7175 12.11L17.9339 18.0875L21.4622 14.5592L20.8074 15.4725L28.1915 7.95918L30.4791 5.54232L23.4224 12.599L23.7175 12.11ZM43.4641 43.1538L40.7872 46.1552L42.4907 44.4517L42.3285 45.0465L45.8166 41.3421L46.8441 40.0983L43.4371 43.5053L43.4641 43.1538ZM1.32715 48.3271L8.0918 41.5625L4.3657 45.5674L1.32715 48.3271ZM11.1479 31.2556L11.5689 30.975L11.3584 31.1855L11.1479 31.2556ZM11.9898 27.4667L12.2003 27.2562L11.7793 27.5369L11.9898 27.4667ZM11.3585 34.5531L11.148 34.7636L10.9375 34.8338L11.3585 34.5531ZM72.929 28.5457L82.2965 19.0792L81.4043 20.0705L86.4597 15.0811L78.2983 23.2425L75.8697 25.8362L72.1029 29.603L65.8249 35.881L69.3934 32.5437L64.5858 37.1531L57.994 43.745L65.7754 35.8314L70.17 31.4369L66.6015 34.7742L69.1623 32.3125L74.2507 27.3562L78.2653 23.2095L72.929 28.5457ZM82.6674 1.83549L84.3245 0.31872L83.3724 1.27088L82.6674 1.83549ZM64.5872 16.1312L62.9301 17.648L63.6351 17.0834L64.5872 16.1312ZM70.868 9.85044L80.0048 1.1214L74.6221 6.47142L70.868 9.85044ZM90.2409 41.9448L70.7578 61.4279L79.5093 53.4795L90.2409 41.9448ZM91.8088 42.5434L95.3963 38.8357L95.2132 39.139L99.5904 34.7618L98.1714 36.261L93.5912 40.9214L93.9973 40.3549L91.8088 42.5434ZM94.331 12.8233L89.9853 17.1691L89.2853 17.5555L86.7259 20.4284L90.142 17.3258L92.3149 15.1529L94.331 12.8233ZM44.7972 62.3259L76.9824 30.1406L59.2542 49.1955L44.7972 62.3259ZM77.1482 40.321L70.1709 47.5323L70 47.6463L70.0895 47.6164L68.1916 49.5779L70.185 47.5846L70.2105 47.5761L70.421 47.3656L70.37 47.3996L73.6557 44.1139L72.6416 45.5283L84.0768 33.893L87.6194 30.1502L76.6913 41.0783L77.1482 40.321ZM50.5355 34.3137L72.6617 12.1875L60.4955 25.3084L50.5355 34.3137ZM70.2104 44.0681L70.6314 43.7875L70.4209 43.998L70.2104 44.0681ZM71.263 40.0687L70.842 40.3494L71.0525 40.2792L71.263 40.0687ZM55.1084 12.4355L55.3189 12.225L54.8979 12.5056L55.1084 12.4355ZM48.8718 15.5785L60.2075 4.70496L49.4056 15.4006L48.8718 15.5785ZM23.7636 57.4491L29.9099 51.5854L26.1656 55.6123L27.2361 54.8244L23.435 58.6255L22.0681 59.9924L20.0562 62.0042L18.5082 63.8349L16.9601 65.6656L15.8328 66.2277L13.9315 67.7051L10.4821 71.0132L14.2832 67.2121L16.6775 65.383L21.1113 60.5253L20.477 60.7357L23.2937 58.4842L25.8277 55.9502L23.7636 57.4491ZM48.3825 74.1824L44.8832 77.8523L46.9145 75.8211L45.4748 77.4881L43.4493 79.2862L42.4082 80.1568L43.9215 79.0414L42.2487 80.7143L39.3752 83.8151L41.8844 81.3059L43.8473 79.6842L42.334 80.7995L44.7237 78.4098L46.1576 76.976L46.9713 75.8779L50.078 72.7713L48.1093 74.6262L48.3825 74.1824ZM29.2877 62.9906L29.0772 63.2011L28.8667 63.2713L29.2877 62.9906ZM29.7088 59.4823L29.9193 59.2719L29.4983 59.5525L29.7088 59.4823ZM29.0772 66.5687L28.8667 66.7792L28.6562 66.8494L29.0772 66.5687ZM22.9729 68.748L23.1834 68.5375L22.7624 68.8181L22.9729 68.748ZM3.8147e-05 91.7593L13.2499 79.1355L6.5001 86.2595L3.8147e-05 91.7593ZM16.0685 87.9974L17.1375 87.0687L16.5382 87.668L16.0685 87.9974ZM21.7869 79.3344L20.7179 80.263L21.1876 79.9337L21.7869 79.3344ZM12.3607 95.0755L13.4298 94.1469L12.8304 94.7462L12.3607 95.0755ZM42.7176 59.3801L43.2789 58.8187L43.0684 59.1696L42.7877 59.4502L42.2966 59.801L42.5772 59.3801H42.7176ZM26.3124 49.3152L24.3599 51.2676L23.996 51.3918L22.8956 52.732L24.4798 51.3875L25.456 50.4113L26.3124 49.3152ZM39.0689 63.3097L38.5777 63.6606L39.56 62.6782L39.0689 63.3097ZM20.3574 55.8032L19.3751 56.7856L19.8662 56.4347L20.3574 55.8032ZM39.9297 64.195L41.5504 62.3779L41.534 62.5907L43.5967 60.528L42.9746 61.2811L40.8628 63.5238L40.961 63.1637L39.9297 64.195ZM22.3921 55.457L21.3998 56.5696L22.0313 55.9381L21.9711 56.1587L23.2642 54.7854L23.6451 54.3243L22.3821 55.5873L22.3921 55.457ZM40.6473 92.4498L45.0485 88.0485L43.0066 90.4079L40.806 92.6085L37.3463 95.7507L39.9384 92.8412L40.6473 92.4498ZM18.5042 48.7973L11.5457 55.7558L10.4249 56.3746L6.32684 60.9746L11.7967 56.0067L15.2759 52.5275L18.5042 48.7973ZM32.7113 78.139L31.1131 79.7372L30.8432 79.8668L29.9145 80.9358L31.1833 79.8074L31.9823 79.0083L32.7113 78.139ZM21.7577 93.9525L31.2855 84.0344L30.8324 84.8777L42.4999 73.2102L38.7408 77.2295L26.5552 89.6753L27.5914 88.1187L21.7577 93.9525ZM98.5132 90.0591L89.9224 97.9224L93.5769 94.9953L98.5132 90.0591ZM97.8456 80.2105L99.5027 78.6937L98.5506 79.6459L97.8456 80.2105ZM88.5656 56.4599L78.9205 65.7009L82.1262 63.3036L78.1413 67.2885L73.7522 70.8692L74.7195 70.5082L67.717 78.117L63.992 81.0336L58.0146 87.011L63.4289 81.7988L66.3887 79.4454L68.1212 78.5213L70.5757 75.6625L73.0302 72.8038L76.194 69.64L78.3434 67.4906L84.3208 61.5132L82.6575 62.7723L88.5656 56.4599ZM85.1893 67.0375L83.7304 68.356L84.3561 67.8707L85.1893 67.0375ZM90.7969 58.2022L99.2725 50.5418L94.4317 55.3826L90.7969 58.2022ZM79.377 76.2172L77.9182 77.5357L78.5438 77.0504L79.377 76.2172ZM59.4922 91.7253L56.4011 94.1231L60.0049 90.8659L63.6087 87.6087L59.4922 91.7253ZM63.8833 75.4153L46 92.3896L49.6884 89.1193L53.3767 85.8491L63.8833 75.4153ZM71.6063 55.0765L69.6609 57.0219L69.3475 57.1949L68.2018 58.481L69.731 57.0921L70.7037 56.1194L71.6063 55.0765ZM55.1405 71.6857L61.4131 65.4131L57.958 69.1267L55.1405 71.6857ZM65.8396 69.4497L61.7138 73.7138L64.2308 71.1968L63.7637 71.8484L69.0313 66.4886L70.6632 64.7645L65.6292 69.7985L65.8396 69.4497ZM53.0034 65.4955L58.2258 59.8914L58.0558 60.4431L64.5517 53.9472L62.5136 56.2398L55.7841 63.2238L56.2513 62.2475L53.0034 65.4955ZM97.0997 71.2032L79.6514 88.6515L86.7697 80.814L97.0997 71.2032ZM35.1848 56.2513L31.93 59.9006L34.0012 57.8294L33.804 58.5527L38.0451 54.0485L39.2945 52.5361L35.1519 56.6787L35.1848 56.2513ZM66.8712 26.2471L78.1907 14.3099L77.7244 15.394L91.6784 1.4399L87.233 6.29715L72.7096 21.2323L73.8482 19.2701L66.8712 26.2471ZM28.0473 68.2068L20.4355 76.375L25.1695 71.641L24.4884 73.0639L34.297 62.8844L37.2675 59.5429L27.7995 69.0109L28.0473 68.2068ZM8.94067 39.5658L14.1631 33.9617L13.993 34.5134L20.4889 28.0175L18.4509 30.3101L11.7213 37.2941L12.1886 36.3178L8.94067 39.5658ZM99.7403 26L88 37.7404L93.2735 32.9508L99.7403 26ZM1.93388 8.08743L4.77765 5.04974L4.67856 5.34275L8.20743 1.81388L7.09578 3.05481L3.4355 6.84437L3.69832 6.32299L1.93388 8.08743ZM54.4485 44.211L48.5985 50.061L47.6563 50.5813L44.211 54.4485L48.8095 50.272L51.7345 47.347L54.4485 44.211Z" />
</pattern><pattern id="streaks-darker" x="0" y="0" width="100" height="100" patternUnits="userSpaceOnUse">
    <path fill="rgba(255, 255, 255, 0.24)" fill-rule="evenodd" clip-rule="evenodd" d="M58.1193 0H58.1703L55.4939 2.67644L58.1193 0ZM45.7725 0H45.811L41.2851 4.61498L42.7191 3.29325L37.0824 8.92997L35.0554 10.9569L32.0719 13.9404L29.6229 16.5017L27.1738 19.0631L25.8089 20.2034L23.2195 22.6244L18.181 27.6068L23.8178 21.97L27.0615 18.9508L33.8666 11.9773L33.1562 12.5194L37.0262 8.87383L40.784 5.11602L38.0299 7.64561L45.7725 0ZM23.1079 0H23.108L21.5814 1.66688L20.3126 2.79534L23.1079 0ZM7.53869 0H7.54254L7.50005 0.035944L7.53869 0ZM2.49995 0H2.52362L0.900245 1.59971L2.49995 0ZM0 3.64398V3.60744L0.278386 3.36559L0 3.64398ZM0 18.6564V18.5398L0.67985 17.8416L3.4459 15.0755L1.15701 17.1333L2.78713 15.6022L6.01437 12.507L8.5168 9.87253L5.15803 13.2313L11.0357 7.25453L10.4926 7.89678L13.6868 4.7686L8.54982 9.90555L7.05177 11.5687L4.68087 13.9396L0.729379 17.8911L3.01827 15.8333L0 18.6564ZM0 69.2431V69.178L1.64651 67.4763L1.46347 67.7796L5.84063 63.4025L4.42167 64.9016L0 69.4007V69.3408L0.247596 68.9955L0 69.2431ZM2.51594 100H2.49238L5.19989 97.2925L7.70071 95.0162L12.8713 89.6772L12.3094 90.0707L15.288 87.3167L18.1542 84.4504L16.0269 86.3532L22.8752 79.6172L18.5364 84.0683L19.6435 83.0734L15.3441 87.3728L13.798 88.9189L11.5224 91.1945L9.66768 93.1615L7.81297 95.1285L6.74529 95.9716L4.75024 97.7983L2.51594 100ZM7.54255 100H7.5387L9.81396 97.884L8.46606 99.2189L7.54255 100ZM45.8189 100H45.7807L46.9912 98.8047L45.8189 100ZM58.1784 100H58.1272L62.2952 95.7511L66.1408 91.9055L63.0037 94.8115L65.2507 92.6635L69.7117 88.3346L73.2165 84.6977L68.5469 89.3673L76.7379 81.0773L75.9634 81.9509L80.3913 77.5889L73.2496 84.7307L71.1346 87.0107L67.8384 90.3069L62.3447 95.8006L65.4818 92.8947L61.2625 96.9159L58.1784 100ZM75.4277 100H75.229L82.1834 92.9039L81.3403 93.5787L86.0063 89.1371L90.5601 84.5833L87.2464 87.6725L98.0937 76.9375L91.1673 83.9761L92.8932 82.3625L86.0625 89.1933L83.6062 91.6496L79.9907 95.265L77.011 98.357L75.4277 100ZM100 18.5398V18.6563L99.9556 18.6979L95.8065 22.847L100 18.5398ZM100 3.60743V3.64398L99.6791 3.9649L99.2094 4.29428L100 3.60743ZM75.4201 0L74.0312 1.4412L72.401 2.84687L69.281 5.79854L63.1812 11.8422L70.0119 5.01151L73.919 1.32893L75.2214 0H75.4201ZM100 69.1858V69.2509L98.059 71.1919L100 69.1858ZM100 69.3486V69.4085L99.8414 69.5698L100 69.3486ZM41.9398 28.8254L53.6223 16.993L52.5215 18.2437L54.7428 16.0575L54.6875 16.0759L54.8008 16.0004L58.842 12.0231L54.9925 15.8726L55.1085 15.7953L54.898 16.0058L54.84 16.0251L48.6523 22.2128L45.6419 25.473L40.9389 30.1759L33.1007 38.0142L37.5866 33.878L31.558 39.6068L23.3278 47.837L33.0257 37.9393L38.5125 32.4525L34.0266 36.5887L37.2369 33.5283L43.6074 27.3576L48.6023 22.1628L41.9398 28.8254ZM41.0977 17.0531L39.718 18.2925L40.312 17.8388L41.0977 17.0531ZM36.875 20.3106L48.1601 7.88137L42.3438 13.7478L36.875 20.3106ZM35.7125 25.8109L34.3328 27.0503L34.9268 26.5966L35.7125 25.8109ZM17.7022 39.7534L19.0819 38.514L18.8092 38.7867L36.7575 21.8045L23.1569 35.3051L13.5771 43.7372L18.1448 39.4154L17.7022 39.7534ZM3.48102 28.9281L1.53562 30.8735L1.22228 31.0465L0.0765686 32.3326L1.60579 30.9437L2.57849 29.971L3.48102 28.9281ZM0.953463 26.2027L19.5702 7.58594L9.31575 18.6078L0.953463 26.2027ZM23.7175 12.11L17.9339 18.0875L21.4622 14.5592L20.8074 15.4725L28.1915 7.95918L30.4791 5.54232L23.4224 12.599L23.7175 12.11ZM43.4641 43.1538L40.7872 46.1552L42.4907 44.4517L42.3285 45.0465L45.8166 41.3421L46.8441 40.0983L43.4371 43.5053L43.4641 43.1538ZM1.32715 48.3271L8.0918 41.5625L4.3657 45.5674L1.32715 48.3271ZM11.1479 31.2556L11.5689 30.975L11.3584 31.1855L11.1479 31.2556ZM11.9898 27.4667L12.2003 27.2562L11.7793 27.5369L11.9898 27.4667ZM11.3585 34.5531L11.148 34.7636L10.9375 34.8338L11.3585 34.5531ZM72.929 28.5457L82.2965 19.0792L81.4043 20.0705L86.4597 15.0811L78.2983 23.2425L75.8697 25.8362L72.1029 29.603L65.8249 35.881L69.3934 32.5437L64.5858 37.1531L57.994 43.745L65.7754 35.8314L70.17 31.4369L66.6015 34.7742L69.1623 32.3125L74.2507 27.3562L78.2653 23.2095L72.929 28.5457ZM82.6674 1.83549L84.3245 0.31872L83.3724 1.27088L82.6674 1.83549ZM64.5872 16.1312L62.9301 17.648L63.6351 17.0834L64.5872 16.1312ZM70.868 9.85044L80.0048 1.1214L74.6221 6.47142L70.868 9.85044ZM90.2409 41.9448L70.7578 61.4279L79.5093 53.4795L90.2409 41.9448ZM91.8088 42.5434L95.3963 38.8357L95.2132 39.139L99.5904 34.7618L98.1714 36.261L93.5912 40.9214L93.9973 40.3549L91.8088 42.5434ZM94.331 12.8233L89.9853 17.1691L89.2853 17.5555L86.7259 20.4284L90.142 17.3258L92.3149 15.1529L94.331 12.8233ZM44.7972 62.3259L76.9824 30.1406L59.2542 49.1955L44.7972 62.3259ZM77.1482 40.321L70.1709 47.5323L70 47.6463L70.0895 47.6164L68.1916 49.5779L70.185 47.5846L70.2105 47.5761L70.421 47.3656L70.37 47.3996L73.6557 44.1139L72.6416 45.5283L84.0768 33.893L87.6194 30.1502L76.6913 41.0783L77.1482 40.321ZM50.5355 34.3137L72.6617 12.1875L60.4955 25.3084L50.5355 34.3137ZM70.2104 44.0681L70.6314 43.7875L70.4209 43.998L70.2104 44.0681ZM71.263 40.0687L70.842 40.3494L71.0525 40.2792L71.263 40.0687ZM55.1084 12.4355L55.3189 12.225L54.8979 12.5056L55.1084 12.4355ZM48.8718 15.5785L60.2075 4.70496L49.4056 15.4006L48.8718 15.5785ZM23.7636 57.4491L29.9099 51.5854L26.1656 55.6123L27.2361 54.8244L23.435 58.6255L22.0681 59.9924L20.0562 62.0042L18.5082 63.8349L16.9601 65.6656L15.8328 66.2277L13.9315 67.7051L10.4821 71.0132L14.2832 67.2121L16.6775 65.383L21.1113 60.5253L20.477 60.7357L23.2937 58.4842L25.8277 55.9502L23.7636 57.4491ZM48.3825 74.1824L44.8832 77.8523L46.9145 75.8211L45.4748 77.4881L43.4493 79.2862L42.4082 80.1568L43.9215 79.0414L42.2487 80.7143L39.3752 83.8151L41.8844 81.3059L43.8473 79.6842L42.334 80.7995L44.7237 78.4098L46.1576 76.976L46.9713 75.8779L50.078 72.7713L48.1093 74.6262L48.3825 74.1824ZM29.2877 62.9906L29.0772 63.2011L28.8667 63.2713L29.2877 62.9906ZM29.7088 59.4823L29.9193 59.2719L29.4983 59.5525L29.7088 59.4823ZM29.0772 66.5687L28.8667 66.7792L28.6562 66.8494L29.0772 66.5687ZM22.9729 68.748L23.1834 68.5375L22.7624 68.8181L22.9729 68.748ZM3.8147e-05 91.7593L13.2499 79.1355L6.5001 86.2595L3.8147e-05 91.7593ZM16.0685 87.9974L17.1375 87.0687L16.5382 87.668L16.0685 87.9974ZM21.7869 79.3344L20.7179 80.263L21.1876 79.9337L21.7869 79.3344ZM12.3607 95.0755L13.4298 94.1469L12.8304 94.7462L12.3607 95.0755ZM42.7176 59.3801L43.2789 58.8187L43.0684 59.1696L42.7877 59.4502L42.2966 59.801L42.5772 59.3801H42.7176ZM26.3124 49.3152L24.3599 51.2676L23.996 51.3918L22.8956 52.732L24.4798 51.3875L25.456 50.4113L26.3124 49.3152ZM39.0689 63.3097L38.5777 63.6606L39.56 62.6782L39.0689 63.3097ZM20.3574 55.8032L19.3751 56.7856L19.8662 56.4347L20.3574 55.8032ZM39.9297 64.195L41.5504 62.3779L41.534 62.5907L43.5967 60.528L42.9746 61.2811L40.8628 63.5238L40.961 63.1637L39.9297 64.195ZM22.3921 55.457L21.3998 56.5696L22.0313 55.9381L21.9711 56.1587L23.2642 54.7854L23.6451 54.3243L22.3821 55.5873L22.3921 55.457ZM40.6473 92.4498L45.0485 88.0485L43.0066 90.4079L40.806 92.6085L37.3463 95.7507L39.9384 92.8412L40.6473 92.4498ZM18.5042 48.7973L11.5457 55.7558L10.4249 56.3746L6.32684 60.9746L11.7967 56.0067L15.2759 52.5275L18.5042 48.7973ZM32.7113 78.139L31.1131 79.7372L30.8432 79.8668L29.9145 80.9358L31.1833 79.8074L31.9823 79.0083L32.7113 78.139ZM21.7577 93.9525L31.2855 84.0344L30.8324 84.8777L42.4999 73.2102L38.7408 77.2295L26.5552 89.6753L27.5914 88.1187L21.7577 93.9525ZM98.5132 90.0591L89.9224 97.9224L93.5769 94.9953L98.5132 90.0591ZM97.8456 80.2105L99.5027 78.6937L98.5506 79.6459L97.8456 80.2105ZM88.5656 56.4599L78.9205 65.7009L82.1262 63.3036L78.1413 67.2885L73.7522 70.8692L74.7195 70.5082L67.717 78.117L63.992 81.0336L58.0146 87.011L63.4289 81.7988L66.3887 79.4454L68.1212 78.5213L70.5757 75.6625L73.0302 72.8038L76.194 69.64L78.3434 67.4906L84.3208 61.5132L82.6575 62.7723L88.5656 56.4599ZM85.1893 67.0375L83.7304 68.356L84.3561 67.8707L85.1893 67.0375ZM90.7969 58.2022L99.2725 50.5418L94.4317 55.3826L90.7969 58.2022ZM79.377 76.2172L77.9182 77.5357L78.5438 77.0504L79.377 76.2172ZM59.4922 91.7253L56.4011 94.1231L60.0049 90.8659L63.6087 87.6087L59.4922 91.7253ZM63.8833 75.4153L46 92.3896L49.6884 89.1193L53.3767 85.8491L63.8833 75.4153ZM71.6063 55.0765L69.6609 57.0219L69.3475 57.1949L68.2018 58.481L69.731 57.0921L70.7037 56.1194L71.6063 55.0765ZM55.1405 71.6857L61.4131 65.4131L57.958 69.1267L55.1405 71.6857ZM65.8396 69.4497L61.7138 73.7138L64.2308 71.1968L63.7637 71.8484L69.0313 66.4886L70.6632 64.7645L65.6292 69.7985L65.8396 69.4497ZM53.0034 65.4955L58.2258 59.8914L58.0558 60.4431L64.5517 53.9472L62.5136 56.2398L55.7841 63.2238L56.2513 62.2475L53.0034 65.4955ZM97.0997 71.2032L79.6514 88.6515L86.7697 80.814L97.0997 71.2032ZM35.1848 56.2513L31.93 59.9006L34.0012 57.8294L33.804 58.5527L38.0451 54.0485L39.2945 52.5361L35.1519 56.6787L35.1848 56.2513ZM66.8712 26.2471L78.1907 14.3099L77.7244 15.394L91.6784 1.4399L87.233 6.29715L72.7096 21.2323L73.8482 19.2701L66.8712 26.2471ZM28.0473 68.2068L20.4355 76.375L25.1695 71.641L24.4884 73.0639L34.297 62.8844L37.2675 59.5429L27.7995 69.0109L28.0473 68.2068ZM8.94067 39.5658L14.1631 33.9617L13.993 34.5134L20.4889 28.0175L18.4509 30.3101L11.7213 37.2941L12.1886 36.3178L8.94067 39.5658ZM99.7403 26L88 37.7404L93.2735 32.9508L99.7403 26ZM1.93388 8.08743L4.77765 5.04974L4.67856 5.34275L8.20743 1.81388L7.09578 3.05481L3.4355 6.84437L3.69832 6.32299L1.93388 8.08743ZM54.4485 44.211L48.5985 50.061L47.6563 50.5813L44.211 54.4485L48.8095 50.272L51.7345 47.347L54.4485 44.211Z" />
</pattern></defs><g id="dataset"><g class="shape" ><path d="M 12 52 C 12 28 62 28 67 28 C 73 28 122 28 122 52 V 122 C 122 146 73 146 67 146 C 62 146 12 146 12 122 V 52 Z" class="shape stroke-B1 fill-AA4" style="stroke-width:2;" /><path d="M10.000089 50.340129 M10.000089 50.340129 C12.963884 27.680246, 63.163171 27.439876, 67.405312 28.857263 M8.269924 49.546535 C11.429286 29.079289, 60.378336 28.661496, 67.490419 26.033797 M67.490419 26.033797 C73.172784 28.488053, 120.839251 29.505631, 122.878905 53.627398 M65.840465 25.110353 C70.813208 29.373630, 123.537822 30.238050, 122.570257 53.920880 M121.938173 54.550467 C122.335115 69.354792, 121.918382 84.082057, 120.850022 120.531127 M121.726982 54.182009 C124.113513 75.056958, 123.017534 95.655449, 122.473743 121.158203 M122.570257 122 C121.596476 147.518251, 72.525848 146.228918, 66.263446 147.836456 M120.683404 121.712535 C123.989807 145.980885, 75.347374 146.104610, 66.780316 146.659546 M66.780316 146.659546 C61.874775 145.279395, 11.718532 147.260766, 11.736186 123.451469 M65.251935 146.187880 C60.492399 147.594156, 13.538052 144.318774, 12.224995 122.739750 M10.917117 122.200341 C9.011733 100.857484, 12.788774 75.611946, 11.646615 53.045551 M12.687773 123.505991 C11.291456 95.230958, 13.033084 67.738274, 11.751067 51.032039 M12.416186 51.825268 C11.908831 51.709839, 10.927929 51.212137, 10.150798 50.212019 M12.202835 51.885032 C11.413902 51.523430, 10.915141 50.909952, 9.951358 50.280753" class="shape stroke-B1 fill-AA4" style="stroke-width:2;" /><path d="M 12 52 C 12 28 62 28 67 28 C 73 28 122 28 122 52 V 122 C 122 146 73 146 67 146 C 62 146 12 146 12 122 V 52 Z" class=" sketch-overlay-AA4" /><path d="M10.000089 50.340129 M10.000089 50.340129 C12.963884 27.680246, 63.163171 27.439876, 67.405312 28.857263 M8.269924 49.546535 C11.429286 29.079289, 60.378336 28.661496, 67.490419 26.033797 M67.490419 26.033797 C73.172784 28.488053, 120.839251 29.505631, 122.878905 53.627398 M65.840465 25.110353 C70.813208 29.373630, 123.537822 30.238050, 122.570257 53.920880 M121.938173 54.550467 C122.335115 69.354792, 121.918382 84.082057, 120.850022 120.531127 M121.726982 54.182009 C124.113513 75.056958, 123.017534 95.655449, 122.473743 121.158203 M122.570257 122 C121.596476 147.518251, 72.525848 146.228918, 66.263446 147.836456 M120.683404 121.712535 C123.989807 145.980885, 75.347374 146.104610, 66.780316 146.659546 M66.780316 146.659546 C61.874775 145.279395, 11.718532 147.260766, 11.736186 123.451469 M65.251935 146.187880 C60.492399 147.594156, 13.538052 144.318774, 12.224995 122.739750 M10.917117 122.200341 C9.011733 100.857484, 12.788774 75.611946, 11.646615 53.045551 M12.687773 123.505991 C11.291456 95.230958, 13.033084 67.738274, 11.751067 51.032039 M12.416186 51.825268 C11.908831 51.709839, 10.927929 51.212137, 10.150798 50.212019 M12.202835 51.885032 C11.413902 51.523430, 10.915141 50.909952, 9.951358 50.280753" class=" sketch-overlay-AA4 sketch-overlay-AA4" /><path d="M 12 52 C 12 76 62 76 67 76 C 73 76 122 76 122 52" class="shape stroke-B1 fill-AA4" style="stroke-width:2;" /><path d="M10.000089 50.340129 M10.000089 50.340129 C12.963884 75.680246, 63.163171 75.439876, 67.405312 76.857263 M8.269924 49.546535 C11.429286 77.079289, 60.378336 76.661496, 67.490419 74.033797 M67.490419 74.033797 C73.172784 76.488053, 120.839251 77.505631, 122.878905 53.627398 M65.840465 73.110353 C70.813208 77.373630, 123.537822 78.238050, 122.570257 53.920880" class="shape stroke-B1 fill-AA4" style="stroke-width:2;" /><path d="M 12 52 C 12 76 62 76 67 76 C 73 76 122 76 122 52" class=" sketch-overlay-AA4" /><path d="M10.000089 50.340129 M10.000089 50.340129 C12.963884 75.680246, 63.163171 75.439876, 67.405312 76.857263 M8.269924 49.546535 C11.429286 77.079289, 60.378336 76.661496, 67.490419 74.033797 M67.490419 74.033797 C73.172784 76.488053, 120.839251 77.505631, 122.878905 53.627398 M65.840465 73.110353 C70.813208 77.373630, 123.537822 78.238050, 122.570257 53.920880" class=" sketch-overlay-AA4 sketch-overlay-AA4" /></g><text x="67.000000" y="104.500000" fill="#0A0F25" class="text-bold fill-N1" style="text-anchor:middle;font-size:16px">Dataset</text></g><g id="split"><g class="shape" ><path d="M 339 133 C 338 133 337 133 336 133 L 193 88 C 191 88 191 87 193 86 L 336 41 C 338 41 340 41 341 41 L 484 86 C 486 86 486 87 484 88 L 342 133 C 341 133 340 133 339 133 Z" class="shape stroke-B1 fill-N4" style="stroke-width:2;" /><path d="M337.000089 131.340129 M337.000089 131.340129 C338.963884 132.680246, 338.163171 132.439876, 336.405312 133.857263 M335.269924 130.546535 C337.429286 134.079289, 335.378336 133.661496, 336.490419 131.033797 M336.978473 129.873048 C287.942870 114.830502, 236.160946 102.135392, 194.536704 86.250566 M335.670024 131.729071 C284.595074 118.012224, 234.413304 102.462717, 193.297677 87.200725 M193 88 C189.531127 88.054625, 191.813753 87.704487, 193.484064 84.279764 M191.313449 88.522259 C190.733199 89.288035, 190.758714 84.895508, 195.473147 87.316002 M196.991399 86.841850 C231.834272 73.807117, 268.300670 63.329133, 336.527637 42.591845 M195.341240 88.041736 C236.591381 72.978705, 278.563874 60.110001, 335.235809 40.764166 M336 41 C336.793919 42.275325, 341.230441 39.655019, 341.179996 41.591800 M336.435913 42.996446 C337.325739 38.748774, 341.101851 43.470075, 339.060602 39.365153 M340.871633 39.618851 C368.909367 49.034236, 404.092196 56.859476, 484.237450 87.975109 M338.618889 39.431594 C384.946108 58.032752, 432.302867 73.436396, 484.617419 85.436314 M484 86 C485.076967 86.275452, 486.347317 88.365202, 484.708439 89.085850 M483.680684 84.343321 C487.659662 84.581013, 485.122225 85.930485, 482.068824 88.249977 M483.852695 89.472483 C447.651714 99.370959, 414.411094 108.821793, 340.505498 131.928189 M482.442301 88.347985 C449.752781 101.071771, 416.602173 110.983009, 341.979859 132.808723 M342 133 C341.173727 131.019360, 340.567213 132.940016, 340.753476 131.085645 M342.559969 131.308489 C340.523667 134.943322, 341.120250 133.611089, 340.399791 132.328261 M340.202503 131.992053 C339.709715 132.038113, 339.010240 131.729962, 336.858896 131.065336 M340.518629 132.278107 C339.410881 132.027085, 338.453839 131.833204, 337.105391 131.426616" class="shape stroke-B1 fill-N4" style="stroke-width:2;" /><path d="M 339 133 C 338 133 337 133 336 133 L 193 88 C 191 88 191 87 193 86 L 336 41 C 338 41 340 41 341 41 L 484 86 C 486 86 486 87 484 88 L 342 133 C 341 133 340 133 339 133 Z" class=" sketch-overlay-N4" /><path d="M337.000089 131.340129 M337.000089 131.340129 C338.963884 132.680246, 338.163171 132.439876, 336.405312 133.857263 M335.269924 130.546535 C337.429286 134.079289, 335.378336 133.661496, 336.490419 131.033797 M336.978473 129.873048 C287.942870 114.830502, 236.160946 102.135392, 194.536704 86.250566 M335.670024 131.729071 C284.595074 118.012224, 234.413304 102.462717, 193.297677 87.200725 M193 88 C189.531127 88.054625, 191.813753 87.704487, 193.484064 84.279764 M191.313449 88.522259 C190.733199 89.288035, 190.758714 84.895508, 195.473147 87.316002 M196.991399 86.841850 C231.834272 73.807117, 268.300670 63.329133, 336.527637 42.591845 M195.341240 88.041736 C236.591381 72.978705, 278.563874 60.110001, 335.235809 40.764166 M336 41 C336.793919 42.275325, 341.230441 39.655019, 341.179996 41.591800 M336.435913 42.996446 C337.325739 38.748774, 341.101851 43.470075, 339.060602 39.365153 M340.871633 39.618851 C368.909367 49.034236, 404.092196 56.859476, 484.237450 87.975109 M338.618889 39.431594 C384.946108 58.032752, 432.302867 73.436396, 484.617419 85.436314 M484 86 C485.076967 86.275452, 486.347317 88.365202, 484.708439 89.085850 M483.680684 84.343321 C487.659662 84.581013, 485.122225 85.930485, 482.068824 88.249977 M483.852695 89.472483 C447.651714 99.370959, 414.411094 108.821793, 340.505498 131.928189 M482.442301 88.347985 C449.752781 101.071771, 416.602173 110.983009, 341.979859 132.808723 M342 133 C341.173727 131.019360, 340.567213 132.940016, 340.753476 131.085645 M342.559969 131.308489 C340.523667 134.943322, 341.120250 133.611089, 340.399791 132.328261 M340.202503 131.992053 C339.709715 132.038113, 339.010240 131.729962, 336.858896 131.065336 M340.518629 132.278107 C339.410881 132.027085, 338.453839 131.833204, 337.105391 131.426616" class=" sketch-overlay-N4 sketch-overlay-N4" /></g><text x="339.000000" y="92.500000" fill="#0A0F25" class="text-bold fill-N1" style="text-anchor:middle;font-size:16px">Train/Test Split</text></g><g id="train"><g class="shape" ><path d="M-1.600310 -0.578379 L158.045551 1.811030 L157.253697 64.234072 L0.925556 67.532483" transform="translate(566.000000 12.000000)" class="shape stroke-B1 fill-B6" style="stroke-width:2;" /><path d="M0.857263 0.963884 C31.080951 0.526830, 62.241287 -2.366506, 156.206405 0.392335 M-0.648665 0.264598 C35.191699 -0.541888, 69.590886 -1.111560, 156.419625 0.752815 M158.536704 -1.749433 C157.489431 15.585410, 158.180967 27.069513, 158.390547 65.130645 M157.297677 -0.799274 C157.657560 16.854002, 156.681091 35.455552, 157.406876 66.352243 M158.052801 65.786559 C124.169849 68.913244, 87.595248 68.369720, 1.836456 65.596476 M156.056573 65.856267 C97.893851 66.623220, 39.759371 66.351756, 0.938949 66.041844 M-0.720604 65.718532 C0.302797 45.542204, -1.429636 28.321166, 0.591800 -1.206080 M0.217956 66.998223 C-1.587850 41.337487, -1.081795 17.082362, 0.440740 0.988030" transform="translate(566.000000 12.000000)" class="shape stroke-B1 fill-B6" style="stroke-width:2;" /><rect width="157.000000" height="66.000000" transform="translate(566.000000 12.000000)" class=" sketch-overlay-B6" /></g><text x="644.500000" y="50.500000" fill="#0A0F25" class="text-bold fill-N1" style="text-anchor:middle;font-size:16px">Training Data</text></g><g id="test"><g class="shape" ><path d="M-1.600310 -0.578379 L127.045551 1.811030 L126.253697 64.234072 L0.925556 67.532483" transform="translate(793.000000 98.000000)" class="shape stroke-B1 fill-B6" style="stroke-width:2;" /><path d="M0.857263 0.963884 C24.880812 0.652477, 49.841009 -2.240859, 125.206405 0.392335 M-0.648665 0.264598 C28.329790 -0.274224, 55.867069 -0.843896, 125.419625 0.752815 M127.536704 -1.749433 C126.489431 15.585410, 127.180967 27.069513, 127.390547 65.130645 M126.297677 -0.799274 C126.657560 16.854002, 125.681091 35.455552, 126.406876 66.352243 M127.052801 65.786559 C99.855696 68.299904, 69.966942 67.756379, 1.836456 65.596476 M125.056573 65.856267 C78.547141 66.552255, 32.065951 66.280791, 0.938949 66.041844 M-0.720604 65.718532 C0.302797 45.542204, -1.429636 28.321166, 0.591800 -1.206080 M0.217956 66.998223 C-1.587850 41.337487, -1.081795 17.082362, 0.440740 0.988030" transform="translate(793.000000 98.000000)" class="shape stroke-B1 fill-B6" style="stroke-width:2;" /><rect width="126.000000" height="66.000000" transform="translate(793.000000 98.000000)" class=" sketch-overlay-B6" /></g><text x="856.000000" y="136.500000" fill="#0A0F25" class="text-bold fill-N1" style="text-anchor:middle;font-size:16px">Test Data</text></g><g id="model"><g class="shape" ><path d="M-1.600310 -0.578379 L121.045551 1.811030 L120.253697 64.234072 L0.925556 67.532483" transform="translate(796.000000 12.000000)" class="shape stroke-B1 fill-B6" style="stroke-width:2;" /><path d="M0.857263 0.963884 C23.680785 0.676795, 47.440955 -2.216540, 119.206405 0.392335 M-0.648665 0.264598 C27.001679 -0.222418, 53.210846 -0.792090, 119.419625 0.752815 M121.536704 -1.749433 C120.489431 15.585410, 121.180967 27.069513, 121.390547 65.130645 M120.297677 -0.799274 C120.657560 16.854002, 119.681091 35.455552, 120.406876 66.352243 M121.052801 65.786559 C95.149731 68.181193, 66.555012 67.637668, 1.836456 65.596476 M119.056573 65.856267 C74.802616 66.538520, 30.576902 66.267056, 0.938949 66.041844 M-0.720604 65.718532 C0.302797 45.542204, -1.429636 28.321166, 0.591800 -1.206080 M0.217956 66.998223 C-1.587850 41.337487, -1.081795 17.082362, 0.440740 0.988030" transform="translate(796.000000 12.000000)" class="shape stroke-B1 fill-B6" style="stroke-width:2;" /><rect width="120.000000" height="66.000000" transform="translate(796.000000 12.000000)" class=" sketch-overlay-B6" /></g><text x="856.000000" y="50.500000" fill="#0A0F25" class="text-bold fill-N1" style="text-anchor:middle;font-size:16px">ML Model</text></g><g id="eval"><g class="shape" ><path d="M-1.600310 -0.578379 L132.045551 1.811030 L131.253697 78.234072 L0.925556 81.532483" transform="translate(999.000000 47.000000)" class="shape stroke-B1 fill-B6" style="stroke-width:2;" /><path d="M0.857263 0.963884 C25.880835 0.632211, 51.841054 -2.261124, 130.206405 0.392335 M-0.648665 0.264598 C29.436550 -0.317395, 58.080587 -0.887068, 130.419625 0.752815 M132.536704 -1.749433 C131.360149 18.630442, 132.051685 33.159578, 132.390547 79.130645 M131.297677 -0.799274 C131.745702 20.611542, 130.769233 42.970633, 131.406876 80.352243 M132.052801 79.786559 C103.777333 82.398830, 72.810217 81.855305, 1.836456 79.596476 M130.056573 79.856267 C81.667578 80.563701, 33.306826 80.292237, 0.938949 80.041844 M-0.720604 79.718532 C0.099591 55.526873, -1.632842 34.290505, 0.591800 -1.206080 M0.217956 80.998223 C-1.760112 50.244759, -1.254057 20.896906, 0.440740 0.988030" transform="translate(999.000000 47.000000)" class="shape stroke-B1 fill-B6" style="stroke-width:2;" /><rect width="131.000000" height="80.000000" transform="translate(999.000000 47.000000)" class=" sketch-overlay-B6" /></g><text x="1064.500000" y="92.500000" fill="#0A0F25" class="text-bold fill-N1" style="text-anchor:middle;font-size:16px">Evaluation</text></g><g id="(dataset -&gt; split)[0]"><marker id="mk-3488378134" markerWidth="10.000000" markerHeight="12.000000" refX="7.000000" refY="6.000000" viewBox="0.000000 0.000000 10.000000 12.000000" orient="auto" markerUnits="userSpaceOnUse"> <polygon points="0.000000,0.000000 10.000000,6.000000 0.000000,12.000000" fill="#0D32B2" class="connection fill-B1" stroke-width="2" /> </marker><path d="M123.000044 87.170064 M122.840168 87.751650 C143.539014 86.414150, 164.239531 87.741200, 187.213518 87.771714 M123.219771 87.576914 C145.346686 87.490893, 167.319440 88.030098, 187.587511 87.769139" fill="none" class="connection stroke-B1" style="stroke-width:2;" mask="url(#d2-1355680374)" /><path d="M-8.527627 -3.097061 L1.749550 0.558791 L-8.562935 4.521533" stroke="none" class="connection fill-B1" style="stroke-width:0;" transform="translate(188.000000 88.000000) rotate(0)" /> <path d="M-10.153731 -4.038897 C-7.293657 -2.964754, -5.552453 -3.126871, 0.222305 -0.654474 M-10.160117 -4.253535 C-7.616436 -2.677663, -5.569656 -2.320404, -0.086565 0.272291 M0.578048 -0.807164 C-2.240460 1.133634, -3.845699 1.135504, -9.579367 4.140709 M-0.217907 -0.322328 C-3.660571 0.941126, -7.003142 2.167050, -10.100296 3.840861 M-9.957758 4.629247 C-9.937438 2.794817, -10.508655 0.509238, -9.330834 -3.522818 M-10.354741 4.285014 C-9.712366 0.996453, -9.805329 -1.235319, -9.648840 -4.366524" fill="none" class="connection stroke-B1" style="stroke-width:2;" transform="translate(188.000000 88.000000) rotate(0)" /></g><g id="(split -&gt; train)[0]"><path d="M439.000030 72.162473 M438.840154 72.744059 C463.381597 71.285261, 487.925329 72.519929, 515.213590 72.475669 M439.219757 72.569323 C465.465696 72.368437, 491.556538 72.808653, 515.587583 72.473094 M516.000072 72.703955 C525.125283 73.215452, 526.615129 73.561220, 526.228103 63.434352 M515.179676 73.399228 C526.393492 71.927365, 526.372097 71.666907, 525.456653 62.270946 M525.466610 62.419278 C525.792491 59.608252, 525.935429 57.919058, 526.191905 54.961094 M525.389523 62.438322 C525.614382 59.855714, 525.798943 57.182310, 525.828031 54.973800 M526 55 C526.795922 44.992354, 526.938949 45.041844, 535.912126 45.263818 M525.868093 55.725734 C525.824082 45.787979, 525.044761 44.705208, 535.921734 44.549622 M536.559397 45.164843 C543.308089 44.985377, 553.036981 44.130828, 561.346061 44.730295 M535.521656 44.405027 C541.659272 44.968106, 546.936466 44.168424, 562.231389 45.383120" fill="none" class="connection stroke-B1" style="stroke-width:2;" mask="url(#d2-1355680374)" /><path d="M-8.527627 -3.097061 L1.749550 0.558791 L-8.562935 4.521533" stroke="none" class="connection fill-B1" style="stroke-width:0;" transform="translate(562.000000 45.000000) rotate(0)" /> <path d="M-10.153731 -4.038897 C-7.293657 -2.964754, -5.552453 -3.126871, 0.222305 -0.654474 M-10.160117 -4.253535 C-7.616436 -2.677663, -5.569656 -2.320404, -0.086565 0.272291 M0.578048 -0.807164 C-2.240460 1.133634, -3.845699 1.135504, -9.579367 4.140709 M-0.217907 -0.322328 C-3.660571 0.941126, -7.003142 2.167050, -10.100296 3.840861 M-9.957758 4.629247 C-9.937438 2.794817, -10.508655 0.509238, -9.330834 -3.522818 M-10.354741 4.285014 C-9.712366 0.996453, -9.805329 -1.235319, -9.648840 -4.366524" fill="none" class="connection stroke-B1" style="stroke-width:2;" transform="translate(562.000000 45.000000) rotate(0)" /></g><g id="(split -&gt; test)[0]"><path d="M440.000029 102.177719 M439.840153 102.759305 C464.062564 101.487237, 488.286031 102.906226, 515.213591 103.066439 M440.219756 102.584569 C466.120657 102.582510, 491.868329 103.220229, 515.587584 103.063864 M516.000073 103.294725 C525.125283 103.882452, 526.615129 104.228220, 526.228103 114.101352 M515.179677 103.989998 C526.393492 102.594365, 526.372097 102.333907, 525.456653 112.937946 M525.467687 113.102332 C525.740448 115.212988, 525.879792 118.567107, 526.212674 120.956883 M525.382258 113.123436 C525.603003 115.927568, 525.786867 118.631324, 525.809419 120.970964 M526 121 C526.795922 130.992354, 526.938949 131.041844, 535.912126 131.263818 M525.868093 121.725734 C525.824082 131.787979, 525.044761 130.705208, 535.921734 130.549622 M536.439199 131.048875 C613.577682 131.484904, 693.134605 130.817668, 788.469327 130.781134 M535.597070 130.432283 C589.268688 129.997016, 642.242072 129.365896, 789.187772 131.310903" fill="none" class="connection stroke-B1" style="stroke-width:2;" mask="url(#d2-1355680374)" /><path d="M-8.527627 -3.097061 L1.749550 0.558791 L-8.562935 4.521533" stroke="none" class="connection fill-B1" style="stroke-width:0;" transform="translate(789.000000 131.000000) rotate(0)" /> <path d="M-10.153731 -4.038897 C-7.293657 -2.964754, -5.552453 -3.126871, 0.222305 -0.654474 M-10.160117 -4.253535 C-7.616436 -2.677663, -5.569656 -2.320404, -0.086565 0.272291 M0.578048 -0.807164 C-2.240460 1.133634, -3.845699 1.135504, -9.579367 4.140709 M-0.217907 -0.322328 C-3.660571 0.941126, -7.003142 2.167050, -10.100296 3.840861 M-9.957758 4.629247 C-9.937438 2.794817, -10.508655 0.509238, -9.330834 -3.522818 M-10.354741 4.285014 C-9.712366 0.996453, -9.805329 -1.235319, -9.648840 -4.366524" fill="none" class="connection stroke-B1" style="stroke-width:2;" transform="translate(789.000000 131.000000) rotate(0)" /></g><g id="(train -&gt; model)[0]"><path d="M724.000044 44.170064 M723.840168 44.751650 C745.499811 43.406921, 767.161124 44.733971, 791.213518 44.771714 M724.219771 44.576914 C747.376201 44.486924, 770.378469 45.026129, 791.587511 44.769139" fill="none" class="connection stroke-B1" style="stroke-width:2;" mask="url(#d2-1355680374)" /><path d="M-8.527627 -3.097061 L1.749550 0.558791 L-8.562935 4.521533" stroke="none" class="connection fill-B1" style="stroke-width:0;" transform="translate(792.000000 45.000000) rotate(0)" /> <path d="M-10.153731 -4.038897 C-7.293657 -2.964754, -5.552453 -3.126871, 0.222305 -0.654474 M-10.160117 -4.253535 C-7.616436 -2.677663, -5.569656 -2.320404, -0.086565 0.272291 M0.578048 -0.807164 C-2.240460 1.133634, -3.845699 1.135504, -9.579367 4.140709 M-0.217907 -0.322328 C-3.660571 0.941126, -7.003142 2.167050, -10.100296 3.840861 M-9.957758 4.629247 C-9.937438 2.794817, -10.508655 0.509238, -9.330834 -3.522818 M-10.354741 4.285014 C-9.712366 0.996453, -9.805329 -1.235319, -9.648840 -4.366524" fill="none" class="connection stroke-B1" style="stroke-width:2;" transform="translate(792.000000 45.000000) rotate(0)" /></g><g id="(model -&gt; eval)[0]"><path d="M917.000044 44.170064 M916.840168 44.751650 C926.970247 43.493671, 937.101998 44.820721, 948.213518 44.771714 M917.219771 44.576914 C928.022024 44.534552, 938.670116 45.073757, 948.587511 44.769139 M949 45 C958.125283 45.549452, 959.615129 45.895220, 959.228103 55.768352 M948.179604 45.695273 C959.393492 44.261365, 959.372097 44.000907, 958.456653 54.604946 M958.470412 54.809925 C958.766994 57.443938, 958.897247 61.628968, 959.265193 64.612235 M958.363886 54.836242 C958.591973 58.335127, 958.774076 61.709416, 958.762357 64.629794 M959 64.666 C959.795922 74.658354, 959.938949 74.707844, 968.912126 74.929818 M958.868093 65.391734 C958.824082 75.453979, 958.044761 74.371208, 968.921734 74.215622 M969.559397 74.830843 C976.308089 74.651377, 986.036981 73.796828, 994.346061 74.396295 M968.521656 74.071027 C974.659272 74.634106, 979.936466 73.834424, 995.231389 75.049120" fill="none" class="connection stroke-B1" style="stroke-width:2;" mask="url(#d2-1355680374)" /><path d="M-8.527627 -3.097061 L1.749550 0.558791 L-8.562935 4.521533" stroke="none" class="connection fill-B1" style="stroke-width:0;" transform="translate(995.000000 74.666000) rotate(0)" /> <path d="M-10.153731 -4.038897 C-7.293657 -2.964754, -5.552453 -3.126871, 0.222305 -0.654474 M-10.160117 -4.253535 C-7.616436 -2.677663, -5.569656 -2.320404, -0.086565 0.272291 M0.578048 -0.807164 C-2.240460 1.133634, -3.845699 1.135504, -9.579367 4.140709 M-0.217907 -0.322328 C-3.660571 0.941126, -7.003142 2.167050, -10.100296 3.840861 M-9.957758 4.629247 C-9.937438 2.794817, -10.508655 0.509238, -9.330834 -3.522818 M-10.354741 4.285014 C-9.712366 0.996453, -9.805329 -1.235319, -9.648840 -4.366524" fill="none" class="connection stroke-B1" style="stroke-width:2;" transform="translate(995.000000 74.666000) rotate(0)" /></g><g id="(test -&gt; eval)[0]"><path d="M920.000044 130.170064 M919.840168 130.751650 C929.009451 129.500900, 938.180404 130.827950, 948.213518 130.771714 M920.219771 130.576914 C929.992509 130.538521, 939.611086 131.077726, 948.587511 130.769139 M949 131 C958.125283 131.549452, 959.615129 131.895220, 959.228103 121.768352 M948.179604 131.695273 C959.393492 130.261365, 959.372097 130.000907, 958.456653 120.604946 M958.469336 120.793897 C958.836262 117.209336, 958.970104 115.054356, 959.244456 111.283439 M958.371140 120.818156 C958.605277 117.524212, 958.788075 114.115235, 958.780939 111.299625 M959 111.333 C959.795922 101.325354, 959.938949 101.374844, 968.912126 101.596818 M958.868093 112.058734 C958.824082 102.120979, 958.044761 101.038208, 968.921734 100.882622 M969.559397 101.497843 C976.308089 101.318377, 986.036981 100.463828, 994.346061 101.063295 M968.521656 100.738027 C974.659272 101.301106, 979.936466 100.501424, 995.231389 101.716120" fill="none" class="connection stroke-B1" style="stroke-width:2;" mask="url(#d2-1355680374)" /><path d="M-8.527627 -3.097061 L1.749550 0.558791 L-8.562935 4.521533" stroke="none" class="connection fill-B1" style="stroke-width:0;" transform="translate(995.000000 101.333000) rotate(0)" /> <path d="M-10.153731 -4.038897 C-7.293657 -2.964754, -5.552453 -3.126871, 0.222305 -0.654474 M-10.160117 -4.253535 C-7.616436 -2.677663, -5.569656 -2.320404, -0.086565 0.272291 M0.578048 -0.807164 C-2.240460 1.133634, -3.845699 1.135504, -9.579367 4.140709 M-0.217907 -0.322328 C-3.660571 0.941126, -7.003142 2.167050, -10.100296 3.840861 M-9.957758 4.629247 C-9.937438 2.794817, -10.508655 0.509238, -9.330834 -3.522818 M-10.354741 4.285014 C-9.712366 0.996453, -9.805329 -1.235319, -9.648840 -4.366524" fill="none" class="connection stroke-B1" style="stroke-width:2;" transform="translate(995.000000 101.333000) rotate(0)" /></g><mask id="d2-1355680374" maskUnits="userSpaceOnUse" x="1" y="1" width="1140" height="174">
<rect x="1" y="1" width="1140" height="174" fill="white"></rect>
<rect x="34.500000" y="88.500000" width="65" height="21" fill="rgba(0,0,0,0.75)"></rect>
<rect x="273.000000" y="76.500000" width="132" height="21" fill="rgba(0,0,0,0.75)"></rect>
<rect x="588.500000" y="34.500000" width="112" height="21" fill="rgba(0,0,0,0.75)"></rect>
<rect x="815.500000" y="120.500000" width="81" height="21" fill="rgba(0,0,0,0.75)"></rect>
<rect x="818.500000" y="34.500000" width="75" height="21" fill="rgba(0,0,0,0.75)"></rect>
<rect x="1021.500000" y="76.500000" width="86" height="21" fill="rgba(0,0,0,0.75)"></rect>
</mask></svg></svg>
" class="img-fluid" style="width:100.0%"></p>
</section>
</section>
<section id="try-it-yourself" class="level2">
<h2 class="anchored" data-anchor-id="try-it-yourself">Try it yourself</h2>
<p>I suggest starting with the <a href="https://play.d2lang.com">D2 playground</a> and any assistant, such as ChatGPT. No installation or magic prompt required. Just ask it to generate the D2 code for a simple diagram.</p>
<p>A more powerful setup is to install D2 locally, index the documentation in Cursor and then use Claude-3.5 Sonnet in a Composer window to generate diagrams.</p>
<hr>
<p>Image background by <a href="https://unsplash.com/@pawel_czerwinski?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Pawel Czerwinski</a> on <a href="https://unsplash.com/photos/background-pattern-C-pmBkHZWQ0?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Unsplash</a></p>


</section>

 ]]></description>
  <category>Productivity</category>
  <guid>https://simmering.dev/blog/diagrams/</guid>
  <pubDate>Fri, 27 Dec 2024 23:00:00 GMT</pubDate>
  <media:content url="https://simmering.dev/blog/diagrams/diagrams.webp" medium="image" type="image/webp"/>
</item>
<item>
  <title>When to use Direct Preference Optimization (DPO)</title>
  <dc:creator>Paul Simmering</dc:creator>
  <link>https://simmering.dev/blog/llm-customization/</link>
  <description><![CDATA[ 






<p>OpenAI recently added the ability to fine-tune their models using direct preference optimization (DPO). They call it <a href="https://platform.openai.com/docs/guides/fine-tuning#preference">preference tuning</a>. Previously, their API only supported supervised fine-tuning (SFT). They join <a href="https://openpipe.ai/blog/announcing-dpo-support">OpenPipe</a> as one of the first pay-per-token APIs to offer DPO. This makes DPO more accessible to developers who don’t want the complexity of managing the training infrastructure themselves. In this article I will briefly introduce DPO and then discuss its use cases in contrast to SFT.</p>
<section id="what-is-dpo" class="level3">
<h3 class="anchored" data-anchor-id="what-is-dpo">What is DPO?</h3>
<p>Skip to the next section if you’re already familiar with DPO.</p>
<p>DPO means training an LLM to conform to the preferences of human raters. Each example contains:</p>
<ul>
<li>A user input, e.g.&nbsp;a question</li>
<li>An ideal assistant reply</li>
<li>A worse assistant reply</li>
</ul>
<p>In a training input file, it looks like this:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode json code-with-copy"><code class="sourceCode json"><span id="cb1-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb1-2">  <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"input"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb1-3">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"messages"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb1-4">      <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb1-5">        <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"role"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"user"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb1-6">        <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"content"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Write a professional email asking for a raise."</span></span>
<span id="cb1-7">      <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb1-8">    <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">]</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb1-9">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">},</span></span>
<span id="cb1-10">  <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"preferred_output"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb1-11">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb1-12">      <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"role"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"assistant"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb1-13">      <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"content"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"I would like to request a salary review. In the past 6 months I have led multiple projects and also assisted colleagues with their tasks."</span></span>
<span id="cb1-14">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb1-15">  <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">]</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb1-16">  <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"non_preferred_output"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb1-17">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb1-18">      <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"role"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"assistant"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb1-19">      <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"content"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"You should increase my salary because I'm doing all the work here."</span></span>
<span id="cb1-20">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb1-21">  <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">]</span></span>
<span id="cb1-22"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span></code></pre></div></div>
<p>DPO adjusts the model weights such that it is more likely to choose the preferred answers. It’s graded on how much more likely it is to choose the preferred answer. This teaches it not just to answer more like the preferred answer, but also to avoid answering like the rejected answer. It stands in contrast to SFT, which only teaches it to mimic a single answer.</p>
</section>
<section id="loss-function" class="level3">
<h3 class="anchored" data-anchor-id="loss-function">Loss function</h3>
<p>Mathematically, DPO fine-tunes the LLM by maximizing the margin between the probability of the preferred and rejected response. The loss function is:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/llm-customization/dpo_loss.webp" class="img-fluid figure-img"></p>
<figcaption>DPO loss function</figcaption>
</figure>
</div>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cpi_%5Ctheta(y%7Cx)">: The probability that our model (with parameters θ) assigns to generating response y given input x</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cpi_%7B%5Ctext%7Bref%7D%7D(y%7Cx)">: The probability that a reference model (usually the initial pre-trained model) assigns to the same response</li>
<li><img src="https://latex.codecogs.com/png.latex?y_w">: The preferred, “winning” response</li>
<li><img src="https://latex.codecogs.com/png.latex?y_l">: The rejected, “losing” response</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cbeta">: Hyperparameter to regulate the strength of weight updates.</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Csigma">: Sigmoid function that maps the difference to a probability between 0 and 1</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BE%7D">: Expected value over the dataset D of preferences</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BD%7D">: Dataset containing triples of (input, preferred response, rejected response)</li>
</ul>
<p>See the <a href="https://arxiv.org/abs/2305.18290">paper</a> by Rafailov et al.&nbsp;(2023) for details and how this loss is turned into a weight update.</p>
<p>The use of a reference model has two advantages over purely optimizing for a high <img src="https://latex.codecogs.com/png.latex?%5Cpi_%5Ctheta(y_w%7Cx)">:</p>
<ol type="1">
<li>It prevents overfitting to the examples. The derivative of the loss function (see after equation 7 in paper) illustrates that the model gets low weight updates from examples where it already gives more probability to the preferred response.</li>
<li>It takes into account how likely the preferred and rejected responses are to begin with. So teaching the model to prefer a rare response over another rare response won’t cause an update that breaks common responses.</li>
</ol>
<p>The choice of <img src="https://latex.codecogs.com/png.latex?%5Cbeta"> is key. Higher values result in more conservative updates, preserving previous behavior. Lower values cause more aggressive updates in favor of the preferred answer. This stems from the interaction of the sigmoid function: a higher beta causes the function to saturate (approach 1) from smaller differences in the probability ratios, leading to a smaller weight update.</p>
<p>DPO and its predecessor reinforcement learning from human feedback (RLHF) have been a staple in the training of LLMs that serve as assistants, including open models like the Llama 3 family. They are one of the key separators between different models, which share a lot of common SFT in the form of web scraped texts, papers and code. It’s what forms the character and mannerisms of an assistant.</p>
</section>
<section id="data-for-dpo" class="level3">
<h3 class="anchored" data-anchor-id="data-for-dpo">Data for DPO</h3>
<p>Collecting DPO data is straightforward. You take the current best model and let it generate multiple answers to a user input at nonzero temperature. Then either a human or a model (a copy of the answering model or a larger, smarter model) judges which answer is superior. This enables a powerful training loop, particularly if an LLM is used as a judge.</p>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">flowchart LR
    A[User Input] --&gt;|Prompt| B[Base model]
    B --&gt;|Generates| C[Multiple responses]
    C --&gt;|Evaluates| D[Human or LLM judge]
    D --&gt;|Selects| G[Preferred response]
    D --&gt;|Rejects| H[Non-preferred response]
    G --&gt; I[DPO training data]
    H --&gt; I
    I --&gt;|Updates| B
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</section>
<section id="when-to-use-dpo" class="level2">
<h2 class="anchored" data-anchor-id="when-to-use-dpo">When to use DPO?</h2>
<p>DPO is best utilized to refine a model that already underwent SFT. By default, OpenAI’s fine-tuning API bundles SFT with DPO by first using SFT to let models learn from the exact wording of the preferred answers before also learning to prefer them using DPO.</p>
<section id="when-prompting-isnt-sufficient" class="level4">
<h4 class="anchored" data-anchor-id="when-prompting-isnt-sufficient">1. When prompting isn’t sufficient</h4>
<p>If the desired behavior can be achieved by a prompt, you don’t need to implement DPO. Prompts are easier to change and different instances of a model can run with different system prompts. However, prompts add tokens on every call, which makes them slower, more expensive and fills up the context window. They’re also more limited in what behaviors they can achieve and may be ignored by the model. In those cases, DPO is a more robust solution and can of course be be combined with prompts.</p>
</section>
<section id="when-you-cant-generate-optimal-answers-at-scale" class="level4">
<h4 class="anchored" data-anchor-id="when-you-cant-generate-optimal-answers-at-scale">2. When you can’t generate optimal answers at scale</h4>
<p>Humans typically have an easier time determining which of two answers is better than developing the best answer on their own. This is especially true for complex outputs, multi-turn conversations, and all matters of style where there are multiple acceptable answers. As an example, it’s faster to judge which of two email texts sounds better than writing the perfect email.</p>
</section>
<section id="when-you-want-to-preserve-previous-behavior" class="level4">
<h4 class="anchored" data-anchor-id="when-you-want-to-preserve-previous-behavior">3. When you want to preserve previous behavior</h4>
<p>DPO is a more measured treatment than SFT and can be regulated with the <img src="https://latex.codecogs.com/png.latex?%5Cbeta"> hyperparameter. This makes it a good choice if the model is already trained and you only want to make small changes. In contrast, SFT is a more aggressive treatment that overrides previous behavior, for example, a model trained on a named entity recognition task would start speaking JSON rather than English.</p>
</section>
<section id="use-cases" class="level3">
<h3 class="anchored" data-anchor-id="use-cases">Use cases</h3>
<p>Let’s consider common LLM use cases and the criteria listed above to decide between SFT+DPO and SFT only.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 17%">
<col style="width: 11%">
<col style="width: 70%">
</colgroup>
<thead>
<tr class="header">
<th>Use Case</th>
<th>Method</th>
<th>Reasoning</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Summarization</td>
<td>SFT+DPO</td>
<td>Humans can easily compare summaries for quality, but writing the perfect summary is harder. Multiple valid summaries exist.</td>
</tr>
<tr class="even">
<td>Code generation</td>
<td>SFT+DPO</td>
<td>Different coding styles and approaches can be valid. Humans can better judge which implementation is more readable/maintainable. SFT can suffice for SQL generation.</td>
</tr>
<tr class="odd">
<td>Question answering</td>
<td>SFT+DPO</td>
<td>Multiple valid answers may exist with varying levels of helpfulness and clarity. Comparing answers is easier than writing the perfect one.</td>
</tr>
<tr class="even">
<td>Writing assistance</td>
<td>SFT+DPO</td>
<td>Writing quality is subjective and context-dependent. Humans can better evaluate style and tone by comparison.</td>
</tr>
<tr class="odd">
<td>Chatbot responses</td>
<td>SFT+DPO</td>
<td>Natural conversation has many valid responses. Comparing helps optimize for engagement and helpfulness.</td>
</tr>
<tr class="even">
<td>Information extraction</td>
<td>SFT only</td>
<td>Tasks like text classification, named entity recognition, relationship extraction, web scraping, and others have one correct answer. DPO is unnecessary.</td>
</tr>
<tr class="odd">
<td>Tool calling</td>
<td>SFT only</td>
<td>Unlike code generation, calls to APIs, data fetching functions and similar are limited in variation and a given user request is usually translated into one optimal set of tool calls.</td>
</tr>
<tr class="even">
<td>Mathematical computation</td>
<td>SFT only</td>
<td>Mathematical problems typically have one correct answer. DPO would be a poor way to teach right and wrong solutions, but may make sense to teach a style of presentation.</td>
</tr>
</tbody>
</table>
<p>Tasks that fully leverage LLM’s free-form input and output tend to benefit most from DPO.</p>
</section>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further reading</h2>
<ul>
<li>To see DPO in action, I suggest reading Anyscale’s article <a href="https://www.anyscale.com/blog/direct-preference-optimization-with-synthetic-data">Direct Preference Optimization with Synthetic Data</a> which walks through DPO for summarization using synthetic data and LLM as a judge.</li>
<li>If you want to get started with your own project, I suggest <a href="https://pytorch.org/torchtune/stable/recipes/dpo.html">torchtune</a> for training on your own infrastructure and the <a href="https://platform.openai.com/docs/guides/fine-tuning#preference">OpenAI API</a> for a managed service.</li>
<li>If you want to learn more details about DPO, I suggest reading the <a href="https://arxiv.org/abs/2305.18290">paper</a> by Rafailov et al.&nbsp;(2023). There is also a <a href="https://www.youtube.com/live/vuWbJlBePPA?si=18sGG8Vn7D6yykeD">YouTube video</a> of a lecture by one of the authors, Christopher Manning.</li>
<li>Read about variants of DPO in a <a href="https://huggingface.co/blog/pref-tuning">blog post</a> on HuggingFace.</li>
</ul>
<p>Photo by <a href="https://unsplash.com/@max_williams?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Max Williams</a> on <a href="https://unsplash.com/photos/multicolored-wallpaper-_OoK2W7OPRM?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Unsplash</a></p>


</section>

 ]]></description>
  <category>Machine Learning</category>
  <guid>https://simmering.dev/blog/llm-customization/</guid>
  <pubDate>Sat, 21 Dec 2024 23:00:00 GMT</pubDate>
  <media:content url="https://simmering.dev/blog/llm-customization/image.webp" medium="image" type="image/webp"/>
</item>
<item>
  <title>Type-safe LLM agents with PydanticAI</title>
  <dc:creator>Paul Simmering</dc:creator>
  <link>https://simmering.dev/blog/pydantic-ai/</link>
  <description><![CDATA[ 






<p>Pydantic AI is a new agent framework by the company behind Pydantic, the popular data validation library. Pydantic has transformed how I write Python, so I’m excited for their take on agents. In this article I’ll walk through an example app and comment on my experience developing with PydanticAI.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>PydanticAI version 0.0.13
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>PydanticAI is in beta. This article is based on version 0.0.13. Code examples may not work with future versions. Limitations that are mentioned may be lifted in future versions.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>What is an agent?
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The term “agent” in the context of LLMs refers to a while loop that calls an LLM to solve a problem. The LLM may be equipped with tools, meaning functions that it can supply arguments to and receive results from. To cut through the marketing hype, I suggest just reading the <a href="https://github.com/pydantic/pydantic-ai/blob/0475da82d5956a2d65678d464328c8f8f8be2bf1/pydantic_ai_slim/pydantic_ai/agent.py#L244">code</a> for PydanticAI’s <code>Agent.run()</code> method.</p>
</div>
</div>
</div>
<p>As an agent framework, PydanticAI lets developers define workflows wherein an LLM interprets a user’s query and can use tools in multiple steps to answer the question or perform a task. Type safety is a big deal in agent development - the LLM has to call tools with the correct arguments and the tools have to return the correct data type. PydanticAI brings the type safety of Pydantic to this space. This also speeds up development, because type checkers like mypy and pyright can catch errors before the code is run.</p>
<p>In addition to type safety, PydanticAI offers:</p>
<ul>
<li>streaming responses, including structured responses</li>
<li>support for async tool calling</li>
<li>support for multiple LLM providers, including OpenAI, Groq, Anthropic, Gemini, Ollama and Mistral, with more to come</li>
<li>optional integration with <a href="https://pydantic.dev/logfire">Logfire</a>, a commercial service by the Pydantic team for logging LLM calls</li>
</ul>
<section id="example-app-market-research-knowledge-manager" class="level2">
<h2 class="anchored" data-anchor-id="example-app-market-research-knowledge-manager">Example app: Market research knowledge manager</h2>
<p>Large companies conduct market research to understand their customers, competition and market trends. Over time, they amass a library of thousands of reports, tables and transcripts. Knowledge management becomes a challenge, because teams are not aware of existing research.</p>
<p>Let’s build an example agent that answers questions based on information in a database with multiple tables. Our final agentic RAG system will enable an interaction like this:</p>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">%%{init: {
  'theme': 'base',
  'themeVariables': {
    'primaryColor': '#ffffff',
    'primaryTextColor': '#2d3748',
    'primaryBorderColor': '#90cdf4',
    'lineColor': '#64748b',
    'secondaryColor': '#ffffff',
    'tertiaryColor': '#ffffff',
    'fontSize': '22px',
    'labelFontSize': '18px',
    'edgeLabelFontSize': '18px'
  }
}}%%
graph LR
    %% Define styles
    classDef default fill:#ffffff,stroke:#90cdf4,stroke-width:2px
    classDef highlight fill:#fdf2f8,stroke:#ed64a6,stroke-width:3px
    classDef api fill:#ffffff,stroke:#4fd1c5,stroke-width:2px

    User([User]) --&gt; |"What reports do we have about electric vehicles?"| Agent
    Agent --&gt; |"Analyze user query"| Groq[LLM Provider Groq]
    Groq --&gt; |"Tool selection"| Agent
    
    Agent --&gt; |"Search topic='Automotive'"| Tool1[tool: search_reports_by_field]
    Agent --&gt; |"Search 'electric vehicles'"| Tool2[tool: search_reports_by_title_similarity]
    
    Tool1 --&gt; |"Query"| DB[(DuckDB)]
    Tool2 --&gt; |"Vector similarity"| DB
    
    Tool1 --&gt; |"Found 2 reports"| Agent
    Tool2 --&gt; |"Found similar titles"| Agent
    
    Agent --&gt; |"There are 2 reports about EVs:
    1. German EV Market Analysis 2024
    2. EV Adoption in Asia"| User

    %% Apply styles
    class Groq api
    class DB highlight

    %% Links between nodes
    linkStyle default stroke:#64748b,stroke-width:2px
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<section id="database" class="level3">
<h3 class="anchored" data-anchor-id="database">Database</h3>
<p>I’m using <a href="https://duckdb.org">DuckDB</a> to create an in-memory database which will be made available to the agent.</p>
<div id="8332ed09" class="cell" data-execution_count="3">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="annotated-cell-1" style="background: #f1f3f5;"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> duckdb</span>
<span id="annotated-cell-1-2"></span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-1" data-target-annotation="1">1</button><span id="annotated-cell-1-3" class="code-annotation-target">con <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> duckdb.<span class="ex" style="color: null;
background-color: null;
font-style: inherit;">connect</span>()</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code></pre></div></div>
<div class="cell-annotation">
<dl class="code-annotation-container-hidden code-annotation-container-grid">
<dt data-target-cell="annotated-cell-1" data-target-annotation="1">1</dt>
<dd>
<span data-code-cell="annotated-cell-1" data-code-lines="3" data-code-annotation="1">Create a local database. In production you’d want to use a persistent database.</span>
</dd>
</dl>
</div>
</div>
<p>I’ll insert a set of reports into the database. The data included is fictional and was generated by an LLM. The data consists of 40 reports like this:</p>
<div id="1554a29c" class="cell" data-execution_count="4">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> polars <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pl</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> great_tables <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> GT</span>
<span id="cb1-3"></span>
<span id="cb1-4">reports <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pl.read_csv(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"data/reports.csv"</span>)</span>
<span id="cb1-5">GT(reports.head(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>))</span></code></pre></div></div>
<div class="cell-output cell-output-display" data-execution_count="4">
<div id="ylufodktok" style="padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>
#ylufodktok table {
          font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;
          -webkit-font-smoothing: antialiased;
          -moz-osx-font-smoothing: grayscale;
        }

#ylufodktok thead, tbody, tfoot, tr, td, th { border-style: none; }
 tr { background-color: transparent; }
#ylufodktok p { margin: 0; padding: 0; }
 #ylufodktok .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; }
 #ylufodktok .gt_caption { padding-top: 4px; padding-bottom: 4px; }
 #ylufodktok .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; }
 #ylufodktok .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; }
 #ylufodktok .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; }
 #ylufodktok .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; }
 #ylufodktok .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; }
 #ylufodktok .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; }
 #ylufodktok .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; }
 #ylufodktok .gt_column_spanner_outer:first-child { padding-left: 0; }
 #ylufodktok .gt_column_spanner_outer:last-child { padding-right: 0; }
 #ylufodktok .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; }
 #ylufodktok .gt_spanner_row { border-bottom-style: hidden; }
 #ylufodktok .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; }
 #ylufodktok .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; }
 #ylufodktok .gt_from_md> :first-child { margin-top: 0; }
 #ylufodktok .gt_from_md> :last-child { margin-bottom: 0; }
 #ylufodktok .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; }
 #ylufodktok .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; }
 #ylufodktok .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; }
 #ylufodktok .gt_row_group_first td { border-top-width: 2px; }
 #ylufodktok .gt_row_group_first th { border-top-width: 2px; }
 #ylufodktok .gt_striped { background-color: rgba(128,128,128,0.05); }
 #ylufodktok .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; }
 #ylufodktok .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; }
 #ylufodktok .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; text-align: left; }
 #ylufodktok .gt_left { text-align: left; }
 #ylufodktok .gt_center { text-align: center; }
 #ylufodktok .gt_right { text-align: right; font-variant-numeric: tabular-nums; }
 #ylufodktok .gt_font_normal { font-weight: normal; }
 #ylufodktok .gt_font_bold { font-weight: bold; }
 #ylufodktok .gt_font_italic { font-style: italic; }
 #ylufodktok .gt_super { font-size: 65%; }
 #ylufodktok .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; }
 #ylufodktok .gt_asterisk { font-size: 100%; vertical-align: 0; }
 
</style>

<table class="gt_table caption-top table table-sm table-striped small" data-quarto-bootstrap="false">
<thead>
<tr class="gt_col_headings header">
<th id="id" class="gt_col_heading gt_columns_bottom_border gt_right" data-quarto-table-cell-role="th" scope="col">id</th>
<th id="year" class="gt_col_heading gt_columns_bottom_border gt_right" data-quarto-table-cell-role="th" scope="col">year</th>
<th id="institute" class="gt_col_heading gt_columns_bottom_border gt_left" data-quarto-table-cell-role="th" scope="col">institute</th>
<th id="country" class="gt_col_heading gt_columns_bottom_border gt_left" data-quarto-table-cell-role="th" scope="col">country</th>
<th id="topic" class="gt_col_heading gt_columns_bottom_border gt_left" data-quarto-table-cell-role="th" scope="col">topic</th>
<th id="title" class="gt_col_heading gt_columns_bottom_border gt_left" data-quarto-table-cell-role="th" scope="col">title</th>
</tr>
</thead>
<tbody class="gt_table_body">
<tr class="odd">
<td class="gt_row gt_right">1</td>
<td class="gt_row gt_right">2018</td>
<td class="gt_row gt_left">Research DNA GmbH</td>
<td class="gt_row gt_left">Germany</td>
<td class="gt_row gt_left">Automotive</td>
<td class="gt_row gt_left">Global Electric Vehicle Market Outlook 2018-2023</td>
</tr>
<tr class="even">
<td class="gt_row gt_right">2</td>
<td class="gt_row gt_right">2018</td>
<td class="gt_row gt_left">Market Insights Inc.</td>
<td class="gt_row gt_left">USA</td>
<td class="gt_row gt_left">Healthcare</td>
<td class="gt_row gt_left">Digital Health Market Size and Growth Analysis</td>
</tr>
<tr class="odd">
<td class="gt_row gt_right">3</td>
<td class="gt_row gt_right">2018</td>
<td class="gt_row gt_left">Global Trends Research</td>
<td class="gt_row gt_left">UK</td>
<td class="gt_row gt_left">FMCG</td>
<td class="gt_row gt_left">Premium Beauty and Personal Care Market Trends</td>
</tr>
<tr class="even">
<td class="gt_row gt_right">4</td>
<td class="gt_row gt_right">2018</td>
<td class="gt_row gt_left">Data Analytics Group</td>
<td class="gt_row gt_left">Canada</td>
<td class="gt_row gt_left">Electronics</td>
<td class="gt_row gt_left">Smartphone Industry Competitive Analysis</td>
</tr>
<tr class="odd">
<td class="gt_row gt_right">5</td>
<td class="gt_row gt_right">2018</td>
<td class="gt_row gt_left">Innovative Solutions Ltd.</td>
<td class="gt_row gt_left">Australia</td>
<td class="gt_row gt_left">Insurance</td>
<td class="gt_row gt_left">Insurtech Market Landscape and Opportunities</td>
</tr>
</tbody>
</table>


</div>
</div>
</div>
<p>To make the title searchable, I’ll embed it using an <a href="https://platform.openai.com/docs/guides/embeddings">OpenAI embedding endpoint</a>. The result will be stored in a new column with 1536 dimensions.</p>
<div id="56ef65bc" class="cell" data-execution_count="5">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> openai <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> OpenAI</span>
<span id="cb2-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> tqdm <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> tqdm</span>
<span id="cb2-3"></span>
<span id="cb2-4"></span>
<span id="cb2-5"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> embed_text(text: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span>]:</span>
<span id="cb2-6">    client <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> OpenAI()</span>
<span id="cb2-7">    model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"text-embedding-3-small"</span></span>
<span id="cb2-8">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> client.embeddings.create(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">input</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>text, model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>model).data[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].embedding</span>
<span id="cb2-9"></span>
<span id="cb2-10"></span>
<span id="cb2-11">title_embeddings <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [embed_text(title) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> title <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> tqdm(reports[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"title"</span>])]</span>
<span id="cb2-12"></span>
<span id="cb2-13">reports <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> reports.with_columns(</span>
<span id="cb2-14">    pl.Series(</span>
<span id="cb2-15">        name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"title_embedding"</span>,</span>
<span id="cb2-16">        values<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>title_embeddings,</span>
<span id="cb2-17">        dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>pl.Array(inner<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>pl.Float64, shape<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1536</span>),</span>
<span id="cb2-18">    )</span>
<span id="cb2-19">)</span></code></pre></div></div>
</div>
<p>Now, I’ll insert the data including the embeddings into the database. The embeddings are stored in a fixed-size <code>ARRAY</code> column. The co-location of the structured data and the embeddings in the same table is convenient for our use case.</p>
<div id="8f1bb9e3" class="cell" data-execution_count="6">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="annotated-cell-4" style="background: #f1f3f5;"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-4-1">con.execute(</span>
<span id="annotated-cell-4-2">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="annotated-cell-4-3"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    CREATE OR REPLACE TABLE reports AS</span></span>
<span id="annotated-cell-4-4"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    SELECT</span></span>
<span id="annotated-cell-4-5"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        id::integer AS id,</span></span>
<span id="annotated-cell-4-6"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        year::integer AS year,</span></span>
<span id="annotated-cell-4-7"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        institute::varchar AS institute,</span></span>
<span id="annotated-cell-4-8"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        country::varchar AS country,</span></span>
<span id="annotated-cell-4-9"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        topic::varchar AS topic,</span></span>
<span id="annotated-cell-4-10"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        title::varchar AS title,</span></span>
<span id="annotated-cell-4-11"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        title_embedding::float[1536] AS title_embedding</span></span>
<span id="annotated-cell-4-12"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    FROM reports;</span></span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-4" data-target-annotation="1">1</button><span id="annotated-cell-4-13" class="code-annotation-target"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="annotated-cell-4-14">)</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code></pre></div></div>
<div class="cell-annotation">
<dl class="code-annotation-container-hidden code-annotation-container-grid">
<dt data-target-cell="annotated-cell-4" data-target-annotation="1">1</dt>
<dd>
<span data-code-cell="annotated-cell-4" data-code-lines="13" data-code-annotation="1">This works because DuckDB can read from a Polars DataFrame.</span>
</dd>
</dl>
</div>
</div>
<div id="e1503c45" class="cell" data-execution_count="7">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">con.execute(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"INSTALL vss;"</span>)</span>
<span id="cb3-2">con.execute(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"LOAD vss;"</span>)</span>
<span id="cb3-3"></span>
<span id="cb3-4">con.execute(</span>
<span id="cb3-5">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"CREATE INDEX titles_hnsw_index ON reports USING HNSW(title_embedding) WITH (metric='cosine');"</span></span>
<span id="cb3-6">)</span></code></pre></div></div>
</div>
<p>I also create a hierarchical navigable small world (HNSW) index on the title embeddings. This enables approximate nearest neighbor search in O(log n). It’s enabled by the <a href="https://duckdb.org/docs/extensions/vss">vss</a> extension. Note that persistence to disk is experimental, so I wouldn’t recommend it for production yet.</p>
</section>
<section id="agent" class="level3">
<h3 class="anchored" data-anchor-id="agent">Agent</h3>
<p>Let’s set up an agent powered by the <a href="https://groq.com">Groq</a> inference API. It serves a range of open source models. Specifically, I’ll use the <code>llama-3.3-70b-versatile</code> model released by Meta on December 6th. Artificial Analysis has a detailed <a href="https://artificialanalysis.ai/models/llama-3-3-instruct-70b/providers">report</a> showing that it advanced the speed-accuracy trade-off. The model has tool calling capabilities, which are critical for our use case.</p>
<div id="6c615539" class="cell" data-execution_count="8">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="annotated-cell-6" style="background: #f1f3f5;"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-6-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pydantic_ai <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Agent</span>
<span id="annotated-cell-6-2"></span>
<span id="annotated-cell-6-3">agent <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Agent(</span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-6" data-target-annotation="1">1</button><span id="annotated-cell-6-4" class="code-annotation-target">    model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"groq:llama-3.3-70b-versatile"</span>,</span>
<span id="annotated-cell-6-5">    system_prompt<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"You are a market research expert and answer questions using a database of reports."</span>,</span>
<span id="annotated-cell-6-6">)</span>
<span id="annotated-cell-6-7"></span>
<span id="annotated-cell-6-8">result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> agent.run_sync(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Who are you?"</span>)</span>
<span id="annotated-cell-6-9"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(result.data)</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code></pre></div></div>
<div class="cell-annotation">
<dl class="code-annotation-container-hidden code-annotation-container-grid">
<dt data-target-cell="annotated-cell-6" data-target-annotation="1">1</dt>
<dd>
<span data-code-cell="annotated-cell-6" data-code-lines="4" data-code-annotation="1">See the <a href="https://ai.pydantic.dev/api/models/base/#pydantic_ai.models.KnownModelName">KnownModelName</a> documentation for a list of supported models.</span>
</dd>
</dl>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>I am a market research expert, providing insights and analysis based on a vast database of reports and studies. My expertise spans various industries, including consumer goods, technology, healthcare, and finance. I can help answer questions, provide data-driven insights, and offer market trends and analysis to support business decisions.

My database includes reports from reputable sources, such as market research firms, academic institutions, and industry associations. I can access a wide range of topics, including market size and growth, consumer behavior, competitor analysis, and emerging trends.

What specific area of market research would you like to explore?</code></pre>
</div>
</div>
</section>
<section id="tools" class="level3">
<h3 class="anchored" data-anchor-id="tools">Tools</h3>
<p>The agent’s job will be to answer questions based on the reports in the database. It needs a way to access the database. We can give it a tool, meaning a function that it can call, to query the database. First, it needs a database connection.</p>
<div id="1b732c95" class="cell" data-execution_count="9">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="annotated-cell-7" style="background: #f1f3f5;"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-7-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> dataclasses <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> dataclass</span>
<span id="annotated-cell-7-2"></span>
<span id="annotated-cell-7-3"></span>
<span id="annotated-cell-7-4"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@dataclass</span></span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-7" data-target-annotation="1">1</button><span id="annotated-cell-7-5" class="code-annotation-target"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> AgentDependencies:</span>
<span id="annotated-cell-7-6">    db: duckdb.DuckDBPyConnection</span>
<span id="annotated-cell-7-7"></span>
<span id="annotated-cell-7-8"></span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-7" data-target-annotation="2">2</button><span id="annotated-cell-7-9" class="code-annotation-target">deps <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> AgentDependencies(db<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>con)</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code></pre></div></div>
<div class="cell-annotation">
<dl class="code-annotation-container-hidden code-annotation-container-grid">
<dt data-target-cell="annotated-cell-7" data-target-annotation="1">1</dt>
<dd>
<span data-code-cell="annotated-cell-7" data-code-lines="5" data-code-annotation="1">A dataclass that contains dependencies needed by the agent. Additional dependencies can be added as needed.</span>
</dd>
<dt data-target-cell="annotated-cell-7" data-target-annotation="2">2</dt>
<dd>
<span data-code-cell="annotated-cell-7" data-code-lines="9" data-code-annotation="2">This is the connection that has the connection to the in-memory DuckDBdatabase.</span>
</dd>
</dl>
</div>
</div>
<p>Next, let’s give the agent a tool to search the database of reports. Based on the user’s question, it can choose which field to search. The result is always a markdown-formatted table with one row per report.</p>
<div id="4aa0faf3" class="cell" data-execution_count="10">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="annotated-cell-8" style="background: #f1f3f5;"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-8-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> json</span>
<span id="annotated-cell-8-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> typing <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Literal</span>
<span id="annotated-cell-8-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pydantic_ai <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> RunContext</span>
<span id="annotated-cell-8-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pydantic <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> validate_call, Field</span>
<span id="annotated-cell-8-5"></span>
<span id="annotated-cell-8-6"></span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-8" data-target-annotation="1">1</button><span id="annotated-cell-8-7" class="code-annotation-target"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> df_to_str(df: pl.DataFrame) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>:</span>
<span id="annotated-cell-8-8">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> json.dumps(df.to_dicts())</span>
<span id="annotated-cell-8-9"></span>
<span id="annotated-cell-8-10"></span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-8" data-target-annotation="2">2</button><span id="annotated-cell-8-11" class="code-annotation-target"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@agent.tool</span></span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-8" data-target-annotation="3">3</button><span id="annotated-cell-8-12" class="code-annotation-target"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@validate_call</span>(config<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>{<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"arbitrary_types_allowed"</span>: <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>})</span>
<span id="annotated-cell-8-13"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> search_reports_by_field(</span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-8" data-target-annotation="4">4</button><span id="annotated-cell-8-14" class="code-annotation-target">    ctx: RunContext[AgentDependencies],</span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-8" data-target-annotation="5">5</button><span id="annotated-cell-8-15" class="code-annotation-target">    field: Literal[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"id"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"year"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"institute"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"country"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"topic"</span>],</span>
<span id="annotated-cell-8-16">    value: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Field(</span>
<span id="annotated-cell-8-17">        description<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"The value to search for in the field. Case insensitive."</span></span>
<span id="annotated-cell-8-18">    ),</span>
<span id="annotated-cell-8-19">) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>:</span>
<span id="annotated-cell-8-20">    base_query <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="annotated-cell-8-21"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        SELECT id, year, institute, country, topic, title </span></span>
<span id="annotated-cell-8-22"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        FROM reports </span></span>
<span id="annotated-cell-8-23"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        WHERE </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{}</span></span>
<span id="annotated-cell-8-24"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="annotated-cell-8-25"></span>
<span id="annotated-cell-8-26">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> field <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"id"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"year"</span>]:</span>
<span id="annotated-cell-8-27">        value <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(value)</span>
<span id="annotated-cell-8-28">        where_clause <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>field<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> = ?"</span></span>
<span id="annotated-cell-8-29">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="annotated-cell-8-30">        where_clause <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"lower(</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>field<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">) = lower(?)"</span></span>
<span id="annotated-cell-8-31"></span>
<span id="annotated-cell-8-32">    final_query <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> base_query.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">format</span>(where_clause)</span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-8" data-target-annotation="6">6</button><span id="annotated-cell-8-33" class="code-annotation-target">    df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ctx.deps.db.execute(final_query, [value]).pl()</span>
<span id="annotated-cell-8-34"></span>
<span id="annotated-cell-8-35">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> df.shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>:</span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-8" data-target-annotation="7">7</button><span id="annotated-cell-8-36" class="code-annotation-target">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"No reports found. Try a different field or value, or use the title similarity tool."</span></span>
<span id="annotated-cell-8-37">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> df_to_str(df)</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code></pre></div></div>
<div class="cell-annotation">
<dl class="code-annotation-container-hidden code-annotation-container-grid">
<dt data-target-cell="annotated-cell-8" data-target-annotation="1">1</dt>
<dd>
<span data-code-cell="annotated-cell-8" data-code-lines="7" data-code-annotation="1">A record-oriented JSON representation of the data frame is understand by an LLM.</span>
</dd>
<dt data-target-cell="annotated-cell-8" data-target-annotation="2">2</dt>
<dd>
<span data-code-cell="annotated-cell-8" data-code-lines="11" data-code-annotation="2">Use the <code>@agent.tool</code> decorator to register the function as a tool.</span>
</dd>
<dt data-target-cell="annotated-cell-8" data-target-annotation="3">3</dt>
<dd>
<span data-code-cell="annotated-cell-8" data-code-lines="12" data-code-annotation="3">Use the <code>@validate_call</code> decorator to enable type checking of the function arguments. This makes sure that only the fields present in the database can be used. <code>arbitrary_types_allowed</code> is required because the <code>RunContext</code> type is not a standard type.</span>
</dd>
<dt data-target-cell="annotated-cell-8" data-target-annotation="4">4</dt>
<dd>
<span data-code-cell="annotated-cell-8" data-code-lines="14" data-code-annotation="4">The <code>RunContext</code> type hint is required for the tool to access the dependencies.</span>
</dd>
<dt data-target-cell="annotated-cell-8" data-target-annotation="5">5</dt>
<dd>
<span data-code-cell="annotated-cell-8" data-code-lines="15" data-code-annotation="5">Tell the model about the available fields in the database and validate that only those are selected.</span>
</dd>
<dt data-target-cell="annotated-cell-8" data-target-annotation="6">6</dt>
<dd>
<span data-code-cell="annotated-cell-8" data-code-lines="33" data-code-annotation="6">The database query returns a polars DataFrame.</span>
</dd>
<dt data-target-cell="annotated-cell-8" data-target-annotation="7">7</dt>
<dd>
<span data-code-cell="annotated-cell-8" data-code-lines="36" data-code-annotation="7">Provide a clear message if no reports are found and hint that another function (which will be introduced later) can be used for fuzzy matching.</span>
</dd>
</dl>
</div>
</div>
<p>This lets the agent execute searches based on the exact match of a field.</p>
<div id="5f301a90" class="cell" data-execution_count="11">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">deps <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> AgentDependencies(db<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>con)</span>
<span id="cb5-2">result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> agent.run_sync(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Which reports do we have from Germany?"</span>, deps<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>deps)</span>
<span id="cb5-3"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(result.data)</span></code></pre></div></div>
<div class="cell-output cell-output-stdout">
<pre><code>We have four reports from Germany:

1. "Global Electric Vehicle Market Outlook 2018-2023" by Research DNA GmbH (2018) - Automotive topic
2. "Digital Advertising Spend Analysis" by Tech Innovations Ltd. (2020) - Media topic
3. "Beverage Market Competitive Analysis" by Research DNA GmbH (2022) - FMCG topic
4. "Medical Imaging Equipment Market Size" by Tech Innovations Ltd. (2024) - Healthcare topic

Let me know if you'd like more information about any of these reports.</code></pre>
</div>
</div>
<p>It works, the agent found the 4 reports from Germany. Let’s check the exact tool call:</p>
<div id="1e729fc6" class="cell" data-execution_count="12">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1">agent.last_run_messages</span></code></pre></div></div>
<div class="cell-output cell-output-display" data-execution_count="12">
<pre><code>[ModelRequest(parts=[SystemPromptPart(content='You are a market research expert and answer questions using a database of reports.', part_kind='system-prompt'), UserPromptPart(content='Which reports do we have from Germany?', timestamp=datetime.datetime(2024, 12, 18, 17, 38, 58, 663721, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'),
 ModelResponse(parts=[ToolCallPart(tool_name='search_reports_by_field', args=ArgsJson(args_json='{"field": "country", "value": "Germany"}'), tool_call_id='call_be61', part_kind='tool-call')], timestamp=datetime.datetime(2024, 12, 18, 17, 38, 58, tzinfo=datetime.timezone.utc), kind='response'),
 ModelRequest(parts=[ToolReturnPart(tool_name='search_reports_by_field', content='[{"id": 1, "year": 2018, "institute": "Research DNA GmbH", "country": "Germany", "topic": "Automotive", "title": "Global Electric Vehicle Market Outlook 2018-2023"}, {"id": 12, "year": 2020, "institute": "Tech Innovations Ltd.", "country": "Germany", "topic": "Media", "title": "Digital Advertising Spend Analysis"}, {"id": 21, "year": 2022, "institute": "Research DNA GmbH", "country": "Germany", "topic": "FMCG", "title": "Beverage Market Competitive Analysis"}, {"id": 32, "year": 2024, "institute": "Tech Innovations Ltd.", "country": "Germany", "topic": "Healthcare", "title": "Medical Imaging Equipment Market Size"}]', tool_call_id='call_be61', timestamp=datetime.datetime(2024, 12, 18, 17, 38, 59, 27429, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request'),
 ModelResponse(parts=[TextPart(content='We have four reports from Germany:\n\n1. "Global Electric Vehicle Market Outlook 2018-2023" by Research DNA GmbH (2018) - Automotive topic\n2. "Digital Advertising Spend Analysis" by Tech Innovations Ltd. (2020) - Media topic\n3. "Beverage Market Competitive Analysis" by Research DNA GmbH (2022) - FMCG topic\n4. "Medical Imaging Equipment Market Size" by Tech Innovations Ltd. (2024) - Healthcare topic\n\nLet me know if you\'d like more information about any of these reports.', part_kind='text')], timestamp=datetime.datetime(2024, 12, 18, 17, 38, 59, tzinfo=datetime.timezone.utc), kind='response')]</code></pre>
</div>
</div>
<p>Here, the model correctly translated the user’s question into the tool call with the arguments <code>{"field": "country", "value": "Germany"}</code>.</p>
<p>To make it easier to evaluate the agent’s output and also make its results useable by other tools, we can create a response model that includes the ids of the identified reports.</p>
<div id="9dc4de41" class="cell" data-execution_count="13">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="annotated-cell-11" style="background: #f1f3f5;"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-11-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pydantic <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> BaseModel</span>
<span id="annotated-cell-11-2"></span>
<span id="annotated-cell-11-3"></span>
<span id="annotated-cell-11-4"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> AgentResponse(BaseModel):</span>
<span id="annotated-cell-11-5">    text: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Field(</span>
<span id="annotated-cell-11-6">        description<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Answer to the user's question in informal language. Don't include the report ids."</span></span>
<span id="annotated-cell-11-7">    )</span>
<span id="annotated-cell-11-8">    relevant_report_ids: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">set</span>[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Field(</span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-11" data-target-annotation="1">1</button><span id="annotated-cell-11-9" class="code-annotation-target">        description<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Set of 'id' integer values of the reports that are relevant to the user's question. Only include ids retrieved by the search tools. Never make up ids. Not all ids returned by the search tools are relevant."</span></span>
<span id="annotated-cell-11-10">    )</span>
<span id="annotated-cell-11-11"></span>
<span id="annotated-cell-11-12"></span>
<span id="annotated-cell-11-13">typed_agent <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Agent(</span>
<span id="annotated-cell-11-14">    model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"groq:llama-3.3-70b-versatile"</span>,</span>
<span id="annotated-cell-11-15">    system_prompt<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"You are a market research expert and answer questions using a database of reports."</span>,</span>
<span id="annotated-cell-11-16">    result_type<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>AgentResponse,</span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-11" data-target-annotation="2">2</button><span id="annotated-cell-11-17" class="code-annotation-target">    result_retries<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>,</span>
<span id="annotated-cell-11-18">)</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code></pre></div></div>
<div class="cell-annotation">
<dl class="code-annotation-container-hidden code-annotation-container-grid">
<dt data-target-cell="annotated-cell-11" data-target-annotation="1">1</dt>
<dd>
<span data-code-cell="annotated-cell-11" data-code-lines="9" data-code-annotation="1">This description fixes a common mistake: the LLM would answer with made up ids like 123, 456 when it didn’t find any reports.</span>
</dd>
<dt data-target-cell="annotated-cell-11" data-target-annotation="2">2</dt>
<dd>
<span data-code-cell="annotated-cell-11" data-code-lines="17" data-code-annotation="2">Give the agent a chance to retry if it doesn’t return a valid structured output on the first try.</span>
</dd>
</dl>
</div>
</div>
<p>The <code>AgentResponse</code> model is used to validate the agent’s output. It will always include a set of integer ids. In an app, these could be used to provide links to the reports.</p>
<div id="837e1955" class="cell" data-execution_count="15">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1">result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> typed_agent.run_sync(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Which reports do we have from Germany? Tell me their titles and ids"</span>, deps<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>deps)</span>
<span id="cb9-2"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(result.data)</span></code></pre></div></div>
<div class="cell-output cell-output-stdout">
<pre><code>text='The reports from Germany are titled Global Electric Vehicle Market Outlook 2018-2023, Digital Advertising Spend Analysis, Beverage Market Competitive Analysis and Medical Imaging Equipment Market Size.' relevant_report_ids={32, 1, 12, 21}</code></pre>
</div>
</div>
<p>Now we have an agent that returns a type-checked structured response. Note that I’ve omitted the re-registration of the tool to the new agent instance for brevity.</p>
<p>However, requests may not exactly match the fields in the database, so let’s also add the ability to search for similar titles.</p>
<div id="c0d28b41" class="cell" data-execution_count="16">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="annotated-cell-13" style="background: #f1f3f5;"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-13-1"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@typed_agent.tool</span></span>
<span id="annotated-cell-13-2"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@validate_call</span>(config<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>{<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"arbitrary_types_allowed"</span>: <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>})</span>
<span id="annotated-cell-13-3"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> search_reports_by_title_similarity(</span>
<span id="annotated-cell-13-4">    ctx: RunContext[AgentDependencies],</span>
<span id="annotated-cell-13-5">    title: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Field(</span>
<span id="annotated-cell-13-6">        description<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"The title of the report to search for with vector similarity."</span></span>
<span id="annotated-cell-13-7">    ),</span>
<span id="annotated-cell-13-8">) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>:</span>
<span id="annotated-cell-13-9">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Embed the title given by the user</span></span>
<span id="annotated-cell-13-10">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">try</span>:</span>
<span id="annotated-cell-13-11">        title_embedding <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> embed_text(title)</span>
<span id="annotated-cell-13-12">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">except</span> <span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">Exception</span> <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> e:</span>
<span id="annotated-cell-13-13">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Error embedding title: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>e<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span></span>
<span id="annotated-cell-13-14"></span>
<span id="annotated-cell-13-15">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Search for similar titles</span></span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-13" data-target-annotation="1">1</button><span id="annotated-cell-13-16" class="code-annotation-target">    title_embedding_str <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"["</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">","</span>.join(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">map</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>, title_embedding)) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"]"</span></span>
<span id="annotated-cell-13-17">    query <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="annotated-cell-13-18"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        SELECT id, year, institute, country, topic, title</span></span>
<span id="annotated-cell-13-19"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        FROM reports</span></span>
<span id="annotated-cell-13-20"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        ORDER BY array_distance(title_embedding, ?::FLOAT[1536])  </span></span>
<span id="annotated-cell-13-21"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        LIMIT 5;</span></span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-13" data-target-annotation="2">2</button><span id="annotated-cell-13-22" class="code-annotation-target"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="annotated-cell-13-23">    df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ctx.deps.db.execute(query, [title_embedding_str]).pl()</span>
<span id="annotated-cell-13-24"></span>
<span id="annotated-cell-13-25">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> (</span>
<span id="annotated-cell-13-26">        df_to_str(df)</span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-13" data-target-annotation="3">3</button><span id="annotated-cell-13-27" class="code-annotation-target">        <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;"> These reports have titles similar to the query, but may not be relevant to the user's question."</span></span>
<span id="annotated-cell-13-28">    )</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code></pre></div></div>
<div class="cell-annotation">
<dl class="code-annotation-container-hidden code-annotation-container-grid">
<dt data-target-cell="annotated-cell-13" data-target-annotation="1">1</dt>
<dd>
<span data-code-cell="annotated-cell-13" data-code-lines="16" data-code-annotation="1">The title is embedded and formatted as a DuckDB array.</span>
</dd>
<dt data-target-cell="annotated-cell-13" data-target-annotation="2">2</dt>
<dd>
<span data-code-cell="annotated-cell-13" data-code-lines="22" data-code-annotation="2">The <code>array_distance</code> function computes the cosine similarity between the query embedding and the title embeddings in the database.</span>
</dd>
<dt data-target-cell="annotated-cell-13" data-target-annotation="3">3</dt>
<dd>
<span data-code-cell="annotated-cell-13" data-code-lines="27" data-code-annotation="3">The note about relevance is added to make it clear that these are just the most similar, not necessarily relevant. Otherwise the agent would return all reports with similar titles.</span>
</dd>
</dl>
</div>
</div>
<p>Let’s ask the agent about a topic that is not in the database to see how it uses the title similarity tool.</p>
<div id="2b25b6e8" class="cell" data-execution_count="17">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1">result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> agent.run_sync(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Do we have reports about quantum computing?"</span>, deps<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>deps)</span>
<span id="cb11-2"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(result.data)</span></code></pre></div></div>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;function=search_reports_by_field {"field": "topic", "value": "quantum computing"}&lt;/function&gt;</code></pre>
</div>
</div>
<p>That worked as expected.</p>
</section>
</section>
<section id="evals" class="level2">
<h2 class="anchored" data-anchor-id="evals">Evals</h2>
<p>Automated evaluations are necessary to ensure that an agent is working as expected, and to switch out models, prompts and tools without breaking the app. PydanticAI offers <a href="https://ai.pydantic.dev/testing-evals/">tools</a> for testing the code (without running a model) and for evaluations. Let’s set up a simple evaluation that checks whether the agent correctly answers questions about the database. We measure the precision (how many of the results found are relevant) and recall (how many of the relevant results are found).</p>
<div id="2d105a1d" class="cell" data-execution_count="18">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1">examples <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [</span>
<span id="cb13-2">    {</span>
<span id="cb13-3">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"question"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"How many reports do we have from Germany?"</span>,</span>
<span id="cb13-4">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"relevant_report_ids"</span>: {<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">21</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">32</span>},</span>
<span id="cb13-5">    },</span>
<span id="cb13-6">    {</span>
<span id="cb13-7">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"question"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"For which countries to we have reports mentioning electric vehicles?"</span>,</span>
<span id="cb13-8">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"relevant_report_ids"</span>: {<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">25</span>},</span>
<span id="cb13-9">    },</span>
<span id="cb13-10">    {</span>
<span id="cb13-11">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"question"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"What reports do we have about the gaming industry?"</span>,</span>
<span id="cb13-12">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"relevant_report_ids"</span>: {<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">22</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">30</span>},</span>
<span id="cb13-13">    },</span>
<span id="cb13-14">    {</span>
<span id="cb13-15">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"question"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"What reports do we have about the pet care industry?"</span>,</span>
<span id="cb13-16">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"relevant_report_ids"</span>: {<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">27</span>},</span>
<span id="cb13-17">    },</span>
<span id="cb13-18">    {</span>
<span id="cb13-19">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"question"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Which reports discuss cyber security insurance?"</span>,</span>
<span id="cb13-20">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"relevant_report_ids"</span>: {<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">29</span>},</span>
<span id="cb13-21">    },</span>
<span id="cb13-22">    {</span>
<span id="cb13-23">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"question"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"What healthcare reports were published in 2024?"</span>,</span>
<span id="cb13-24">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"relevant_report_ids"</span>: {<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">32</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">38</span>},</span>
<span id="cb13-25">    },</span>
<span id="cb13-26">    {</span>
<span id="cb13-27">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"question"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Which reports are about the smartphone or mobile phone market?"</span>,</span>
<span id="cb13-28">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"relevant_report_ids"</span>: {<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">40</span>},</span>
<span id="cb13-29">    },</span>
<span id="cb13-30">    {</span>
<span id="cb13-31">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"question"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"What reports do we have from Market Insights Inc.?"</span>,</span>
<span id="cb13-32">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"relevant_report_ids"</span>: {<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">22</span>},</span>
<span id="cb13-33">    },</span>
<span id="cb13-34">]</span></code></pre></div></div>
</div>
<div id="3db50b93" class="cell" data-execution_count="19">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="annotated-cell-16" style="background: #f1f3f5;"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-16-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> collections <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Counter</span>
<span id="annotated-cell-16-2"></span>
<span id="annotated-cell-16-3"></span>
<span id="annotated-cell-16-4"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> eval_example(</span>
<span id="annotated-cell-16-5">    example: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">dict</span>[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">|</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">set</span>[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>]], print_errors: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">bool</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span></span>
<span id="annotated-cell-16-6">) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">dict</span>[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>]:</span>
<span id="annotated-cell-16-7">    result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> typed_agent.run_sync(example[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"question"</span>], deps<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>deps)</span>
<span id="annotated-cell-16-8">    act, exp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> result.data.relevant_report_ids, example[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"relevant_report_ids"</span>]</span>
<span id="annotated-cell-16-9">    metrics <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Counter(</span>
<span id="annotated-cell-16-10">        {</span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-16" data-target-annotation="1">1</button><span id="annotated-cell-16-11" class="code-annotation-target">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"tp"</span>: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(act <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&amp;</span> exp),</span>
<span id="annotated-cell-16-12">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"fp"</span>: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(act <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> exp),</span>
<span id="annotated-cell-16-13">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"fn"</span>: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(exp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> act),</span>
<span id="annotated-cell-16-14">        }</span>
<span id="annotated-cell-16-15">    )</span>
<span id="annotated-cell-16-16"></span>
<span id="annotated-cell-16-17">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> print_errors <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">and</span> (metrics[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"fp"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">or</span> metrics[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"fn"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>):</span>
<span id="annotated-cell-16-18">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Error in evaluation:"</span>)</span>
<span id="annotated-cell-16-19">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"  Question: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>example[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'question'</span>]<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="annotated-cell-16-20">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"  Found: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>act<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="annotated-cell-16-21">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"  Expected: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>exp<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="annotated-cell-16-22"></span>
<span id="annotated-cell-16-23">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> metrics</span>
<span id="annotated-cell-16-24"></span>
<span id="annotated-cell-16-25"></span>
<span id="annotated-cell-16-26">metric_totals <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Counter()</span>
<span id="annotated-cell-16-27"></span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-16" data-target-annotation="2">2</button><span id="annotated-cell-16-28" class="code-annotation-target"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> example <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> tqdm(examples):</span>
<span id="annotated-cell-16-29">    metrics <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> eval_example(example)</span>
<span id="annotated-cell-16-30">    metric_totals <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> metrics</span>
<span id="annotated-cell-16-31"></span>
<span id="annotated-cell-16-32">precision <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> metric_totals[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"tp"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> (metric_totals[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"tp"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> metric_totals[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"fp"</span>])</span>
<span id="annotated-cell-16-33">recall <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> metric_totals[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"tp"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> (metric_totals[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"tp"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> metric_totals[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"fn"</span>])</span>
<span id="annotated-cell-16-34"></span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-16" data-target-annotation="3">3</button><span id="annotated-cell-16-35" class="code-annotation-target"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Precision: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>precision<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.2f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">, Recall: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>recall<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.2f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code></pre></div></div>
<div class="cell-annotation">
<dl class="code-annotation-container-hidden code-annotation-container-grid">
<dt data-target-cell="annotated-cell-16" data-target-annotation="1">1</dt>
<dd>
<span data-code-cell="annotated-cell-16" data-code-lines="11" data-code-annotation="1">Use set operations to compare the expected and found ids.</span>
</dd>
<dt data-target-cell="annotated-cell-16" data-target-annotation="2">2</dt>
<dd>
<span data-code-cell="annotated-cell-16" data-code-lines="28" data-code-annotation="2">This should be parallelized if the number of examples is large.</span>
</dd>
<dt data-target-cell="annotated-cell-16" data-target-annotation="3">3</dt>
<dd>
<span data-code-cell="annotated-cell-16" data-code-lines="35" data-code-annotation="3">Precision and recall could also be combined into the F1 score, which is their harmonic mean.</span>
</dd>
</dl>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>  0%|          | 0/8 [00:00&lt;?, ?it/s] 12%|█▎        | 1/8 [00:00&lt;00:05,  1.19it/s] 25%|██▌       | 2/8 [00:07&lt;00:24,  4.02s/it] 38%|███▊      | 3/8 [00:18&lt;00:37,  7.43s/it] 50%|█████     | 4/8 [00:34&lt;00:43, 10.85s/it] 62%|██████▎   | 5/8 [00:50&lt;00:37, 12.51s/it] 75%|███████▌  | 6/8 [01:05&lt;00:26, 13.41s/it] 88%|████████▊ | 7/8 [01:27&lt;00:16, 16.16s/it]100%|██████████| 8/8 [01:39&lt;00:00, 14.97s/it]100%|██████████| 8/8 [01:39&lt;00:00, 12.44s/it]</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Precision: 1.00, Recall: 0.62</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code></code></pre>
</div>
</div>
<p>This is a joint evaluation of the agent, the tools and the database. What’s missing is an evaluation of the generated text. In a real RAG system, you’d also want separate evaluations of retrieval and result ranking.</p>
</section>
<section id="discussion" class="level2">
<h2 class="anchored" data-anchor-id="discussion">Discussion</h2>
<section id="comparison-to-other-libraries" class="level3">
<h3 class="anchored" data-anchor-id="comparison-to-other-libraries">Comparison to other libraries</h3>
<p>PydanticAI is a late entrant to the agent framework space. It joins several established libraries including:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Library</th>
<th>Description</th>
<th style="text-align: right;">Github Stars ⭐</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><a href="https://github.com/Significant-Gravitas/AutoGPT">AutoGPT</a></td>
<td>AI automation platform with frontend, server and monitoring</td>
<td style="text-align: right;">169k</td>
</tr>
<tr class="even">
<td><a href="https://github.com/langchain-ai/langchain">LangChain</a></td>
<td>Package ecosystem for LLM applications</td>
<td style="text-align: right;">96k</td>
</tr>
<tr class="odd">
<td><a href="https://github.com/microsoft/autogen">autogen</a></td>
<td>Multi-agent AI chat framework by Microsoft</td>
<td style="text-align: right;">36k</td>
</tr>
<tr class="even">
<td><a href="https://github.com/crewAIInc/crewai">crewAI</a></td>
<td>Framework for orchestrating role-based AI agents</td>
<td style="text-align: right;">22k</td>
</tr>
<tr class="odd">
<td><a href="https://github.com/openai/swarm">swarm</a></td>
<td>Educational framework for multi-agent apps by OpenAI</td>
<td style="text-align: right;">17k</td>
</tr>
<tr class="even">
<td><a href="https://github.com/phidatahq/phidata">phidata</a></td>
<td>Multi-agent backend and chat frontend</td>
<td style="text-align: right;">16k</td>
</tr>
</tbody>
</table>
<p>There are dozens of other libraries with fewer stars. In addition, there are libraries specialized for RAG like <a href="https://github.com/run-llama/llama_index">LlamaIndex</a> and <a href="https://github.com/deepset-ai/haystack">Haystack</a>. The competition landscape doesn’t show signs of consolidation or slowing down.</p>
</section>
<section id="development-team" class="level3">
<h3 class="anchored" data-anchor-id="development-team">Development team</h3>
<p>Pydantic Services, the company behind Pydantic, has raised a $12.5m <a href="https://www.crunchbase.com/funding_round/pydantic-services-series-a--ddd115fb">Series A</a> in October 2024. This is great news for the project: funding pays for full time developers. It also raises the question of how Pydantic will make money, and the answer to that is Logfire subscriptions. This is a good model that gives long-term stability to the project and follows the lead of LangChain with its commercial product, <a href="https://www.langchain.com/langsmith">LangSmith</a>. I just hope that the integration remains optional. While Logfire looks great, my team already uses <a href="https://wandb.ai/site/weave/">Weave</a> by Weights &amp; Biases, and having to switch would be a barrier to adopting PydanticAI.</p>
</section>
<section id="review" class="level3">
<h3 class="anchored" data-anchor-id="review">Review</h3>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Pros ✅</strong></p>
<ul>
<li>Sensible abstractions that don’t get in the way and enable coding in a Pythonic style.</li>
<li>Type safety and integration with Pydantic.</li>
<li>Support for streaming responses and async tool calling. This is critical for live chat applications.</li>
<li>Pydantic is familiar to many Python developers who will have an easier time learning PydanticAI.</li>
<li>High quality documentation and examples that also cover tests and evals.</li>
<li>Strong reputation of the Pydantic team and high responsiveness in Github issues.</li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>Cons ❌</strong></p>
<ul>
<li>Launches into a competitive market with many established libraries.</li>
<li>Early stage of development, so expect breaking changes.</li>
<li>Many concepts to learn, but mild compared to langchain which invented its own domain-specific language LCEL.</li>
<li>No support for multimodal (image, audio, video) inputs and out yet, but it’s <a href="https://github.com/pydantic/pydantic-ai/issues/126">planned</a>.</li>
<li>Economic incentives to lock users into Logfire. This hasn’t happened but is a risk.</li>
</ul>
</div>
</div>
<p>I’m looking forward to an opportunity to build a full-scale application with PydanticAI. The best place to get started is the <a href="https://ai.pydantic.dev/">PydanticAI documentation</a>.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Not every app needs an agent framework
</div>
</div>
<div class="callout-body-container callout-body">
<p>A lot can be accomplished by single API calls or by specifying a fixed sequence of calls. That would also work for the example app shown in this article. Unless you truly need the flexibility of an agent framework, you may be better off with plain Python. If all you need is Pydantic + LLM calls, you can use <a href="https://github.com/jxnl/instructor">instructor</a>. <a href="https://openai.com/index/introducing-structured-outputs-in-the-api/">OpenAI</a> even supports structured outputs based on Pydantic models without an additional library.</p>
</div>
</div>
<hr>
<p>Preview photo by <a href="https://unsplash.com/@magicpattern?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">MagicPattern</a> on <a href="https://unsplash.com/photos/purple-and-black-polka-dot-textile-eHH_5rn3xnU?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Unsplash</a></p>


</section>
</section>

 ]]></description>
  <category>Machine Learning</category>
  <category>Python</category>
  <guid>https://simmering.dev/blog/pydantic-ai/</guid>
  <pubDate>Sun, 15 Dec 2024 23:00:00 GMT</pubDate>
  <media:content url="https://simmering.dev/blog/pydantic-ai/image.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Constrained by Context, Not Reasoning</title>
  <dc:creator>Paul Simmering</dc:creator>
  <link>https://simmering.dev/blog/context-constrained/</link>
  <description><![CDATA[ 






<p>Frontier LLMs rarely give completely wrong answers. Even when their responses aren’t exactly what we need, they’re usually logical given the information provided.</p>
<p>Recent advances in chain-of-thought reasoning, such as in models like <a href="https://openai.com/index/learning-to-reason-with-llms/">OpenAI’s o1</a> and <a href="https://www.alibabacloud.com/blog/alibaba-cloud-unveils-open-source-ai-reasoning-model-qwq-and-new-image-editing-tool_601813">Alibaba’s QwQ</a>, have led to remarkable achievements. These models now outperform most humans on complex tasks like competition mathematics (AIME 2024) and PhD-level science questions (GPQA Diamond).</p>
<p>Yet here’s the paradox: despite this impressive reasoning capability, LLMs often struggle to provide immediately useful outputs for everyday professional tasks. Usually, their output has to be edited or the prompt rewritten multiple times to produce a copy-pasteable result. This leads to my thesis: <strong>The real-world effectiveness of LLMs is now limited more by their awareness of context than by their reasoning capabilities</strong>.</p>
<p>Think of an LLM as a brilliant but newly hired colleague who hasn’t been properly onboarded. While they can tackle complex problems, they miss crucial contextual details required to fit their work into the existing workflows. The challenge isn’t their intelligence—it’s their need for situational awareness.</p>
<section id="context-makes-outputs-more-useful" class="level2">
<h2 class="anchored" data-anchor-id="context-makes-outputs-more-useful">Context makes outputs more useful</h2>
<p>Here are some examples of how adding context lets LLMs produce outputs that are more readily applicable:</p>
<ul>
<li>When summarizing a technical document, telling the model “This is for marketing executives who need to understand the business implications” yields very different (and more useful) results than just asking for a summary</li>
<li>For educational content, specifying “Explain this for a high school student” versus “Explain this for a graduate student” completely changes the depth and terminology used</li>
<li>In correspondence, sharing details like “This is for a long-time client who prefers informal communication” helps create more appropriately-toned messages For social media, providing examples of past successful posts or a company style guide helps the model match the preferred tone</li>
<li>In software development, showing the model your existing codebase helps it suggest solutions that integrate seamlessly with your architecture</li>
<li>During translation work, specifying “This is medical documentation” versus “This is marketing material” ensures appropriate terminology and tone</li>
</ul>
</section>
<section id="infusing-context-actively-and-passively" class="level2">
<h2 class="anchored" data-anchor-id="infusing-context-actively-and-passively">Infusing context actively and passively</h2>
<p>It’s tedious to write a detailed briefing each time, just like you wouldn’t want to repeat onboarding of a colleague. Here are ways to reuse prompts or passively infuse context:</p>
<ul>
<li>Write a persistent system prompt that’s automatically applied to all conversations. In ChatGPT, you can do this by creating a custom GPT.</li>
<li>Enable chat history to be able to copy-paste successful prompts into new conversations.</li>
<li>Turn on features that let the model learn from past interactions (if not dealing with sensitive data).</li>
<li>When writing in an editor enhanced by AI, prefer one long document over spreading content across many shorter documents.</li>
<li>Work with developer tools like GitHub Copilot or Cursor that read your code base rather than copy-pasting snippets into a separate chat window. This also works for non-coding tasks, such as writing articles.</li>
<li>Use dictation to speak your prompt effortlessly. Speak about the situation and the task in a stream of consciousness.</li>
<li>Share your screen with an assistant. This <a href="https://beebom.com/how-you-can-try-google-project-astra-stream-realtime/">feature</a> was added to Google Gemini in December 2024. While my experience testing it was mixed, I think this could become an effective way to continuously share context. It makes most sense with apps that don’t have their own built-in assistant.</li>
</ul>
<hr>
<p>Preview photo by <a href="https://unsplash.com/@magicpattern?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">MagicPattern</a> on <a href="https://unsplash.com/photos/purple-and-pink-letter-blocks-jbywvpa9vH8?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Unsplash</a></p>


</section>

 ]]></description>
  <category>Productivity</category>
  <category>Machine Learning</category>
  <guid>https://simmering.dev/blog/context-constrained/</guid>
  <pubDate>Fri, 13 Dec 2024 23:00:00 GMT</pubDate>
  <media:content url="https://simmering.dev/blog/context-constrained/image.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Aspect-based Sentiment Analysis with DSPy</title>
  <dc:creator>Paul Simmering</dc:creator>
  <link>https://simmering.dev/blog/absa-with-dspy/</link>
  <description><![CDATA[ 






<p>Last year, my colleague Paavo Huoviala and I explored prompting and fine-tuning large language models for aspect-based sentiment analysis (ABSA) <span class="citation" data-cites="simmering2023large">(Simmering and Huoviala 2023)</span>. Like many researchers at the time, we spent considerable effort manually crafting prompts and selecting few-shot examples. But what if we could automate this process? Enter DSPy - a Python library that automatically optimizes LLM prompts. In this article, I’ll revisit our ABSA experiments using DSPy’s automated approach instead of manual prompt engineering.</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Resource</th>
<th>Link</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>💻 Code</td>
<td><a href="https://github.com/psimm/website/blob/master/blog/absa-with-dspy/index.qmd">GitHub</a></td>
</tr>
<tr class="even">
<td>📊 Experiments</td>
<td><a href="https://wandb.ai/psimm/absa-dspy">Weights &amp; Biases project</a></td>
</tr>
<tr class="odd">
<td>📝 Dataset</td>
<td><a href="https://huggingface.co/datasets/psimm/absa-semeval2014-alpaca">Hugging Face Hub</a></td>
</tr>
</tbody>
</table>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>DSPy version 2.5.32
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>DSPy is in rapid development. I’ve encountered outdated tutorials, dead links in the documentation and deprecation warnings. The code of this article may not work with future versions.</p>
</div>
</div>
</div>
<section id="dspy-programming-not-prompting-llms" class="level2">
<h2 class="anchored" data-anchor-id="dspy-programming-not-prompting-llms">DSPy: Programming — not prompting — LLMs</h2>
<p><img src="https://simmering.dev/blog/absa-with-dspy/dspy_logo.webp" class="img-fluid" style="width:50.0%"></p>
<p><a href="https://dspy.ai">DSPy</a> is a Python library developed by Stanford NLP. Rather than manually crafting prompts and seeing them break whenever something changes elsewhere in the pipeline, DSPy automates the process of finding the optimal prompts. The documentation has an <a href="https://dspy.ai/learn/">overview</a> of the main building blocks of the library. In this article, I’ll introduce the elements needed to optimize a structured prediction task, using ABSA as an example.</p>
<section id="experiment-setup" class="level3">
<h3 class="anchored" data-anchor-id="experiment-setup">Experiment setup</h3>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">%%{init: {
  'theme': 'base',
  'themeVariables': {
    'primaryColor': '#ffffff',
    'primaryTextColor': '#2d3748',
    'primaryBorderColor': '#90cdf4',
    'lineColor': '#64748b',
    'secondaryColor': '#ffffff',
    'tertiaryColor': '#ffffff',
    'fontSize': '22px',
    'labelFontSize': '18px',
    'edgeLabelFontSize': '18px'
  }
}}%%
graph TB
    %% Define styles
    classDef default fill:#ffffff,stroke:#90cdf4,stroke-width:2px
    classDef highlight fill:#fdf2f8,stroke:#ed64a6,stroke-width:3px
    classDef api fill:#ffffff,stroke:#4fd1c5,stroke-width:2px
    
    subgraph Data ["1️⃣ Data"]
        D1[SemEval Dataset] --&gt; |"Transform"| D2[DSPy Examples]
    end
    
    subgraph Definition ["2️⃣ Model Definition"]
        M2[Pydantic Models] --&gt; |"Define Structure"| M1[DSPy Signature]
        M1 --&gt; |"Initialize"| M3[Predictor]
        M4[Language Models] --&gt; |"Power"| M3
        A1[OpenAI API] --&gt; |"Provide"| M4
        A2[Fireworks.ai API] --&gt; |"Provide"| M4
    end
    
    subgraph Optimization ["3️⃣ Optimization"]
        O1[Evaluation Function] --&gt; |"Guide"| O2[MIPROv2 Optimizer]
        M3 --&gt; |"Optimize"| O2
        D2 --&gt; |"Train"| O2
        O2 --&gt; |"Output"| O3[Optimized Predictor]
    end
    
    subgraph Evaluation ["4️⃣ Evaluation"]
        O3 --&gt; |"Test"| E1[Test Set Evaluation]
        O1 --&gt; |"Measure"| E1
        E1 --&gt; |"Log"| E2[Weights &amp; Biases]
    end

    %% Apply styles
    class O2 highlight
    class A1,A2,E2 api
    
    %% Links between subgraphs
    linkStyle default stroke:#64748b,stroke-width:2px
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<p>The steps will be explained in the following sections.</p>
</section>
</section>
<section id="dataset-for-aspect-based-sentiment-analysis" class="level2">
<h2 class="anchored" data-anchor-id="dataset-for-aspect-based-sentiment-analysis">Dataset for Aspect-based Sentiment Analysis</h2>
<p>The goal of ABSA is to analyze a review and extract the discussed aspects of a product or service and the sentiment towards each aspect. For example, the review “The pizza was great, but the service was terrible” contains two aspects: “pizza” (positive) and “service” (negative). There are more advanced variants of ABSA, but for this article I’ll focus on the basic task. I will also let a single model handle the extraction and the classification.</p>
<section id="semeval-2014-task-4" class="level3">
<h3 class="anchored" data-anchor-id="semeval-2014-task-4">SemEval 2014 Task 4</h3>
<p>I’m using the SemEval 2014 Task 4 dataset by <span class="citation" data-cites="pontiki_semeval">Pontiki et al. (2014)</span>. The <a href="https://huggingface.co/datasets/psimm/absa-semeval2014-alpaca">dataset</a> is available on Hugging Face. This is a cleaned version of the original XML files consisting of train and test splits. The small number of examples with the “conflict” label are excluded, as is common in the literature.</p>
<div id="c9a578ab" class="cell" data-execution_count="1">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> polars <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pl</span>
<span id="cb1-2"></span>
<span id="cb1-3">url <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"hf://datasets/psimm/absa-semeval2014-alpaca"</span></span>
<span id="cb1-4"></span>
<span id="cb1-5">train <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pl.read_parquet(url <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"/data/train-00000-of-00001.parquet"</span>)</span>
<span id="cb1-6">test <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pl.read_parquet(url <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"/data/test-00000-of-00001.parquet"</span>)</span></code></pre></div></div>
</div>
<div id="b21443cd" class="cell" data-execution_count="2">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> great_tables <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> GT</span>
<span id="cb2-2"></span>
<span id="cb2-3">overview <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (</span>
<span id="cb2-4">    train.vstack(test)</span>
<span id="cb2-5">    .group_by([<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"split"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"domain"</span>])</span>
<span id="cb2-6">    .agg(examples<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>pl.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>())</span>
<span id="cb2-7">    .sort(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"split"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"domain"</span>, descending<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb2-8">)</span>
<span id="cb2-9">GT(overview).tab_header(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"SemEval 2014 Task 4 Dataset"</span>).cols_label(</span>
<span id="cb2-10">    split<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Split"</span>,</span>
<span id="cb2-11">    domain<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Domain"</span>,</span>
<span id="cb2-12">    examples<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Examples"</span>,</span>
<span id="cb2-13">).cols_align(align<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"right"</span>, columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"examples"</span>])</span></code></pre></div></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="2">
<div id="oykrqaoiln" style="padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>
#oykrqaoiln table {
          font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;
          -webkit-font-smoothing: antialiased;
          -moz-osx-font-smoothing: grayscale;
        }

#oykrqaoiln thead, tbody, tfoot, tr, td, th { border-style: none; }
 tr { background-color: transparent; }
#oykrqaoiln p { margin: 0; padding: 0; }
 #oykrqaoiln .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; }
 #oykrqaoiln .gt_caption { padding-top: 4px; padding-bottom: 4px; }
 #oykrqaoiln .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; }
 #oykrqaoiln .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; }
 #oykrqaoiln .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; }
 #oykrqaoiln .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; }
 #oykrqaoiln .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; }
 #oykrqaoiln .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; }
 #oykrqaoiln .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; }
 #oykrqaoiln .gt_column_spanner_outer:first-child { padding-left: 0; }
 #oykrqaoiln .gt_column_spanner_outer:last-child { padding-right: 0; }
 #oykrqaoiln .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; }
 #oykrqaoiln .gt_spanner_row { border-bottom-style: hidden; }
 #oykrqaoiln .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; }
 #oykrqaoiln .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; }
 #oykrqaoiln .gt_from_md> :first-child { margin-top: 0; }
 #oykrqaoiln .gt_from_md> :last-child { margin-bottom: 0; }
 #oykrqaoiln .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; }
 #oykrqaoiln .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; }
 #oykrqaoiln .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; }
 #oykrqaoiln .gt_row_group_first td { border-top-width: 2px; }
 #oykrqaoiln .gt_row_group_first th { border-top-width: 2px; }
 #oykrqaoiln .gt_striped { background-color: rgba(128,128,128,0.05); }
 #oykrqaoiln .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; }
 #oykrqaoiln .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; }
 #oykrqaoiln .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; text-align: left; }
 #oykrqaoiln .gt_left { text-align: left; }
 #oykrqaoiln .gt_center { text-align: center; }
 #oykrqaoiln .gt_right { text-align: right; font-variant-numeric: tabular-nums; }
 #oykrqaoiln .gt_font_normal { font-weight: normal; }
 #oykrqaoiln .gt_font_bold { font-weight: bold; }
 #oykrqaoiln .gt_font_italic { font-style: italic; }
 #oykrqaoiln .gt_super { font-size: 65%; }
 #oykrqaoiln .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; }
 #oykrqaoiln .gt_asterisk { font-size: 100%; vertical-align: 0; }
 
</style>

<table class="gt_table caption-top table table-sm table-striped small" data-quarto-bootstrap="false">
<thead>
<tr class="gt_heading header">
<td colspan="3" class="gt_heading gt_title gt_font_normal">SemEval 2014 Task 4 Dataset</td>
</tr>
<tr class="gt_col_headings even">
<th id="Split" class="gt_col_heading gt_columns_bottom_border gt_left" data-quarto-table-cell-role="th" scope="col">Split</th>
<th id="Domain" class="gt_col_heading gt_columns_bottom_border gt_left" data-quarto-table-cell-role="th" scope="col">Domain</th>
<th id="Examples" class="gt_col_heading gt_columns_bottom_border gt_right" data-quarto-table-cell-role="th" scope="col">Examples</th>
</tr>
</thead>
<tbody class="gt_table_body">
<tr class="odd">
<td class="gt_row gt_left">train</td>
<td class="gt_row gt_left">restaurants</td>
<td class="gt_row gt_right">2957</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">train</td>
<td class="gt_row gt_left">laptops</td>
<td class="gt_row gt_right">3002</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">test</td>
<td class="gt_row gt_left">restaurants</td>
<td class="gt_row gt_right">786</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">test</td>
<td class="gt_row gt_left">laptops</td>
<td class="gt_row gt_right">786</td>
</tr>
</tbody>
</table>


</div>
</div>
</div>
<p>The dataset contains a similar number of restaurant and laptop reviews.</p>
<p>The goal is to choose the optimal prompt and few-shot examples to maximize the F1 score of the aspect extraction and classification. To achieve this, DSPy needs to be able to evaluate the metrics and a training set to learn from.</p>
</section>
</section>
<section id="model-definition" class="level2">
<h2 class="anchored" data-anchor-id="model-definition">Model Definition</h2>
<section id="pydantic-models-for-absa" class="level3">
<h3 class="anchored" data-anchor-id="pydantic-models-for-absa">Pydantic models for ABSA</h3>
<p>We create classes to represent the input and output of the task using the data validation library <a href="https://docs.pydantic.dev/latest/">Pydantic</a>. This helps with validating the data and provides a structured output format for predictor. The <code>Field</code> class is used to describe the expected data type. Their descriptions match the ones used in <span class="citation" data-cites="simmering2023large">(Simmering and Huoviala 2023)</span>. This is a form of prompting, but DSPy also supports automatically setting the structure’s descriptions using the <a href="https://dspy.ai/learn/8-typed_predictors/?h=typed#optimizing-typed-predictors"><code>optimize_signature</code></a> optimizer. In this experiment I’ll stick with the original descriptions and only vary the normal prompt and few-shot examples.</p>
<div id="fa24fc6d" class="cell" data-execution_count="3">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> typing <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Literal</span>
<span id="cb3-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pydantic <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> BaseModel, Field</span>
<span id="cb3-3"></span>
<span id="cb3-4"></span>
<span id="cb3-5"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> Input(BaseModel):</span>
<span id="cb3-6">    text: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Field()</span>
<span id="cb3-7"></span>
<span id="cb3-8"></span>
<span id="cb3-9"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> Aspect(BaseModel):</span>
<span id="cb3-10">    term: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Field(</span>
<span id="cb3-11">        description<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"An aspect term, which is a verbatim text snippet. Single or multiword terms naming particular aspects of the reviewed product or service."</span></span>
<span id="cb3-12">    )</span>
<span id="cb3-13">    polarity: Literal[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"positive"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"neutral"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"negative"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Field(</span>
<span id="cb3-14">        description<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"The polarity expressed towards the aspect term. Valid polarities are ‘positive’, ‘neutral’, ‘negative'."</span></span>
<span id="cb3-15">    )</span>
<span id="cb3-16"></span>
<span id="cb3-17">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__hash__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>):</span>
<span id="cb3-18">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb3-19"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Make the aspect hashable to enable set operations in evaluation.</span></span>
<span id="cb3-20"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Hash is case-insensitive.</span></span>
<span id="cb3-21"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb3-22">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">hash</span>((<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.term.lower(), <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.polarity.lower()))</span>
<span id="cb3-23"></span>
<span id="cb3-24">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__eq__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, other):</span>
<span id="cb3-25">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb3-26"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Define equality for case-insensitive comparison.</span></span>
<span id="cb3-27"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb3-28">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">isinstance</span>(other, Aspect):</span>
<span id="cb3-29">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span></span>
<span id="cb3-30">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> (</span>
<span id="cb3-31">            <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.term.lower() <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> other.term.lower()</span>
<span id="cb3-32">            <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">and</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.polarity.lower() <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> other.polarity.lower()</span>
<span id="cb3-33">        )</span>
<span id="cb3-34"></span>
<span id="cb3-35"></span>
<span id="cb3-36"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> Aspects(BaseModel):</span>
<span id="cb3-37">    aspects: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>[Aspect] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Field(</span>
<span id="cb3-38">        description<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"An array of aspects and their polarities. If no aspects are mentioned in the text, use an empty array."</span></span>
<span id="cb3-39">    )</span></code></pre></div></div>
</div>
<p>The <code>__hash__</code> and <code>__eq__</code> methods will be helpful for evaluation, because they allow for use of set operations to compare gold and predicted aspects.</p>
</section>
<section id="transform-dataset-to-dspy-examples" class="level3">
<h3 class="anchored" data-anchor-id="transform-dataset-to-dspy-examples">Transform dataset to DSPy examples</h3>
<p>Each row in the dataset needs to be turned into an instance of the <code>dspy.Example</code> class. The <code>with_inputs</code> method is used to tell DSPy which column contains the input. Other columns are used as expected model outputs.</p>
<div id="ba082b2b" class="cell" data-execution_count="4">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> json</span>
<span id="cb4-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> dspy</span>
<span id="cb4-3"></span>
<span id="cb4-4"></span>
<span id="cb4-5"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> to_example(row):</span>
<span id="cb4-6">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> dspy.Example(</span>
<span id="cb4-7">        text<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>row[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"input"</span>],</span>
<span id="cb4-8">        aspects<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>Aspects(aspects<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>json.loads(row[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"output"</span>])[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"aspects"</span>]),</span>
<span id="cb4-9">    ).with_inputs(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"text"</span>)</span>
<span id="cb4-10"></span>
<span id="cb4-11"></span>
<span id="cb4-12">trainset <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [to_example(row) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> row <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> train.to_dicts()]</span>
<span id="cb4-13">testset <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [to_example(row) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> row <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> test.to_dicts()]</span></code></pre></div></div>
</div>
<p>Let’s look at the first example.</p>
<div id="ee11a3cc" class="cell" data-execution_count="5">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">trainset[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span></code></pre></div></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>Example({'text': 'I charge it at night and skip taking the cord with me because of the good battery life.', 'aspects': Aspects(aspects=[Aspect(term='cord', polarity='neutral'), Aspect(term='battery life', polarity='positive')])}) (input_keys={'text'})</code></pre>
</div>
</div>
</section>
<section id="creating-a-dspy-typed-predictor" class="level3">
<h3 class="anchored" data-anchor-id="creating-a-dspy-typed-predictor">Creating a DSPy typed predictor</h3>
<p>In DSPy, a module is a language model and a way of prompting. They can also consist of multiple requests and also include external tools such as a vector database for retrieval augmented generation. In this example, we have a single request using few-shot examples and chain of thought.</p>
<p>In order to be able to parse the output as a dictionary, the LLM must output valid JSON. Therefore I’ll use a <a href="https://dspy.ai/learn/8-typed_predictors/?h=typed">Typed Predictor</a> in DSPy, which is similar to structured outputs via instructor or a similar library.</p>
<div id="01bdde17" class="cell" data-execution_count="6">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> AbsaSignature(dspy.Signature):</span>
<span id="cb7-2">    text: Input <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dspy.InputField()</span>
<span id="cb7-3">    aspects: Aspects <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dspy.OutputField()</span>
<span id="cb7-4"></span>
<span id="cb7-5"></span>
<span id="cb7-6">predictor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dspy.ChainOfThought(AbsaSignature)</span></code></pre></div></div>
</div>
<p>We also need to choose a language model. DSPy works with OpenAI, Anthropic, Ollama, vllm and other OpenAI-compatible platforms and libraries. This is powered by <a href="https://github.com/BerriAI/litellm">litellm</a> under the hood.</p>
<p>For this article, I’ll use OpenAI’s gpt-4o-mini as well as the 70B version of Meta’s Llama 3.1 hosted on <a href="https://fireworks.ai">fireworks.ai</a>. Fireworks.ai generously supplied me with credits as part of the <a href="https://maven.com/parlance-labs/fine-tuning?utm_campaign=d45fef&amp;utm_medium=partner&amp;utm_source=instructor">Mastering LLMs For Developers &amp; Data Scientists</a> course.</p>
<div id="9ba79829" class="cell" data-execution_count="7">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># FIREWORKS_AI_API_KEY environment variable must be set.</span></span>
<span id="cb8-2"></span>
<span id="cb8-3">lm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dspy.LM(</span>
<span id="cb8-4">    api_base<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"https://api.fireworks.ai/inference/v1/"</span>,</span>
<span id="cb8-5">    model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"fireworks_ai/accounts/fireworks/models/llama-v3p1-70b-instruct"</span>,</span>
<span id="cb8-6">    temperature<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span>,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># best for structured outputs</span></span>
<span id="cb8-7">    cache<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb8-8">    max_tokens<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">250</span>,</span>
<span id="cb8-9">)</span>
<span id="cb8-10">dspy.configure(lm<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>lm)</span></code></pre></div></div>
</div>
</section>
</section>
<section id="optimization" class="level2">
<h2 class="anchored" data-anchor-id="optimization">Optimization</h2>
<p>Let’s run a single example to check that everything is working.</p>
<div id="dcddfe3d" class="cell" data-execution_count="8">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1">predictor(text<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"The pizza was great, but the service was terrible"</span>)</span></code></pre></div></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>Prediction(
    rationale='We produce the aspects by identifying the terms "pizza" and "service" as aspects and determining their polarities based on the context. The term "pizza" is associated with the positive sentiment "great", while the term "service" is associated with the negative sentiment "terrible".',
    aspects=Aspects(aspects=[Aspect(term='pizza', polarity='positive'), Aspect(term='service', polarity='negative')])
)</code></pre>
</div>
</div>
<p>That’s a good start. I’m a fan of <a href="https://hamel.dev/blog/posts/prompt/">Hamel Husain’s advice</a> to always demand: “Show me the prompt”, so let’s check what DSPy actually sent to OpenAI:</p>
<div id="35504bec" class="cell" data-execution_count="9">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1">lm.inspect_history(n<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span></code></pre></div></div>
<div class="cell-output cell-output-stdout">
<pre><code>



[2024-11-27T08:58:15.497789]

System message:

Your input fields are:
1. `text` (Input)

Your output fields are:
1. `rationale` (str): ${produce the aspects}. We ...
2. `aspects` (Aspects)

All interactions will be structured in the following way, with the appropriate values filled in.

[[ ## text ## ]]
{text}

[[ ## rationale ## ]]
{rationale}

[[ ## aspects ## ]]
{aspects}        # note: the value you produce must be pareseable according to the following JSON schema: {"type": "object", "$defs": {"Aspect": {"type": "object", "properties": {"polarity": {"type": "string", "description": "The polarity expressed towards the aspect term. Valid polarities are ‘positive’, ‘neutral’, ‘negative'.", "enum": ["positive", "neutral", "negative"], "title": "Polarity"}, "term": {"type": "string", "description": "An aspect term, which is a verbatim text snippet. Single or multiword terms naming particular aspects of the reviewed product or service.", "title": "Term"}}, "required": ["term", "polarity"], "title": "Aspect"}}, "properties": {"aspects": {"type": "array", "description": "An array of aspects and their polarities. If no aspects are mentioned in the text, use an empty array.", "items": {"$ref": "#/$defs/Aspect"}, "title": "Aspects"}}, "required": ["aspects"], "title": "Aspects"}

[[ ## completed ## ]]

In adhering to this structure, your objective is: 
        Given the fields `text`, produce the fields `aspects`.


User message:

[[ ## text ## ]]
The pizza was great, but the service was terrible

Respond with the corresponding output fields, starting with the field `[[ ## rationale ## ]]`, then `[[ ## aspects ## ]]` (must be formatted as a valid Python Aspects), and then ending with the marker for `[[ ## completed ## ]]`.


Response:

[[ ## rationale ## ]]
We produce the aspects by identifying the terms "pizza" and "service" as aspects and determining their polarities based on the context. The term "pizza" is associated with the positive sentiment "great", while the term "service" is associated with the negative sentiment "terrible".

[[ ## aspects ## ]]
{"aspects": [{"term": "pizza", "polarity": "positive"}, {"term": "service", "polarity": "negative"}]}

[[ ## completed ## ]]




</code></pre>
</div>
</div>
<p>Verbose but it works. It doesn’t use function calling or a different way to get structured outputs, so there is some chance of getting an invalid JSON.</p>
<section id="specify-the-evaluation-function" class="level3">
<h3 class="anchored" data-anchor-id="specify-the-evaluation-function">Specify the evaluation function</h3>
<p>An evaluation function takes an example and a prediction and returns an F1 score. A true positive is a predicted aspect that is also in the gold answer, a false positive is a predicted aspect that is not in the gold answer, and a false negative is a gold answer aspect that is not predicted. Here are the precision, recall, and F1 score functions.</p>
<div id="2a060d62" class="cell" data-execution_count="10">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> precision(tp: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>, fp: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span>:</span>
<span id="cb13-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Handle division by zero</span></span>
<span id="cb13-3">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> tp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> fp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span> tp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> (tp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> fp)</span>
<span id="cb13-4"></span>
<span id="cb13-5"></span>
<span id="cb13-6"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> recall(tp: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>, fn: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span>:</span>
<span id="cb13-7">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> tp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> fn <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span> tp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> (tp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> fn)</span>
<span id="cb13-8"></span>
<span id="cb13-9"></span>
<span id="cb13-10"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> f1_score(tp: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>, fp: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>, fn: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span>:</span>
<span id="cb13-11">    prec <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> precision(tp, fp)</span>
<span id="cb13-12">    rec <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> recall(tp, fn)</span>
<span id="cb13-13">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> prec <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> rec <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> (prec <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> rec) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> (prec <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> rec)</span></code></pre></div></div>
</div>
<p>Next is the evaluation function which compares the gold and predicted aspects. To count as a true positive, both the term and the polarity have to be correct. As it is conventional on this benchmark, the case where both the gold answers and the prediction are empty is treated as a correct prediction of no aspects.</p>
<div id="a5bf9cf4" class="cell" data-execution_count="11">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> evaluate_absa(example: dspy.Example, prediction: Aspects, trace<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span>:</span>
<span id="cb14-2">    gold_aspects <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">set</span>(example.aspects.aspects)</span>
<span id="cb14-3">    pred_aspects <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">set</span>(prediction.aspects.aspects)</span>
<span id="cb14-4"></span>
<span id="cb14-5">    tp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(gold_aspects <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&amp;</span> pred_aspects)</span>
<span id="cb14-6">    fp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(pred_aspects <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> gold_aspects)</span>
<span id="cb14-7">    fn <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(gold_aspects <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> pred_aspects)</span>
<span id="cb14-8"></span>
<span id="cb14-9">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(gold_aspects) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">and</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(pred_aspects) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>:</span>
<span id="cb14-10">        tp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># correct prediction of no aspects</span></span>
<span id="cb14-11"></span>
<span id="cb14-12">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> f1_score(tp, fp, fn)</span></code></pre></div></div>
</div>
<p>Let’s try the evaluation function with a single example. We expect the F1 score to be 1.0, because the prediction matches the gold answer exactly.</p>
<div id="0bc42ba9" class="cell" data-execution_count="12">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1">example <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dspy.Example(</span>
<span id="cb15-2">    text<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"The pizza was great, but the service was terrible"</span>,</span>
<span id="cb15-3">    aspects<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>Aspects(</span>
<span id="cb15-4">        aspects<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[</span>
<span id="cb15-5">            Aspect(term<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"pizza"</span>, polarity<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"positive"</span>),</span>
<span id="cb15-6">            Aspect(term<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"service"</span>, polarity<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"negative"</span>),</span>
<span id="cb15-7">        ]</span>
<span id="cb15-8">    ),</span>
<span id="cb15-9">).with_inputs(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"text"</span>)</span>
<span id="cb15-10">prediction <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> predictor(text<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>example.text)</span>
<span id="cb15-11">evaluate_absa(example, prediction)</span></code></pre></div></div>
<div class="cell-output cell-output-display" data-execution_count="12">
<pre><code>1.0</code></pre>
</div>
</div>
</section>
<section id="optimizers" class="level3">
<h3 class="anchored" data-anchor-id="optimizers">Optimizers</h3>
<p>DSPy has a variety of <a href="https://dspy.ai/learn/optimization/optimizers/?h=optimizers">optimizers</a>, loops that change the prompt and/or few-shot examples and evaluate the performance. They’re analogous to optimizers like SGD and Adam in PyTorch. The choice of optimizer depends on the task, the amount of labeled data and the computational resources available. As we have a large labeled dataset, it’s not necessary to have the model bootstrap artificial examples. Our 2023 paper found that fine-tuning yields the best results, but the goal of this article is to showcase DSPy’s prompt optimization.</p>
<p>The most powerful optimizer available for a prompting approach for this task is <a href="[Multiprompt Instruction PRoposal Optimizer Version 2](https://dspy.ai/deep-dive/optimizers/miprov2/?h=miprov)">MIPROv2</a> (Multiprompt Instruction PRoposal Optimizer Version 2) by <span class="citation" data-cites="opsahlong2024optimizinginstructionsdemonstrationsmultistage">Opsahl-Ong et al. (2024)</span>. MIPROv2 uses Bayesian optimization to find an optimal combination of few-shot examples and prompt instructions.</p>
<div id="556aaa52" class="cell" data-execution_count="13">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1">optimizer_settings <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">dict</span>(</span>
<span id="cb17-2">    metric<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>evaluate_absa,</span>
<span id="cb17-3">    num_threads<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># make parallel requests to Fireworks.ai</span></span>
<span id="cb17-4">    max_errors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># keep going even when invalid JSON is returned</span></span>
<span id="cb17-5">)</span>
<span id="cb17-6">optimizer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dspy.teleprompt.MIPROv2(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>optimizer_settings)</span></code></pre></div></div>
</div>
<p>The final step is to call the <code>compile</code> method, which starts the optimization process. After about 5 minutes, the best prompt and few-shot examples are saved to a JSON file.</p>
<div id="c003b7c7" class="cell" data-execution_count="14">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define settings for the comilation step of the optimizer.</span></span>
<span id="cb18-2">compile_settings <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">dict</span>(</span>
<span id="cb18-3">    minibatch_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># evaluate changes on a subset of the validation set</span></span>
<span id="cb18-4">    minibatch_full_eval_steps<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># evaluate on the full validation set after every 10 steps</span></span>
<span id="cb18-5">    max_labeled_demos<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># the number of few-shot examples to use</span></span>
<span id="cb18-6">    max_bootstrapped_demos<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># not required because we have labeled examples, but setting it to 0 causes an error during sampling</span></span>
<span id="cb18-7">    num_trials<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># how many combinations of few-shot examples and prompt instructions to try</span></span>
<span id="cb18-8">    seed<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># for reproducibility</span></span>
<span id="cb18-9">    requires_permission_to_run<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># skip confirmation dialog</span></span>
<span id="cb18-10">)</span></code></pre></div></div>
</div>
<p>We save the optimized predictor to a JSON file. It’s a small config file listing the chosen few-shot examples and the optimized prompt.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1">optimized_predictor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> optimizer.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">compile</span>(</span>
<span id="cb19-2">    student<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>predictor, trainset<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>trainset, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>compile_settings</span>
<span id="cb19-3">)</span>
<span id="cb19-4">optimized_predictor.save(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"configs/absa_model.json"</span>)</span></code></pre></div></div>
<p>Let’s check if we can load it again:</p>
<div id="08ac763f" class="cell" data-execution_count="15">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1">optimized_predictor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dspy.ChainOfThought(signature<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>AbsaSignature)</span>
<span id="cb20-2">optimized_predictor.load(path<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"configs/absa_model.json"</span>)</span></code></pre></div></div>
</div>
<p>Again: “Show me the prompt”.</p>
<div id="eaed34bf" class="cell" data-execution_count="16">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(optimized_predictor.extended_signature.instructions)</span></code></pre></div></div>
<div class="cell-output cell-output-stdout">
<pre><code>You are a product reviewer tasked with analyzing customer feedback for laptops and netbooks. Given the fields `text`, which contains a customer review, produce the fields `aspects`, which should include the specific features or aspects of the laptop or netbook mentioned in the review, along with their corresponding sentiment or polarity.</code></pre>
</div>
</div>
<p>and show me the chosen few-shot examples:</p>
<div id="e49e8c57" class="cell" data-execution_count="17">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> demo <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> optimized_predictor.demos[:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>]:  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># first 3 examples</span></span>
<span id="cb23-2">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(demo[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"text"</span>])</span>
<span id="cb23-3">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(demo[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"aspects"</span>])</span></code></pre></div></div>
<div class="cell-output cell-output-stdout">
<pre><code>-Called headquarters again, they report that TFT panel is broken, should be fixed by the end of the week (week 3).
{"aspects":[{"term":"TFT panel","polarity":"negative"}]}
But we had paid for bluetooth, and there was none.
{"aspects":[{"term":"bluetooth","polarity":"negative"}]}
The powerpoint opened seamlessly in the apple and the mac hooked up to the projector so easily it was almost scary.
{"aspects":[{"term":"powerpoint","polarity":"positive"}]}</code></pre>
</div>
</div>
</section>
</section>
<section id="evaluation" class="level2">
<h2 class="anchored" data-anchor-id="evaluation">Evaluation</h2>
<p>So far, we’ve only evaluated on the validation part of the training set (this was automatically done by DSPy). Let’s evaluate the optimized predictor on the test set.</p>
<div id="9ebae982" class="cell" data-execution_count="18">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1">evaluator <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dspy.Evaluate(</span>
<span id="cb25-2">    devset<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>testset,</span>
<span id="cb25-3">    metric<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>evaluate_absa,</span>
<span id="cb25-4">    display_progress<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb25-5">    num_threads<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>,</span>
<span id="cb25-6">)</span></code></pre></div></div>
</div>
<div id="aab61074" class="cell" data-execution_count="19">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1">score <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> evaluator(optimized_predictor)</span></code></pre></div></div>
</div>
<p>The first run yields an F1 score of 47.6. That’s rather poor, but the compiler settings only allow for 4 labeled examples and 1 bootstrapped example and only 3 trials.</p>
</section>
<section id="hyperparameter-optimization" class="level2">
<h2 class="anchored" data-anchor-id="hyperparameter-optimization">Hyperparameter optimization</h2>
<p>What would happen if we changed the hyperparameters? Let’s do a grid search over the number of few-shot examples and the number of trials, as well as try different models.</p>
<div id="d029a7bb" class="cell" data-execution_count="20">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> itertools</span>
<span id="cb27-2"></span>
<span id="cb27-3">max_labeled_demos <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">40</span>]</span>
<span id="cb27-4">num_trials <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">15</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">30</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">60</span>]</span>
<span id="cb27-5">chain_of_thought <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>]</span>
<span id="cb27-6"></span>
<span id="cb27-7">default_lm_settings <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">dict</span>(</span>
<span id="cb27-8">    temperature<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span>,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># best for structured outputs, no creativity needed</span></span>
<span id="cb27-9">    cache<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb27-10">    max_tokens<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">250</span>,</span>
<span id="cb27-11">)</span>
<span id="cb27-12"></span>
<span id="cb27-13">lm_settings <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [</span>
<span id="cb27-14">    {</span>
<span id="cb27-15">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"model"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"fireworks_ai/accounts/fireworks/models/llama-v3p1-70b-instruct"</span>,</span>
<span id="cb27-16">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"api_base"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"https://api.fireworks.ai/inference/v1/"</span>,</span>
<span id="cb27-17">        <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>default_lm_settings,</span>
<span id="cb27-18">    },</span>
<span id="cb27-19">    {</span>
<span id="cb27-20">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"model"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"gpt-4o-mini-2024-07-18"</span>,</span>
<span id="cb27-21">        <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>default_lm_settings,</span>
<span id="cb27-22">    },</span>
<span id="cb27-23">]</span>
<span id="cb27-24"></span>
<span id="cb27-25">grid <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>(</span>
<span id="cb27-26">    itertools.product(max_labeled_demos, num_trials, chain_of_thought, lm_settings)</span>
<span id="cb27-27">)</span></code></pre></div></div>
</div>
<p>This results in a grid with 48 combinations. Next, we iterate over the grid, perform the optimization run and save the results to Weights &amp; Biases.</p>
<div id="d4cf55fc" class="cell" data-execution_count="21">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb28" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> os</span>
<span id="cb28-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> copy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> deepcopy</span>
<span id="cb28-3"></span>
<span id="cb28-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> wandb</span>
<span id="cb28-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> tqdm <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> tqdm</span>
<span id="cb28-6"></span>
<span id="cb28-7"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">assert</span> os.getenv(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"FIREWORKS_AI_API_KEY"</span>) <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"FIREWORKS_AI_API_KEY is not set."</span></span>
<span id="cb28-8"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">assert</span> os.getenv(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"OPENAI_API_KEY"</span>) <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"OPENAI_API_KEY is not set."</span></span>
<span id="cb28-9"></span>
<span id="cb28-10"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> max_labeled_demos, num_trials, chain_of_thought, lm_settings <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> tqdm(grid):</span>
<span id="cb28-11"></span>
<span id="cb28-12">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate a filename for the run</span></span>
<span id="cb28-13">    modelname <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> lm_settings[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"model"</span>].replace(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"/"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"_"</span>)</span>
<span id="cb28-14">    cot_name <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cot"</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> chain_of_thought <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"predict"</span></span>
<span id="cb28-15">    run_name <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>modelname<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">_</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>max_labeled_demos<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">_</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>num_trials<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">_</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>cot_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span></span>
<span id="cb28-16">    filepath <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"configs/"</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> run_name <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">".json"</span></span>
<span id="cb28-17"></span>
<span id="cb28-18">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> os.path.exists(filepath):</span>
<span id="cb28-19">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Skipping </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>run_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> because it already exists."</span>)</span>
<span id="cb28-20">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">continue</span></span>
<span id="cb28-21">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb28-22">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Running </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>run_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">."</span>)</span>
<span id="cb28-23"></span>
<span id="cb28-24">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create fresh copies of settings for this run</span></span>
<span id="cb28-25">    run_compile_settings <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> deepcopy(compile_settings)</span>
<span id="cb28-26">    run_optimizer_settings <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> deepcopy(optimizer_settings)</span>
<span id="cb28-27"></span>
<span id="cb28-28">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Update settings</span></span>
<span id="cb28-29">    run_compile_settings[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"max_labeled_demos"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> max_labeled_demos</span>
<span id="cb28-30">    run_compile_settings[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"num_trials"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> num_trials</span>
<span id="cb28-31"></span>
<span id="cb28-32">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> chain_of_thought:</span>
<span id="cb28-33">        predictor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dspy.ChainOfThought(AbsaSignature)</span>
<span id="cb28-34">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb28-35">        predictor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dspy.Predict(AbsaSignature)</span>
<span id="cb28-36"></span>
<span id="cb28-37">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Do an optimization run and evaluate the resulting model</span></span>
<span id="cb28-38">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">try</span>:</span>
<span id="cb28-39">        dspy.configure(lm<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>dspy.LM(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>lm_settings))</span>
<span id="cb28-40">        optimizer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dspy.teleprompt.MIPROv2(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>run_optimizer_settings)</span>
<span id="cb28-41">        optimized_predictor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> optimizer.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">compile</span>(</span>
<span id="cb28-42">            student<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>predictor, trainset<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>trainset, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>run_compile_settings</span>
<span id="cb28-43">        )</span>
<span id="cb28-44">        score <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> evaluator(optimized_predictor)</span>
<span id="cb28-45">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">except</span> <span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">Exception</span> <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> e:</span>
<span id="cb28-46">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(</span>
<span id="cb28-47">            <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Failed run with settings: max_labeled_demos=</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>max_labeled_demos<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">, "</span></span>
<span id="cb28-48">            <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"num_trials=</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>num_trials<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">, model=</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>lm_settings[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'model'</span>]<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span></span>
<span id="cb28-49">        )</span>
<span id="cb28-50">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Error: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>(e)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb28-51">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">continue</span></span>
<span id="cb28-52"></span>
<span id="cb28-53">    optimized_predictor.save(filepath)</span>
<span id="cb28-54"></span>
<span id="cb28-55">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Log experiment to W&amp;B</span></span>
<span id="cb28-56">    config <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb28-57">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"output_schema"</span>: Aspects.model_json_schema(),</span>
<span id="cb28-58">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"compile_settings"</span>: run_compile_settings,</span>
<span id="cb28-59">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"optimizer_settings"</span>: run_optimizer_settings,</span>
<span id="cb28-60">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"lm_settings"</span>: lm_settings,</span>
<span id="cb28-61">    }</span>
<span id="cb28-62"></span>
<span id="cb28-63">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> wandb.init(project<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"absa-dspy"</span>, config<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>config, name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>run_name) <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> run:</span>
<span id="cb28-64">        wandb.log({<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"f1"</span>: score})</span>
<span id="cb28-65">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Save config to artifact</span></span>
<span id="cb28-66">        artifact <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> wandb.Artifact(</span>
<span id="cb28-67">            name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"dspy_config_</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>run_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>,</span>
<span id="cb28-68">            <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">type</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"config"</span>, </span>
<span id="cb28-69">            description<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Config file for </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>run_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span></span>
<span id="cb28-70">        )</span>
<span id="cb28-71">        artifact.add_file(filepath)</span>
<span id="cb28-72">        run.log_artifact(artifact)</span></code></pre></div></div>
</div>
</section>
<section id="comparison-with-manual-prompts" class="level2">
<h2 class="anchored" data-anchor-id="comparison-with-manual-prompts">Comparison with manual prompts</h2>
<p>In the 2023 paper, co-author and I manually crafted prompts and chose few-shot examples that, in our opinion, illustrated the task well. Inference was done using the OpenAI API and using function calling to ensure structured outputs. To make the comparison fair, we’ll now use the same prompts within DSPy.</p>
<p>The manual prompts and few-shot examples are available on <a href="https://github.com/psimm/website/blob/master/blog/absa-with-dspy/configs/manual_prompt.json">Github</a>.</p>
<p>The models <code>gpt-4-0613</code> and <code>gpt-3.5-turbo-0613</code> that were used in the 2023 paper are no longer available on the OpenAI API. Therefore, we use the closest substitutes here.</p>
<div id="88dcd13e" class="cell" data-execution_count="22">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb29" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1">models <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [</span>
<span id="cb29-2">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"gpt-4o-2024-11-20"</span>,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># similar to gpt-4-0613</span></span>
<span id="cb29-3">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"gpt-3.5-turbo-0125"</span>,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># similar to gpt-3.5-turbo-0613</span></span>
<span id="cb29-4">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"gpt-4o-mini-2024-07-18"</span>,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># reference</span></span>
<span id="cb29-5">]</span>
<span id="cb29-6"></span>
<span id="cb29-7">manual_predictor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dspy.Predict(AbsaSignature)</span>
<span id="cb29-8">manual_predictor.load(path<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"configs/manual_prompt.json"</span>)</span>
<span id="cb29-9"></span>
<span id="cb29-10"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> model <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> models:</span>
<span id="cb29-11">    lm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dspy.LM(</span>
<span id="cb29-12">        model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>model,</span>
<span id="cb29-13">        temperature<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,</span>
<span id="cb29-14">        cache<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb29-15">        max_tokens<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">250</span>,</span>
<span id="cb29-16">    )</span>
<span id="cb29-17">    dspy.configure(lm<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>lm)</span>
<span id="cb29-18">    score <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> evaluator(manual_predictor)</span>
<span id="cb29-19">    runname <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>model<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">_manual_prompt"</span></span>
<span id="cb29-20"></span>
<span id="cb29-21">    config <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb29-22">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"output_schema"</span>: Aspects.model_json_schema(),</span>
<span id="cb29-23">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"compile_settings"</span>: {</span>
<span id="cb29-24">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"max_labeled_demos"</span>: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(manual_predictor.demos),</span>
<span id="cb29-25">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"max_bootstrapped_demos"</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,</span>
<span id="cb29-26">        },</span>
<span id="cb29-27">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"lm_settings"</span>: {</span>
<span id="cb29-28">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"model"</span>: model,</span>
<span id="cb29-29">        },</span>
<span id="cb29-30">    }</span>
<span id="cb29-31"></span>
<span id="cb29-32">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> wandb.init(project<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"absa-dspy"</span>, name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>runname, config<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>config) <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> run:</span>
<span id="cb29-33">        wandb.log({<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"f1"</span>: score})</span>
<span id="cb29-34">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Save manual prompt to artifact</span></span>
<span id="cb29-35">        artifact <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> wandb.Artifact(</span>
<span id="cb29-36">            name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"dspy_config_</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>runname<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>,</span>
<span id="cb29-37">            <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">type</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"model"</span>,</span>
<span id="cb29-38">            description<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Manual prompt configuration"</span></span>
<span id="cb29-39">        )</span>
<span id="cb29-40">        artifact.add_file(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"configs/manual_prompt.json"</span>)</span>
<span id="cb29-41">        run.log_artifact(artifact)</span></code></pre></div></div>
</div>
</section>
<section id="results-and-discussion" class="level2">
<h2 class="anchored" data-anchor-id="results-and-discussion">Results and discussion</h2>
<p>We load the results from the Weights &amp; Biases project and show the most relevant columns for a comparison of the runs.</p>
<div id="a36f5554" class="cell" data-execution_count="23">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb30" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> wandb</span>
<span id="cb30-2"></span>
<span id="cb30-3">api <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> wandb.Api()</span>
<span id="cb30-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get all runs from the project</span></span>
<span id="cb30-5">runs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> api.runs(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"psimm/absa-dspy"</span>)</span>
<span id="cb30-6"></span>
<span id="cb30-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Convert to DataFrame</span></span>
<span id="cb30-8">results <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb30-9"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> run <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> runs:</span>
<span id="cb30-10">    results.append(</span>
<span id="cb30-11">        {</span>
<span id="cb30-12">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"run_name"</span>: run.name,</span>
<span id="cb30-13">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"model"</span>: run.config[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"lm_settings"</span>][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"model"</span>],</span>
<span id="cb30-14">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"max_demos"</span>: run.config[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"compile_settings"</span>][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"max_labeled_demos"</span>],</span>
<span id="cb30-15">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"max_bootstrapped_demos"</span>: run.config[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"compile_settings"</span>][</span>
<span id="cb30-16">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"max_bootstrapped_demos"</span></span>
<span id="cb30-17">            ],</span>
<span id="cb30-18">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"num_trials"</span>: run.config.get(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"compile_settings"</span>, {}).get(</span>
<span id="cb30-19">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"num_trials"</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span></span>
<span id="cb30-20">            ),</span>
<span id="cb30-21">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"chain_of_thought"</span>: run.config[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"chain_of_thought"</span>],</span>
<span id="cb30-22">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"f1"</span>: run.summary[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"f1"</span>],</span>
<span id="cb30-23">        }</span>
<span id="cb30-24">    )</span>
<span id="cb30-25"></span>
<span id="cb30-26">results_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pl.DataFrame(results)</span>
<span id="cb30-27"></span>
<span id="cb30-28">table_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (</span>
<span id="cb30-29">    results_df.with_columns(</span>
<span id="cb30-30">        method<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>pl.when(pl.col(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"run_name"</span>).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>.contains(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"manual"</span>))</span>
<span id="cb30-31">        .then(pl.lit(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Manual (2023)"</span>))</span>
<span id="cb30-32">        .otherwise(pl.lit(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"DSPy"</span>)),</span>
<span id="cb30-33">        model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>pl.col(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"model"</span>).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>.replace(</span>
<span id="cb30-34">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"fireworks_ai/accounts/fireworks/models/"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span></span>
<span id="cb30-35">        ),</span>
<span id="cb30-36">        demos<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>pl.when(pl.col(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"max_bootstrapped_demos"</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb30-37">        .then(pl.col(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"max_demos"</span>).cast(pl.Utf8))</span>
<span id="cb30-38">        .otherwise(</span>
<span id="cb30-39">            pl.col(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"max_demos"</span>).cast(pl.Utf8)</span>
<span id="cb30-40">            <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">" + "</span></span>
<span id="cb30-41">            <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> pl.col(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"max_bootstrapped_demos"</span>).cast(pl.Utf8)</span>
<span id="cb30-42">        ),</span>
<span id="cb30-43">        chain_of_thought<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>pl.when(pl.col(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"chain_of_thought"</span>))</span>
<span id="cb30-44">        .then(pl.lit(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"✅"</span>))</span>
<span id="cb30-45">        .otherwise(pl.lit(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"❌"</span>)),</span>
<span id="cb30-46">    )</span>
<span id="cb30-47">    .sort(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"f1"</span>, descending<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb30-48">    .select(</span>
<span id="cb30-49">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"model"</span>,</span>
<span id="cb30-50">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"method"</span>,</span>
<span id="cb30-51">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"num_trials"</span>,</span>
<span id="cb30-52">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"demos"</span>,</span>
<span id="cb30-53">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"chain_of_thought"</span>,</span>
<span id="cb30-54">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"f1"</span>,</span>
<span id="cb30-55">    )</span>
<span id="cb30-56">)</span>
<span id="cb30-57"></span>
<span id="cb30-58">GT(table_df).tab_header(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"SemEval 2014 Task 4 1+2 Few-Shot Predictors"</span>).cols_label(</span>
<span id="cb30-59">    model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Model"</span>,</span>
<span id="cb30-60">    method<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Method"</span>,</span>
<span id="cb30-61">    demos<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Examples¹"</span>,</span>
<span id="cb30-62">    num_trials<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Trials"</span>,</span>
<span id="cb30-63">    chain_of_thought<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"CoT"</span>,</span>
<span id="cb30-64">    f1<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"F1"</span>,</span>
<span id="cb30-65">).cols_align(align<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"right"</span>, columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"demos"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"num_trials"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"f1"</span>]).fmt_number(</span>
<span id="cb30-66">    columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"f1"</span>], decimals<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span></span>
<span id="cb30-67">).tab_source_note(</span>
<span id="cb30-68">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"¹ Bootstrapped + labeled examples. Notes: Limited Llama 3.1 70B non-CoT runs due to API constraints. Manual prompt runs use 10 examples vs. 6 in original paper."</span></span>
<span id="cb30-69">)</span></code></pre></div></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="20">
<div id="fhjsfutory" style="padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>
#fhjsfutory table {
          font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;
          -webkit-font-smoothing: antialiased;
          -moz-osx-font-smoothing: grayscale;
        }

#fhjsfutory thead, tbody, tfoot, tr, td, th { border-style: none; }
 tr { background-color: transparent; }
#fhjsfutory p { margin: 0; padding: 0; }
 #fhjsfutory .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; }
 #fhjsfutory .gt_caption { padding-top: 4px; padding-bottom: 4px; }
 #fhjsfutory .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; }
 #fhjsfutory .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; }
 #fhjsfutory .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; }
 #fhjsfutory .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; }
 #fhjsfutory .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; }
 #fhjsfutory .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; }
 #fhjsfutory .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; }
 #fhjsfutory .gt_column_spanner_outer:first-child { padding-left: 0; }
 #fhjsfutory .gt_column_spanner_outer:last-child { padding-right: 0; }
 #fhjsfutory .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; }
 #fhjsfutory .gt_spanner_row { border-bottom-style: hidden; }
 #fhjsfutory .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; }
 #fhjsfutory .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; }
 #fhjsfutory .gt_from_md> :first-child { margin-top: 0; }
 #fhjsfutory .gt_from_md> :last-child { margin-bottom: 0; }
 #fhjsfutory .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; }
 #fhjsfutory .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; }
 #fhjsfutory .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; }
 #fhjsfutory .gt_row_group_first td { border-top-width: 2px; }
 #fhjsfutory .gt_row_group_first th { border-top-width: 2px; }
 #fhjsfutory .gt_striped { background-color: rgba(128,128,128,0.05); }
 #fhjsfutory .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; }
 #fhjsfutory .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; }
 #fhjsfutory .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; text-align: left; }
 #fhjsfutory .gt_left { text-align: left; }
 #fhjsfutory .gt_center { text-align: center; }
 #fhjsfutory .gt_right { text-align: right; font-variant-numeric: tabular-nums; }
 #fhjsfutory .gt_font_normal { font-weight: normal; }
 #fhjsfutory .gt_font_bold { font-weight: bold; }
 #fhjsfutory .gt_font_italic { font-style: italic; }
 #fhjsfutory .gt_super { font-size: 65%; }
 #fhjsfutory .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; }
 #fhjsfutory .gt_asterisk { font-size: 100%; vertical-align: 0; }
 
</style>

<table class="gt_table caption-top table table-sm table-striped small" data-quarto-bootstrap="false">
<thead>
<tr class="gt_heading header">
<td colspan="6" class="gt_heading gt_title gt_font_normal">SemEval 2014 Task 4 1+2 Few-Shot Predictors</td>
</tr>
<tr class="gt_col_headings even">
<th id="Model" class="gt_col_heading gt_columns_bottom_border gt_left" data-quarto-table-cell-role="th" scope="col">Model</th>
<th id="Method" class="gt_col_heading gt_columns_bottom_border gt_left" data-quarto-table-cell-role="th" scope="col">Method</th>
<th id="Trials" class="gt_col_heading gt_columns_bottom_border gt_right" data-quarto-table-cell-role="th" scope="col">Trials</th>
<th id="Examples¹" class="gt_col_heading gt_columns_bottom_border gt_right" data-quarto-table-cell-role="th" scope="col">Examples¹</th>
<th id="CoT" class="gt_col_heading gt_columns_bottom_border gt_left" data-quarto-table-cell-role="th" scope="col">CoT</th>
<th id="F1" class="gt_col_heading gt_columns_bottom_border gt_right" data-quarto-table-cell-role="th" scope="col">F1</th>
</tr>
</thead>
<tbody class="gt_table_body">
<tr class="odd">
<td class="gt_row gt_left">gpt-4o-2024-11-20</td>
<td class="gt_row gt_left">Manual (2023)</td>
<td class="gt_row gt_right">None</td>
<td class="gt_row gt_right">10</td>
<td class="gt_row gt_left">❌</td>
<td class="gt_row gt_right">71.28</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">15</td>
<td class="gt_row gt_right">40 + 1</td>
<td class="gt_row gt_left">❌</td>
<td class="gt_row gt_right">62.83</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">llama-v3p1-70b-instruct</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">60</td>
<td class="gt_row gt_right">5 + 1</td>
<td class="gt_row gt_left">❌</td>
<td class="gt_row gt_right">61.49</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">60</td>
<td class="gt_row gt_right">10 + 1</td>
<td class="gt_row gt_left">❌</td>
<td class="gt_row gt_right">61.34</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">15</td>
<td class="gt_row gt_right">20 + 1</td>
<td class="gt_row gt_left">❌</td>
<td class="gt_row gt_right">60.87</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">30</td>
<td class="gt_row gt_right">20 + 1</td>
<td class="gt_row gt_left">❌</td>
<td class="gt_row gt_right">60.87</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">60</td>
<td class="gt_row gt_right">20 + 1</td>
<td class="gt_row gt_left">❌</td>
<td class="gt_row gt_right">60.87</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">llama-v3p1-70b-instruct</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">15</td>
<td class="gt_row gt_right">40 + 1</td>
<td class="gt_row gt_left">❌</td>
<td class="gt_row gt_right">60.32</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">llama-v3p1-70b-instruct</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">60</td>
<td class="gt_row gt_right">5 + 1</td>
<td class="gt_row gt_left">✅</td>
<td class="gt_row gt_right">60.27</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">60</td>
<td class="gt_row gt_right">40 + 1</td>
<td class="gt_row gt_left">✅</td>
<td class="gt_row gt_right">59.80</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">15</td>
<td class="gt_row gt_right">20 + 1</td>
<td class="gt_row gt_left">✅</td>
<td class="gt_row gt_right">59.68</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">30</td>
<td class="gt_row gt_right">20 + 1</td>
<td class="gt_row gt_left">✅</td>
<td class="gt_row gt_right">59.68</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">60</td>
<td class="gt_row gt_right">20 + 1</td>
<td class="gt_row gt_left">✅</td>
<td class="gt_row gt_right">59.68</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">30</td>
<td class="gt_row gt_right">40 + 1</td>
<td class="gt_row gt_left">✅</td>
<td class="gt_row gt_right">59.60</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">15</td>
<td class="gt_row gt_right">40 + 1</td>
<td class="gt_row gt_left">✅</td>
<td class="gt_row gt_right">59.32</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">60</td>
<td class="gt_row gt_right">5 + 1</td>
<td class="gt_row gt_left">❌</td>
<td class="gt_row gt_right">58.83</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">llama-v3p1-70b-instruct</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">30</td>
<td class="gt_row gt_right">10 + 1</td>
<td class="gt_row gt_left">❌</td>
<td class="gt_row gt_right">58.79</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">llama-v3p1-70b-instruct</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">60</td>
<td class="gt_row gt_right">10 + 1</td>
<td class="gt_row gt_left">❌</td>
<td class="gt_row gt_right">58.79</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">llama-v3p1-70b-instruct</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">30</td>
<td class="gt_row gt_right">5 + 1</td>
<td class="gt_row gt_left">❌</td>
<td class="gt_row gt_right">58.36</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">llama-v3p1-70b-instruct</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">60</td>
<td class="gt_row gt_right">20 + 1</td>
<td class="gt_row gt_left">❌</td>
<td class="gt_row gt_right">57.98</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">llama-v3p1-70b-instruct</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">30</td>
<td class="gt_row gt_right">20 + 1</td>
<td class="gt_row gt_left">❌</td>
<td class="gt_row gt_right">57.84</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">gpt-3.5-turbo-0125</td>
<td class="gt_row gt_left">Manual (2023)</td>
<td class="gt_row gt_right">None</td>
<td class="gt_row gt_right">10</td>
<td class="gt_row gt_left">❌</td>
<td class="gt_row gt_right">57.45</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">llama-v3p1-70b-instruct</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">60</td>
<td class="gt_row gt_right">40 + 1</td>
<td class="gt_row gt_left">✅</td>
<td class="gt_row gt_right">56.46</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">Manual (2023)</td>
<td class="gt_row gt_right">None</td>
<td class="gt_row gt_right">10</td>
<td class="gt_row gt_left">❌</td>
<td class="gt_row gt_right">55.67</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">llama-v3p1-70b-instruct</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">15</td>
<td class="gt_row gt_right">20 + 1</td>
<td class="gt_row gt_left">❌</td>
<td class="gt_row gt_right">54.90</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">llama-v3p1-70b-instruct</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">60</td>
<td class="gt_row gt_right">10 + 1</td>
<td class="gt_row gt_left">✅</td>
<td class="gt_row gt_right">54.33</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">llama-v3p1-70b-instruct</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">15</td>
<td class="gt_row gt_right">40 + 1</td>
<td class="gt_row gt_left">✅</td>
<td class="gt_row gt_right">54.09</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">llama-v3p1-70b-instruct</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">30</td>
<td class="gt_row gt_right">40 + 1</td>
<td class="gt_row gt_left">✅</td>
<td class="gt_row gt_right">54.09</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">15</td>
<td class="gt_row gt_right">5 + 1</td>
<td class="gt_row gt_left">❌</td>
<td class="gt_row gt_right">53.70</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">30</td>
<td class="gt_row gt_right">5 + 1</td>
<td class="gt_row gt_left">❌</td>
<td class="gt_row gt_right">53.70</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">llama-v3p1-70b-instruct</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">30</td>
<td class="gt_row gt_right">5 + 1</td>
<td class="gt_row gt_left">✅</td>
<td class="gt_row gt_right">53.05</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">60</td>
<td class="gt_row gt_right">10 + 1</td>
<td class="gt_row gt_left">✅</td>
<td class="gt_row gt_right">52.64</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">15</td>
<td class="gt_row gt_right">10 + 1</td>
<td class="gt_row gt_left">❌</td>
<td class="gt_row gt_right">51.19</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">30</td>
<td class="gt_row gt_right">10 + 1</td>
<td class="gt_row gt_left">❌</td>
<td class="gt_row gt_right">51.19</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">15</td>
<td class="gt_row gt_right">5 + 1</td>
<td class="gt_row gt_left">✅</td>
<td class="gt_row gt_right">51.16</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">30</td>
<td class="gt_row gt_right">5 + 1</td>
<td class="gt_row gt_left">✅</td>
<td class="gt_row gt_right">51.16</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">60</td>
<td class="gt_row gt_right">5 + 1</td>
<td class="gt_row gt_left">✅</td>
<td class="gt_row gt_right">51.16</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">llama-v3p1-70b-instruct</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">30</td>
<td class="gt_row gt_right">20 + 1</td>
<td class="gt_row gt_left">✅</td>
<td class="gt_row gt_right">50.90</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">llama-v3p1-70b-instruct</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">60</td>
<td class="gt_row gt_right">20 + 1</td>
<td class="gt_row gt_left">✅</td>
<td class="gt_row gt_right">50.90</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">30</td>
<td class="gt_row gt_right">10 + 1</td>
<td class="gt_row gt_left">✅</td>
<td class="gt_row gt_right">49.97</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">gpt-4o-mini-2024-07-18</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">15</td>
<td class="gt_row gt_right">10 + 1</td>
<td class="gt_row gt_left">✅</td>
<td class="gt_row gt_right">49.74</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">llama-v3p1-70b-instruct</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">15</td>
<td class="gt_row gt_right">20 + 1</td>
<td class="gt_row gt_left">✅</td>
<td class="gt_row gt_right">49.47</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">llama-v3p1-70b-instruct</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">15</td>
<td class="gt_row gt_right">10 + 1</td>
<td class="gt_row gt_left">❌</td>
<td class="gt_row gt_right">48.63</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">llama-v3p1-70b-instruct</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">15</td>
<td class="gt_row gt_right">5 + 1</td>
<td class="gt_row gt_left">✅</td>
<td class="gt_row gt_right">47.73</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">llama-v3p1-70b-instruct</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">30</td>
<td class="gt_row gt_right">10 + 1</td>
<td class="gt_row gt_left">✅</td>
<td class="gt_row gt_right">47.30</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">llama-v3p1-70b-instruct</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">15</td>
<td class="gt_row gt_right">5 + 1</td>
<td class="gt_row gt_left">❌</td>
<td class="gt_row gt_right">46.46</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">llama-v3p1-70b-instruct</td>
<td class="gt_row gt_left">DSPy</td>
<td class="gt_row gt_right">15</td>
<td class="gt_row gt_right">10 + 1</td>
<td class="gt_row gt_left">✅</td>
<td class="gt_row gt_right">46.31</td>
</tr>
</tbody><tfoot class="gt_sourcenotes">
<tr class="odd">
<td colspan="6" class="gt_sourcenote">¹ Bootstrapped + labeled examples. Notes: Limited Llama 3.1 70B non-CoT runs due to API constraints. Manual prompt runs use 10 examples vs. 6 in original paper.</td>
</tr>
</tfoot>

</table>


</div>
</div>
</div>
<section id="comparison-to-the-2023-manual-prompts" class="level3">
<h3 class="anchored" data-anchor-id="comparison-to-the-2023-manual-prompts">Comparison to the 2023 manual prompts</h3>
<p>The DSPy runs are competitive with the manually crafted prompts from the 2023 paper. In contrast to the manual prompt, DSPy instructions are relatively short and emphasize the use of few-shot examples to illustrate the task.</p>
</section>
<section id="impact-of-hyperparameters" class="level3">
<h3 class="anchored" data-anchor-id="impact-of-hyperparameters">Impact of hyperparameters</h3>
<p>To understand which factors significantly influence the F1 score, we’ll run a simple linear regression analysis. The manual runs are excluded. To analyze the impact of the model choice, we’ll create a boolean variable for <code>gpt-4o-mini</code> and treat <code>llama-v3p1-70b-instruct</code> as the baseline.</p>
<div id="6973a37c" class="cell" data-execution_count="24">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb31" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> statsmodels.api <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> sm</span>
<span id="cb31-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb31-3"></span>
<span id="cb31-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Prepare data for regression</span></span>
<span id="cb31-5">reg_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> results_df.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">filter</span>(</span>
<span id="cb31-6">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">~</span>pl.col(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"run_name"</span>).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>.contains(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"manual"</span>),</span>
<span id="cb31-7">    pl.col(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"model"</span>).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>.contains(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"gpt-4o-mini"</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">|</span> pl.col(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"model"</span>).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>.contains(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"llama"</span>),</span>
<span id="cb31-8">).with_columns(  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># exclude manual prompts</span></span>
<span id="cb31-9">    pl.col(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"model"</span>).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>.contains(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"gpt-4o-mini"</span>).alias(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"is_gpt4_mini"</span>),</span>
<span id="cb31-10">)</span>
<span id="cb31-11"></span>
<span id="cb31-12"></span>
<span id="cb31-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Convert to pandas and ensure numeric types</span></span>
<span id="cb31-14">X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> reg_df.select(</span>
<span id="cb31-15">    [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"max_demos"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"chain_of_thought"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"num_trials"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"is_gpt4_mini"</span>]</span>
<span id="cb31-16">).to_pandas()</span>
<span id="cb31-17"></span>
<span id="cb31-18"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Convert boolean columns to int</span></span>
<span id="cb31-19">bool_columns <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"chain_of_thought"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"is_gpt4_mini"</span>]</span>
<span id="cb31-20"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> col <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> bool_columns:</span>
<span id="cb31-21">    X[col] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> X[col].astype(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>)</span>
<span id="cb31-22"></span>
<span id="cb31-23">y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> reg_df.select(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"f1"</span>).to_pandas()</span>
<span id="cb31-24"></span>
<span id="cb31-25"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Add constant for intercept</span></span>
<span id="cb31-26">X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> sm.add_constant(X)</span>
<span id="cb31-27"></span>
<span id="cb31-28"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Fit regression</span></span>
<span id="cb31-29">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> sm.OLS(y, X).fit()</span>
<span id="cb31-30">n <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(reg_df)</span>
<span id="cb31-31">r2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.rsquared</span>
<span id="cb31-32"></span>
<span id="cb31-33"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Print results using GT</span></span>
<span id="cb31-34">df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame(</span>
<span id="cb31-35">    model.summary().tables[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>],</span>
<span id="cb31-36">    columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[</span>
<span id="cb31-37">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Parameter"</span>,</span>
<span id="cb31-38">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Coefficient"</span>,</span>
<span id="cb31-39">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Std Error"</span>,</span>
<span id="cb31-40">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"t"</span>,</span>
<span id="cb31-41">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"p&gt;|t|"</span>,</span>
<span id="cb31-42">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"[0.025"</span>,</span>
<span id="cb31-43">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"0.975]"</span>,</span>
<span id="cb31-44">    ],</span>
<span id="cb31-45">)</span>
<span id="cb31-46"></span>
<span id="cb31-47">df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df.iloc[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>:]  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># remove row with repeated column names</span></span>
<span id="cb31-48"></span>
<span id="cb31-49">GT(df).tab_header(</span>
<span id="cb31-50">    title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Hyperparameter Analysis"</span>, subtitle<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Dependent variable: F1 score"</span></span>
<span id="cb31-51">).cols_align(align<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"right"</span>).tab_source_note(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"n=</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>n<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> runs, R²=</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>r2<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.2f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span></code></pre></div></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="21">
<div id="weybrcaczr" style="padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>
#weybrcaczr table {
          font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;
          -webkit-font-smoothing: antialiased;
          -moz-osx-font-smoothing: grayscale;
        }

#weybrcaczr thead, tbody, tfoot, tr, td, th { border-style: none; }
 tr { background-color: transparent; }
#weybrcaczr p { margin: 0; padding: 0; }
 #weybrcaczr .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; }
 #weybrcaczr .gt_caption { padding-top: 4px; padding-bottom: 4px; }
 #weybrcaczr .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; }
 #weybrcaczr .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; }
 #weybrcaczr .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; }
 #weybrcaczr .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; }
 #weybrcaczr .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; }
 #weybrcaczr .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; }
 #weybrcaczr .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; }
 #weybrcaczr .gt_column_spanner_outer:first-child { padding-left: 0; }
 #weybrcaczr .gt_column_spanner_outer:last-child { padding-right: 0; }
 #weybrcaczr .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; }
 #weybrcaczr .gt_spanner_row { border-bottom-style: hidden; }
 #weybrcaczr .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; }
 #weybrcaczr .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; }
 #weybrcaczr .gt_from_md> :first-child { margin-top: 0; }
 #weybrcaczr .gt_from_md> :last-child { margin-bottom: 0; }
 #weybrcaczr .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; }
 #weybrcaczr .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; }
 #weybrcaczr .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; }
 #weybrcaczr .gt_row_group_first td { border-top-width: 2px; }
 #weybrcaczr .gt_row_group_first th { border-top-width: 2px; }
 #weybrcaczr .gt_striped { background-color: rgba(128,128,128,0.05); }
 #weybrcaczr .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; }
 #weybrcaczr .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; }
 #weybrcaczr .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; text-align: left; }
 #weybrcaczr .gt_left { text-align: left; }
 #weybrcaczr .gt_center { text-align: center; }
 #weybrcaczr .gt_right { text-align: right; font-variant-numeric: tabular-nums; }
 #weybrcaczr .gt_font_normal { font-weight: normal; }
 #weybrcaczr .gt_font_bold { font-weight: bold; }
 #weybrcaczr .gt_font_italic { font-style: italic; }
 #weybrcaczr .gt_super { font-size: 65%; }
 #weybrcaczr .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; }
 #weybrcaczr .gt_asterisk { font-size: 100%; vertical-align: 0; }
 
</style>

<table class="gt_table caption-top table table-sm table-striped small" data-quarto-bootstrap="false">
<thead>
<tr class="gt_heading header">
<td colspan="7" class="gt_heading gt_title gt_font_normal">Hyperparameter Analysis</td>
</tr>
<tr class="gt_heading even">
<td colspan="7" class="gt_heading gt_subtitle gt_font_normal gt_bottom_border">Dependent variable: F1 score</td>
</tr>
<tr class="gt_col_headings header">
<th id="Parameter" class="gt_col_heading gt_columns_bottom_border gt_right" data-quarto-table-cell-role="th" scope="col">Parameter</th>
<th id="Coefficient" class="gt_col_heading gt_columns_bottom_border gt_right" data-quarto-table-cell-role="th" scope="col">Coefficient</th>
<th id="Std Error" class="gt_col_heading gt_columns_bottom_border gt_right" data-quarto-table-cell-role="th" scope="col">Std Error</th>
<th id="t" class="gt_col_heading gt_columns_bottom_border gt_right" data-quarto-table-cell-role="th" scope="col">t</th>
<th id="p&amp;gt;|t|" class="gt_col_heading gt_columns_bottom_border gt_right" data-quarto-table-cell-role="th" scope="col">p&gt;|t|</th>
<th id="[0.025" class="gt_col_heading gt_columns_bottom_border gt_right" data-quarto-table-cell-role="th" scope="col">[0.025</th>
<th id="0.975]" class="gt_col_heading gt_columns_bottom_border gt_right" data-quarto-table-cell-role="th" scope="col">0.975]</th>
</tr>
</thead>
<tbody class="gt_table_body">
<tr class="odd">
<td class="gt_row gt_right">const</td>
<td class="gt_row gt_right">49.3654</td>
<td class="gt_row gt_right">1.457</td>
<td class="gt_row gt_right">33.885</td>
<td class="gt_row gt_right">0.000</td>
<td class="gt_row gt_right">46.419</td>
<td class="gt_row gt_right">52.312</td>
</tr>
<tr class="even">
<td class="gt_row gt_right">max_demos</td>
<td class="gt_row gt_right">0.2021</td>
<td class="gt_row gt_right">0.042</td>
<td class="gt_row gt_right">4.794</td>
<td class="gt_row gt_right">0.000</td>
<td class="gt_row gt_right">0.117</td>
<td class="gt_row gt_right">0.287</td>
</tr>
<tr class="odd">
<td class="gt_row gt_right">chain_of_thought</td>
<td class="gt_row gt_right">-4.3317</td>
<td class="gt_row gt_right">1.038</td>
<td class="gt_row gt_right">-4.172</td>
<td class="gt_row gt_right">0.000</td>
<td class="gt_row gt_right">-6.432</td>
<td class="gt_row gt_right">-2.232</td>
</tr>
<tr class="even">
<td class="gt_row gt_right">num_trials</td>
<td class="gt_row gt_right">0.1062</td>
<td class="gt_row gt_right">0.027</td>
<td class="gt_row gt_right">3.892</td>
<td class="gt_row gt_right">0.000</td>
<td class="gt_row gt_right">0.051</td>
<td class="gt_row gt_right">0.161</td>
</tr>
<tr class="odd">
<td class="gt_row gt_right">is_gpt4_mini</td>
<td class="gt_row gt_right">2.2964</td>
<td class="gt_row gt_right">1.016</td>
<td class="gt_row gt_right">2.260</td>
<td class="gt_row gt_right">0.029</td>
<td class="gt_row gt_right">0.241</td>
<td class="gt_row gt_right">4.351</td>
</tr>
</tbody><tfoot class="gt_sourcenotes">
<tr class="odd">
<td colspan="7" class="gt_sourcenote">n=44 runs, R²=0.56</td>
</tr>
</tfoot>

</table>


</div>
</div>
</div>
</section>
<section id="few-shot-examples" class="level3">
<h3 class="anchored" data-anchor-id="few-shot-examples">Few-shot examples</h3>
<p>More examples are generally better, as indicated by the positive coefficient in the regression. However, the top runs didn’t use more than 20 examples, indicating that there are diminishing returns.</p>
</section>
<section id="chain-of-thought-cot" class="level3">
<h3 class="anchored" data-anchor-id="chain-of-thought-cot">Chain of thought (CoT)</h3>
<p>Runs where the model was instructed to perform an intermediate reasoning step yielded worse results than those without. This is an unusual result - typically CoT helps LLMs achieve better results, for example the main advantage of OpenAI’s <code>o1-preview</code> over <code>gpt-4o</code> is the advanced CoT that is built into it. However, on this structured task and using DSPy’s <code>Predictor</code> and <code>ChainOfThought</code> classes, CoT seems to be detrimental.</p>
</section>
<section id="model-choice" class="level3">
<h3 class="anchored" data-anchor-id="model-choice">Model choice</h3>
<ul>
<li><code>gpt-4o-mini-2024-07-18</code> seems to have an edge over <code>llama-v3p1-70b-instruct</code>, but the confidence interval is wide.</li>
<li><code>gpt-4o-2024-11-20</code> performs better than the other models that were tested. I expect that performance of similar sized models such as <code>Llama 3.1 405B</code> will be similar. Due to cost considerations, I’ve skipped the optimization of a large model with DSPy.</li>
<li><code>gpt-3.5-turbo-0125</code> performed better than <code>gpt-4o-mini-2024-07-18</code>, but worse than the deprecated <code>gpt-3.5-turbo-0613</code> performed during the experiments for the 2023 paper (57.45 vs.&nbsp;65.65 F1 Score).</li>
</ul>
</section>
<section id="number-of-trials" class="level3">
<h3 class="anchored" data-anchor-id="number-of-trials">Number of trials</h3>
<p>Using more trials is associated with higher F1 scores. However, the table also shows setups with identical results at 15, 30 and 60 trials. Going beyond 60 trials isn’t likely to be helpful.</p>
</section>
</section>
<section id="review-of-dspy" class="level2">
<h2 class="anchored" data-anchor-id="review-of-dspy">Review of DSPy</h2>
<p>Here are my conclusions based on this experiment.</p>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Pros ✅</strong></p>
<ul>
<li>Creates prompts that are as good as or better than manually crafted prompts.</li>
<li>No need to manually craft prompts, leading to faster iteration speed.</li>
<li>Able to deal with multi-step workflows.</li>
<li>Naturally encourages a structured approach focused on evaluation.</li>
<li>Supports many LLMs, via APIs and locally.</li>
<li>Lightweight JSON export of the optimized prompts.</li>
<li>Supports custom evaluation metrics.</li>
<li>Built-in threading and caching, which saved me time and money.</li>
<li>Actively developed and has a large community.</li>
<li>Lots of <a href="https://github.com/stanfordnlp/dspy/tree/main/examples">tutorial notebooks</a>.</li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>Cons ❌</strong></p>
<ul>
<li>Generated prompts seem too short to explain the nuances of the task, placing a lot of burden on the few-shot examples. They need to implicitly explain the annotation rules and cover all relevant cases.</li>
<li>Loss of control over the exact prompt. But arguably, if you want to control the prompt DSPy is not the approach to go for anyway.</li>
<li>Adds a layer of abstraction to a stack that’s already complex.</li>
<li>Structured output is not guaranteed, because it’s based on prompting only. Integration with function calling, JSON mode or constrained generation APIs and libraries would improve the reliability of the format.</li>
<li>Steep learning curve with many concepts to understand.</li>
<li>I encountered some bugs and deprecated functions and tutorials.</li>
</ul>
</div>
</div>
<p>DSPy is a great alternative to manual prompting, especially for tasks that have a clear evaluation metric and are demonstrable using few-shot examples. The high variability in the results of my grid search experiment indicates that it’s necessary to run DSPy multiple times with different settings to find the best performing configuration.</p>
<p>A feature that I haven’t explored here is the fine-tuning <a href="https://dspy.ai/learn/optimization/optimizers/?h=fine#automatic-finetuning">optimizer</a> of DSPy that actually modifies the model weights. It’s promising for this task, as a fine-tuned <code>gpt-3.5-turbo-0613</code> is still the <a href="https://paperswithcode.com/sota/aspect-based-sentiment-analysis-on-semeval-6">record holder</a> at an F1 score of 83.76.</p>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0">
<div id="ref-opsahlong2024optimizinginstructionsdemonstrationsmultistage" class="csl-entry">
Opsahl-Ong, Krista, Michael J Ryan, Josh Purtell, David Broman, Christopher Potts, Matei Zaharia, and Omar Khattab. 2024. <span>“Optimizing Instructions and Demonstrations for Multi-Stage Language Model Programs.”</span> <a href="https://arxiv.org/abs/2406.11695">https://arxiv.org/abs/2406.11695</a>.
</div>
<div id="ref-pontiki_semeval" class="csl-entry">
Pontiki, Maria, Dimitris Galanis, John Pavlopoulos, Harris Papageorgiou, Ion Androutsopoulos, and Suresh Manandhar. 2014. <span>“<span>SemEval</span>-2014 <span>Task</span> 4: <span>Aspect</span> <span>Based</span> <span>Sentiment</span> <span>Analysis</span>.”</span> In <em>Proceedings of the 8th <span>International</span> <span>Workshop</span> on <span>Semantic</span> <span>Evaluation</span> (<span>SemEval</span> 2014)</em>, 27–35. Dublin, Ireland: Association for Computational Linguistics. <a href="https://doi.org/10.3115/v1/S14-2004">https://doi.org/10.3115/v1/S14-2004</a>.
</div>
<div id="ref-simmering2023large" class="csl-entry">
Simmering, Paul F., and Paavo Huoviala. 2023. <span>“Large Language Models for Aspect-Based Sentiment Analysis.”</span> <a href="https://arxiv.org/abs/2310.18025">https://arxiv.org/abs/2310.18025</a>.
</div>
</div></section></div> ]]></description>
  <category>Machine Learning</category>
  <category>Python</category>
  <guid>https://simmering.dev/blog/absa-with-dspy/</guid>
  <pubDate>Sat, 23 Nov 2024 23:00:00 GMT</pubDate>
  <media:content url="https://simmering.dev/blog/absa-with-dspy/image.webp" medium="image" type="image/webp"/>
</item>
<item>
  <title>From 5-7-5 to Thousand Lines: The Case for Longer Prompts</title>
  <dc:creator>Paul Simmering</dc:creator>
  <link>https://simmering.dev/blog/long-prompts/</link>
  <description><![CDATA[ 






<p>Prompts are the key to guide LLMs for any task, from a chatbot to a text classifier. Longer prompts are usually better than shorter ones, as I’ll argue below. There is a tradeoff, though: each interaction with a long prompt has a longer input sequence, which increases inference cost and latency. Further, a long prompt takes up more of the model’s context window, leaving less for user interaction. But both of these concerns are becoming less relevant with recent developments.</p>
<section id="long-prompts-are-getting-cheaper" class="level2">
<h2 class="anchored" data-anchor-id="long-prompts-are-getting-cheaper">Long prompts are getting cheaper</h2>
<p>There are two developments that keep bringing down the cost of long prompts:</p>
<ol type="1">
<li><p><strong>Decrease in input token cost</strong> on API platforms like OpenAI, Anthropic and others. At launch of gpt-3.5-turbo in March 2023, OpenAI charged $2 for 1 million input tokens. By August 2024, it’s $0.15 for gpt-4o-mini, a more capable model. This is a 92.5% reduction in cost. It reflects the fierce competition and the increasing efficiency of inference software, a fall in GPU prices and advances in quantization. Similar trends can be observed in inference cost for open source models, though it’s harder to reach the same economies of scale as the big platforms.</p></li>
<li><p><strong>Context caching</strong>, meaning that the model doesn’t have to recompute the prefix of the prompt for each interaction. This is also called prompt caching. It uses a KV cache (see a good explanation by <span class="citation" data-cites="log2023kvcache">Log (2023)</span>) to skip the calculation of the attention keys and values for cached tokens. Originally, this was only used within a single generation task to avoid having to re-read all tokens for each additional token generated. However, it can also be used across different generations. It’s integrated in <a href="https://docs.vllm.ai/en/stable/automatic_prefix_caching/apc.html">vLLM</a> <span class="citation" data-cites="kwon2023efficientmemorymanagementlarge">(Kwon et al. 2023)</span>, an inference library that can serve many popular open source models. Since June 2024, three API platforms have also added this feature: <a href="https://platform.deepseek.com/api-docs/news/news0802/">DeepSeek</a>, <a href="https://ai.google.dev/gemini-api/docs/caching?lang=python">Google Gemini</a> and <a href="https://www.anthropic.com/news/prompt-caching">Anthropic</a>.</p></li>
</ol>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/long-prompts/kv_cache_example.JPEG" class="img-fluid figure-img"></p>
<figcaption>Context caching lets subsequent requests with the same prefix use a cache. Image from <a href="platform">DeepSeek</a>.</figcaption>
</figure>
</div>
<table class="caption-top table">
<colgroup>
<col style="width: 11%">
<col style="width: 20%">
<col style="width: 16%">
<col style="width: 33%">
<col style="width: 16%">
</colgroup>
<thead>
<tr class="header">
<th>Platform</th>
<th>Model</th>
<th>Regular price</th>
<th>Caching price</th>
<th>Savings</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>DeepSeek</td>
<td>deepseek-chat</td>
<td>$0.14 / Mtok</td>
<td>$0.014 / Mtok for cache read</td>
<td>90%</td>
</tr>
<tr class="even">
<td>Anthropic</td>
<td>Claude 3.5 Sonnet</td>
<td>$3.00 / Mtok</td>
<td>$3.75 / MTok for cache write, $0.30 /Mtok for cache hits</td>
<td>90%</td>
</tr>
<tr class="odd">
<td>Gemini</td>
<td>Gemini 1.5 Pro</td>
<td>$3.50 / Mtok</td>
<td>Free cache read, $4.50 / Mtok per hour for storage</td>
<td>Variable</td>
</tr>
</tbody>
</table>
<p>The table above compares the cost savings from prompt caching on different platforms. Mtok stands for million tokens.</p>
<p>The pricing models are quite different. DeepSeek offers the best savings at 90% reduction on cache hit and no storage fees. Keep in mind that this is not a frontier model. The documentation says the cache is cleared after a few hours. Further, the feature is active by default and doesn’t require a change in code. This is different at Anthropic where the cache has to be explicitly enabled and writing to it carries a higher cost than a normal input token. As of August 31, the cache only has a 5 minute time to live (TTL), making it only useful apps with high frequency of the same prompt. Gemini charges for storage and gives control over the TTL with a default of one hour and requires explicit enabling.</p>
<p>Why is it so expensive to store 1 million tokens for one hour? The reason is that the KV cache takes a surprising amount of memory. The formula for the memory per token is:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7Bmemory%7D%20=%20n_%7Btokens%7D%20*%202%20*%20n_%7Bheads%7D%20*%20d_%7Bhead%7D%20*%20n_%7Blayers%7D%20*%20%5Ctext%7Bprecision%20(bytes)%7D%0A"></p>
<p>The 2 represents the key and value vectors, <img src="https://latex.codecogs.com/png.latex?n_%7Bheads%7D"> is the number of attention heads, <img src="https://latex.codecogs.com/png.latex?d_%7Bhead%7D"> is the dimension of the attention head, <img src="https://latex.codecogs.com/png.latex?n_%7Blayers%7D"> is the number of layers and precision is the number of bytes used to store a single weight. Note that this doesn’t include optimizations like sparsity, quantizastion or grouped query attention <span class="citation" data-cites="ainslie2023gqatraininggeneralizedmultiquery">(Ainslie et al. 2023)</span>.</p>
<p>For a 1024 token sequence on a 175B GPT-3 model with 96 heads with 128 dimensions and 96 layers at FP16 precision, this results in</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A1024%20*%202%20*%2096%20*%20128%20*%2096%20*%2016%20%5Ctext%7B%20bytes%7D%20=%2038.65%20%5Ctext%7B%20GB%7D%0A"></p>
<p>This has to be stored in GPU memory to be accessible for the model.</p>
<p>But while $4.5 / Mtok might seem expensive for just one hour, if that input token is used at least twice in that hour, it’s already cheaper than the regular input token price. The savings are multiplied with each additional use. For use of open models on your own GPUs, this means that allocating a portion of your GPU memory to cache can be an excellent investment. It also means that for same-y inference requests, GPU memory matters more than its speed.</p>
</section>
<section id="context-sizes-are-getting-larger" class="level2">
<h2 class="anchored" data-anchor-id="context-sizes-are-getting-larger">Context sizes are getting larger</h2>
<p>Current frontier models have a context length of at least 128,000 tokens - equivalent to roughly 100,000 words or a 400 page novel.</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Provider</th>
<th>Model</th>
<th>Context size</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Google</td>
<td>Gemini 1.5 Pro</td>
<td>2m</td>
</tr>
<tr class="even">
<td>Anthropic</td>
<td>Claude 3.5 Sonnet</td>
<td>200k</td>
</tr>
<tr class="odd">
<td>Alibaba</td>
<td>Qwen2 72B</td>
<td>128k</td>
</tr>
<tr class="even">
<td>Meta</td>
<td>Llama 3.1 Instruct 405B</td>
<td>128k</td>
</tr>
<tr class="odd">
<td>Mistral</td>
<td>Mistral Large 2</td>
<td>128k</td>
</tr>
<tr class="even">
<td>OpenAI</td>
<td>GPT-4o</td>
<td>128k</td>
</tr>
</tbody>
</table>
<p>Source: <a href="https://artificialanalysis.ai">Artificialanalysis.ai</a></p>
<p>In contrast, early models like gpt-3.5-turbo in March 2023 only had a context size of 4096 tokens. In a RAG context, this means that more text chunks can be included in the prompt and in a chat context, more questions and answers can be included before the oldest ones are evicted. The problem that a prompt doesn’t fit into the context window is effectively solved for almost all applications.</p>
</section>
<section id="longer-prompts-are-often-better" class="level2">
<h2 class="anchored" data-anchor-id="longer-prompts-are-often-better">Longer prompts are often better</h2>
<p>Ok, so long prompts are getting cheaper. But how does a longer prompt help?</p>
<section id="more-detailed-guidelines" class="level3">
<h3 class="anchored" data-anchor-id="more-detailed-guidelines">1. More detailed guidelines</h3>
<p>A longer prompt can provide more context to the model, letting it perform a task more accurately or represent a brand or character more faithfully. Consider including information like this:</p>
<ul>
<li>Background information about the website, app or task that the model is embedded in.</li>
<li>Behavioral constraints, like not using certain words or phrases. For example telling the prompt to avoid starting answers with “Certainly!”, to make it sound less AI-like.</li>
<li>Style guidelines, like using a certain tone or level of formality, whether to address the user by first or last name, or to use emojis.</li>
<li>Characterization, giving the model a personality or role to play. For example, a chatbot for a bank could be characterized as a friendly and professional customer service agent.</li>
<li>A more detailed task description, like a list of steps to follow or a description of the desired output.</li>
<li>Information about the user, like their name, location, or preferences.</li>
<li>A translation glossary, if the model is used in a multilingual setting.</li>
</ul>
<p>If you’re looking for inspiration for a chatbot prompt, check the recently revealed prompts for Anthropic’s <a href="https://docs.anthropic.com/en/release-notes/system-prompts#july-12th-2024">Claude</a>.</p>
</section>
<section id="many-shot-in-context-learning" class="level3">
<h3 class="anchored" data-anchor-id="many-shot-in-context-learning">2. Many-shot in-context learning</h3>
<p>Few-shot examples can be included in the prompt for in-context learning (ICL). These examples can teach the model about the rules for the task, the desired output format, intermediate reasoning steps and handling of edge cases. Commonly this is done with 1 to 5 examples, but with prefix caching it’s possible to include 50, 100 or even more examples.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/long-prompts/many_shot_learning.png" class="img-fluid figure-img"></p>
<figcaption>Many-shot in-context learning. Image from Agarwal et al.&nbsp;(2024)</figcaption>
</figure>
</div>
<p><span class="citation" data-cites="agarwal2024manyshotincontextlearning">Agarwal et al. (2024)</span> ran this experiment with Gemini 1.5 Pro across several tasks. Many-shot ICL outperformed few-shot learning in all cases. For sentiment analysis they went as far as 2048 examples in the prompt, achieving an increase in 18.2 percentage points over a 32-shot prompt. In many of their experiments the limiting factor wasn’t the context size, but the number of available examples.</p>
<p>This allows a prompting approach become closer to fine-tuning, but without the need for training or a model store. <span class="citation" data-cites="bertsch2024incontextlearninglongcontextmodels">Bertsch et al. (2024)</span> made the comparison between many-shot ICL and LoRA <span class="citation" data-cites="hu2021loralowrankadaptationlarge">(Hu et al. 2021)</span> on 5 classification tasks and conclude that “finetuning is more data-hungry than ICL”. In their experiments with Llama2-7b, many-shot prompting outperformed fine-tuning up to about 1000 examples (see figure 2 of their paper).</p>
</section>
<section id="more-rag-context" class="level3">
<h3 class="anchored" data-anchor-id="more-rag-context">3. More RAG context</h3>
<p>A key design parameter in retrieval augmented generation (RAG) is the number of text chunks to retrieve from a source. With a larger context size, more and longer text chunks can be included in the prompt. This increases the likelihood that the information required to answer the query is present in the prompt.</p>
<p><span class="citation" data-cites="leng2024longcontextrag">Leng et al. (2024)</span> tested RAG answer correctness on 13 open source and proprietary LLMs.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/long-prompts/long_context_performance.png" class="img-fluid figure-img"></p>
<figcaption>Long context performance of GPT, Claude, Llama, Mistral and DBRX models on 4 curated RAG datasets (Databricks DocsQA, FinanceBench, HotPotQA and Natural Questions), from Leng et al.&nbsp;(2024).</figcaption>
</figure>
</div>
<p>As the graph above shows, answer correctness increased with longer context all models up to 4k tokens and up to 32k tokens for most models. This is driven by the boost in retrieval (see experiment 1 in the article).</p>
<p>However, the “lost in the middle” problem can occur, a phenomemon first found by <span class="citation" data-cites="liu2023lostmiddlelanguagemodels">(Liu et al. 2023)</span>, where information presented in the middle is not used as well as information presented at the beginning or end. It can be measured by the “needle in a haystack” method, meaning that a piece of information is hidden in a long text and the model has to find it. The longer the text, the harder it is to find the information. The RULER benchmark by <span class="citation" data-cites="hsieh2024rulerwhatsrealcontext">(Hsieh et al. 2024)</span> extended this to more complex tasks and introduced the concept of an effective context length, which is shorter than the technical context length of a model.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/long-prompts/lost_in_the_middle.png" class="img-fluid figure-img" style="width:50.0%"></p>
<figcaption>Lost in the middle problem. Image from Liu et al.&nbsp;(2023)</figcaption>
</figure>
</div>
<p>Retrieving more information also increases the risk of including irrelevant information. If chunk ranking works correctly, lower ranking chunks are less likely to be relevant and adding them reduces the density of relevant information. <span class="citation" data-cites="levy2024tasktokensimpactinput">Levy, Jacoby, and Goldberg (2024)</span> found that irrelevant information isn’t neutral, it’s detrimental to model performance on a question-answering task.</p>
</section>
<section id="more-functions-for-agentic-models" class="level3">
<h3 class="anchored" data-anchor-id="more-functions-for-agentic-models">4. More functions for agentic models</h3>
<p>Models used as agents are given function signatures in a JSON schema. Each of these has to be sent to the model as part of the prompt. The more functions and the more arguments they have, the longer the prompt. With lower prompt costs, it’s becoming more economical to have agents with many different and more detailed functions in their repertoire.</p>
<p>Common functions include:</p>
<ul>
<li>Send a task to a sub-agent</li>
<li>Web search</li>
<li>Query a database by using text-to-SQL</li>
<li>Redirect to a human agent</li>
<li>Call a REST API, e.g.&nbsp;to send an email or schedule a meeting</li>
<li>Execute code in Python, JavaScript or another language</li>
</ul>
<p>The Berkeley function calling leaderboard <span class="citation" data-cites="berkeley-function-calling-leaderboard">(Yan et al. 2024)</span> offers detailed benchmarks for a variety of function calling tasks.</p>
</section>
</section>
<section id="conclusion-revisit-your-prompts" class="level2">
<h2 class="anchored" data-anchor-id="conclusion-revisit-your-prompts">Conclusion: revisit your prompts</h2>
<p>In 2023, the cost of long prompts was a major concern. Each input token was precious. This has changed with the introduction of prompt caching and a massive reduction in input token cost. It’s worth reevaluating prompts and consider whether adding more information would benefit the application.</p>
<p>About the title: 5-7-5 refers to the syllable count in a haiku, a form of short poetry from Japan.</p>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0">
<div id="ref-agarwal2024manyshotincontextlearning" class="csl-entry">
Agarwal, Rishabh, Avi Singh, Lei M. Zhang, Bernd Bohnet, Luis Rosias, Stephanie Chan, Biao Zhang, et al. 2024. <span>“Many-Shot in-Context Learning.”</span> <a href="https://arxiv.org/abs/2404.11018">https://arxiv.org/abs/2404.11018</a>.
</div>
<div id="ref-ainslie2023gqatraininggeneralizedmultiquery" class="csl-entry">
Ainslie, Joshua, James Lee-Thorp, Michiel de Jong, Yury Zemlyanskiy, Federico Lebrón, and Sumit Sanghai. 2023. <span>“GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints.”</span> <a href="https://arxiv.org/abs/2305.13245">https://arxiv.org/abs/2305.13245</a>.
</div>
<div id="ref-bertsch2024incontextlearninglongcontextmodels" class="csl-entry">
Bertsch, Amanda, Maor Ivgi, Uri Alon, Jonathan Berant, Matthew R. Gormley, and Graham Neubig. 2024. <span>“In-Context Learning with Long-Context Models: An in-Depth Exploration.”</span> <a href="https://arxiv.org/abs/2405.00200">https://arxiv.org/abs/2405.00200</a>.
</div>
<div id="ref-hsieh2024rulerwhatsrealcontext" class="csl-entry">
Hsieh, Cheng-Ping, Simeng Sun, Samuel Kriman, Shantanu Acharya, Dima Rekesh, Fei Jia, Yang Zhang, and Boris Ginsburg. 2024. <span>“RULER: What’s the Real Context Size of Your Long-Context Language Models?”</span> <a href="https://arxiv.org/abs/2404.06654">https://arxiv.org/abs/2404.06654</a>.
</div>
<div id="ref-hu2021loralowrankadaptationlarge" class="csl-entry">
Hu, Edward J., Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. 2021. <span>“LoRA: Low-Rank Adaptation of Large Language Models.”</span> <a href="https://arxiv.org/abs/2106.09685">https://arxiv.org/abs/2106.09685</a>.
</div>
<div id="ref-kwon2023efficientmemorymanagementlarge" class="csl-entry">
Kwon, Woosuk, Zhuohan Li, Siyuan Zhuang, Ying Sheng, Lianmin Zheng, Cody Hao Yu, Joseph E. Gonzalez, Hao Zhang, and Ion Stoica. 2023. <span>“Efficient Memory Management for Large Language Model Serving with PagedAttention.”</span> <a href="https://arxiv.org/abs/2309.06180">https://arxiv.org/abs/2309.06180</a>.
</div>
<div id="ref-leng2024longcontextrag" class="csl-entry">
Leng, Quinn, Jacob Portes, Sam Havens, Matei Zaharia, and Michael Carbin. 2024. <span>“Long Context RAG Performance of LLMs.”</span> <a href="https://www.databricks.com/blog/long-context-rag-performance-llms" class="uri">https://www.databricks.com/blog/long-context-rag-performance-llms</a>.
</div>
<div id="ref-levy2024tasktokensimpactinput" class="csl-entry">
Levy, Mosh, Alon Jacoby, and Yoav Goldberg. 2024. <span>“Same Task, More Tokens: The Impact of Input Length on the Reasoning Performance of Large Language Models.”</span> <a href="https://arxiv.org/abs/2402.14848">https://arxiv.org/abs/2402.14848</a>.
</div>
<div id="ref-liu2023lostmiddlelanguagemodels" class="csl-entry">
Liu, Nelson F., Kevin Lin, John Hewitt, Ashwin Paranjape, Michele Bevilacqua, Fabio Petroni, and Percy Liang. 2023. <span>“Lost in the Middle: How Language Models Use Long Contexts.”</span> <a href="https://arxiv.org/abs/2307.03172">https://arxiv.org/abs/2307.03172</a>.
</div>
<div id="ref-log2023kvcache" class="csl-entry">
Log, Matt. 2023. <span>“What Is the KV Cache?”</span> https://mett29.github.io/posts/kv-cache/.
</div>
<div id="ref-berkeley-function-calling-leaderboard" class="csl-entry">
Yan, Fanjia, Huanzhi Mao, Charlie Cheng-Jie Ji, Tianjun Zhang, Shishir G. Patil, Ion Stoica, and Joseph E. Gonzalez. 2024. <span>“Berkeley Function Calling Leaderboard.”</span> In. <a href="https://gorilla.cs.berkeley.edu/blogs/8_berkeley_function_calling_leaderboard.html" class="uri">https://gorilla.cs.berkeley.edu/blogs/8_berkeley_function_calling_leaderboard.html</a>.
</div>
</div></section></div> ]]></description>
  <category>Machine Learning</category>
  <guid>https://simmering.dev/blog/long-prompts/</guid>
  <pubDate>Sat, 31 Aug 2024 22:00:00 GMT</pubDate>
  <media:content url="https://simmering.dev/blog/long-prompts/image.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>OpenAI’s structured output vs. instructor and outlines</title>
  <dc:creator>Paul Simmering</dc:creator>
  <link>https://simmering.dev/blog/openai_structured_output/</link>
  <description><![CDATA[ 






<p>On August 6 OpenAI released <a href="https://openai.com/index/introducing-structured-outputs-in-the-api/">structured outputs</a> in their API. Is structured outputs a replacement for instructor, outlines and other libraries that provide structured outputs for language models? Let’s compare them.</p>
<p>OpenAI’s structured outputs makes the following code possible:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> json</span>
<span id="cb1-2"></span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pydantic <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> BaseModel</span>
<span id="cb1-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> openai <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> OpenAI</span>
<span id="cb1-5"></span>
<span id="cb1-6"></span>
<span id="cb1-7"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> Ingredient(BaseModel):</span>
<span id="cb1-8">    name: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span></span>
<span id="cb1-9">    amount: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span></span>
<span id="cb1-10">    kcal: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span></span>
<span id="cb1-11"></span>
<span id="cb1-12"></span>
<span id="cb1-13"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> Recipe(BaseModel):</span>
<span id="cb1-14">    ingredients: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>[Ingredient]</span>
<span id="cb1-15">    instructions: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span></span>
<span id="cb1-16"></span>
<span id="cb1-17"></span>
<span id="cb1-18">client <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> OpenAI()</span>
<span id="cb1-19"></span>
<span id="cb1-20">completion <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> client.beta.chat.completions.parse(</span>
<span id="cb1-21">    model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"gpt-4o-2024-08-06"</span>,</span>
<span id="cb1-22">    messages<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[{<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"role"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"user"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"content"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Write an apple pie recipe"</span>}],</span>
<span id="cb1-23">    response_format<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>Recipe,</span>
<span id="cb1-24">)</span>
<span id="cb1-25"></span>
<span id="cb1-26">apple_pie_recipe <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Recipe(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>json.loads(completion.choices[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].message.content))</span></code></pre></div></div>
<p>It’s guaranteed that the output will be JSON that can be parsed into a <code>Recipe</code> object. The code looks very similar to the code you’d write with any of the <a href="../../blog/structured_output/">10 libraries</a> I compared in May.</p>
<p>Besides removing the need for a library, structured output works quite differently from function calling under the hood. With function calling the model is trained to follow an instruction given as a JSON schema and is likely but not guaranteed to follow it. At any token position it’s still free to output a token that doesn’t fit the schema. With structured output, the output of the model is constrained to fit the schema. This is the same approach as the <a href="https://github.com/outlines-dev/outlines">outlines</a> library uses for open source models.</p>
<section id="pros-and-cons" class="level2">
<h2 class="anchored" data-anchor-id="pros-and-cons">Pros and cons</h2>
<p>The structured output feature has several advantages over function calling:</p>
<ol type="1">
<li>✅ The definition of the output format doesn’t count as input tokens, making it significantly cheaper, especially for short input messages and complex output formats.</li>
<li>✅ The output is 100% guaranteed to follow the structure, in contrast to JSON mode and function calling which are just very likely to follow the structure.</li>
<li>✅ It doesn’t slow down the generation process, rather it speeds it up because tokens with no alternatives can be automatically placed rather than generated by the model.</li>
</ol>
<p>But also some downsides:</p>
<ol type="1">
<li>❌ OpenAI’s implementation only works with its own models.</li>
<li>❌ It only supports a subset of JSON schema. In particular, they don’t support <code>minLength</code> and <code>maxLength</code> constraints. See their <a href="https://platform.openai.com/docs/guides/structured-outputs">docs</a>. These are supported by outlines and instructor.</li>
<li>❌ The first API call with a schema has a higher latency than subsequent calls because the schema has to be compiled.</li>
</ol>
<p>I expect that the first two downsides will be addressed in the future. Thanks to the outlines library, the implementation of structured outputs is already available for open source models. Perhaps providers like Fireworks AI and Groq will adopt it with the same API specification as OpenAI. They’ve done this with function calling. In turn, platform-agnostic libraries like mirascope, marvin and instructor may adopt it as well.</p>
</section>
<section id="are-instructor-and-other-structured-output-libraries-obsolete" class="level2">
<h2 class="anchored" data-anchor-id="are-instructor-and-other-structured-output-libraries-obsolete">Are instructor and other structured output libraries obsolete?</h2>
<p>Right after the announcement, Jason Liu, author of instructor posted:</p>
<blockquote class="blockquote">
<p>They solved instructor.</p>
</blockquote>
<p>on <a href="https://x.com/jxnlco/status/1820880349288595629">X</a>. Later he added a longer <a href="https://x.com/jxnlco/status/1820976130096074940">post</a> with his thoughts.</p>
<p>Yes, the core value proposition of: “give me a Pydantic model and I’ll use function calling to guarantee the output fits the schema” is now covered for OpenAI models, but only for OpenAI models. If you’re using other models or want to stay flexible, structured output libraries are still useful. Each library also comes with additional features, as I’ve covered in my <a href="../../blog/structured_output/">comparison</a>. Examples are multiple provider support, error handling, caching, chaining and more.</p>
<p>So in short: no, they’re not obsolete, but their space is getting squeezed.</p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>If you’re exclusively using OpenAI models and only need basic structured responses, I recommend using OpenAI’s structured outputs. It’s the most convenient, secure and cheapest method. If you prefer other LLM providers or want your code to be provider-agnostic, I recommend sticking with outlines (if self-hosting) or instructor (if using API providers).</p>


</section>

 ]]></description>
  <category>Machine Learning</category>
  <category>Python</category>
  <guid>https://simmering.dev/blog/openai_structured_output/</guid>
  <pubDate>Fri, 09 Aug 2024 22:00:00 GMT</pubDate>
  <media:content url="https://simmering.dev/blog/openai_structured_output/image.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Levels of Abstraction in the LLM Stack</title>
  <dc:creator>Paul Simmering</dc:creator>
  <link>https://simmering.dev/blog/abstractions/</link>
  <description><![CDATA[ 






<p>Training and serving LLMs requires a tall software stack. You can engage with this stack at different levels of abstraction, from low-level frameworks like CUDA to ready-to-go inference APIs like the OpenAI API. The aim of this article is to provide an overview of the abstraction levels and help you choose the right one for your project. Typical questions are:</p>
<ul>
<li>“<em>Should I use OpenAI’s GPT models or an open source model?</em>”</li>
<li>“<em>Should I use HuggingFace transformers or load the model into PyTorch directly?</em>”</li>
<li>“<em>Should I use AWS SageMaker or rent plain EC2 instances and manage everything myself?</em>”</li>
</ul>
<p>The choice depends on you and your project, but this overview and the decision criteria at the end may help you decide. I’ll discuss 3 levels of abstraction:</p>
<ol type="1">
<li>Open source tools and frameworks</li>
<li>Managed LLM services, e.g.&nbsp;AWS SageMaker</li>
<li>Cloud APIs, e.g.&nbsp;OpenAI</li>
</ol>
<section id="open-source-llm-stack" class="level2">
<h2 class="anchored" data-anchor-id="open-source-llm-stack">1. Open source LLM stack</h2>
<p>The open source LLM stack is the most flexible and customizable option and what is underlying the other two options. It consists of several layers. The list below has examples of tools at each level. I’ve not included optional MLOps tools like experiment tracking, monitoring, model store etc. which are not on the critical path for training and serving LLMs.</p>
<p>The term open source is not accurate for the lowest levels: hardware is proprietary and Nvidia holds a near-monopoly on GPUs for machine learning. Cloud providers are also proprietary, but there are many to choose from and they allow running open source software.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 17%">
<col style="width: 33%">
<col style="width: 48%">
</colgroup>
<thead>
<tr class="header">
<th>Level</th>
<th>Description</th>
<th>Examples</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1. Hardware</td>
<td>Physical graphics processors with high VRAM</td>
<td>Nvidia H100, AMD MI350, Intel Gaudi 3</td>
</tr>
<tr class="even">
<td>2. Cloud Providers</td>
<td>Platforms offering rentable GPU resources for LLM training and inference</td>
<td>AWS, Google Cloud, Azure, Modal, Lambda Labs</td>
</tr>
<tr class="odd">
<td>3. Acceleration Framework</td>
<td>Software interfaces for efficient use of GPUs for machine learning</td>
<td>CUDA, ROCm</td>
</tr>
<tr class="even">
<td>4. Distributed Computing</td>
<td>Libraries for distributing training workloads across multiple GPUs and machines</td>
<td>DeepSpeed, horovod, Ray, accelerate</td>
</tr>
<tr class="odd">
<td>5. Low-level Frameworks</td>
<td>Core libraries for building and training large language models</td>
<td>PyTorch, TensorFlow, JAX</td>
</tr>
<tr class="even">
<td>6. High-level Frameworks</td>
<td>Libraries that build on top of low-level frameworks to simplify common uses</td>
<td>Hugging Face Transformers, PyTorch Lightning, Axolotl</td>
</tr>
<tr class="odd">
<td>7. Inference Engine</td>
<td>Software for efficient LLM execution and serving</td>
<td>vLLM, llama.cpp, TorchServe, ONNX</td>
</tr>
<tr class="even">
<td>8. LLM Orchestration</td>
<td>Tools for prompting and chaining LLM calls, constraining and censoring output. These are also compatible with managed ML services and inference APIs</td>
<td>LangChain, llamaindex, litellm, instructor, outlines, guardrails</td>
</tr>
</tbody>
</table>
<p>To illustrate, let’s compare the type of code you’d write at the low and high levels of abstraction.</p>
<p>Creating a simple neural network in PyTorch:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch.nn <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> nn</span>
<span id="cb1-3"></span>
<span id="cb1-4"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> MyModel(nn.Module):</span>
<span id="cb1-5">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>):</span>
<span id="cb1-6">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">super</span>().<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>()</span>
<span id="cb1-7">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.l1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.Linear(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">768</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">512</span>)</span>
<span id="cb1-8">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.l2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.Linear(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">512</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">256</span>)</span>
<span id="cb1-9">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.l3 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.Linear(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">256</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb1-10"></span>
<span id="cb1-11">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> forward(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, x):</span>
<span id="cb1-12">        x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.relu(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.l1(x))</span>
<span id="cb1-13">        x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.relu(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.l2(x))</span>
<span id="cb1-14">        x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.l3(x)</span>
<span id="cb1-15">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> x</span></code></pre></div></div>
<p>Loading a pre-trained transformer model from Hugging Face:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> transformers <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> BertTokenizer, BertForSequenceClassification</span>
<span id="cb2-2"></span>
<span id="cb2-3">tokenizer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> BertTokenizer.from_pretrained(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'bert-base-uncased'</span>)</span>
<span id="cb2-4">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> BertForSequenceClassification.from_pretrained(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'bert-base-uncased'</span>)</span></code></pre></div></div>
<p>PyTorch confronts you with the details of layers, their sizes, activation functions and more. Hugging Face abstracts them away.</p>
<section id="more-alternatives-at-higher-levels" class="level3">
<h3 class="anchored" data-anchor-id="more-alternatives-at-higher-levels">More alternatives at higher levels</h3>
<p>There tend to be more alternatives the higher you go in the stack. Recently, I’ve <a href="../../blog/structured_output/">compared</a> 10 different libraries for structured LLM outputs, all at the highest level of abstraction. In contrast, there is no widely used alternative to Nvidia GPUs and CUDA for the hardware and acceleration levels.</p>
</section>
<section id="too-much-abstraction" class="level3">
<h3 class="anchored" data-anchor-id="too-much-abstraction">Too much abstraction?</h3>
<p>There is such a thing as too many layers of abstractions. Hamel Husain put it well in his article: <a href="https://hamel.dev/blog/posts/prompt/">“Fuck You, Show Me The Prompt”</a>. Make sure you know which tokens are actually being sent to the LLM, and whether there’s more than one round-trip involved in getting a response. For education, too many layers can also hinder understanding. Andrej Karpathy is known for re-implementing the GPT architecture for education, for example <a href="https://github.com/karpathy/nanoGPT">nanoGPT</a>, which is GPT2 in ~600 lines of Python.</p>
</section>
<section id="fine-tune-dont-train-from-scratch" class="level3">
<h3 class="anchored" data-anchor-id="fine-tune-dont-train-from-scratch">Fine-tune, don’t train from scratch</h3>
<p>Training LLMs from scratch is almost never worth it for organizations whose main business isn’t providing foundation models for others. It requires far too much training data and GPU hours. As an example, even the smallest of Meta’s Llama 3.1 models was trained for 1.46M GPU hours (<a href="https://huggingface.co/blog/llama31#:~:text=The%20Llama%203.1%20models%20were%20trained%20on%20over,for%208B%2C%207.0M%20for%2070B%2C%2030.84M%20for%20405B%29.">source</a>). In contrast, fine-tuning a LoRA adapter for that model can be done in less than 1 GPU hour on an H100.</p>
<p>When working with lower-level libraries like PyTorch, it’s therefore necessary to start by copying the architecture of an existing LLM and loading its weights. Tweaks like a new output layer must be done carefully in order to preserve the usefulness of the learned weights. This is in contrast to less compute-intensive machine learning models, where training one’s own model from scratch is common. For these reasons, starting from a high-level framework like Hugging Face Transformers is more common for working with LLMs.</p>
</section>
</section>
<section id="managed-ml-services" class="level2">
<h2 class="anchored" data-anchor-id="managed-ml-services">2. Managed ML services</h2>
<p>AWS SageMaker, Google Cloud AI Platform, and Azure Machine Learning are examples of managed LLM services. They wrap the DIY stack in their cloud infrastructure, providing a unified interface for training, serving and monitoring models. Essentially, these services bundle the DIY stack into a single product, freeing you from having to manage the details. You still have a selection of open source models to fine-tuned with your own data.</p>
<p>This approach caters to enterprises with large-scale ML needs and tight security requirements. They’re typically already using the cloud provider for other services and want to keep everything in one place.</p>
</section>
<section id="inference-apis" class="level2">
<h2 class="anchored" data-anchor-id="inference-apis">3. Inference APIs</h2>
<p>Pre-trained LLMs are offered via API by OpenAI, Anthropic and many others including cloud providers with services like AWS Bedrock. These APIs are the highest level of abstraction, letting you directly connect your app to a powerful LLM without any setup or training. The downside is that you have the least control over the model and your data.</p>
<p>Some inference API providers, like Fireworks.ai also offer fine-tuning, getting close to the level of control you’d have with a managed service.</p>
</section>
<section id="choosing-the-right-level-of-abstraction" class="level2">
<h2 class="anchored" data-anchor-id="choosing-the-right-level-of-abstraction">Choosing the right level of abstraction</h2>
<p>Which level of abstraction do you want to work at?</p>
<section id="high-level-of-abstraction" class="level3">
<h3 class="anchored" data-anchor-id="high-level-of-abstraction">High level of abstraction</h3>
<p>Choose a higher level of abstraction if you:</p>
<ul>
<li>Are a beginner seeking quick first successes</li>
<li>Work at a startup focused on product-market fit</li>
<li>Are a researcher in a different field wishing to use LLMs</li>
<li>Want to integrate LLMs without deep ML expertise</li>
<li>Are already committed to a specific cloud ecosystem</li>
<li>Have no need for deep customization of models (you’d know if you did)</li>
</ul>
<p>The danger of choosing a too high level of abstraction is that you may hit a wall when you need to do something the tool doesn’t support. For example, OpenAI’s API doesn’t support reinforcement learning from human feedback (RLHF), only supervised fine-tuning. If you need RLHF, you’d have to switch to a lower level of abstraction.</p>
</section>
<section id="low-level-of-abstraction" class="level3">
<h3 class="anchored" data-anchor-id="low-level-of-abstraction">Low level of abstraction</h3>
<p>Opt for a lower level of abstraction if you:</p>
<ul>
<li>Are a researcher or engineer pushing LLM boundaries</li>
<li>Require fine-grained control over the model</li>
<li>Need on-premises or on-device deployment</li>
<li>Desire a deep understanding of the underlying technology</li>
<li>Prioritize code and model portability</li>
<li>Have engineers familiar with distributed systems and GPU programming</li>
</ul>
<p>The danger of choosing a too low level of abstraction is that you may spend too much time on infrastructure and not enough on the actual problem you’re trying to solve. For example, if you’re building a prototype for a meeting summarization chatbot, your time is better spent talking to project managers than optimizing your distributed training setup.</p>
</section>
<section id="cost-can-go-both-ways" class="level3">
<h3 class="anchored" data-anchor-id="cost-can-go-both-ways">Cost can go both ways</h3>
<p>High level tools can add a tax, but prices have been decreasing quickly. Managed services and API providers can leverage economies of scale and have highly optimized infrastructure. This can be difficult to achieve with a DIY stack. For example, a privately owned GPU deployed for inference may be underutilized outside of business hours, while a GPU at a cloud provider services other customers.</p>
</section>
<section id="keep-your-training-data-portable" class="level3">
<h3 class="anchored" data-anchor-id="keep-your-training-data-portable">Keep your training data portable</h3>
<p>The linear progression from low to high abstraction is a simplification. As the ecosystem matures, interoperability increases. For example, Hugging Face Transformers abstracts away the model architecture, but you can still access the PyTorch model and adjust it. Then that model can be deployed to AWS SageMaker. Not all combinations are possible though - for example a GPT model fine-tuned on OpenAI’s API can only run on that account. When it’s cheap to do so, use solutions that have as little lock-in as possible. Especially your training data should remain portable. In a time where research labs one-up each other weekly with better base models, being able to switch to a new model quickly is an advantage.</p>


</section>
</section>

 ]]></description>
  <category>Machine Learning</category>
  <guid>https://simmering.dev/blog/abstractions/</guid>
  <pubDate>Wed, 07 Aug 2024 22:00:00 GMT</pubDate>
  <media:content url="https://simmering.dev/blog/abstractions/image.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Less stress, more focus: How to handle waiting times in development</title>
  <dc:creator>Paul Simmering</dc:creator>
  <link>https://simmering.dev/blog/waiting/</link>
  <description><![CDATA[ 






<p>It’s unfortunate, but there are many waiting times in data science. Dealing with them well can make work more productive and enjoyable. Common waiting times include:</p>
<ul>
<li>model is training</li>
<li>data pipeline is running</li>
<li>report is rendering</li>
<li>Docker image is building</li>
<li>tests are running</li>
<li>someone else is reviewing your code</li>
<li>huge upload/download</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/waiting/compiling.png" class="img-fluid figure-img"></p>
<figcaption>Waiting isn’t new in software development. <a href="https://xkcd.com/303/">XKCD 303</a></figcaption>
</figure>
</div>
<p>These waits range from seconds to days.</p>
<p>Ideally, there would not be any waiting times. Many can be eliminated or reduced Here are the top strategies, ranked by effectiveness in my experience:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 29%">
<col style="width: 44%">
<col style="width: 26%">
</colgroup>
<thead>
<tr class="header">
<th>Strategy</th>
<th>Effectiveness</th>
<th>Downsides</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Caching results</td>
<td>Very high, cuts wait times to zero</td>
<td>Stale data</td>
</tr>
<tr class="even">
<td>Indexing databases</td>
<td>High, can massively speed up queries</td>
<td>Not always possible, slows down writes</td>
</tr>
<tr class="odd">
<td>Mocking dependencies</td>
<td>High, can speed up tests</td>
<td>Adds complexity</td>
</tr>
<tr class="even">
<td>Running with smaller inputs</td>
<td>High, can speed up debugging</td>
<td>Not the real result</td>
</tr>
<tr class="odd">
<td>Writing more efficient code</td>
<td>Medium, can speed up code</td>
<td>It’s hard</td>
</tr>
<tr class="even">
<td>Parallelizing code</td>
<td>Medium, can speed up code</td>
<td>Hard and adds complexity</td>
</tr>
<tr class="odd">
<td>Using faster hardware</td>
<td>Medium, can speed up code</td>
<td>Expensive, not always effective</td>
</tr>
</tbody>
</table>
<p>It’s very easy to lose 50% or more of one’s productivity to waiting times. The most common form is an inefficient debug cycle: change code, wait for build, run code, wait for results, repeat. Bonus points if the code is a CI/CD pipeline.</p>
<p>Eliminating a waiting time in a workflow is a huge win, especially when multiple people are using the same workflow.</p>
<p>However, many waiting times are unavoidable, especially when working with large language models. Given that these wait times occur regularly, it makes sense to put together a little plan for what to do with them.</p>
<p>I suggest spending the time in a way that guards focus and short-term memory of the work at hand. Else, you’re effectively doing this:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/waiting/focus.jpeg" class="img-fluid figure-img"></p>
<figcaption>Programmer focus (from Monkeyuser.com)</figcaption>
</figure>
</div>
<p>Except the interruptions are self-inflicted.</p>
<p>The longer the wait is, the more it’s worth to switch context. Here’s a rough, opinionated guide based on my experience and research by <a href="http://www.chrisparnin.me/pdf/parnin-sqj11.pdf">Parnin and Rugaber (2010)</a>. The authors measure <em>edit lag</em>, the time between a developer returning to a task and making the first edit. In a study of 10,000 Java developers, they measured these edit lags:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/waiting/edit_lag.png" class="img-fluid figure-img"></p>
<figcaption>Edit lag, Parning and Rugaber (2010)</figcaption>
</figure>
</div>
<p>For difficult tasks, the edit lag after an interruption can easily exceed the length of the interruption itself. Let’s get to the tactics to handle waiting times.</p>
<section id="seconds-to-minutes" class="level2">
<h2 class="anchored" data-anchor-id="seconds-to-minutes">Seconds to minutes</h2>
<p>These wait times can turn into interruptions, but they don’t have to. It’s tempting to fill smaller breaks with social media or news. However, this floods the short-term memory with new information, replacing the context of the work you were doing. Plus, scrolling is addictive and tends to exceed the actual wait time.</p>
<p>If possible, resist the urge to switch context. It’s ok to just wait for a moment. Look out the window, stretch, take a sip of water, breathe. If you must do something, I suggest doing a physical task like tidying up your desk or making a cup of tea, rather than a computer task.</p>
</section>
<section id="minutes-to-an-hour" class="level2">
<h2 class="anchored" data-anchor-id="minutes-to-an-hour">Minutes to an hour</h2>
<p>This is too long to just do nothing. Before switching context, try to leave an intentional cue for yourself to pick up where you left off, such as a TODO comment that lets you pick up the thread. Keep the IDE open with the file you were working on.</p>
<p>Ideally, pick a little task that is still relevant to your main task. Read through the code, write a comment, plan your next steps, write another test or refactor a small piece of code. Alternatively take a little break or knock out some easy tasks, such as answering emails.</p>
<p>Starting a new big task is not worth it, as it would take a ramp-up time to get back into the context of that task first. This is one of the main points behind Paul Graham’s <a href="http://www.paulgraham.com/makersschedule.html">Maker’s Schedule, Manager’s Schedule</a>.</p>
</section>
<section id="hours-to-days" class="level2">
<h2 class="anchored" data-anchor-id="hours-to-days">Hours to days</h2>
<p>Outside of training large models or running simulations, waiting times this long shouldn’t occur for technical reasons. If they do, it’s a sign that a process is not well-optimized. Fix the process, don’t suffer this wait time too often.</p>
<p>For processes involving humans this sort of wait time is normal though. There the best strategy is to have a plan for what to do during the wait time. When allocating tasks in a team I suggest that every developer has one or more backup tasks that can be worked on when waiting on something on the main task.</p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>Waiting times are a fact of life in data science. They can be reduced, but not eliminated. It’s worth having a plan for how to spend the time to avoid losing focus and short-term memory. This can make work not just more productive but also more enjoyable, as the stress of re-finding context is reduced.</p>


</section>

 ]]></description>
  <category>Productivity</category>
  <guid>https://simmering.dev/blog/waiting/</guid>
  <pubDate>Sat, 27 Jul 2024 22:00:00 GMT</pubDate>
  <media:content url="https://simmering.dev/blog/waiting/clocks.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Text Tournament: Rank Marketing Copy with LLMs</title>
  <dc:creator>Paul Simmering</dc:creator>
  <link>https://simmering.dev/blog/text-tournament/</link>
  <description><![CDATA[ 






<p>The launch of the <a href="../../projects/aspectwise/index.html">review analysis project</a> has me working on various marketing tasks. Naturally, I built a tool to let LLMs help with the creative process. It’s called Text Tournament and the purpose is to compare ideas for company names, taglines, product descriptions and ad copy in a tournament-style competition. The project is available on <a href="https://github.com/psimm/text-tournament">GitHub</a> under the MIT license.</p>
<p>This is the companion blog post to the project which explains my thought process and technical details.</p>
<section id="the-tournament" class="level2">
<h2 class="anchored" data-anchor-id="the-tournament">The Tournament</h2>
<p>The user gives a set of competitors and a set of attributes. Each competitor is paired with every other competitor on each aspect. For example, if there are three name choices for a Spotify competitor, say ‘Streamio’, ‘MelodiX’ and ‘SoundWave’ and two attributes ‘memorability’ and ‘pronounceability’, the tournament would look like this:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Competitor 1</th>
<th>Competitor 2</th>
<th>Attribute</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Streamio</td>
<td>MelodiX</td>
<td>memorability</td>
</tr>
<tr class="even">
<td>Streamio</td>
<td>SoundWave</td>
<td>memorability</td>
</tr>
<tr class="odd">
<td>MelodiX</td>
<td>SoundWave</td>
<td>memorability</td>
</tr>
<tr class="even">
<td>Streamio</td>
<td>MelodiX</td>
<td>pronounceability</td>
</tr>
<tr class="odd">
<td>Streamio</td>
<td>SoundWave</td>
<td>pronounceability</td>
</tr>
<tr class="even">
<td>MelodiX</td>
<td>SoundWave</td>
<td>pronounceability</td>
</tr>
</tbody>
</table>
<p>Each of these pairings is turned into a prompt for the LLM, like “Compare the company names Streamio and MelodiX. Which one is more memorable?”</p>
<p>Each pairing is run twice, once as A vs.&nbsp;B and once as B vs.&nbsp;A. The reason is that LLMs tend to have a bias towards picking the first option <span class="citation" data-cites="dominguezolmedo2024questioningsurveyresponseslarge">(Dominguez-Olmedo, Hardt, and Mendler-Dünner 2024)</span>.</p>
</section>
<section id="structured-output-reasoning" class="level2">
<h2 class="anchored" data-anchor-id="structured-output-reasoning">Structured output &amp; reasoning</h2>
<p>To make sure that the LLM’s answer is interpretable, I used <a href="https://github.com/jxnl/instructor">instructor</a>. Further, I asked the model to not just pick the winner but also to provide a reason. This is done with a simple Pydantic model:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> Rating(BaseModel):</span>
<span id="cb1-2">    reason: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span></span>
<span id="cb1-3">    preferred: Literal[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>]</span></code></pre></div></div>
<p>By asking for the reason first, the tokens generated as the reason are influencing the token chosen for the “preferred” field. This makes use of the auto-regressive nature of the model.</p>
<p>The benefit of the reason is that it typically improves the model’s thinking and it also provides an inspectable record. For example, here are two outputs from the tournament above:</p>
<p>Streamio vs MelodiX on pronounceability:</p>
<blockquote class="blockquote">
<p>Streamio is straightforward to pronounce with a clear phonetic structure, while MelodiX may cause hesitation due to the unusual capital ‘X’ at the end.</p>
</blockquote>
<p>MelodiX vs SoundWave on memorability:</p>
<blockquote class="blockquote">
<p>The name ‘MelodiX’ is unique and contains a playful twist with the ‘X’ at the end, making it more distinctive and easier to remember. The name ‘SoundWave’ is more generic and can be easily confused with other similar terms in the tech and music industry.</p>
</blockquote>
</section>
<section id="ranking-competitors-with-the-bradley-terry-model" class="level2">
<h2 class="anchored" data-anchor-id="ranking-competitors-with-the-bradley-terry-model">Ranking competitors with the Bradley-Terry model</h2>
<p>The simplest approach is to count the number of wins for each competitor. However, this doesn’t take into account the strength of the competitors. A competitor that has only faced weak competitors might have a high win count but not be the best choice. I considered two ranking methods that account for this: the Elo <span class="citation" data-cites="elo1978rating">(Elo and Sloan 1978)</span> model and the Bradley-Terry <span class="citation" data-cites="bradley1952rank">(Bradley and Terry 1952)</span> model.</p>
<p>Elo is better known due to the popularity of ranking method in Chess. Many people are familiar with the concept of a player’s Elo rating and how it changes after a match.</p>
<p>The downside of Elo in this context is that ordering of the matches matters. Thce results of the LLM calls are coming in all at once. I’d have to artificially order the matches to use Elo. This is not ideal.</p>
<p>The Bradley-Terry model is a better fit for this situation. It’s a probabilistic model that estimates the strength of competitors based on the outcomes of matches.</p>
<p>The probability of competitor <img src="https://latex.codecogs.com/png.latex?i"> beating competitor <img src="https://latex.codecogs.com/png.latex?j"> is given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(i%20%5Ctext%7B%20beats%20%7D%20j)%20=%20%5Cfrac%7Br_i%7D%7Br_i%20+%20r_j%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?r_i"> is the strength of competitor <img src="https://latex.codecogs.com/png.latex?i">. The model is fit by modifying the strengths <code>r</code> to maximize the likelihood of the observed outcomes.</p>
<p>The Bradley-Terry model is also the basis for Direct Preference Optimization <span class="citation" data-cites="rafailov2024direct">(Rafailov et al. 2024)</span>. So I’m asking an LLM that was likely trained with DPO to do be a ranking model itself. So meta. This also means that the outputs of the ranking could be used as inputs to the DPO model. For example, a larger model could be used to teach a smaller model how to rank the competitors.</p>
</section>
<section id="results" class="level2">
<h2 class="anchored" data-anchor-id="results">Results</h2>
<p>I ran a tournament with more name options and additional attributes to compare them on. Here is the overall result:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/text-tournament/ranking.png" class="img-fluid figure-img"></p>
<figcaption>Tournament results</figcaption>
</figure>
</div>
<p>Does it match your preferences?</p>
<p>The full results with rankings on each attribute are available on this <a href="">Github page</a>.</p>
</section>
<section id="validity" class="level2">
<h2 class="anchored" data-anchor-id="validity">Validity</h2>
<p>The rankings produced by the tournament are not a replacement for tests with real users and human judgment. LLMs are known to be politically biased, may give random answers, and are heavily influenced by how a question is posed. The rankings are a tool to help with the creative process, not a definitive answer. If you decide to use it, I suggest starting with a low-stakes use case like the title of a blog post.</p>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0">
<div id="ref-bradley1952rank" class="csl-entry">
Bradley, Ralph Allan, and Milton E Terry. 1952. <span>“Rank Analysis of Incomplete Block Designs: I. The Method of Paired Comparisons.”</span> <em>Biometrika</em> 39 (3/4): 324–45.
</div>
<div id="ref-dominguezolmedo2024questioningsurveyresponseslarge" class="csl-entry">
Dominguez-Olmedo, Ricardo, Moritz Hardt, and Celestine Mendler-Dünner. 2024. <span>“Questioning the Survey Responses of Large Language Models.”</span> <a href="https://arxiv.org/abs/2306.07951">https://arxiv.org/abs/2306.07951</a>.
</div>
<div id="ref-elo1978rating" class="csl-entry">
Elo, Arpad E, and Sam Sloan. 1978. <span>“The Rating of Chessplayers: Past and Present.”</span>
</div>
<div id="ref-rafailov2024direct" class="csl-entry">
Rafailov, Rafael, Archit Sharma, Eric Mitchell, Christopher D Manning, Stefano Ermon, and Chelsea Finn. 2024. <span>“Direct Preference Optimization: Your Language Model Is Secretly a Reward Model.”</span> <em>Advances in Neural Information Processing Systems</em> 36.
</div>
</div></section></div> ]]></description>
  <category>Machine Learning</category>
  <category>Python</category>
  <category>Marketing</category>
  <guid>https://simmering.dev/blog/text-tournament/</guid>
  <pubDate>Mon, 22 Jul 2024 22:00:00 GMT</pubDate>
  <media:content url="https://simmering.dev/blog/text-tournament/tournament.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Let Research Settle Before Consuming It</title>
  <dc:creator>Paul Simmering</dc:creator>
  <link>https://simmering.dev/blog/settled-knowledge/</link>
  <description><![CDATA[ 






<p>The pace of publishing in machine learning is extremely high. There were 242,290 AI publications in 2022. That’s 663 per day, or one every two minutes. Based on comments on X, Reddit and Discord, I can see that many people feel FOMO, overwhelmed or inadequate because they can’t keep up, even in subfields they’re supposed to be experts in.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/settled-knowledge/publications.png" class="img-fluid figure-img"></p>
<figcaption>Number of AI publications by year, Source: <a href="https://aiindex.stanford.edu/report/">Stanford University AI Index 2024</a></figcaption>
</figure>
</div>
<p>For those who can afford it, the antidote is to deliberately let research settle before consuming it. This means holding off on reading papers and waiting for the ideas to be integrated into textbooks, video courses and libraries, or at least wait to see which papers are getting cited more than others. This has advantages:</p>
<ul>
<li><strong>Higher quality learning materials</strong>: The initial paper is rarely the best explanation or fullest version of an idea. It necessarily doesn’t have as many real world examples as later explanations. It comes from the single perspective of an author with the intent to communicate to peers that are equally deep in the field. Later explanations are written by people with a teaching background and have been refined by feedback and real world experiences. They also have more accessible formats. Most people find it easier to learn from a video course or a textbook than from a collection of papers.</li>
<li><strong>Higher quality software implementations</strong>: Software behind research papers is often brittle and not suitable for production. Waiting for a library to implement the idea means you get a more robust and better documented implementation. It’s also more likely to be compatible with other tools you’re using and easier to install.</li>
<li><strong>Less likely to be wrong or irrelevant</strong>: The initial paper may have a mistake or a result that’s not replicable with other datasets. It may be a theoretical dead end or be quickly surpassed by other research. Waiting a while lets the community sort out what actually works.</li>
</ul>
<p>Time for learning is precious. Spending it on debugging software or deciphering a paper that is later proven wrong is a waste. By delaying consumption of research your learning is more efficient so you can learn more and more long-term valuable skills in the same time.</p>
<p>Of course, waiting is a luxury that those in research can’t afford because they’d be scooped and forever behind the curve. Let’s rank roles in the ecosystem by how close they have to be to the cutting edge:</p>
<ol type="1">
<li>Research scientist in university or industry lab</li>
<li>Research engineer developing platforms for researchers</li>
<li>Novel software developer creating cutting-edge products</li>
<li>Consultant advising on business integration</li>
<li>General developer at a company that uses ML but not at the cutting edge</li>
<li>Developer in slow-moving industry exploring ML adoption</li>
</ol>
<p>The lower you are on the list, the longer you can afford to wait before consuming research. The dropoff is steep. A researcher needs to be up to date with the latest papers within weeks, while a developer in a slow-moving industry can wait multiple years before an idea could become relevant in their work.</p>
<p>Staying at the bleeding edge carries a cost in learning efficiency and stress. If your role permits it, consider letting research settle more before consuming it.</p>



 ]]></description>
  <category>Productivity</category>
  <guid>https://simmering.dev/blog/settled-knowledge/</guid>
  <pubDate>Fri, 19 Jul 2024 22:00:00 GMT</pubDate>
  <media:content url="https://simmering.dev/blog/settled-knowledge/spiral.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>The World is Large and Very Detailed</title>
  <dc:creator>Paul Simmering</dc:creator>
  <link>https://simmering.dev/blog/detailed-world/</link>
  <description><![CDATA[ 






<p><img src="https://simmering.dev/blog/detailed-world/world.jpg" class="img-fluid"></p>
<p>It’s easy to underestimate how vast and heterogeneous the world is. For entrepreneurs and developers this has two implications:</p>
<ol type="1">
<li>There are many niches to exploit.</li>
<li>It’s hard to scale.</li>
</ol>
<section id="detail-creates-opportunities" class="level2">
<h2 class="anchored" data-anchor-id="detail-creates-opportunities">Detail creates opportunities</h2>
<p>Some examples of detail: geography, languages, currencies, time zones, cultural norms, consumer preferences, age groups, currencies, laws, corporate structures, payment systems and so on. The detail is layered, like geographical features: countries contain states, which contain cities, which contain neighborhoods. Each combination of details creates a different environment for businesses to carve out their niche.</p>
<p>This puts a natural dampener on monopolies. The existence of an incumbent doesn’t mean that there is no room for a new player. This is most obvious in local businesses: just because there is a hairdresser in town doesn’t mean that there isn’t room for another in a different neighborhood. In digital businesses, this is less obvious but still true. Some examples:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>General incumbent</th>
<th>Competitor</th>
<th>Niche</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Zoom</td>
<td>Tuple</td>
<td>Remote pair programming</td>
</tr>
<tr class="even">
<td>Google</td>
<td>DuckDuckGo</td>
<td>Privacy-first search</td>
</tr>
<tr class="odd">
<td>AWS</td>
<td>Modal</td>
<td>Dev-friendly serverless platform</td>
</tr>
<tr class="even">
<td>Word</td>
<td>iA Writer</td>
<td>Distraction-free writing</td>
</tr>
<tr class="odd">
<td>Excel</td>
<td>AirTable</td>
<td>Linked records</td>
</tr>
<tr class="even">
<td>PowerPoint</td>
<td>Pitch</td>
<td>Pitch decks</td>
</tr>
<tr class="odd">
<td>VSCode</td>
<td>Cursor</td>
<td>AI-powered code completion</td>
</tr>
<tr class="even">
<td>Indeed</td>
<td>RemoteOK</td>
<td>Remote job board</td>
</tr>
<tr class="odd">
<td>Yelp</td>
<td>HappyCow</td>
<td>Vegan restaurant search</td>
</tr>
<tr class="even">
<td>Audible</td>
<td>Blinkist</td>
<td>Audio book summaries</td>
</tr>
</tbody>
</table>
<p>In each of these cases the job can be done using the general incumbent, but the competitors offer better experiences within their niches.</p>
<p>Even seemingly standardized technologies like SQL (officially <a href="https://blog.ansi.org/sql-standard-iso-iec-9075-2023-ansi-x3-135/">standardized</a> in 1986) have a huge number of <a href="https://db-engines.com/en/ranking">implementations</a>. Why? Because no single database covers every use case.</p>
<p>The level of detail of the world also provides a natural moat for employees against automation and offshoring.</p>
<ul>
<li>Self-driving cars have been in works for decades, but there are still millions of truck drivers. Why? Trucking is a detailed task that involves driving in all sorts of conditions, loading and unloading cargo and dealing with customers.</li>
<li>Remote work has been a thing for more than 10 years, but software companies still have expensive offices in the Bay Area populated by highly paid developers. Why? Because they have inertia, culture, social networks and talent density that only exist in that particular place.</li>
<li>Figma released its new <a href="https://www.figma.com/ai/">AI</a>. Does this mean that designers will be out of a job? No, because the AI doesn’t have the context and communication skills that a designer has.</li>
</ul>
</section>
<section id="detail-is-the-enemy-of-scaling" class="level2">
<h2 class="anchored" data-anchor-id="detail-is-the-enemy-of-scaling">Detail is the enemy of scaling</h2>
<p>In the same way that detail creates niches, it also inhibits scaling because each new detail requires a new solution. If the world is infinitely detailed, a given solution only applies to an infinitesimally small part of the world.</p>
<p>But the practical level of detail is not infinite: the further you zoom out the more systems and standards become visible. The laws of physics are the same everywhere. A microprocessor works the same way in Paris as in Tokyo. More than 5.4 billion people have a <a href="https://www.weforum.org/agenda/2023/04/charted-there-are-more-phones-than-people-in-the-world/">mobile phone</a>.</p>
<p>This unlocks huge economies of scale: technology that is applicable in many conditions can be invented once, mass-manufactured or copy-pasted millions of times, and used by millions of people. That is why technology companies are the <a href="https://companiesmarketcap.com">most valuable companies</a> in the world.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/detailed-world/marketcap.png" class="img-fluid figure-img"></p>
<figcaption>Largest companies by market cap. From companiesmarketcap.com, July 13 2024</figcaption>
</figure>
</div>
<p>Standardization can turn to natural monopolies when network effects come into play. The more people use a communication platform or a marketplace, the more valuable it becomes. This is why Facebook, Google and Amazon are so dominant. Standardization can also create monopolies to due scale, hence the dominance of TSMC in the semiconductor space.</p>
<p>But it’s also easy to overestimate how much can be standardized. Recently, a friend of mine who works in finance cautioned me about specializing in machine learning. He argued that the field is essentially solved because an LLM can answer any question. The economy needs one research company to develop the model and everyone else just uses their API. Applied LLM developers <a href="https://applied-llms.org/#enough-0-to-1-demos-its-time-for-1-to-n-products">disagree</a>. Building an LLM demo is easy, but real products must meet a much higher bar.</p>
<div class="grid">
<div class="g-col-6">
<p>It’s at this stage that the details of the world painfully intrude. Real world data is often incomplete, noisy, biased, inaccessible or in the wrong format. Predictions may be inaccurate or lack context of the business. The standard chat interface is not suitable for most actual use cases. This is why there is an army of data scientists and <a href="https://www.nytimes.com/2024/06/26/technology/ai-consultants.html">consultants</a> working as “technology sherpas” on the last-mile problems of LLMs. Realizing the economic benefits of LLMs may well require more consultants and software developers than actual ML researchers.</p>
</div>
<div class="g-col-6">
<p><img src="https://simmering.dev/blog/detailed-world/llm_needs.png" class="img-fluid"></p>
</div>
</div>
<p>But my friend isn’t all wrong. Hundreds of startups are building on top of OpenAI’s models. Smartly, OpenAI is leaving the last-mile problems to others and focusing on the core, scalable, and in a way less detailed, technology.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/detailed-world/openai.png" class="img-fluid figure-img" style="width:75.0%"></p>
<figcaption>OpenAI as a platform for companies serving niches</figcaption>
</figure>
</div>
<p>This positioning as the default source of intelligence is lucrative, but requires enormous upfront investment and must be defended against competition. By now, 01 AI, Anthropic, Google, Nvidia and others have released models that have <a href="https://chat.lmsys.org/?leaderboard">surpassed</a> the original GPT-4 model. It models are only measured by their arena benchmark, it’s hard to differentiate. More detail-oriented niches offer more ways to differentiate and are generally less competitive.</p>
</section>
<section id="strategy" class="level2">
<h2 class="anchored" data-anchor-id="strategy">Strategy</h2>
<p>Scalability and detail can be seen in a matrix:</p>
<p><img src="https://simmering.dev/blog/detailed-world/matrix.png" class="img-fluid" style="width:75.0%"></p>
<ul>
<li><strong>New Platforms</strong>: A new technology or business model emerged and has catapulted a company to the top. Their offering is basic but scalable. Examples: OpenAI in 2023, Zoom in 2020, Google in 2000. Naming the year is required because this position is not stable, unless it’s a natural monopoly.</li>
<li><strong>Mature Platforms</strong>: Over time, the platform has added more features and detail to cater to more niches. Examples: AWS, Facebook, MS Office, Stripe. In software, this carries the risk of becoming bloated.</li>
<li><strong>Consulting &amp; bespoke software</strong>: Dealing with each client’s needs separately. Scale is achieved by hiring more people or working more hours. Examples: Accenture, Capgemini, Infosys, freelancers, local businesses.</li>
<li><strong>Failure</strong>: The company has an undifferentiated offering and hasn’t achieved scale. It’s unlikely to survive in the long term.</li>
</ul>
<p>There are plenty of niches to exploit and the existence of an incumbent can be taken as a signal that there is a market, rather than that the market is saturated. The hard part isn’t to find just any niche, but a niche large enough and amenable to scaling.</p>
<p>Questions for entrepreneurs and investors:</p>
<ul>
<li>Where do general incumbents fail to meet the needs of a niche?</li>
<li>What types of scale does the niche support?</li>
<li>Which details can I safely ignore or fix later?</li>
</ul>


</section>

 ]]></description>
  <category>Economics</category>
  <guid>https://simmering.dev/blog/detailed-world/</guid>
  <pubDate>Fri, 12 Jul 2024 22:00:00 GMT</pubDate>
  <media:content url="https://simmering.dev/blog/detailed-world/world.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Rich Personal Wiki in Quarto</title>
  <dc:creator>Paul Simmering</dc:creator>
  <link>https://simmering.dev/blog/quarto-wiki/</link>
  <description><![CDATA[ 






<p>Machine learning is a deep and constantly evolving field. In an applied project, the details of models are typically compressed into a few lines of a configuration file. Take this excerpt from a configuration file for an LLM training run using <a href="https://github.com/OpenAccess-AI-Collective/axolotl">Axolotl</a>:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode yaml code-with-copy"><code class="sourceCode yaml"><span id="cb1-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">adapter</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> lora</span></span>
<span id="cb1-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">lora_r</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">32</span></span>
<span id="cb1-3"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">lora_alpha</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">16</span></span>
<span id="cb1-4"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">lora_dropout</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.05</span></span>
<span id="cb1-5"></span>
<span id="cb1-6"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">gradient_accumulation_steps</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span></span>
<span id="cb1-7"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">micro_batch_size</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span></span>
<span id="cb1-8"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">num_epochs</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span></span>
<span id="cb1-9"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">optimizer</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> adamw_bnb_8bit</span></span>
<span id="cb1-10"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">lr_scheduler</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> cosine</span></span>
<span id="cb1-11"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">learning_rate</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0002</span></span></code></pre></div></div>
<p>There are so many concepts packed into just 10 lines: low-rank adapters, backpropagation, batching, quantization, optimizers. Each of these decomposes into sub-concepts and sub-sub-concepts. The further you go down, the closer you get to pure mathematics. In this case, matrix factorization, calculus, binary arithmetic and trigonometry.</p>
<p>I’ve understood each of these at some point in the last 10 years, but I’m not “exam-ready” on all of them at all times. A year ago I started writing a set of notes that form a personal wiki for machine learning topics. In this article I’ll share the software and workflow I use.</p>
<p>This project helped calm some of my anxiety about forgetting. I can’t remember everything, but I can remember where to find it. Re-learning from a note I’ve written myself is much faster than learning from other sources.</p>
<section id="beware-of-pseudowork" class="level2">
<h2 class="anchored" data-anchor-id="beware-of-pseudowork">Beware of pseudowork</h2>
<p>Before I get into the details, I feel obliged to warn about <em>pseudowork</em>. Setting up note taking systems, reading books about learning, reading advice from successful academics, all of these feel productive but don’t accomplish the main goal: understanding and retaining the material. Endless tweaking of the system can be a form of procrastination.</p>
<p>In other words, don’t go too midwit:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/quarto-wiki/notes_midwit.png" class="img-fluid figure-img" style="width:75.0%"></p>
<figcaption>Notes Midwit Meme</figcaption>
</figure>
</div>
<p>With that warning out of the way, I’ll try to convince you that using Quarto for studying <em>is</em> worthwhile, even though it’s a little more complex than Apple Notes.</p>
</section>
<section id="quarto-website-as-a-personal-wiki" class="level2">
<h2 class="anchored" data-anchor-id="quarto-website-as-a-personal-wiki">Quarto website as a personal wiki</h2>
<p>A personal wiki is a repository of documents that are linked to each other.</p>
<section id="section" class="level3">
<h3 class="anchored" data-anchor-id="section"></h3>
<p align="center">
<img src="https://simmering.dev/blog/quarto-wiki/quarto.png" class="img-fluid">
</p>
<p><a href="https://quarto.org">Quarto</a> is a scientific publishing system that is based on Markdown and supports code execution in Python, R and other languages. It can be used to create reports, books, slides and <a href="https://quarto.org/docs/websites/">websites</a> (including this one 😄). I use it to create a personal wiki for machine learning. It’s a collection of <code>.qmd</code> files that contain text, code snippets, formulas and interactive visualizations. The files are rendered to HTML and can be viewed in a browser. Notes (web pages) can be <a href="https://quarto.org/docs/websites/#linking">linked</a> to each other.</p>
</section>
<section id="file-structure" class="level3">
<h3 class="anchored" data-anchor-id="file-structure">File structure</h3>
<p>Each concept gets its own file. For example, to learn about quantization I’ve created three files in the <code>notes</code> folder:</p>
<ol type="1">
<li><code>notes/binary_numbers.qmd</code></li>
<li><code>notes/quantization.qmd</code></li>
<li><code>notes/qlora.qmd</code></li>
</ol>
<p>In <code>binary_numbers.qmd</code>, I’ve written about the binary number system starting with integers and then moving on to floating-point numbers. Hugging Face has an excellent guide on the <a href="https://huggingface.co/blog/hf-bitsandbytes-integration">topic</a> from which I’ve copied visualizations.</p>
<p>In <code>quantization.qmd</code> I’ve written about how reducing the number of bits used to represent weights reduces the memory footprint and computational cost of neural networks. It has a link to <code>binary_numbers.qmd</code> because binary numbers are used in quantization. The <code>qlora.qmd</code> connects it to LoRA adapters.</p>
<div class="grid">
<div class="g-col-6">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/quarto-wiki/files.png" class="img-fluid figure-img" style="width:60.0%"></p>
<figcaption>Note files</figcaption>
</figure>
</div>
</div>
<div class="g-col-6">
<p>When I come across a new concept or find myself unsure of an old one, I create a new file. Starting with a basic definition, I summarize the topic. The last time I had to manually calculate something using the chain rule was in 2017, so recently I refreshed the topic by writing a detailed <code>chain_rule.md</code> note.</p>
</div>
</div>
</section>
<section id="notes" class="level3">
<h3 class="anchored" data-anchor-id="notes">Notes</h3>
<p>Notes are a weave of Markdown, code snippets and images. If you’re familiar with Jupyter notebooks or R Markdown, you’ll feel right at home. Quarto’s <a href="https://quarto.org/docs/get-started/hello/jupyter.html">tutorial</a> is a great place to start.</p>
<p>Here’s an example of a note about derivatives:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/quarto-wiki/derivatives.png" class="img-fluid figure-img"></p>
<figcaption>Example file derivatives.qmd</figcaption>
</figure>
</div>
<p>I end every note with a sources section, e.g.&nbsp;</p>
<pre><code>## Sources

- [Stackoverflow AI in your pocket](https://stackoverflow.blog/2023/08/23/fitting-ai-models-in-your-pocket-with-quantization/)
- [Transformers Quantization Documentation](https://huggingface.co/docs/transformers/quantization)
- [Quantization](https://huggingface.co/blog/merve/quantization)
- [4bit transformers](https://huggingface.co/blog/4bit-transformers-bitsandbytes)
- [A Gentle Introduction to 8-bit Matrix Multiplication for transformers at scale using Hugging Face Transformers, Accelerate and bitsandbytes](https://huggingface.co/blog/hf-bitsandbytes-integration)
- [LLM-Model-VRAM-Calculator](https://huggingface.co/spaces/NyxKrage/LLM-Model-VRAM-Calculator)</code></pre>
<p>in <code>quantization.qmd</code>. These can be links to blog posts, books, papers, documentation, YouTube videos or anything else that helped me understand the topic, like the <a href="https://huggingface.co/spaces/NyxKrage/LLM-Model-VRAM-Calculator">VRAM-calculator</a> in the last link.</p>
</section>
<section id="website" class="level3">
<h3 class="anchored" data-anchor-id="website">Website</h3>
<p>To turn this collection of files into a website, two additional files are needed:</p>
<p>index.qmd:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode yaml code-with-copy"><code class="sourceCode yaml"><span id="cb3-1"><span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">---</span></span>
<span id="cb3-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">title</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Study Wiki"</span></span>
<span id="cb3-3"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">listing</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span></span>
<span id="cb3-4"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">  </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">contents</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> notes</span></span>
<span id="cb3-5"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">  </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sort</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"date desc"</span></span>
<span id="cb3-6"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">  </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">type</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> default</span></span>
<span id="cb3-7"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">  </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sort-ui</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">true</span></span>
<span id="cb3-8"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">  </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">filter-ui</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">true</span></span>
<span id="cb3-9"><span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">---</span></span></code></pre></div></div>
<p>and <code>_quarto.yml</code>:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode yaml code-with-copy"><code class="sourceCode yaml"><span id="cb4-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">project</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span></span>
<span id="cb4-2"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">  </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">type</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> website</span></span>
<span id="cb4-3"></span>
<span id="cb4-4"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">website</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span></span>
<span id="cb4-5"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">  </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">title</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Study wiki"</span></span>
<span id="cb4-6"></span>
<span id="cb4-7"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">format</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span></span>
<span id="cb4-8"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">  </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">html</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span></span>
<span id="cb4-9"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">    </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">theme</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> darkly</span></span>
<span id="cb4-10"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">    </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">toc</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">true</span></span></code></pre></div></div>
<p>The overall structure looks like this:</p>
<pre><code>_quarto.yml
index.qmd
notes/
  binary_numbers.qmd
  quantization.qmd
  qlora.qmd</code></pre>
<p>To render the website, run <code>quarto render</code> in the terminal. The website is then available in <code>_site/index.html</code> and can be opened in a browser. Typically, I render individual notes using the <code>render</code> button rather than the whole website.</p>
<p>And this is what the website looks like:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/quarto-wiki/wiki.png" class="img-fluid figure-img"></p>
<figcaption>Personal wiki website, please excuse the mix of German and English</figcaption>
</figure>
</div>
<p>It has sorting and search functionality.</p>
<p>And this is what a note looks like:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/quarto-wiki/batching.png" class="img-fluid figure-img"></p>
<figcaption>Rendered note about batching</figcaption>
</figure>
</div>
<p>It has a table of contents and references to sources. Quarto can be <a href="https://quarto.org/docs/output-formats/html-themes.html">themed</a>, here with the darkly theme.</p>
</section>
<section id="ide-and-extensions" class="level3">
<h3 class="anchored" data-anchor-id="ide-and-extensions">IDE and extensions</h3>
<p>I use Quarto with <a href="https://code.visualstudio.com">VSCode</a> and the <a href="https://marketplace.visualstudio.com/items?itemName=quarto.quarto">Quarto extension</a>. I find <a href="https://plotly.com/python/">Plotly</a> to be the best for these notes because it’s interactive (tooltips, zoom, filter) without a need for customization.</p>
</section>
</section>
<section id="copilots-are-great-at-formulas-and-visualizations" class="level2">
<h2 class="anchored" data-anchor-id="copilots-are-great-at-formulas-and-visualizations">Copilots are great at formulas and visualizations</h2>
<p><a href="https://github.com/features/copilot">Github Copilot</a> and other code completers like <a href="https://www.tabnine.com">TabNine</a> and <a href="https://supermaven.com">Supermaven</a> can generate LaTeX formulas and interactive Plotly visualizations.</p>
<p>Using a copilot, you can fly through creating notes and illustrate them beautifully.</p>
<p>For example, if you’re writing a note about linear regression, you might ask Copilot for the formula:</p>
<blockquote class="blockquote">
<p>Formula for linear regression:</p>
</blockquote>
<p>and Copilot will generate:</p>
<pre><code>$$ y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \ldots + \beta_n x_n $$</code></pre>
<p>which renders as:</p>
<p><img src="https://latex.codecogs.com/png.latex?%20y%20=%20%5Cbeta_0%20+%20%5Cbeta_1%20x_1%20+%20%5Cbeta_2%20x_2%20+%20%5Cldots%20+%20%5Cbeta_n%20x_n%20"></p>
<p>or ask for a visualization:</p>
<blockquote class="blockquote">
<p>Visualization of linear regression using a sample dataset:</p>
</blockquote>
<p>and Copilot might generate:</p>
<div id="1d90c91c" class="cell" data-execution_count="1">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> plotly.express <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> px</span>
<span id="cb7-2"></span>
<span id="cb7-3">df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> px.data.tips()</span>
<span id="cb7-4">fig <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> px.scatter(df, x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"total_bill"</span>, y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"tip"</span>, trendline<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ols"</span>, height<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">250</span>, width<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">600</span>)</span>
<span id="cb7-5">fig.data[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].line.color <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"red"</span></span>
<span id="cb7-6"></span>
<span id="cb7-7">fig.show()</span></code></pre></div></div>
<div class="cell-output cell-output-display">
<div>                            <div id="2743f3fa-a0e7-4b9a-9006-5ce693514382" class="plotly-graph-div" style="height:250px; width:600px;"></div>            <script type="text/javascript">                require(["plotly"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById("2743f3fa-a0e7-4b9a-9006-5ce693514382")) {                    Plotly.newPlot(                        "2743f3fa-a0e7-4b9a-9006-5ce693514382",                        [{"hovertemplate":"total_bill=%{x}\u003cbr\u003etip=%{y}\u003cextra\u003e\u003c\u002fextra\u003e","legendgroup":"","marker":{"color":"#636efa","symbol":"circle"},"mode":"markers","name":"","orientation":"v","showlegend":false,"x":[16.99,10.34,21.01,23.68,24.59,25.29,8.77,26.88,15.04,14.78,10.27,35.26,15.42,18.43,14.83,21.58,10.33,16.29,16.97,20.65,17.92,20.29,15.77,39.42,19.82,17.81,13.37,12.69,21.7,19.65,9.55,18.35,15.06,20.69,17.78,24.06,16.31,16.93,18.69,31.27,16.04,17.46,13.94,9.68,30.4,18.29,22.23,32.4,28.55,18.04,12.54,10.29,34.81,9.94,25.56,19.49,38.01,26.41,11.24,48.27,20.29,13.81,11.02,18.29,17.59,20.08,16.45,3.07,20.23,15.01,12.02,17.07,26.86,25.28,14.73,10.51,17.92,27.2,22.76,17.29,19.44,16.66,10.07,32.68,15.98,34.83,13.03,18.28,24.71,21.16,28.97,22.49,5.75,16.32,22.75,40.17,27.28,12.03,21.01,12.46,11.35,15.38,44.3,22.42,20.92,15.36,20.49,25.21,18.24,14.31,14.0,7.25,38.07,23.95,25.71,17.31,29.93,10.65,12.43,24.08,11.69,13.42,14.26,15.95,12.48,29.8,8.52,14.52,11.38,22.82,19.08,20.27,11.17,12.26,18.26,8.51,10.33,14.15,16.0,13.16,17.47,34.3,41.19,27.05,16.43,8.35,18.64,11.87,9.78,7.51,14.07,13.13,17.26,24.55,19.77,29.85,48.17,25.0,13.39,16.49,21.5,12.66,16.21,13.81,17.51,24.52,20.76,31.71,10.59,10.63,50.81,15.81,7.25,31.85,16.82,32.9,17.89,14.48,9.6,34.63,34.65,23.33,45.35,23.17,40.55,20.69,20.9,30.46,18.15,23.1,15.69,19.81,28.44,15.48,16.58,7.56,10.34,43.11,13.0,13.51,18.71,12.74,13.0,16.4,20.53,16.47,26.59,38.73,24.27,12.76,30.06,25.89,48.33,13.27,28.17,12.9,28.15,11.59,7.74,30.14,12.16,13.42,8.58,15.98,13.42,16.27,10.09,20.45,13.28,22.12,24.01,15.69,11.61,10.77,15.53,10.07,12.6,32.83,35.83,29.03,27.18,22.67,17.82,18.78],"xaxis":"x","y":[1.01,1.66,3.5,3.31,3.61,4.71,2.0,3.12,1.96,3.23,1.71,5.0,1.57,3.0,3.02,3.92,1.67,3.71,3.5,3.35,4.08,2.75,2.23,7.58,3.18,2.34,2.0,2.0,4.3,3.0,1.45,2.5,3.0,2.45,3.27,3.6,2.0,3.07,2.31,5.0,2.24,2.54,3.06,1.32,5.6,3.0,5.0,6.0,2.05,3.0,2.5,2.6,5.2,1.56,4.34,3.51,3.0,1.5,1.76,6.73,3.21,2.0,1.98,3.76,2.64,3.15,2.47,1.0,2.01,2.09,1.97,3.0,3.14,5.0,2.2,1.25,3.08,4.0,3.0,2.71,3.0,3.4,1.83,5.0,2.03,5.17,2.0,4.0,5.85,3.0,3.0,3.5,1.0,4.3,3.25,4.73,4.0,1.5,3.0,1.5,2.5,3.0,2.5,3.48,4.08,1.64,4.06,4.29,3.76,4.0,3.0,1.0,4.0,2.55,4.0,3.5,5.07,1.5,1.8,2.92,2.31,1.68,2.5,2.0,2.52,4.2,1.48,2.0,2.0,2.18,1.5,2.83,1.5,2.0,3.25,1.25,2.0,2.0,2.0,2.75,3.5,6.7,5.0,5.0,2.3,1.5,1.36,1.63,1.73,2.0,2.5,2.0,2.74,2.0,2.0,5.14,5.0,3.75,2.61,2.0,3.5,2.5,2.0,2.0,3.0,3.48,2.24,4.5,1.61,2.0,10.0,3.16,5.15,3.18,4.0,3.11,2.0,2.0,4.0,3.55,3.68,5.65,3.5,6.5,3.0,5.0,3.5,2.0,3.5,4.0,1.5,4.19,2.56,2.02,4.0,1.44,2.0,5.0,2.0,2.0,4.0,2.01,2.0,2.5,4.0,3.23,3.41,3.0,2.03,2.23,2.0,5.16,9.0,2.5,6.5,1.1,3.0,1.5,1.44,3.09,2.2,3.48,1.92,3.0,1.58,2.5,2.0,3.0,2.72,2.88,2.0,3.0,3.39,1.47,3.0,1.25,1.0,1.17,4.67,5.92,2.0,2.0,1.75,3.0],"yaxis":"y","type":"scatter"},{"hovertemplate":"\u003cb\u003eOLS trendline\u003c\u002fb\u003e\u003cbr\u003etip = 0.105025 * total_bill + 0.92027\u003cbr\u003eR\u003csup\u003e2\u003c\u002fsup\u003e=0.456617\u003cbr\u003e\u003cbr\u003etotal_bill=%{x}\u003cbr\u003etip=%{y} \u003cb\u003e(trend)\u003c\u002fb\u003e\u003cextra\u003e\u003c\u002fextra\u003e","legendgroup":"","marker":{"color":"#636efa","symbol":"circle"},"mode":"lines","name":"","showlegend":false,"x":[3.07,5.75,7.25,7.25,7.51,7.56,7.74,8.35,8.51,8.52,8.58,8.77,9.55,9.6,9.68,9.78,9.94,10.07,10.07,10.09,10.27,10.29,10.33,10.33,10.34,10.34,10.51,10.59,10.63,10.65,10.77,11.02,11.17,11.24,11.35,11.38,11.59,11.61,11.69,11.87,12.02,12.03,12.16,12.26,12.43,12.46,12.48,12.54,12.6,12.66,12.69,12.74,12.76,12.9,13.0,13.0,13.03,13.13,13.16,13.27,13.28,13.37,13.39,13.42,13.42,13.42,13.51,13.81,13.81,13.94,14.0,14.07,14.15,14.26,14.31,14.48,14.52,14.73,14.78,14.83,15.01,15.04,15.06,15.36,15.38,15.42,15.48,15.53,15.69,15.69,15.77,15.81,15.95,15.98,15.98,16.0,16.04,16.21,16.27,16.29,16.31,16.32,16.4,16.43,16.45,16.47,16.49,16.58,16.66,16.82,16.93,16.97,16.99,17.07,17.26,17.29,17.31,17.46,17.47,17.51,17.59,17.78,17.81,17.82,17.89,17.92,17.92,18.04,18.15,18.24,18.26,18.28,18.29,18.29,18.35,18.43,18.64,18.69,18.71,18.78,19.08,19.44,19.49,19.65,19.77,19.81,19.82,20.08,20.23,20.27,20.29,20.29,20.45,20.49,20.53,20.65,20.69,20.69,20.76,20.9,20.92,21.01,21.01,21.16,21.5,21.58,21.7,22.12,22.23,22.42,22.49,22.67,22.75,22.76,22.82,23.1,23.17,23.33,23.68,23.95,24.01,24.06,24.08,24.27,24.52,24.55,24.59,24.71,25.0,25.21,25.28,25.29,25.56,25.71,25.89,26.41,26.59,26.86,26.88,27.05,27.18,27.2,27.28,28.15,28.17,28.44,28.55,28.97,29.03,29.8,29.85,29.93,30.06,30.14,30.4,30.46,31.27,31.71,31.85,32.4,32.68,32.83,32.9,34.3,34.63,34.65,34.81,34.83,35.26,35.83,38.01,38.07,38.73,39.42,40.17,40.55,41.19,43.11,44.3,45.35,48.17,48.27,48.33,50.81],"xaxis":"x","y":[1.2426948819246395,1.5241605885147065,1.6816973645912365,1.6816973645912365,1.7090037391111685,1.7142549649803862,1.7331593781095698,1.7972243337140252,1.814028256495522,1.8150785016693654,1.8213799727124267,1.8413346310154537,1.9232537545752495,1.9285049804444672,1.9369069418352154,1.9474093935736507,1.9642133163551472,1.9778665036151133,1.9778665036151133,1.9799669939628002,1.9988714070919837,2.000971897439671,2.005172878135045,2.005172878135045,2.0062231233088887,2.0062231233088887,2.024077291264229,2.032479252654977,2.036680233350351,2.038780723698038,2.0513836657841606,2.0776397951302488,2.093393472737902,2.1007451889548068,2.1122978858670853,2.1154486213886163,2.1375037700393302,2.1396042603870176,2.1480062217777656,2.1669106349069494,2.182664312514602,2.183714557688446,2.1973677449484117,2.207870196686847,2.225724364642187,2.2288751001637177,2.230975590511405,2.237277061554466,2.2435785325975273,2.2498800036405884,2.253030739162119,2.258281965031337,2.2603824553790237,2.2750858878128333,2.2855883395512686,2.2855883395512686,2.288739075072799,2.2992415268112345,2.302392262332765,2.313944959245044,2.3149952044188877,2.3244474109834794,2.3265479013311667,2.329698636852697,2.329698636852697,2.329698636852697,2.339150843417289,2.370658198632595,2.370658198632595,2.384311385892561,2.390612856935622,2.3979645731525268,2.406366534543275,2.4179192314555538,2.4231704573247717,2.4410246252801118,2.4452256059754855,2.4672807546262,2.472531980495418,2.4777832063646352,2.496687619493819,2.4998383550153496,2.501938845363037,2.5334462005783425,2.53554669092603,2.539747671621404,2.546049142664465,2.5513003685336826,2.568104291315179,2.568104291315179,2.5765062527059275,2.5807072334013017,2.5954106658351113,2.598561401356642,2.598561401356642,2.6006618917043287,2.604862872399703,2.622717040355043,2.629018511398104,2.631119001745791,2.6332194920934784,2.634269737267322,2.64267169865807,2.6458224341796006,2.647922924527288,2.650023414874975,2.6521239052226617,2.6615761117872534,2.6699780731780023,2.6867819959594987,2.6983346928717773,2.7025356735671515,2.7046361639148384,2.713038125305587,2.7329927836086143,2.7361435191301444,2.7382440094778318,2.753997687085485,2.755047932259328,2.7592489129547024,2.767650874345451,2.787605532648478,2.7907562681700084,2.791806513343852,2.799158229560757,2.8023089650822874,2.8023089650822874,2.8149119071684097,2.8264646040806887,2.8359168106452803,2.8380173009929677,2.8401177913406546,2.841168036514498,2.841168036514498,2.8474695075575593,2.8558714689483073,2.8779266175990217,2.8831778434682396,2.8852783338159265,2.8926300500328312,2.9241374052481373,2.961946231506505,2.967197457375722,2.9840013801572187,2.996604322243341,3.000805302938715,3.001855548112559,3.0291619226324906,3.044915600240144,3.0491165809355176,3.051217071283205,3.051217071283205,3.0680209940647014,3.072221974760075,3.07642295545545,3.089025897541572,3.0932268782369463,3.0932268782369463,3.100578594453851,3.11528202688766,3.1173825172353475,3.1268347237999397,3.1268347237999397,3.1425884014075924,3.1782967373182727,3.1866986987090207,3.199301640795143,3.2434119380965716,3.2549646350088506,3.2749192933118776,3.2822710095287824,3.301175422657966,3.309577384048714,3.310627629222558,3.316929100265619,3.346335965133238,3.353687681350143,3.370491604131639,3.4072501852161627,3.435606804909938,3.4419082759529998,3.447159501822217,3.449259992169904,3.4692146504729315,3.4954707798190197,3.49862151534055,3.5028224960359244,3.515425438122047,3.5458825481635095,3.567937696814224,3.5752894130311286,3.576339658204972,3.6046962778987472,3.6204499555064005,3.639354368635584,3.693967117675448,3.712871530804631,3.7412281504984066,3.7433286408460935,3.761182808801434,3.7748359960613995,3.776936486409087,3.7853384477998353,3.8767097779242223,3.8788102682719097,3.907166887965685,3.918719584877964,3.9628298821793924,3.9691313532224535,4.050000231608406,4.055251457477623,4.0636534188683715,4.077306606128338,4.085708567519086,4.113014942039017,4.119316413082079,4.204386272163405,4.250597059812521,4.265300492246331,4.323063976807724,4.352470841675343,4.368224519282996,4.375576235499901,4.522610559837996,4.557268650574833,4.559369140922519,4.576173063704016,4.578273554051703,4.623434096526975,4.683298071436057,4.912251519333947,4.918552990377008,4.987869171850681,5.060336088845886,5.1391044768841505,5.1790137934902045,5.24622948461619,5.4478765579941495,5.572855733681529,5.683131476935101,5.979300615958977,5.989803067697413,5.9961045387404734,6.256565341853671],"yaxis":"y","type":"scatter","line":{"color":"red"}}],                        {"template":{"data":{"histogram2dcontour":[{"type":"histogram2dcontour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"choropleth":[{"type":"choropleth","colorbar":{"outlinewidth":0,"ticks":""}}],"histogram2d":[{"type":"histogram2d","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmap":[{"type":"heatmap","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmapgl":[{"type":"heatmapgl","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"contourcarpet":[{"type":"contourcarpet","colorbar":{"outlinewidth":0,"ticks":""}}],"contour":[{"type":"contour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"surface":[{"type":"surface","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"mesh3d":[{"type":"mesh3d","colorbar":{"outlinewidth":0,"ticks":""}}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"parcoords":[{"type":"parcoords","line":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolargl":[{"type":"scatterpolargl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"scattergeo":[{"type":"scattergeo","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolar":[{"type":"scatterpolar","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"scattergl":[{"type":"scattergl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatter3d":[{"type":"scatter3d","line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermapbox":[{"type":"scattermapbox","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterternary":[{"type":"scatterternary","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattercarpet":[{"type":"scattercarpet","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"pie":[{"automargin":true,"type":"pie"}]},"layout":{"autotypenumbers":"strict","colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"hovermode":"closest","hoverlabel":{"align":"left"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"bgcolor":"#E5ECF6","angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"ternary":{"bgcolor":"#E5ECF6","aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]]},"xaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"yaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"geo":{"bgcolor":"white","landcolor":"#E5ECF6","subunitcolor":"white","showland":true,"showlakes":true,"lakecolor":"white"},"title":{"x":0.05},"mapbox":{"style":"light"},"margin":{"b":0,"l":0,"r":0,"t":30}}},"xaxis":{"anchor":"y","domain":[0.0,1.0],"title":{"text":"total_bill"}},"yaxis":{"anchor":"x","domain":[0.0,1.0],"title":{"text":"tip"}},"legend":{"tracegroupgap":0},"height":250,"width":600},                        {"responsive": true}                    ).then(function(){
                            
var gd = document.getElementById('2743f3fa-a0e7-4b9a-9006-5ce693514382');
var x = new MutationObserver(function (mutations, observer) {{
        var display = window.getComputedStyle(gd).display;
        if (!display || display === 'none') {{
            console.log([gd, 'removed!']);
            Plotly.purge(gd);
            observer.disconnect();
        }}
}});

// Listen for the removal of the full notebook cells
var notebookContainer = gd.closest('#notebook-container');
if (notebookContainer) {{
    x.observe(notebookContainer, {childList: true});
}}

// Listen for the clearing of the current output cell
var outputEl = gd.closest('.output');
if (outputEl) {{
    x.observe(outputEl, {childList: true});
}}

                        })                };                });            </script>        </div>
</div>
</div>
<p>Using a separate chat like ChatGPT also works, but requires more copy-pasting, which breaks the flow.</p>
</section>
<section id="discussion" class="level2">
<h2 class="anchored" data-anchor-id="discussion">Discussion</h2>
<div class="grid">
<section id="pros" class="level3 g-col-6">
<h3 class="anchored" data-anchor-id="pros">Pros</h3>
<ul>
<li>Enhance understanding with code snippets, formulas and interactive visualizations</li>
<li>Collect the best learning resources in one place</li>
<li>Free, open-source software running locally without needing an internet connection</li>
<li>Text files are future-proof and can be read by any text editor</li>
<li>Possible to version control with Git</li>
<li>Easy to back up</li>
<li>Gets better over time as more notes are added and interlinked</li>
<li>Visualizes learning progress in a satisfying way</li>
</ul>
</section>
<section id="cons" class="level3 g-col-6">
<h3 class="anchored" data-anchor-id="cons">Cons</h3>
<ul>
<li>It doesn’t work well on mobile. You could find a way to read the notes, but editing is not practical</li>
<li>Over-engineering notes with interactivity can turn into pseudowork</li>
<li>Creating many shallow notes using an LLM can also be pseudowork</li>
<li>Learning curve if you’re not familiar with Markdown and a programming language supported by Quarto</li>
</ul>
</section>
</div>
<p>If you’re in machine learning, data engineering, or a similar technical field I highly recommend <a href="https://quarto.org">Quarto</a> for creating a personal wiki. If you don’t need code, formulas or interactive visualizations, <a href="https://obsidian.md">Obsidian</a> is an easier alternative that is based on Markdown and local-first. Finally, Apple Notes and Microsoft OneNote are OK too, if you don’t mind being locked into their ecosystems.</p>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further reading</h2>
<ul>
<li><a href="https://x.com/karpathy/status/1756380066580455557">The shortification of learning</a> by Andrej Karpathy</li>
<li><a href="https://www.scotthyoung.com/blog/2019/02/15/memory/">The Complete Guide to Memory</a> by Scott Young and Jakub Jílek</li>
</ul>


</section>

 ]]></description>
  <category>Productivity</category>
  <category>Machine Learning</category>
  <guid>https://simmering.dev/blog/quarto-wiki/</guid>
  <pubDate>Sat, 06 Jul 2024 22:00:00 GMT</pubDate>
  <media:content url="https://simmering.dev/blog/quarto-wiki/library.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Fast and good</title>
  <dc:creator>Paul Simmering</dc:creator>
  <link>https://simmering.dev/blog/fast-and-good/</link>
  <description><![CDATA[ 






<p>The adage goes: fast, good, cheap. Pick two. As a developer, you probably don’t want to be cheap labor, so I suggest that you strive for fast and good. Not just good, and not just fast—both.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://simmering.dev/blog/fast-and-good/good_fast_cheap.png" class="img-fluid figure-img" style="width:65.0%"></p>
<figcaption>Good, fast, cheap</figcaption>
</figure>
</div>
<p>A developer writing bad code quickly creates troublesome “spaghetti code” that may function for a demo but becomes a nightmare to maintain as the project scales. LLMs have made this even easier.</p>
<p>Conversely, a developer who writes good code at a glacial pace may see the project run out of money, be overtaken by competitors or get stuck in a cycle of endless refactoring.</p>
<p>Both outcomes are to be avoided.</p>
<p>But can’t you just write the first version quickly, get feedback, and then rewrite it properly?</p>
<p>You may not get the luxury of a full rewrite. Rewrites are <a href="https://swizec.com/blog/you-can-t-stop-the-business-or-why-rewrites-fail/">risky</a> and often <a href="https://www.joelonsoftware.com/2000/04/06/things-you-should-never-do-part-i/">ill-advised</a>. It’s hard to find the time for a rewrite on a project that is accelerating. It’s not impossible to do a successful rewrite, but rare. Projects like <a href="https://tailwindcss.com/blog/tailwindcss-v4-alpha">Tailwind CSS</a> and <a href="https://docs.pydantic.dev/2.0/blog/pydantic-v2-alpha/">Pydantic</a> have done successful rewrites in Rust. This happened after they achieved amazing adoption and had plenty of resources. For most projects, a rewrite is not a viable option. That means you need to get it right the first time.</p>
<p>The dual optimum of fast and good is achievable with a balanced approach.</p>
<p>Before diving into strategies, I’d like to clarify that fast doesn’t just mean typing quickly. <a href="https://en.wiktionary.org/wiki/slow_is_smooth,_smooth_is_fast">“Slow is smooth, smooth is fast”</a>. The fastest way to write a feature can involve spending 2 hours sketching out the design first.</p>
<p>Now, here are some strategies that helped me, and might help you, get closer to the dual optimum:</p>
<section id="strategies-for-the-dual-optimum" class="level2">
<h2 class="anchored" data-anchor-id="strategies-for-the-dual-optimum">Strategies for the dual optimum</h2>
<section id="prioritize-and-plan" class="level3">
<h3 class="anchored" data-anchor-id="prioritize-and-plan">Prioritize and plan</h3>
<ul>
<li><strong>Don’t build unnecessary features</strong>: much easier said than done, but this belongs at the top of every list of productivity tips.</li>
<li><strong>Involve users early</strong>: work in sprints, get feedback and iterate.</li>
<li><strong>Sketch it first</strong>: write the names of functions and classes before writing the code, then fill in the details.</li>
<li><strong>Don’t over-engineer for scale you don’t have</strong>: Most companies have gigabytes to terrabytes of data, <a href="https://motherduck.com/blog/big-data-is-dead/">not petabytes</a>, and an outage once in a few months is acceptable. Don’t build for the scale of Google if you’re not Google.</li>
<li><strong>Don’t reinvent the wheel</strong>: For everything but your core differentiating features, use libraries and services. It can be worth adjusting your design to fit existing software.</li>
</ul>
</section>
<section id="minimize-waiting" class="level3">
<h3 class="anchored" data-anchor-id="minimize-waiting">Minimize waiting</h3>
<ul>
<li><strong>Minimize waiting for code</strong>: use a fast computer, fast internet connection, and run your code and tests locally if possible</li>
<li><strong>Minimize waiting for people</strong>: establish time limits for code reviews, schedule tasks in a way that minimizes dependencies on others.</li>
</ul>
</section>
<section id="create-an-environment-that-supports-flow" class="level3">
<h3 class="anchored" data-anchor-id="create-an-environment-that-supports-flow">Create an environment that supports flow</h3>
<ul>
<li><strong>Minimize interruptions</strong>: both external and <a href="https://ics.uci.edu/~gmark/Home_page/Publications_files/CHI%202011%20Self-interruption.pdf">self-interruptions</a>.</li>
<li><strong>Embrace bursts of productivity</strong>: use your best hours for coding, take breaks when you’re not productive, get on a <a href="https://www.paulgraham.com/makersschedule.html">maker’s schedule</a>, if possible.</li>
<li><strong>Learn to type fast</strong>: Not because typing speed itself is important, but because it reduces the friction between your thoughts and the code editor and the mental cost of rewriting a section of code.</li>
<li><strong>Learn your tools</strong>: keyboard shortcuts, IDE extensions, terminal commands.</li>
<li><strong>Use a <a href="https://github.com/features/copilot">Copilot</a></strong>: not because it writes better code than you, but because it lets you get it onto the page faster. This is especially useful for boilerplate code and for writing tests and documentation.</li>
</ul>
</section>
<section id="keep-a-clean-codebase" class="level3">
<h3 class="anchored" data-anchor-id="keep-a-clean-codebase">Keep a clean codebase</h3>
<ul>
<li><strong>Be willing to throw away code</strong>: if you realize you’ve gone down the wrong path during a coding session, don’t be afraid to delete parts of the code and start over.</li>
<li><strong>Hop from good state to good state</strong>: When working on a big feature, break it down into smaller tasks that leave the code in a runnable state at the end of each task. This also makes for clean commits and easier code reviews.</li>
<li><strong>Putter, within reason</strong>: Reading and re-reading code, refactoring and tweaking it is necessary to make it good. But don’t overdo it.</li>
</ul>
</section>
<section id="test-and-automate" class="level3">
<h3 class="anchored" data-anchor-id="test-and-automate">Test and automate</h3>
<ul>
<li><strong>Reduce worry about breaking things</strong>: use version control, write tests, use a test environment rather than working on production data.</li>
<li><strong>Automate everything</strong>: use a linter, formatter, test runner, CI/CD, deployment scripts and infrastructure as code.</li>
<li><strong>Write tests as you go</strong>: tests will give you the confidence to refactor and add features quickly. It’s easiest to write tests when you’re writing the code.</li>
</ul>
<p>May you code swiftly and wisely.</p>
<p>The term dual optimum and finding strategies to achieve it came from the book <a href="https://www.goodreads.com/book/show/17730608-winning-without-losing">Winning without Losing</a> by Martin Bjergegaard and Jordan Milne.</p>


</section>
</section>

 ]]></description>
  <category>Productivity</category>
  <category>Career</category>
  <guid>https://simmering.dev/blog/fast-and-good/</guid>
  <pubDate>Fri, 21 Jun 2024 22:00:00 GMT</pubDate>
  <media:content url="https://simmering.dev/blog/fast-and-good/good_fast_cheap.png" medium="image" type="image/png" height="132" width="144"/>
</item>
</channel>
</rss>
