---
title: "Open SOTA model for aspect-based sentiment analysis"
author: "Paul Simmering"
date: "2024-06-24"
bibliography: bibliography.bib
categories: ["Machine Learning", "Python"]
image: llama.png
---

In October 2023, my colleague and me published a paper [@simmering2023large] on aspect-based sentiment analysis using a fine-tuned GPT-3.5 model. This model achieved state of the art performance on the SemEval 2014 task 4 1+2 benchmark. A downside of this approach is that it relies on OpenAI's proprietary GPT-3.5 model. We couldn't share the model, only the training and evaluation code.

I'm happy to report that a LoRA fine-tune of Llama-3 8B achieves similar performance and can even run locally using llama.cpp.

This article will cover the technical details of training and evaluating the model. You can find the code on [GitHub]() and the model on [HuggingFace]().

## SemEval 2014 task 4 dataset

As in the original paper, I'll use the SemEval 2014 task 4 dataset [@pontiki_semeval-2014_2014]. This dataset contains reviews of laptops and restaurants. Each review is annotated with the aspect and sentiment expressed towards that aspect.

Here's an example: "The food was great, but the service was terrible." The aspect terms are "food" and "service". The sentiment towards "food" is positive, and the sentiment towards "service" is negative.

The approach to ABSA taken in this dataset has some limitations:

- aspects have to be noun phrases
- aspects can't be indirect
- the output only tells you what aspect and polarity is, not the reasoning behind it

As before, I'll only target the task 4 subtask 1+2 mode. This means the model jointly predicts the aspect and sentiment polarity. As in previous work, I'll exclude examples with the "conflict" sentiment label.

## Model

I'm looking for a model with the following properties:

- Relatively small, to keep training cost and time low, as well as enable local deployment
- Open source model
- Available from Hugging Face's model hub
- Compatible with [axolotl](https://github.com/OpenAccess-AI-Collective/axolotl)
- Not a mixture-of-experts model, as the task I'll train for is very specific and unlikely to benefit from an ensemble

Meta's [Llama-3 8B](https://huggingface.co/meta-llama/Meta-Llama-3-8B) is the best model I found that meets these criteria. I have also tried Mistral-7B and Llama-3 70B.

I'll use the base pretrained model rather than the instruction tuned model. The reason is that the instructions it was tuned on are different from the ABSA task, and that it introduces the need to include tokens indicating turns in a chat format.

## Training

I use [axolotl](https://github.com/OpenAccess-AI-Collective/axolotl) to train the model. Training runs on GPUs by [Modal](https://modal.com).

`llama-3.yml` specifies the training configuration according to axolotl's [configuration format](https://openaccess-ai-collective.github.io/axolotl/docs/config.html).

Examples were prepared in the Alpaca format.

LoRA settings: r = 16, alpha = 32, dropout = 0.05.

## Evaluation

Each occurence of an aspect in an example of the gold set is counted as a prediction. The model's prediction is considered correct if it predicts the same aspect and sentiment polarity as the gold set. The evaluation metric is the F1 score. Correctly predicting that an example doesn't contain any aspects is also considered a correct prediction.

$$ F1 = \frac{2 \cdot \text{precision} \cdot \text{recall}}{\text{precision} + \text{recall}} $$

Precision is the number of correct predictions divided by the number of predictions made by the model. Recall is the number of correct predictions divided by the number of aspects in the gold set.

$$ \text{precision} = \frac{\text{correct predictions}}{\text{predictions}} $$

$$ \text{recall} = \frac{\text{correct predictions}}{\text{aspects in gold set}} $$

If the model outputs a text that doesn't match the expected format, we disregard the example. We count a separate percentage of malformed examples.

## Discussion

## Thanks

Thanks to Hamel Husain and Dan Becker for their course on LLM fine-tuning. Thanks to Modal for providing compute credits. Thanks to Wing Lian for developing axolotl.

## References
